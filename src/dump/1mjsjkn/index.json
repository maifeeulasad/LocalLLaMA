[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Pretty much what the title says. But to expand they are worse at coding than qwen 32B, more hallucinations than fireman festival, and they seem to be trained only to pass benchmarks. \nIf any other company released this,  it would be a shoulder shrug, yeah thats good I guess, and move on\n\nEdit: I'm not asking if it's good. I'm asking if without the OpenAI name behind it would ot get this much hype",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "If the gpt-oss models were made by any other company than OpenAI would anyone care about them?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjsjkn",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.88,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 137,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1rkptb2m",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 137,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1754548620,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754547734,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pretty much what the title says. But to expand they are worse at coding than qwen 32B, more hallucinations than fireman festival, and they seem to be trained only to pass benchmarks. \nIf any other company released this,  it would be a shoulder shrug, yeah thats good I guess, and move on&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m not asking if it&amp;#39;s good. I&amp;#39;m asking if without the OpenAI name behind it would ot get this much hype&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mjsjkn",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "chunkypenguion1991",
            "discussion_type": null,
            "num_comments": 80,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/",
            "subreddit_subscribers": 512874,
            "created_utc": 1754547734,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dfuhq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "rookan",
            "can_mod_post": false,
            "created_utc": 1754548300,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 77,
            "author_fullname": "t2_1pnyrt9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "No",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dfuhq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dfuhq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754548300,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 77
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7doogp",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "dankhorse25",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dmtte",
                                "score": 10,
                                "author_fullname": "t2_5g07smxd",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "OpenAI has such a massive first mover advantage.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7doogp",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OpenAI has such a massive first mover advantage.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7doogp/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754553265,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754553265,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 10
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n7e0wq3",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Straight_Abrocoma321",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n7dz0ga",
                                                              "score": 2,
                                                              "author_fullname": "t2_a4794dp2j",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Yep, forgot about gemini  \nAnd also not having seen anyone who uses it for work is different, that is probably only because Deepseek is chinese. But yeah, given only 79 percent of adults know about chatgpt (i expected it to be around 90 percent), Probably only around 20-30 percent know about deepseek.",
                                                              "edited": 1754560915,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n7e0wq3",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yep, forgot about gemini&lt;br/&gt;\nAnd also not having seen anyone who uses it for work is different, that is probably only because Deepseek is chinese. But yeah, given only 79 percent of adults know about chatgpt (i expected it to be around 90 percent), Probably only around 20-30 percent know about deepseek.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mjsjkn",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e0wq3/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754560298,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754560298,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7dz0ga",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "Anduin1357",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n7dvjly",
                                                    "score": 1,
                                                    "author_fullname": "t2_lpy03",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Imo Gemini is just as well-known as ChatGPT. DeepSeek disappeared as quickly as the headlines, and it seems like nobody has even heard of Huggingface, less custom local AI as a concept. Local AI to them is straight up just the ChatGPT Copilot key, simply because of Copilot+ PC even when it's not local AI at all.\n\nI haven't seen one person around who uses DeepSeek for work.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7dz0ga",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Imo Gemini is just as well-known as ChatGPT. DeepSeek disappeared as quickly as the headlines, and it seems like nobody has even heard of Huggingface, less custom local AI as a concept. Local AI to them is straight up just the ChatGPT Copilot key, simply because of Copilot+ PC even when it&amp;#39;s not local AI at all.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t seen one person around who uses DeepSeek for work.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mjsjkn",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dz0ga/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754559249,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754559249,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7e0uky",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "Straight_Abrocoma321",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n7dvjly",
                                                    "score": 1,
                                                    "author_fullname": "t2_a4794dp2j",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Just found some stats, according to pew research (https://www.pewresearch.org/short-reads/2025/06/25/34-of-us-adults-have-used-chatgpt-about-double-the-share-in-2023/) 79% of Americans are atleast a little aware of ChatGPT. Couldn't find one for any other companies though.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7e0uky",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just found some stats, according to pew research (&lt;a href=\"https://www.pewresearch.org/short-reads/2025/06/25/34-of-us-adults-have-used-chatgpt-about-double-the-share-in-2023/\"&gt;https://www.pewresearch.org/short-reads/2025/06/25/34-of-us-adults-have-used-chatgpt-about-double-the-share-in-2023/&lt;/a&gt;) 79% of Americans are atleast a little aware of ChatGPT. Couldn&amp;#39;t find one for any other companies though.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mjsjkn",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e0uky/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754560267,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754560267,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7dvjly",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "jebuizy",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7dpz3e",
                                          "score": 8,
                                          "author_fullname": "t2_efdi1",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I'm not even sure if \"most adults\" know about chatgpt. There are a lot of people with still no clue. Definitely not going to be widespread deepseek knowledge",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7dvjly",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not even sure if &amp;quot;most adults&amp;quot; know about chatgpt. There are a lot of people with still no clue. Definitely not going to be widespread deepseek knowledge&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjsjkn",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dvjly/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754557238,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754557238,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 8
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7efitz",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "vibjelo",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7dpz3e",
                                          "score": 2,
                                          "author_fullname": "t2_hr2hgnsk",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "&gt; I'm pretty sure that most adults know atleast about deepseek\n\nI'm pretty sure you live in a bubble of some sorts if you think most people know any names beyond \"ChatGPT\" at this point. If we change the context to \"most adults whole use LLMs daily for work\", then it might be true, but for the rest of the population, they most likely never heard the name DeepSeek in any context.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7efitz",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I&amp;#39;m pretty sure that most adults know atleast about deepseek&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m pretty sure you live in a bubble of some sorts if you think most people know any names beyond &amp;quot;ChatGPT&amp;quot; at this point. If we change the context to &amp;quot;most adults whole use LLMs daily for work&amp;quot;, then it might be true, but for the rest of the population, they most likely never heard the name DeepSeek in any context.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjsjkn",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7efitz/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754567168,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754567168,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7efk2j",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "LofiStarforge",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7dpz3e",
                                          "score": 2,
                                          "author_fullname": "t2_1uyyq1y8ka",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "You are way to inside baseball if you think most adults know about Deepseek lol",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7efk2j",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You are way to inside baseball if you think most adults know about Deepseek lol&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjsjkn",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7efk2j/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754567182,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754567182,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7dpz3e",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Straight_Abrocoma321",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dmtte",
                                "score": 0,
                                "author_fullname": "t2_a4794dp2j",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Well.. I'm pretty sure that most adults know atleast about deepseek but apart from that and maybe anthropic, yeah probably only 5 percent know about any others",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7dpz3e",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well.. I&amp;#39;m pretty sure that most adults know atleast about deepseek but apart from that and maybe anthropic, yeah probably only 5 percent know about any others&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dpz3e/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754554002,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754554002,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 1,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dmtte",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Axelni98",
                      "can_mod_post": false,
                      "created_utc": 1754552193,
                      "send_replies": true,
                      "parent_id": "t1_n7dhmki",
                      "score": 25,
                      "author_fullname": "t2_y4j8da1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "50% is overly generous more like 95 or 98%. We are a niche group. The average Joe has no clue.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dmtte",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;50% is overly generous more like 95 or 98%. We are a niche group. The average Joe has no clue.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dmtte/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754552193,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 25
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7egco3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BoJackHorseMan53",
                      "can_mod_post": false,
                      "created_utc": 1754567508,
                      "send_replies": true,
                      "parent_id": "t1_n7dhmki",
                      "score": 2,
                      "author_fullname": "t2_58t8ty6v",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I think people should know about Gemini because Google Assistant got replaced by Gemini on Android and 90% of the world population uses Android.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7egco3",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think people should know about Gemini because Google Assistant got replaced by Gemini on Android and 90% of the world population uses Android.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7egco3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754567508,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dj30v",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "chunkypenguion1991",
                      "can_mod_post": false,
                      "created_utc": 1754550069,
                      "send_replies": true,
                      "parent_id": "t1_n7dhmki",
                      "score": 1,
                      "author_fullname": "t2_1rkptb2m",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "If you have a close tie to the companies making the benchmarks I'm sure it hard to pass them",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dj30v",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you have a close tie to the companies making the benchmarks I&amp;#39;m sure it hard to pass them&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dj30v/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754550069,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7ejds5",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Amazing_Athlete_2265",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dvugz",
                                "score": 2,
                                "author_fullname": "t2_1nw9fzb7dt",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "z.ai aren't an unknown lab, they are the corporate arm of THUDM",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7ejds5",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;z.ai aren&amp;#39;t an unknown lab, they are the corporate arm of THUDM&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7ejds5/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754568691,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754568691,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dvugz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "lizerome",
                      "can_mod_post": false,
                      "created_utc": 1754557413,
                      "send_replies": true,
                      "parent_id": "t1_n7dhmki",
                      "score": 1,
                      "author_fullname": "t2_14wyb7",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It is a good question in the sense that it's evidence that the models aren't groundbreaking. If an unknown lab like z.ai released a model which beat o3, or a laptop-sized model which was competitive with Claude at coding, the entire world would be talking about it, as it happened with R1.\n\nThese models are more akin to a \"Mistral announces Model 3.3, it's 8% better than their previous Model 3.2\" type release. The proper reaction to that is an \"oh, cool I suppose\".\n\nOpenAI \"spreading the good word\" about local models and getting more people into \"the scene\" would be a good point, but they also chose the worst possible timing for that. News of \"OpenAI releases a model you can run on your laptop\" are *already* buried underneath a flood of \"Google invents the Matrix\", \"OpenAI gives ChatGPT to the government for $1\", \"ElevenLabs has a new music model\" and \"OpenAI to be valued at $500bn\". Mind you, that's NOW, if I specifically search for OpenAI on Google News. In less than 10 hours, *GPT fucking 5* is getting announced. Good luck finding anyone on the internet discussing gpt-oss in a day, let alone a month from now.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dvugz",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is a good question in the sense that it&amp;#39;s evidence that the models aren&amp;#39;t groundbreaking. If an unknown lab like z.ai released a model which beat o3, or a laptop-sized model which was competitive with Claude at coding, the entire world would be talking about it, as it happened with R1.&lt;/p&gt;\n\n&lt;p&gt;These models are more akin to a &amp;quot;Mistral announces Model 3.3, it&amp;#39;s 8% better than their previous Model 3.2&amp;quot; type release. The proper reaction to that is an &amp;quot;oh, cool I suppose&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;OpenAI &amp;quot;spreading the good word&amp;quot; about local models and getting more people into &amp;quot;the scene&amp;quot; would be a good point, but they also chose the worst possible timing for that. News of &amp;quot;OpenAI releases a model you can run on your laptop&amp;quot; are &lt;em&gt;already&lt;/em&gt; buried underneath a flood of &amp;quot;Google invents the Matrix&amp;quot;, &amp;quot;OpenAI gives ChatGPT to the government for $1&amp;quot;, &amp;quot;ElevenLabs has a new music model&amp;quot; and &amp;quot;OpenAI to be valued at $500bn&amp;quot;. Mind you, that&amp;#39;s NOW, if I specifically search for OpenAI on Google News. In less than 10 hours, &lt;em&gt;GPT fucking 5&lt;/em&gt; is getting announced. Good luck finding anyone on the internet discussing gpt-oss in a day, let alone a month from now.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dvugz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754557413,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7dhmki",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "LevianMcBirdo",
            "can_mod_post": false,
            "created_utc": 1754549278,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 45,
            "author_fullname": "t2_cw9f6o0r",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Of course it wouldn't get the same hype if some company mostly unknown to the public released the same models. This isn't a good question Imho. The public often only thinks of OpenAI when thinking about generative ai. I am not sure that 50% of adults could even name another company. Even less knew that open models that could run on a lot of consumer PCs even existed. So in that sense, openai helped the scene a lot",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dhmki",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Of course it wouldn&amp;#39;t get the same hype if some company mostly unknown to the public released the same models. This isn&amp;#39;t a good question Imho. The public often only thinks of OpenAI when thinking about generative ai. I am not sure that 50% of adults could even name another company. Even less knew that open models that could run on a lot of consumer PCs even existed. So in that sense, openai helped the scene a lot&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dhmki/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754549278,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 45
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dfad3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "abskvrm",
            "can_mod_post": false,
            "created_utc": 1754547994,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 53,
            "author_fullname": "t2_1519jb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "At least it's _safe_.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dfad3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;At least it&amp;#39;s &lt;em&gt;safe&lt;/em&gt;.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dfad3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754547994,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 53
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": "",
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n7eny46",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "vibjelo",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n7ek7ej",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_hr2hgnsk",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "&gt; Is that with all of the context filled up and allocated for?\n\nI think so. If I run with ctx size 1024, llama-server ends up taking 60940MiB and with ctx size 131072, it ends up taking 65526MiB, so a ~4586MiB difference. I run it like this: \n\n`CUDA_VISIBLE_DEVICES=\"0\" ./build/bin/llama-server -fa --gpu-layers 100 --threads $(nproc) --threads-batch $(nproc) --batch-size 4096 --ctx-size 131072 --jinja --model /mnt/nas/models/lmstudio-community/gpt-oss-120b-GGUF/gpt-oss-120b-MXFP4-00001-of-00002.gguf`\n\nWith llama.cpp rev 1d72c841888b (compiled today)\n\n&gt; What about CPU-only MXFP4 in llama.cpp?\n\nIf I set the --gpu-layers to 0, ~64GB of residential memory, more or less the same but on RAM rather than VRAM :) But then it does like 7 tok/s, compared to ~180 tok/s on the GPU, so not sure why anyone would like to run it like that.",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n7eny46",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Is that with all of the context filled up and allocated for?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I think so. If I run with ctx size 1024, llama-server ends up taking 60940MiB and with ctx size 131072, it ends up taking 65526MiB, so a ~4586MiB difference. I run it like this: &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=&amp;quot;0&amp;quot; ./build/bin/llama-server -fa --gpu-layers 100 --threads $(nproc) --threads-batch $(nproc) --batch-size 4096 --ctx-size 131072 --jinja --model /mnt/nas/models/lmstudio-community/gpt-oss-120b-GGUF/gpt-oss-120b-MXFP4-00001-of-00002.gguf&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;With llama.cpp rev 1d72c841888b (compiled today)&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;What about CPU-only MXFP4 in llama.cpp?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;If I set the --gpu-layers to 0, ~64GB of residential memory, more or less the same but on RAM rather than VRAM :) But then it does like 7 tok/s, compared to ~180 tok/s on the GPU, so not sure why anyone would like to run it like that.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mjsjkn",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7eny46/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754569709,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754569709,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n7ek7ej",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "lizerome",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n7eg96u",
                                                              "score": 1,
                                                              "author_fullname": "t2_14wyb7",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Is that with all of the context filled up and allocated for? What about CPU-only MXFP4 in llama.cpp? I'm having trouble finding concrete memory usage numbers on this thing, everybody keeps talking only about how fast it is, or that they \"can\" run it on some 128 GB Mac Pro or their 3x3090 setup.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n7ek7ej",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is that with all of the context filled up and allocated for? What about CPU-only MXFP4 in llama.cpp? I&amp;#39;m having trouble finding concrete memory usage numbers on this thing, everybody keeps talking only about how fast it is, or that they &amp;quot;can&amp;quot; run it on some 128 GB Mac Pro or their 3x3090 setup.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mjsjkn",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7ek7ej/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754569001,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754569001,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7eg96u",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "vibjelo",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n7e8o7k",
                                                    "score": 1,
                                                    "author_fullname": "t2_hr2hgnsk",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "&gt; OpenAI themselves even advertise the 120b model as being great because it fits on a single H100 when quantized, an enterprise GPU with 80 GB of memory. They only use the word \"local\" for the 20b.\n\ngpt-oss-120b-MXFP4 fits unquantized on ~65GB of VRAM (with context size of 131072). Not disagreeing with anything else you wrote, just a small clarification/correction :)\n\nPersonally, I love the size segmentation OpenAI did in this case, allows me to run both gpt-oss-20b and gpt-oss-120b at the same time, with maximum context so my tooling don't need to unload/load the models depending on the prompt.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7eg96u",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;OpenAI themselves even advertise the 120b model as being great because it fits on a single H100 when quantized, an enterprise GPU with 80 GB of memory. They only use the word &amp;quot;local&amp;quot; for the 20b.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;gpt-oss-120b-MXFP4 fits unquantized on ~65GB of VRAM (with context size of 131072). Not disagreeing with anything else you wrote, just a small clarification/correction :)&lt;/p&gt;\n\n&lt;p&gt;Personally, I love the size segmentation OpenAI did in this case, allows me to run both gpt-oss-20b and gpt-oss-120b at the same time, with maximum context so my tooling don&amp;#39;t need to unload/load the models depending on the prompt.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mjsjkn",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7eg96u/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754567469,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754567469,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7e8o7k",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "lizerome",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7dtflg",
                                          "score": 1,
                                          "author_fullname": "t2_14wyb7",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "What exactly do we mean by \"consumer hardware\" here? The model *weights* of gpt-oss-120b are 65 GB, without the full context. If you're in the 4% of the population who owns a desktop machine with 64 GBs of RAM, you'll... probably still want to sell your RAM sticks and buy more, because a modern OS with a browser and a couple of apps open will eat 9-10 GBs of RAM by itself.\n\nYou could technically quantize the model even further, or squeeze the hell out of it with limited context and 98.8% memory use, then connect to your desktop from a second machine in order to do actual work, but I wouldn't really call that a \"perfect\" experience.\n\nOpenAI themselves even advertise the 120b model as being great because it fits *on a single H100 when quantized*, an enterprise GPU with 80 GB of memory. They only use the word \"local\" for the 20b.\n\nDon't get me wrong, MoE with native fp4 *is* the best architecture for local use, but think something more in the 20-30b range. If you go above 100b+, that's the sort of model that'll only be used by people who specifically dropped a couple grand on a home server to run AI inference, at which point you can play around with unified memory, 4xP40 setups and other weird shit at roughly the same cost.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7e8o7k",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What exactly do we mean by &amp;quot;consumer hardware&amp;quot; here? The model &lt;em&gt;weights&lt;/em&gt; of gpt-oss-120b are 65 GB, without the full context. If you&amp;#39;re in the 4% of the population who owns a desktop machine with 64 GBs of RAM, you&amp;#39;ll... probably still want to sell your RAM sticks and buy more, because a modern OS with a browser and a couple of apps open will eat 9-10 GBs of RAM by itself.&lt;/p&gt;\n\n&lt;p&gt;You could technically quantize the model even further, or squeeze the hell out of it with limited context and 98.8% memory use, then connect to your desktop from a second machine in order to do actual work, but I wouldn&amp;#39;t really call that a &amp;quot;perfect&amp;quot; experience.&lt;/p&gt;\n\n&lt;p&gt;OpenAI themselves even advertise the 120b model as being great because it fits &lt;em&gt;on a single H100 when quantized&lt;/em&gt;, an enterprise GPU with 80 GB of memory. They only use the word &amp;quot;local&amp;quot; for the 20b.&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t get me wrong, MoE with native fp4 &lt;em&gt;is&lt;/em&gt; the best architecture for local use, but think something more in the 20-30b range. If you go above 100b+, that&amp;#39;s the sort of model that&amp;#39;ll only be used by people who specifically dropped a couple grand on a home server to run AI inference, at which point you can play around with unified memory, 4xP40 setups and other weird shit at roughly the same cost.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjsjkn",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e8o7k/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754564191,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754564191,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7dtflg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Wrong-Historian",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dipep",
                                "score": 12,
                                "author_fullname": "t2_69r67vj3",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Sure, but that's the main thing to be hyped about. 120B MOE native fp4 might be the perfect architecture for local running on consumer hardware",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7dtflg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sure, but that&amp;#39;s the main thing to be hyped about. 120B MOE native fp4 might be the perfect architecture for local running on consumer hardware&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dtflg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754556017,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754556017,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 12
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dipep",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Bitter-Raisin-3251",
                      "can_mod_post": false,
                      "created_utc": 1754549863,
                      "send_replies": true,
                      "parent_id": "t1_n7dhbuf",
                      "score": 19,
                      "author_fullname": "t2_xc2n1ia00",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "120B is MOE with 5.1B active parameters so compare that size.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dipep",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;120B is MOE with 5.1B active parameters so compare that size.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dipep/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754549863,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 19
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7drgmy",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Wrong-Historian",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dozv4",
                                "score": 7,
                                "author_fullname": "t2_69r67vj3",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Useable context. RAG, aider, etc all seemed to work. Eg actually usefull. Also very fast preprocessing (60T/s). I just need to work more with it to see if the quality of the responses is good enough and tool calling etc is also reliable",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7drgmy",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Useable context. RAG, aider, etc all seemed to work. Eg actually usefull. Also very fast preprocessing (60T/s). I just need to work more with it to see if the quality of the responses is good enough and tool calling etc is also reliable&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7drgmy/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754554866,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754554866,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 7
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dozv4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "admajic",
                      "can_mod_post": false,
                      "created_utc": 1754553446,
                      "send_replies": true,
                      "parent_id": "t1_n7dhbuf",
                      "score": 3,
                      "author_fullname": "t2_60b9farf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "At a usable context window or 4k?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dozv4",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;At a usable context window or 4k?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dozv4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754553446,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7e8b61",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "TheTerrasque",
                      "can_mod_post": false,
                      "created_utc": 1754564026,
                      "send_replies": true,
                      "parent_id": "t1_n7dhbuf",
                      "score": 2,
                      "author_fullname": "t2_9uv8v",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; So you'll have to compare it to any other ***70B*** q4 or worse quant, which are *very very bad models*.\n\n\nAnd this gets upvoted.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7e8b61",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;So you&amp;#39;ll have to compare it to any other &lt;strong&gt;&lt;em&gt;70B&lt;/em&gt;&lt;/strong&gt; q4 or worse quant, which are &lt;em&gt;very very bad models&lt;/em&gt;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;And this gets upvoted.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e8b61/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754564026,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7eh20o",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Danmoreng",
                      "can_mod_post": false,
                      "created_utc": 1754567787,
                      "send_replies": true,
                      "parent_id": "t1_n7dhbuf",
                      "score": 1,
                      "author_fullname": "t2_7z26p",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "May compare it to GLM 4.5 Air? Speed will be slower because of 12B active parameters over 5B, but the quality is whats really interesting.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7eh20o",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;May compare it to GLM 4.5 Air? Speed will be slower because of 12B active parameters over 5B, but the quality is whats really interesting.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7eh20o/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754567787,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7di4m5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "chunkypenguion1991",
                      "can_mod_post": false,
                      "created_utc": 1754549552,
                      "send_replies": true,
                      "parent_id": "t1_n7dhbuf",
                      "score": -21,
                      "author_fullname": "t2_1rkptb2m",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I guess you removed the newline keys from the output? What you posted is a train of thought",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7di4m5",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I guess you removed the newline keys from the output? What you posted is a train of thought&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7di4m5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754549552,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -21
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7dhbuf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Wrong-Historian",
            "can_mod_post": false,
            "created_utc": 1754549116,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 45,
            "author_fullname": "t2_69r67vj3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Its *fast*. The 120B runs at 25T/s on my single 3090 + 14900K. So you'll have to compare it to any other 70B q4 or worse quant, which are very very bad models. In my testings gpt-oss 120B is by far the best model I'm able to run at somewhat decent speed locally. There does need to be a fine-tune o remove some of the 'safety'... Now, the question is, is it good enough for practical use? I don't know yet. Until now I've always fallen back on online API's (gpt 4o / claude) because local llm's were either not good enough and/or too slow. This model is on the edge of that, so yeah, that's hype worthy",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dhbuf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Its &lt;em&gt;fast&lt;/em&gt;. The 120B runs at 25T/s on my single 3090 + 14900K. So you&amp;#39;ll have to compare it to any other 70B q4 or worse quant, which are very very bad models. In my testings gpt-oss 120B is by far the best model I&amp;#39;m able to run at somewhat decent speed locally. There does need to be a fine-tune o remove some of the &amp;#39;safety&amp;#39;... Now, the question is, is it good enough for practical use? I don&amp;#39;t know yet. Until now I&amp;#39;ve always fallen back on online API&amp;#39;s (gpt 4o / claude) because local llm&amp;#39;s were either not good enough and/or too slow. This model is on the edge of that, so yeah, that&amp;#39;s hype worthy&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dhbuf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754549116,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 45
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7dutt0",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "agentcubed",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dhcfh",
                                "score": 12,
                                "author_fullname": "t2_duqfsmw4g",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You can't compare a 120b 5b active to a 235b 22b active model. One of them I can't even run.\n\nIts the smartest model that can run on a consumer grade gpu, according to the independent Artificial Analysis.\n\nTo be clear, I'm not saying use it cuz it's so censored, but it's definitely not crap",
                                "edited": 1754557025,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7dutt0",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can&amp;#39;t compare a 120b 5b active to a 235b 22b active model. One of them I can&amp;#39;t even run.&lt;/p&gt;\n\n&lt;p&gt;Its the smartest model that can run on a consumer grade gpu, according to the independent Artificial Analysis.&lt;/p&gt;\n\n&lt;p&gt;To be clear, I&amp;#39;m not saying use it cuz it&amp;#39;s so censored, but it&amp;#39;s definitely not crap&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dutt0/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754556823,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754556823,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 12
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7dhri4",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "UltrMgns",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dhcfh",
                                "score": 10,
                                "author_fullname": "t2_nvmilgf",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "To be honest, I completely agree with that.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7dhri4",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;To be honest, I completely agree with that.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dhri4/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754549353,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754549353,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 10
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7dkcqd",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ThinkExtension2328",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dhcfh",
                                "score": 4,
                                "author_fullname": "t2_8eneodlk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Actually they are trying to get free labor, it being good or bad is irrelevant to them. They just want to see if people can make it unlocked. Which they  will simply use the new knowledge to make a Safer model.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7dkcqd",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Actually they are trying to get free labor, it being good or bad is irrelevant to them. They just want to see if people can make it unlocked. Which they  will simply use the new knowledge to make a Safer model.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dkcqd/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754550782,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754550782,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7dnzll",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": "LOW_SCORE",
                                "no_follow": true,
                                "author": "custodiam99",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dhcfh",
                                "score": -5,
                                "author_fullname": "t2_nqnhgqqf5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "No, it is absolutely not true. According to LiveBench: 1.) This is the BEST open and local Western model. 2.) It is exactly the same as GPT4o and GPT4.1. \\*\\*\\* Obviously the Chinese are very good at open models to undercut Western firms. They are releasing SOTA open models to do that. OpenAI is releasing local SOTA models  *from a year ago. I have no problems with this.*",
                                "edited": 1754553161,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7dnzll",
                                "is_submitter": false,
                                "collapsed": true,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, it is absolutely not true. According to LiveBench: 1.) This is the BEST open and local Western model. 2.) It is exactly the same as GPT4o and GPT4.1. *** Obviously the Chinese are very good at open models to undercut Western firms. They are releasing SOTA open models to do that. OpenAI is releasing local SOTA models  &lt;em&gt;from a year ago. I have no problems with this.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": "comment score below threshold",
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dnzll/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754552865,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754552865,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": -5
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dhcfh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "chunkypenguion1991",
                      "can_mod_post": false,
                      "created_utc": 1754549125,
                      "send_replies": true,
                      "parent_id": "t1_n7dftb4",
                      "score": -7,
                      "author_fullname": "t2_1rkptb2m",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It's not even the censored part, it just seems like openAi released some crappy model so we would shut up about open source. But its crap",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dhcfh",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s not even the censored part, it just seems like openAi released some crappy model so we would shut up about open source. But its crap&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dhcfh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754549125,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7dftb4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "custodiam99",
            "can_mod_post": false,
            "created_utc": 1754548282,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 28,
            "author_fullname": "t2_nqnhgqqf5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yes, it is a very good scientific model. Clear thinking patterns. VERY quick and quality summaries. Sure, it is very censored.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dftb4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, it is a very good scientific model. Clear thinking patterns. VERY quick and quality summaries. Sure, it is very censored.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dftb4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754548282,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 28
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7eg3un",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "vibjelo",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dvrdq",
                                "score": 1,
                                "author_fullname": "t2_hr2hgnsk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Not to mention the first two iterations of GPT were released to the public, and we used those for local inference back in the day (around 2019-2020 I think?). I'm not sure if people are forgetting those initial releases on purpose, or if the community is just filled with people who weren't around at that point.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7eg3un",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not to mention the first two iterations of GPT were released to the public, and we used those for local inference back in the day (around 2019-2020 I think?). I&amp;#39;m not sure if people are forgetting those initial releases on purpose, or if the community is just filled with people who weren&amp;#39;t around at that point.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7eg3un/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754567409,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754567409,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dvrdq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "mrjackspade",
                      "can_mod_post": false,
                      "created_utc": 1754557364,
                      "send_replies": false,
                      "parent_id": "t1_n7dosp5",
                      "score": 8,
                      "author_fullname": "t2_5ow51",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "They couldn't say that before either, OpenAI has been releasing Open Source models for years. \n\nWhisper 3 just released in November.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dvrdq",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They couldn&amp;#39;t say that before either, OpenAI has been releasing Open Source models for years. &lt;/p&gt;\n\n&lt;p&gt;Whisper 3 just released in November.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dvrdq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754557364,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 8
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7dosp5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "FrontLanguage6036",
            "can_mod_post": false,
            "created_utc": 1754553333,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 4,
            "author_fullname": "t2_1rceeq01eo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "At least now people can't say that Open AI has no open models",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dosp5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;At least now people can&amp;#39;t say that Open AI has no open models&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dosp5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754553333,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7eok73",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Meowliketh",
                      "can_mod_post": false,
                      "created_utc": 1754569933,
                      "send_replies": true,
                      "parent_id": "t1_n7dwl8s",
                      "score": 1,
                      "author_fullname": "t2_1ly590s93s",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "When I asked it how it would communicate that it was censored.\nAmong its examples was \"What was the result of the 2024 US election?\" | \"I don't have that information\"\nbecause its cutoff is right before then. The problem solver in me is so impressed with how a bunch of smart people are planning around any possible controversy. \n\nI like the way chatgpt communicates information, and it runs quite well on my regular, nothing special macbook pro too. Until the new Qwen models fit reasonably comfortably on there AND the output is as user-friendly to my needs as this gpt-oss, I mean, not bad. seems more business/education friendly at least.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7eok73",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;When I asked it how it would communicate that it was censored.\nAmong its examples was &amp;quot;What was the result of the 2024 US election?&amp;quot; | &amp;quot;I don&amp;#39;t have that information&amp;quot;\nbecause its cutoff is right before then. The problem solver in me is so impressed with how a bunch of smart people are planning around any possible controversy. &lt;/p&gt;\n\n&lt;p&gt;I like the way chatgpt communicates information, and it runs quite well on my regular, nothing special macbook pro too. Until the new Qwen models fit reasonably comfortably on there AND the output is as user-friendly to my needs as this gpt-oss, I mean, not bad. seems more business/education friendly at least.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7eok73/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754569933,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7ecuz5",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "plankalkul-z1",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7eabak",
                                "score": 1,
                                "author_fullname": "t2_w73n3yrsx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; but Qwen 3 235 and GLM 4.5 air both compete against this model where it could be a tie or a win depending on your use case. So I think you overstate that.\n\n\nI was very careful to not to overstate anything here...\n\n\nThere's no question that Qwen 3 235B is (noticeably) better as a model. But I can only run it at about 8 tps as it doesn't fit my VRAM. gpt-oss 120b is 10+times faster.\n\n\nAs to GLM 4.5 Air: even though I *heard* great things about it, I still can't run it. First I was waiting for the vLLM's and SGLang's support... Then versions supporting GLM 4.5 came out, but still don't work for me due to some strange bugs. I still haven't decided what to do about that (dig deeper? switch to GGUFs?..)\n\n\nSo, *to me*, comparison to Mistral Large and Command-A is the only apples-to-apples one.\n\n\nIn other words, I always speak from *my experience*. Most of LocalLLaMA's problems as a forum stem from people just repeating what others said, what they *think* is true... I don't do that.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7ecuz5",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;but Qwen 3 235 and GLM 4.5 air both compete against this model where it could be a tie or a win depending on your use case. So I think you overstate that.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I was very careful to not to overstate anything here...&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s no question that Qwen 3 235B is (noticeably) better as a model. But I can only run it at about 8 tps as it doesn&amp;#39;t fit my VRAM. gpt-oss 120b is 10+times faster.&lt;/p&gt;\n\n&lt;p&gt;As to GLM 4.5 Air: even though I &lt;em&gt;heard&lt;/em&gt; great things about it, I still can&amp;#39;t run it. First I was waiting for the vLLM&amp;#39;s and SGLang&amp;#39;s support... Then versions supporting GLM 4.5 came out, but still don&amp;#39;t work for me due to some strange bugs. I still haven&amp;#39;t decided what to do about that (dig deeper? switch to GGUFs?..)&lt;/p&gt;\n\n&lt;p&gt;So, &lt;em&gt;to me&lt;/em&gt;, comparison to Mistral Large and Command-A is the only apples-to-apples one.&lt;/p&gt;\n\n&lt;p&gt;In other words, I always speak from &lt;em&gt;my experience&lt;/em&gt;. Most of LocalLLaMA&amp;#39;s problems as a forum stem from people just repeating what others said, what they &lt;em&gt;think&lt;/em&gt; is true... I don&amp;#39;t do that.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7ecuz5/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754566055,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754566055,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7eabak",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "silenceimpaired",
                      "can_mod_post": false,
                      "created_utc": 1754564930,
                      "send_replies": true,
                      "parent_id": "t1_n7dwl8s",
                      "score": 1,
                      "author_fullname": "t2_dissgzyl",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I agreed Apache licensing is amazing coming from OpenAI, but Qwen 3 30b/235 and GLM 4.5 air both compete against this model where it could be a tie or a win depending on your use case. So I think you overstate that.\n\nStill, they contributed some meaningful model structure that Im excited to see implemented. \n\nTheir smaller model is unacceptable for my use case, but I still need to give their large model more time and testing.",
                      "edited": 1754566930,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7eabak",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agreed Apache licensing is amazing coming from OpenAI, but Qwen 3 30b/235 and GLM 4.5 air both compete against this model where it could be a tie or a win depending on your use case. So I think you overstate that.&lt;/p&gt;\n\n&lt;p&gt;Still, they contributed some meaningful model structure that Im excited to see implemented. &lt;/p&gt;\n\n&lt;p&gt;Their smaller model is unacceptable for my use case, but I still need to give their large model more time and testing.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7eabak/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754564930,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7dwl8s",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "plankalkul-z1",
            "can_mod_post": false,
            "created_utc": 1754557851,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 8,
            "author_fullname": "t2_w73n3yrsx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt; I'm asking if without the OpenAI name behind it would ot get this much hype\n\n\nI think even with that clarification you're still asking a wrong question...\n\n\nThere is no way a company other than OpenAI could produce a model that is exactly what the gpt-oss models are. Let me explain what I mean.\n\n\n**First, the dreaded \"safety\" issue.**\n\n\nHow my gpt-oss assesses \"safety\" of every promp, however benign, during its \"thinking\" step is indeed hilarious.\n\n\n*No other company* would *have* to do that. OpenAI's exposure is enormous. Have you ever thought about the possibility of having to defend what you did or didn't do for the \"safety\" before the US Congress?\n\n\n**Second, the model value**\n\n\nIt's Apache 2.0 whereas othe models of comparable quality that I have (Mistral Large, Command-A) are all NC.\n\n\nIt's freaking fast.\n\n\nIt's innovative because of the MXFP4: it has sh!tload of weights (117B) and yet is stillcompact for what it is.\n\n\nDespite that aforementioned hilarity of the \"safety\" assessment during \"thinking\" phase, I do not see any rejections that would bug *me*. It produces the bloodiest write-ups I've ever seen. It lies to me wnen I tell it to. It talks about copyrighted works. And so on. It is still immensely useful.\n\n\nIt has one of the largest vocabularies (200+k tokens; I haven't seen bigger), and is very good at translation according to *my* tests.\n\n\nSo... if it was *not* by the universally (and quite rightfully) hated OpenAI, it would be accepted better but slower... Discovery would be much slower, but it would still appear as a \"hidden gem\", and gain traction.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dwl8s",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I&amp;#39;m asking if without the OpenAI name behind it would ot get this much hype&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I think even with that clarification you&amp;#39;re still asking a wrong question...&lt;/p&gt;\n\n&lt;p&gt;There is no way a company other than OpenAI could produce a model that is exactly what the gpt-oss models are. Let me explain what I mean.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;First, the dreaded &amp;quot;safety&amp;quot; issue.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How my gpt-oss assesses &amp;quot;safety&amp;quot; of every promp, however benign, during its &amp;quot;thinking&amp;quot; step is indeed hilarious.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;No other company&lt;/em&gt; would &lt;em&gt;have&lt;/em&gt; to do that. OpenAI&amp;#39;s exposure is enormous. Have you ever thought about the possibility of having to defend what you did or didn&amp;#39;t do for the &amp;quot;safety&amp;quot; before the US Congress?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Second, the model value&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s Apache 2.0 whereas othe models of comparable quality that I have (Mistral Large, Command-A) are all NC.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s freaking fast.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s innovative because of the MXFP4: it has sh!tload of weights (117B) and yet is stillcompact for what it is.&lt;/p&gt;\n\n&lt;p&gt;Despite that aforementioned hilarity of the &amp;quot;safety&amp;quot; assessment during &amp;quot;thinking&amp;quot; phase, I do not see any rejections that would bug &lt;em&gt;me&lt;/em&gt;. It produces the bloodiest write-ups I&amp;#39;ve ever seen. It lies to me wnen I tell it to. It talks about copyrighted works. And so on. It is still immensely useful.&lt;/p&gt;\n\n&lt;p&gt;It has one of the largest vocabularies (200+k tokens; I haven&amp;#39;t seen bigger), and is very good at translation according to &lt;em&gt;my&lt;/em&gt; tests.&lt;/p&gt;\n\n&lt;p&gt;So... if it was &lt;em&gt;not&lt;/em&gt; by the universally (and quite rightfully) hated OpenAI, it would be accepted better but slower... Discovery would be much slower, but it would still appear as a &amp;quot;hidden gem&amp;quot;, and gain traction.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dwl8s/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754557851,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7do26t",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ComprehensiveJury509",
            "can_mod_post": false,
            "created_utc": 1754552909,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 16,
            "author_fullname": "t2_1mc77zutzr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hype? I'd say there is a lot of negativity on here that feels forced. I think people in this community really want it to bomb, so they focus on all the stuff that isn't good. Mind, I dislike openAI with a passion myself, but I don't think these are mediocre models. They are very solid models for their weight classes. Reminder, they only have 5.1 and 3.6B active parameters, yet people seem to compare them to beefier models all the time.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7do26t",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hype? I&amp;#39;d say there is a lot of negativity on here that feels forced. I think people in this community really want it to bomb, so they focus on all the stuff that isn&amp;#39;t good. Mind, I dislike openAI with a passion myself, but I don&amp;#39;t think these are mediocre models. They are very solid models for their weight classes. Reminder, they only have 5.1 and 3.6B active parameters, yet people seem to compare them to beefier models all the time.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7do26t/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754552909,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 16
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7djxkp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "chunkypenguion1991",
                      "can_mod_post": false,
                      "created_utc": 1754550544,
                      "send_replies": true,
                      "parent_id": "t1_n7dj1hm",
                      "score": -3,
                      "author_fullname": "t2_1rkptb2m",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "$$$ thats why",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7djxkp",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;$$$ thats why&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7djxkp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754550544,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dngcb",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Mayion",
                      "can_mod_post": false,
                      "created_utc": 1754552557,
                      "send_replies": true,
                      "parent_id": "t1_n7dj1hm",
                      "score": -2,
                      "author_fullname": "t2_ohrjhy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "with the way it's being pushed, I just assumed LM Studio was part of OpenAI",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dngcb",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;with the way it&amp;#39;s being pushed, I just assumed LM Studio was part of OpenAI&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dngcb/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754552557,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7dj1hm",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "NinjaK3ys",
            "can_mod_post": false,
            "created_utc": 1754550045,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 10,
            "author_fullname": "t2_3dec46nr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "totally. I don't understand why such hype for the openai oss models.\nLM Studio is pushing it with a notification on their app.\nGeezz.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dj1hm",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;totally. I don&amp;#39;t understand why such hype for the openai oss models.\nLM Studio is pushing it with a notification on their app.\nGeezz.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dj1hm/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754550045,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n7dt38c",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "Wrong-Historian",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n7dhswk",
                                                              "score": 8,
                                                              "author_fullname": "t2_69r67vj3",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "NOT deepseek. Deepseek is a 671B model. You're running 'fake' deepseek (a qwen distill with very little parameters like 14B). Eg you're being scammed by ollama",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n7dt38c",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;NOT deepseek. Deepseek is a 671B model. You&amp;#39;re running &amp;#39;fake&amp;#39; deepseek (a qwen distill with very little parameters like 14B). Eg you&amp;#39;re being scammed by ollama&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mjsjkn",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dt38c/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754555816,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754555816,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 8
                                                            }
                                                          },
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n7dk3mp",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "chunkypenguion1991",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n7dhswk",
                                                              "score": 1,
                                                              "author_fullname": "t2_1rkptb2m",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "You missed the entire point of the post",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n7dk3mp",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You missed the entire point of the post&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mjsjkn",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dk3mp/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754550639,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754550639,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7dhswk",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "iron_coffin",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n7dgxi2",
                                                    "score": -4,
                                                    "author_fullname": "t2_5c3ri",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "My 5070ti and someone's 3090 were over 100 tps, and it sounds like a 3090 is 50tps on deepseek",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7dhswk",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My 5070ti and someone&amp;#39;s 3090 were over 100 tps, and it sounds like a 3090 is 50tps on deepseek&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mjsjkn",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dhswk/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754549375,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754549375,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": -4
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7dgxi2",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "chunkypenguion1991",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7dgpm4",
                                          "score": -1,
                                          "author_fullname": "t2_1rkptb2m",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Yes",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7dgxi2",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjsjkn",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dgxi2/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754548899,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754548899,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 1,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -1
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7dll7p",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "DeltaSqueezer",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7dgpm4",
                                          "score": -1,
                                          "author_fullname": "t2_8jqx3m14",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "also the 30ba3b",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7dll7p",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;also the 30ba3b&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjsjkn",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dll7p/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754551477,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754551477,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7dgpm4",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": "LOW_SCORE",
                                "no_follow": true,
                                "author": "nikhilprasanth",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dg3bu",
                                "score": -6,
                                "author_fullname": "t2_2iedc63",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It's deepseek 14b right?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7dgpm4",
                                "is_submitter": false,
                                "collapsed": true,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s deepseek 14b right?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": "comment score below threshold",
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dgpm4/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754548780,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754548780,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": -6
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dg3bu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "chunkypenguion1991",
                      "can_mod_post": false,
                      "created_utc": 1754548434,
                      "send_replies": true,
                      "parent_id": "t1_n7dfv5d",
                      "score": -10,
                      "author_fullname": "t2_1rkptb2m",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes, deepseek still the primary one",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dg3bu",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, deepseek still the primary one&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dg3bu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754548434,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -10
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7dfv5d",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "iron_coffin",
            "can_mod_post": false,
            "created_utc": 1754548310,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 7,
            "author_fullname": "t2_5c3ri",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Is there a faster and better model that fits on a 16 GB gpu?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dfv5d",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is there a faster and better model that fits on a 16 GB gpu?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dfv5d/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754548310,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7djlp6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Accomplished-Copy332",
            "can_mod_post": false,
            "created_utc": 1754550359,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 2,
            "author_fullname": "t2_98ouo03z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Is there really that much hype? It doesnt perform well on the [qualitative benchmarks](https://www.designarena.ai/) and are not even comparable to Qwen3 30B. Who knows Qwen 4B might outperform it.\n\nGPT-5 is clearly the model OAI cares about",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7djlp6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is there really that much hype? It doesnt perform well on the &lt;a href=\"https://www.designarena.ai/\"&gt;qualitative benchmarks&lt;/a&gt; and are not even comparable to Qwen3 30B. Who knows Qwen 4B might outperform it.&lt;/p&gt;\n\n&lt;p&gt;GPT-5 is clearly the model OAI cares about&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7djlp6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754550359,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7e8uy3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Only-Letterhead-3411",
            "can_mod_post": false,
            "created_utc": 1754564280,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 2,
            "author_fullname": "t2_pbfqmgf8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If another company released this models they'd be a laughing stock. But since it's OAI we see dozens of OAI fanboys that try to sell it as a success",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7e8uy3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If another company released this models they&amp;#39;d be a laughing stock. But since it&amp;#39;s OAI we see dozens of OAI fanboys that try to sell it as a success&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e8uy3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754564280,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7ebe6f",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "JLeonsarmiento",
            "can_mod_post": false,
            "created_utc": 1754565414,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 2,
            "author_fullname": "t2_9b9s4a7g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Ernie 4.5 21b mlx version put gptoss into shame.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7ebe6f",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ernie 4.5 21b mlx version put gptoss into shame.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7ebe6f/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754565414,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dlwib",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "DeltaSqueezer",
            "can_mod_post": false,
            "created_utc": 1754551659,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 4,
            "author_fullname": "t2_8jqx3m14",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "No. I think LocalLLaMA got flooded with posts because these were the first modern Apache Licensed models from OpenAI and were eagerly anticipated. Maybe some were curious if there was any secret sauce from OpenAI that would be revealed.\n\nIf this were any other company, there might have been a couple of posts and then quickly forgotten. \n\nCompare to models like Command A, which were announced, had a bit of discussion but then have not been discussed much since.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dlwib",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No. I think LocalLLaMA got flooded with posts because these were the first modern Apache Licensed models from OpenAI and were eagerly anticipated. Maybe some were curious if there was any secret sauce from OpenAI that would be revealed.&lt;/p&gt;\n\n&lt;p&gt;If this were any other company, there might have been a couple of posts and then quickly forgotten. &lt;/p&gt;\n\n&lt;p&gt;Compare to models like Command A, which were announced, had a bit of discussion but then have not been discussed much since.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dlwib/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754551659,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dl408",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "adalaza",
            "can_mod_post": false,
            "created_utc": 1754551205,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 2,
            "author_fullname": "t2_118tcp",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If by any other company, you meant an American company, yes.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dl408",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If by any other company, you meant an American company, yes.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dl408/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754551205,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7e3hvi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "RetroWPD",
            "can_mod_post": false,
            "created_utc": 1754561661,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 3,
            "author_fullname": "t2_m2x5v9e6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "No, there is no use case for that model.\n\nIf it had good general knowledge or at least good writing it would be usable. It seems like the model was made for math/riddles/coding...and that puts them directly in competition with qwen3. Their models are just better at that. Gpt-oss spits out bad code often (with sometimes a gold nugget in between). Design wise its just horrible, the recent chinese llms are much better at making pretty website and games. Its not even a competition.\n\nAnd on top of all that is the insane refusal. You cant even ask anything about public characters or get a copyright refusal. Its that bad. Just imagine the outcry if mistral put out a model like that. \n\nIts so obvious how bad it is, even the people on X and youtube (who do it for money obv.) say its a great model because.....its super fast....and not made in china. That pretty much says it all.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7e3hvi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, there is no use case for that model.&lt;/p&gt;\n\n&lt;p&gt;If it had good general knowledge or at least good writing it would be usable. It seems like the model was made for math/riddles/coding...and that puts them directly in competition with qwen3. Their models are just better at that. Gpt-oss spits out bad code often (with sometimes a gold nugget in between). Design wise its just horrible, the recent chinese llms are much better at making pretty website and games. Its not even a competition.&lt;/p&gt;\n\n&lt;p&gt;And on top of all that is the insane refusal. You cant even ask anything about public characters or get a copyright refusal. Its that bad. Just imagine the outcry if mistral put out a model like that. &lt;/p&gt;\n\n&lt;p&gt;Its so obvious how bad it is, even the people on X and youtube (who do it for money obv.) say its a great model because.....its super fast....and not made in china. That pretty much says it all.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e3hvi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754561661,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dgbqy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "PicklesLLM",
            "can_mod_post": false,
            "created_utc": 1754548565,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 1,
            "author_fullname": "t2_j995gw3z4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Honestly I kind of agree. But the reason this is big is because it's an LLM that alot more people are more familiar with. This will encourage more people to actually get into the local model route, and it may also encourage companies to create more AI focused hardware, which would allow a more affordable route for homelabs.\n\nI feel the excitement isn't so much about the LLM itself, but the expansion of people new to this hobby or lifestyle. After many years of trying to get my family to use local LLMs, this expansion has allowed me to introduce them to the idea of a local llm for their home servers. They only trusted chatgpt for the longest time, but now they're getting more open to it because I can download the 20b model on their own personal PCs. Which they enjoy using for writing and story ideas. My uncle uses it for help with coding, but he's been more open to local LLMs for a long time. Anyways, this is why I like it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dgbqy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Honestly I kind of agree. But the reason this is big is because it&amp;#39;s an LLM that alot more people are more familiar with. This will encourage more people to actually get into the local model route, and it may also encourage companies to create more AI focused hardware, which would allow a more affordable route for homelabs.&lt;/p&gt;\n\n&lt;p&gt;I feel the excitement isn&amp;#39;t so much about the LLM itself, but the expansion of people new to this hobby or lifestyle. After many years of trying to get my family to use local LLMs, this expansion has allowed me to introduce them to the idea of a local llm for their home servers. They only trusted chatgpt for the longest time, but now they&amp;#39;re getting more open to it because I can download the 20b model on their own personal PCs. Which they enjoy using for writing and story ideas. My uncle uses it for help with coding, but he&amp;#39;s been more open to local LLMs for a long time. Anyways, this is why I like it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dgbqy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754548565,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7emsgb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Faintly_glowing_fish",
            "can_mod_post": false,
            "created_utc": 1754569282,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 1,
            "author_fullname": "t2_97avhniv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "For me its actually really really fast, and at ~100k context 120B one is even a little faster than glm 4.5 air.  That in itself is pretty crazy.  \n\nIt hallucinate like hell but does search very very well so works extremely nicely with search tools; \n\nIt actually might be one of the smartest models around the size, if not the one.  But its incredibly lazy and cautious.   Im not even talking about safety.  It would refuse large refactor tasks because it think its dangerous and I had to threaten it to execute commands on the host machine. This makes it very hard to use for coding, even though it analyzes bugs and makes plans very very well.\n\nThere are some other extremely interesting tech there.   Adjustable reasoning for one: qwen tried that with hybrid reasoning too, and failed miserably, but those in oss just works.  Being able to do that through prompt is crazy, and I wonder if we can go even higher reasoning by a bit fine tuning.  \n\nIt can also use tools while reasoning; I dont think anything else does that.  It works extraordinarily well with search tools.\n\nThen of course theres the interesting attention structure and native 4fp moe, which I expect a lot of open models in the future will pick up, if thats what makes it so fast.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7emsgb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For me its actually really really fast, and at ~100k context 120B one is even a little faster than glm 4.5 air.  That in itself is pretty crazy.  &lt;/p&gt;\n\n&lt;p&gt;It hallucinate like hell but does search very very well so works extremely nicely with search tools; &lt;/p&gt;\n\n&lt;p&gt;It actually might be one of the smartest models around the size, if not the one.  But its incredibly lazy and cautious.   Im not even talking about safety.  It would refuse large refactor tasks because it think its dangerous and I had to threaten it to execute commands on the host machine. This makes it very hard to use for coding, even though it analyzes bugs and makes plans very very well.&lt;/p&gt;\n\n&lt;p&gt;There are some other extremely interesting tech there.   Adjustable reasoning for one: qwen tried that with hybrid reasoning too, and failed miserably, but those in oss just works.  Being able to do that through prompt is crazy, and I wonder if we can go even higher reasoning by a bit fine tuning.  &lt;/p&gt;\n\n&lt;p&gt;It can also use tools while reasoning; I dont think anything else does that.  It works extraordinarily well with search tools.&lt;/p&gt;\n\n&lt;p&gt;Then of course theres the interesting attention structure and native 4fp moe, which I expect a lot of open models in the future will pick up, if thats what makes it so fast.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7emsgb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754569282,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7eode1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Acrobatic-Paint7185",
            "can_mod_post": false,
            "created_utc": 1754569863,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 1,
            "author_fullname": "t2_z68pljm75",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yes because it's the only 20B MoE model out there.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7eode1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes because it&amp;#39;s the only 20B MoE model out there.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7eode1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754569863,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dr0jw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Cool-Chemical-5629",
            "can_mod_post": false,
            "created_utc": 1754554607,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 1,
            "author_fullname": "t2_qz1qjc86",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If it was made by different company, I would actually care about the model more, because there would be always chance for improvement in the future. With Open AI that option is pretty much zero. If they meant to release a good model for our community, they wouldnt release such an otherworldly censored model in the first place. The 120B suffers less from this censorship, but its not gonna be widely used by all of us due to its much bigger size that simply doesnt fit that easily.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dr0jw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If it was made by different company, I would actually care about the model more, because there would be always chance for improvement in the future. With Open AI that option is pretty much zero. If they meant to release a good model for our community, they wouldnt release such an otherworldly censored model in the first place. The 120B suffers less from this censorship, but its not gonna be widely used by all of us due to its much bigger size that simply doesnt fit that easily.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dr0jw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754554607,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7ed1f8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "a_beautiful_rhind",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7e9jit",
                                "score": 2,
                                "author_fullname": "t2_h5utwre7",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Now nobody can say they aren't opensource.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7ed1f8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Now nobody can say they aren&amp;#39;t opensource.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjsjkn",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7ed1f8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754566131,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754566131,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7e9jit",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "evilbarron2",
                      "can_mod_post": false,
                      "created_utc": 1754564585,
                      "send_replies": true,
                      "parent_id": "t1_n7e3l8a",
                      "score": 2,
                      "author_fullname": "t2_gr2fr79s1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I use a gemma3:27b tool using variant, and it kinda kicks the crap out of gpt-oss:20b in my setup. Plus it has vision. I had hoped its integration with Ollama would provide some benefit, but the 2 ollama updates in 2 days to fix bugs and its real-world performance shows the opposite.\n\nIm wondering why OpenAI even released whats basically a me-too product.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7e9jit",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I use a gemma3:27b tool using variant, and it kinda kicks the crap out of gpt-oss:20b in my setup. Plus it has vision. I had hoped its integration with Ollama would provide some benefit, but the 2 ollama updates in 2 days to fix bugs and its real-world performance shows the opposite.&lt;/p&gt;\n\n&lt;p&gt;Im wondering why OpenAI even released whats basically a me-too product.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e9jit/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754564585,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7e3l8a",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "a_beautiful_rhind",
            "can_mod_post": false,
            "created_utc": 1754561708,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 1,
            "author_fullname": "t2_h5utwre7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If it wasn't openAI, nobody would be shilling it or saying how PoWeRFuL it is despite the drawbacks. There would be no vote fights in the comments either.\n\nI'll go further and say I don't get the hype for them in the first place. Other models do just as well and their responses are more pleasant to the eye. Even as first movers, they gave us slop and refusals. Their legacy is going to be poisoning all other LLM and the internet for decades.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7e3l8a",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If it wasn&amp;#39;t openAI, nobody would be shilling it or saying how PoWeRFuL it is despite the drawbacks. There would be no vote fights in the comments either.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll go further and say I don&amp;#39;t get the hype for them in the first place. Other models do just as well and their responses are more pleasant to the eye. Even as first movers, they gave us slop and refusals. Their legacy is going to be poisoning all other LLM and the internet for decades.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e3l8a/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754561708,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dobly",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "KTibow",
            "can_mod_post": false,
            "created_utc": 1754553061,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 1,
            "author_fullname": "t2_83uo8ytp",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "See: Phi series",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dobly",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;See: Phi series&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dobly/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754553061,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dwzo3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "k2ui",
            "can_mod_post": false,
            "created_utc": 1754558087,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 1,
            "author_fullname": "t2_6i288",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Absolutely not",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dwzo3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Absolutely not&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dwzo3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754558087,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7e904w",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "evilbarron2",
                      "can_mod_post": false,
                      "created_utc": 1754564344,
                      "send_replies": true,
                      "parent_id": "t1_n7e4i49",
                      "score": 1,
                      "author_fullname": "t2_gr2fr79s1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Software, although some of it deserves your suggestion",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7e904w",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Software, although some of it deserves your suggestion&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e904w/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754564344,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7e4i49",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Lollerstakes",
            "can_mod_post": false,
            "created_utc": 1754562175,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 1,
            "author_fullname": "t2_7i27v",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Does anyone know what \"oss\" stands for? I'd guess that the first o is \"open\" and first s is \"source\", the 2nd s? \"Shit\"?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7e4i49",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know what &amp;quot;oss&amp;quot; stands for? I&amp;#39;d guess that the first o is &amp;quot;open&amp;quot; and first s is &amp;quot;source&amp;quot;, the 2nd s? &amp;quot;Shit&amp;quot;?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7e4i49/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754562175,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dp9ll",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Holly_Shiits",
            "can_mod_post": false,
            "created_utc": 1754553598,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 0,
            "author_fullname": "t2_dcgkj1u3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If it was another chinese company, China fanboys and chicom operators would harass USAF psyops agents again",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dp9ll",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If it was another chinese company, China fanboys and chicom operators would harass USAF psyops agents again&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dp9ll/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754553598,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7doins",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Iory1998",
            "can_mod_post": false,
            "created_utc": 1754553174,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": -3,
            "author_fullname": "t2_byt5wa14",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "No one would care unless it's an American company. Nothing new here. It's the propaganda machine at work to make everyone believe that GPT-OSS is the best open-source model ever released. How can a model be SOTA and yet not be among the top 5? Qwen3-4b-thinking, the best 4b model I ever used, was released and no one talk about it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7doins",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No one would care unless it&amp;#39;s an American company. Nothing new here. It&amp;#39;s the propaganda machine at work to make everyone believe that GPT-OSS is the best open-source model ever released. How can a model be SOTA and yet not be among the top 5? Qwen3-4b-thinking, the best 4b model I ever used, was released and no one talk about it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7doins/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754553174,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dmv5i",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No-Refrigerator-1672",
                      "can_mod_post": false,
                      "created_utc": 1754552215,
                      "send_replies": true,
                      "parent_id": "t1_n7dknp8",
                      "score": -3,
                      "author_fullname": "t2_baavelp5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Of course they did. Every other company either drops the models without notice, or dors just a few humble tweets up to a week prior. OpenAI was milking the OSS for month, starting from the announcement in Spring. I wonder if they needed it for some kind of compliance with investors, government grants, etc.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dmv5i",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Of course they did. Every other company either drops the models without notice, or dors just a few humble tweets up to a week prior. OpenAI was milking the OSS for month, starting from the announcement in Spring. I wonder if they needed it for some kind of compliance with investors, government grants, etc.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjsjkn",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dmv5i/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754552215,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7dknp8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "adalgis231",
            "can_mod_post": false,
            "created_utc": 1754550954,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": -1,
            "author_fullname": "t2_oyfbhun0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think it's quite intentional. OAI did it because of its media exposure",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dknp8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it&amp;#39;s quite intentional. OAI did it because of its media exposure&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dknp8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754550954,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7dsuoa",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "smartdev12",
            "can_mod_post": false,
            "created_utc": 1754555675,
            "send_replies": true,
            "parent_id": "t3_1mjsjkn",
            "score": 0,
            "author_fullname": "t2_14uwv6nva8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I can't even run it",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dsuoa",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t even run it&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjsjkn/if_the_gptoss_models_were_made_by_any_other/n7dsuoa/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754555675,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjsjkn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]