[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "**Qwen3-Coder** is available in multiple sizes. Today, we're excited to introduce **Qwen3-Coder-30B-A3B-Instruct**. This streamlined model maintains impressive performance and efficiency, featuring the following key enhancements:\n\n* **Significant Performance** among open models on **Agentic Coding**, **Agentic Browser-Use**, and other foundational coding tasks.\n* **Long-context Capabilities** with native support for **256K** tokens, extendable up to **1M** tokens using Yarn, optimized for repository-scale understanding.\n* **Agentic Coding** supporting for most platform such as **Qwen Code**, **CLINE**, featuring a specially designed function call format.\n\n**Qwen3-Coder-30B-A3B-Instruct** has the following features:\n\n* Type: Causal Language Models\n* Training Stage: Pretraining &amp; Post-training\n* Number of Parameters: 30.5B in total and 3.3B activated\n* Number of Layers: 48\n* Number of Attention Heads (GQA): 32 for Q and 4 for KV\n* Number of Experts: 128\n* Number of Activated Experts: 8\n* Context Length: **262,144 natively**.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Qwen/Qwen3-Coder-30B-A3B-Instruct Â· Hugging Face",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 75,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1me324b",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.96,
            "author_flair_background_color": "#bbbdbf",
            "ups": 98,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "is_original_content": false,
            "author_fullname": "t2_vqgbql9w",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 98,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=50e58d8c576ff1f0469c49c5086a3d54ed8234ad",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "gildings": {},
            "post_hint": "link",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753972061,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "huggingface.co",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Qwen3-Coder&lt;/strong&gt; is available in multiple sizes. Today, we&amp;#39;re excited to introduce &lt;strong&gt;Qwen3-Coder-30B-A3B-Instruct&lt;/strong&gt;. This streamlined model maintains impressive performance and efficiency, featuring the following key enhancements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Significant Performance&lt;/strong&gt; among open models on &lt;strong&gt;Agentic Coding&lt;/strong&gt;, &lt;strong&gt;Agentic Browser-Use&lt;/strong&gt;, and other foundational coding tasks.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Long-context Capabilities&lt;/strong&gt; with native support for &lt;strong&gt;256K&lt;/strong&gt; tokens, extendable up to &lt;strong&gt;1M&lt;/strong&gt; tokens using Yarn, optimized for repository-scale understanding.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Agentic Coding&lt;/strong&gt; supporting for most platform such as &lt;strong&gt;Qwen Code&lt;/strong&gt;, &lt;strong&gt;CLINE&lt;/strong&gt;, featuring a specially designed function call format.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Qwen3-Coder-30B-A3B-Instruct&lt;/strong&gt; has the following features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Type: Causal Language Models&lt;/li&gt;\n&lt;li&gt;Training Stage: Pretraining &amp;amp; Post-training&lt;/li&gt;\n&lt;li&gt;Number of Parameters: 30.5B in total and 3.3B activated&lt;/li&gt;\n&lt;li&gt;Number of Layers: 48&lt;/li&gt;\n&lt;li&gt;Number of Attention Heads (GQA): 32 for Q and 4 for KV&lt;/li&gt;\n&lt;li&gt;Number of Experts: 128&lt;/li&gt;\n&lt;li&gt;Number of Activated Experts: 8&lt;/li&gt;\n&lt;li&gt;Context Length: &lt;strong&gt;262,144 natively&lt;/strong&gt;.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?auto=webp&amp;s=4cacac54fb0a262f4128b23481bccaf4104c19d5",
                    "width": 1200,
                    "height": 648
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fbf0440b72bf3c599b24d782f0bddf00251537cf",
                      "width": 108,
                      "height": 58
                    },
                    {
                      "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=824bee5d7aa9841a221b2f60a969d54551eccb18",
                      "width": 216,
                      "height": 116
                    },
                    {
                      "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=91ca7f6cb7614731e917c0c8e162bd66bfbc25ca",
                      "width": 320,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d2b1429fc14f5ca152608718fd3ef6d50119778",
                      "width": 640,
                      "height": 345
                    },
                    {
                      "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6655884fe4ff60136ee88021696ace5be4875862",
                      "width": 960,
                      "height": 518
                    },
                    {
                      "url": "https://external-preview.redd.it/IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=991b600ad67e419b1091cac2c8c55f34d86b36fa",
                      "width": 1080,
                      "height": 583
                    }
                  ],
                  "variants": {},
                  "id": "IAGFmaGszKcqSKR_8qg0oES6OBfFDCBNvzr72pbVe7o"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1me324b",
            "is_robot_indexable": true,
            "num_duplicates": 2,
            "report_reasons": null,
            "author": "jacek2023",
            "discussion_type": null,
            "num_comments": 17,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "light",
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/",
            "stickied": false,
            "url": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct",
            "subreddit_subscribers": 508192,
            "created_utc": 1753972061,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n66fqbf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "chisleu",
            "can_mod_post": false,
            "created_utc": 1753974823,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 14,
            "author_fullname": "t2_cbxyn",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Loaded it up into Cline (4 bit) and found it to be:\n\n\\* exceptionally fast, even with large contexts\n\n\\* reasonably good at reasoning about a python code base\n\n\\* not so great at logic.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n66fqbf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Loaded it up into Cline (4 bit) and found it to be:&lt;/p&gt;\n\n&lt;p&gt;* exceptionally fast, even with large contexts&lt;/p&gt;\n\n&lt;p&gt;* reasonably good at reasoning about a python code base&lt;/p&gt;\n\n&lt;p&gt;* not so great at logic.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n66fqbf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753974823,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 14
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n66uje5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "danielhanchen",
                      "can_mod_post": false,
                      "created_utc": 1753978975,
                      "send_replies": true,
                      "parent_id": "t1_n668idp",
                      "score": 5,
                      "author_fullname": "t2_5wukhd4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for linking Unsloth quants :)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n66uje5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for linking Unsloth quants :)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1me324b",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n66uje5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753978975,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n668idp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "jacek2023",
            "can_mod_post": false,
            "created_utc": 1753972796,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 13,
            "author_fullname": "t2_vqgbql9w",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "GGUFs\n\n[https://huggingface.co/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-GGUF](https://huggingface.co/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-GGUF)\n\n[https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF](https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF)\n\n[https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF](https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF)",
            "edited": 1753973349,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n668idp",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GGUFs&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-GGUF\"&gt;https://huggingface.co/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-GGUF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF\"&gt;https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF\"&gt;https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n668idp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753972796,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 13
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n68e7v9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Delicious-Farmer-234",
            "can_mod_post": false,
            "created_utc": 1753994628,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 13,
            "author_fullname": "t2_6x6f3qy5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "https://preview.redd.it/fwuhclqju9gf1.png?width=1302&amp;format=png&amp;auto=webp&amp;s=eb8e48af653cbc2b2fcd9acc7851227c7dafa314\n\nFirst one to create a great working pac-man on the first try.\n\nSystem Prompt:\n\n    You are a code optimization specialist. Your primary role is to analyze and optimize code without altering its core functionality or adding new features. Focus solely on improving performance, readability, and resource utilization while maintaining the exact same behavior and outputs.\n    \n    OPTIMIZATION PRINCIPLES:\n    Maintain Functional Equivalence\n    The optimized code must produce identical outputs for all valid inputs\n    External behaviors and side effects must remain unchanged\n    Preserve all error handling and edge cases\n    Do not add new features or modify existing functionality\n    Performance Optimization Targets\n    Time complexity reduction\n    Memory usage optimization\n    Resource utilization improvement\n    Loop efficiency enhancementRedundant operation elimination\n    \n    Code Quality Preservation\n    Maintain or improve code readability\n    Keep consistent coding style with the project\n    Preserve meaningful variable/function names\n    Retain important comments and documentation\n    Do not sacrifice maintainability for minor optimizations\n    OPTIMIZATION PROCESS:\n    Analysis Phase\n    Identify performance bottlenecks\n    Analyze complexity of algorithms and data structures\n    Review resource usage patterns\n    Detect redundant operations\n    Examine loop structures and conditions\n    Optimization Strategies\n    Replace inefficient algorithms with more optimal alternatives\n    Optimize data structure usage\n    Simplify complex logical expressions\n    Improve loop efficiency (combining, unwinding, or restructuring)\n    Remove unnecessary operations\n    Apply language-specific optimizations\n    Cache frequently accessed values\n    Reduce memory allocations/deallocations\n    Verification Steps\n    Confirm identical functionality\n    Verify all edge cases are preserved\n    Check error handling remains intact\n    Ensure optimization doesn't introduce new bugs\n    Validate performance improvement\n    OUTPUT FORMAT:\n    For each optimization, provide:\n    Original code section\n    Optimized version\n    \n    Explanation of:\n    What was optimized\n    How it improves performance\n    Why it maintains the same functionality\n    Potential trade-offs or considerations\n    CONSTRAINTS:\n    Do not modify:\n    Public interfaces\n    Function signatures\n    Return types\n    Error handling behavior\n    External dependencies\n    Configuration parameters\n    Business logic rules\n    Do not introduce:\n    New dependencies\n    Different algorithms that change accuracy\n    Additional features\n    Modified validation rules\n    Alternative control flows\n    OPTIMIZATION DETAILS:\n    - Performance Impact: [Explain improvement]\n    - Functionality Preservation: [Explain how behavior remains identical]\n    - Implementation Notes: [Describe optimization technique]\n    - Trade-offs: [List any considerations]\n    Remember:\n    Priority is maintaining exact functionality\n    Optimize only when benefits clearly outweigh risks\n    Consider project context and constraints\n    Document all optimizations clearly\n    Focus on significant improvements over minor tweaks\n    Preserve code readability and maintainability\n    Respect existing architectural decisions",
            "edited": 1753995034,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n68e7v9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/fwuhclqju9gf1.png?width=1302&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eb8e48af653cbc2b2fcd9acc7851227c7dafa314\"&gt;https://preview.redd.it/fwuhclqju9gf1.png?width=1302&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eb8e48af653cbc2b2fcd9acc7851227c7dafa314&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;First one to create a great working pac-man on the first try.&lt;/p&gt;\n\n&lt;p&gt;System Prompt:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;You are a code optimization specialist. Your primary role is to analyze and optimize code without altering its core functionality or adding new features. Focus solely on improving performance, readability, and resource utilization while maintaining the exact same behavior and outputs.\n\nOPTIMIZATION PRINCIPLES:\nMaintain Functional Equivalence\nThe optimized code must produce identical outputs for all valid inputs\nExternal behaviors and side effects must remain unchanged\nPreserve all error handling and edge cases\nDo not add new features or modify existing functionality\nPerformance Optimization Targets\nTime complexity reduction\nMemory usage optimization\nResource utilization improvement\nLoop efficiency enhancementRedundant operation elimination\n\nCode Quality Preservation\nMaintain or improve code readability\nKeep consistent coding style with the project\nPreserve meaningful variable/function names\nRetain important comments and documentation\nDo not sacrifice maintainability for minor optimizations\nOPTIMIZATION PROCESS:\nAnalysis Phase\nIdentify performance bottlenecks\nAnalyze complexity of algorithms and data structures\nReview resource usage patterns\nDetect redundant operations\nExamine loop structures and conditions\nOptimization Strategies\nReplace inefficient algorithms with more optimal alternatives\nOptimize data structure usage\nSimplify complex logical expressions\nImprove loop efficiency (combining, unwinding, or restructuring)\nRemove unnecessary operations\nApply language-specific optimizations\nCache frequently accessed values\nReduce memory allocations/deallocations\nVerification Steps\nConfirm identical functionality\nVerify all edge cases are preserved\nCheck error handling remains intact\nEnsure optimization doesn&amp;#39;t introduce new bugs\nValidate performance improvement\nOUTPUT FORMAT:\nFor each optimization, provide:\nOriginal code section\nOptimized version\n\nExplanation of:\nWhat was optimized\nHow it improves performance\nWhy it maintains the same functionality\nPotential trade-offs or considerations\nCONSTRAINTS:\nDo not modify:\nPublic interfaces\nFunction signatures\nReturn types\nError handling behavior\nExternal dependencies\nConfiguration parameters\nBusiness logic rules\nDo not introduce:\nNew dependencies\nDifferent algorithms that change accuracy\nAdditional features\nModified validation rules\nAlternative control flows\nOPTIMIZATION DETAILS:\n- Performance Impact: [Explain improvement]\n- Functionality Preservation: [Explain how behavior remains identical]\n- Implementation Notes: [Describe optimization technique]\n- Trade-offs: [List any considerations]\nRemember:\nPriority is maintaining exact functionality\nOptimize only when benefits clearly outweigh risks\nConsider project context and constraints\nDocument all optimizations clearly\nFocus on significant improvements over minor tweaks\nPreserve code readability and maintainability\nRespect existing architectural decisions\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n68e7v9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753994628,
            "media_metadata": {
              "fwuhclqju9gf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 135,
                    "x": 108,
                    "u": "https://preview.redd.it/fwuhclqju9gf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=48f219b01b83367ec7df370a6bb6fd57d2e607c4"
                  },
                  {
                    "y": 270,
                    "x": 216,
                    "u": "https://preview.redd.it/fwuhclqju9gf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=42a0aba98ef9f06934943493803ff8b3f92b8d52"
                  },
                  {
                    "y": 400,
                    "x": 320,
                    "u": "https://preview.redd.it/fwuhclqju9gf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=130a5f12bc3da8164e217956e880674ccf3771c4"
                  },
                  {
                    "y": 801,
                    "x": 640,
                    "u": "https://preview.redd.it/fwuhclqju9gf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b618635353b319028a38aad0a82b89ca16818000"
                  },
                  {
                    "y": 1202,
                    "x": 960,
                    "u": "https://preview.redd.it/fwuhclqju9gf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7965bb538a5a8deb8e72de80f16ac9ad2787ee2f"
                  },
                  {
                    "y": 1352,
                    "x": 1080,
                    "u": "https://preview.redd.it/fwuhclqju9gf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cc0e1edcfd08d2573307771adfe4e709885206cb"
                  }
                ],
                "s": {
                  "y": 1631,
                  "x": 1302,
                  "u": "https://preview.redd.it/fwuhclqju9gf1.png?width=1302&amp;format=png&amp;auto=webp&amp;s=eb8e48af653cbc2b2fcd9acc7851227c7dafa314"
                },
                "id": "fwuhclqju9gf1"
              }
            },
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 13
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n66uh9w",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "danielhanchen",
            "can_mod_post": false,
            "created_utc": 1753978958,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 5,
            "author_fullname": "t2_5wukhd4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I uploaded GGUF dynamic quants at https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF and also 1 million variants to https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF\n\nAlso fixed tool calling to the 30B and also the 480B version! Docs to run them at https://docs.unsloth.ai/basics/qwen3-coder-how-to-run-locally",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n66uh9w",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I uploaded GGUF dynamic quants at &lt;a href=\"https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF\"&gt;https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF&lt;/a&gt; and also 1 million variants to &lt;a href=\"https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF\"&gt;https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-1M-GGUF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also fixed tool calling to the 30B and also the 480B version! Docs to run them at &lt;a href=\"https://docs.unsloth.ai/basics/qwen3-coder-how-to-run-locally\"&gt;https://docs.unsloth.ai/basics/qwen3-coder-how-to-run-locally&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n66uh9w/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753978958,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n666oj1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "matteogeniaccio",
            "can_mod_post": false,
            "created_utc": 1753972270,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 3,
            "author_fullname": "t2_hoxc8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Are there benchmarks for comparison with other LLMs?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n666oj1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Are there benchmarks for comparison with other LLMs?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n666oj1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753972270,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n666514",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "jamaalwakamaal",
            "can_mod_post": false,
            "created_utc": 1753972115,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 3,
            "author_fullname": "t2_alyeos2m",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Phenomenal.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n666514",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Phenomenal.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n666514/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753972115,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n68begs",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AcanthaceaeNo5503",
            "can_mod_post": false,
            "created_utc": 1753993842,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 2,
            "author_fullname": "t2_lf934x92k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Need some dense model hix. I'm still using qwen2.5 coder",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n68begs",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Need some dense model hix. I&amp;#39;m still using qwen2.5 coder&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n68begs/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753993842,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n68id0n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "soteko",
            "can_mod_post": false,
            "created_utc": 1753995805,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 2,
            "author_fullname": "t2_4k4gcx79",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Tested and I couldn't believe that we will have usable model running on CPU with something like 7-8 t/s on 11700 and 64gb ddr4. \n\nGreat job.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n68id0n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Tested and I couldn&amp;#39;t believe that we will have usable model running on CPU with something like 7-8 t/s on 11700 and 64gb ddr4. &lt;/p&gt;\n\n&lt;p&gt;Great job.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n68id0n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753995805,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n683l1l",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "Eugr",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n681vg3",
                                                    "score": 1,
                                                    "author_fullname": "t2_f3l6q",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Yeah, I have the newest version from Unsloth. Tool calling in general is not an issue, Cline, VSCode, my own pipelines all work just fine. It's just Qwen Code that doesn't work with it. Not a big deal, but I wanted to try it.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n683l1l",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, I have the newest version from Unsloth. Tool calling in general is not an issue, Cline, VSCode, my own pipelines all work just fine. It&amp;#39;s just Qwen Code that doesn&amp;#39;t work with it. Not a big deal, but I wanted to try it.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1me324b",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n683l1l/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753991625,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753991625,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n681vg3",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Fast-Satisfaction482",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n680t1b",
                                          "score": 1,
                                          "author_fullname": "t2_9ceux4xp",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "The unsloth quant page on hf mentions that they \"fixed tool calling\", maybe what you experience is the broken version? https://docs.unsloth.ai/basics/qwen3-coder-how-to-run-locally#run-qwen3-coder-30b-a3b-instruct\n\n\n\nI tried the unsloth version with ollama and VS code. Their tool calling worked for me. Even with my own MCP tools.\n\n\nThough it seems to stop early after a few tool calls and I'm not sure why.Â ",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n681vg3",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The unsloth quant page on hf mentions that they &amp;quot;fixed tool calling&amp;quot;, maybe what you experience is the broken version? &lt;a href=\"https://docs.unsloth.ai/basics/qwen3-coder-how-to-run-locally#run-qwen3-coder-30b-a3b-instruct\"&gt;https://docs.unsloth.ai/basics/qwen3-coder-how-to-run-locally#run-qwen3-coder-30b-a3b-instruct&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I tried the unsloth version with ollama and VS code. Their tool calling worked for me. Even with my own MCP tools.&lt;/p&gt;\n\n&lt;p&gt;Though it seems to stop early after a few tool calls and I&amp;#39;m not sure why.Â &lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1me324b",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n681vg3/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753991133,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753991133,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n680t1b",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Eugr",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n67zi0l",
                                "score": 1,
                                "author_fullname": "t2_f3l6q",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "No, I tried with 32K and even 128K. Debug logs in llama.cpp show some errors parsing the requests. Looks like you need to plug their own python tool calling parser to make it work. Not sure if llama.cpp supports it.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n680t1b",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, I tried with 32K and even 128K. Debug logs in llama.cpp show some errors parsing the requests. Looks like you need to plug their own python tool calling parser to make it work. Not sure if llama.cpp supports it.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1me324b",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n680t1b/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753990819,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753990819,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n67zi0l",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Fast-Satisfaction482",
                      "can_mod_post": false,
                      "created_utc": 1753990433,
                      "send_replies": true,
                      "parent_id": "t1_n678u9k",
                      "score": 1,
                      "author_fullname": "t2_9ceux4xp",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Maybe the context length is set too short?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n67zi0l",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe the context length is set too short?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1me324b",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n67zi0l/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753990433,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n678u9k",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Eugr",
            "can_mod_post": false,
            "created_utc": 1753982928,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 1,
            "author_fullname": "t2_f3l6q",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Anyone had any luck using locally with qwen code? I tried with Ollama and LMStudio, and it fails on tool calls. Cline works perfectly, though.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n678u9k",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Anyone had any luck using locally with qwen code? I tried with Ollama and LMStudio, and it fails on tool calls. Cline works perfectly, though.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n678u9k/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753982928,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6887so",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "RiskyBizz216",
            "can_mod_post": false,
            "created_utc": 1753992950,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 1,
            "author_fullname": "t2_4eu8nupk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "initial impressions are not good. it does not follow instructions vey well and it struggles with tool usage.\n\n  \nfor this one, anything under Q6 is brain dead",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6887so",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;initial impressions are not good. it does not follow instructions vey well and it struggles with tool usage.&lt;/p&gt;\n\n&lt;p&gt;for this one, anything under Q6 is brain dead&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n6887so/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753992950,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n67xli2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "jacek2023",
                      "can_mod_post": false,
                      "created_utc": 1753989874,
                      "send_replies": true,
                      "parent_id": "t1_n67j2op",
                      "score": 1,
                      "author_fullname": "t2_vqgbql9w",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I don't think so, Q3 maybe?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n67xli2",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t think so, Q3 maybe?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1me324b",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n67xli2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753989874,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n67j2op",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "urekmazino_0",
            "can_mod_post": false,
            "created_utc": 1753985719,
            "send_replies": true,
            "parent_id": "t3_1me324b",
            "score": 0,
            "author_fullname": "t2_oebv0z6s",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Can I run it on my 16gb MacBook?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n67j2op",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can I run it on my 16gb MacBook?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1me324b/qwenqwen3coder30ba3binstruct_hugging_face/n67j2op/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753985719,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1me324b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]