[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I have seen thousands of posts of people asking what card to buy and there is two points of view. One is buy expensive 3090, or even more expensive 5000 series or, buy cheap and try it. This post will cover why the P102-100 is still relevant and why it is simply the best budget card to get at 60 dollars.\n\nIf you are just doing LLM, Vision and no image or video generation. This is hands down the best budget card to get all because of its memory bandwidth. This list covers entry level cards form all series. Yes I know there are better cards but I am comparing the P102-100 with all entry level cards only and those better cards are 10x more.This is for the budget build people.\n\n2060 - 336.0 GB/s - $150 8GB  \n3060 - 360.0 GB/s - $200+ 8GB\n\n4060 - 272.0 GB/s - $260+ 8GB\n\n5060 - 448.0 GB/s - $350+ 8GB\n\nP102-100 - 440.3 GB/s - $60 10GB.\n\nIs the P102-100 faster than an\n\nentry 2060 = yes\n\nentry 3060 = yes\n\nentry 4060 = yes.\n\nonly a 5060 would be faster and not by much.\n\nDoes the P102-100 load slower, yes it takes about 1 second per GB on the model. PCie 1x4 =1GB/s but once the model is leaded it will be normal with no delays on all your queries.\n\nI have attached screenshots of a bunch of models, all with 32K context so you can see what to expect. Compare those results with other entry cards using the same 32K context and you will for yourself. Make sure they are using 32K context as the P102-100 would also be faster with lower context.\n\nso if you want to try LLM's and not go broke, the P102-100 is a solid card to try for 60 bucks. I have 2 of them and those results are using 2 cards so I have 20GB VRAM for 70 bucks at 35 each when I bought them. Now they would be 120 bucks. I am not sure if you can get 20GB VRAM for less than is as fast as this.\n\nI hope this helps other people that have been afraid to try local private ai because of the costs. I hope this motivates you to at least try. It is just 60 bucks.\n\nI will probably be updating this next week as I have a third card and I am moving up to 30GB. I should be able to run these models with higher context, 128k, 256k and even bigger models. I will post some updates for anyone interested.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "is the P102-100 still a viable option for LLM?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 140,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mgdh6r",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.8,
            "author_flair_background_color": null,
            "ups": 9,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_vnvnb9oa",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 9,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/ZS0zNrB2tczhH3IbcM5RQIgldEEZAXIMP8grHZwjSys.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754207144,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have seen thousands of posts of people asking what card to buy and there is two points of view. One is buy expensive 3090, or even more expensive 5000 series or, buy cheap and try it. This post will cover why the P102-100 is still relevant and why it is simply the best budget card to get at 60 dollars.&lt;/p&gt;\n\n&lt;p&gt;If you are just doing LLM, Vision and no image or video generation. This is hands down the best budget card to get all because of its memory bandwidth. This list covers entry level cards form all series. Yes I know there are better cards but I am comparing the P102-100 with all entry level cards only and those better cards are 10x more.This is for the budget build people.&lt;/p&gt;\n\n&lt;p&gt;2060 - 336.0 GB/s - $150 8GB&lt;br/&gt;\n3060 - 360.0 GB/s - $200+ 8GB&lt;/p&gt;\n\n&lt;p&gt;4060 - 272.0 GB/s - $260+ 8GB&lt;/p&gt;\n\n&lt;p&gt;5060 - 448.0 GB/s - $350+ 8GB&lt;/p&gt;\n\n&lt;p&gt;P102-100 - 440.3 GB/s - $60 10GB.&lt;/p&gt;\n\n&lt;p&gt;Is the P102-100 faster than an&lt;/p&gt;\n\n&lt;p&gt;entry 2060 = yes&lt;/p&gt;\n\n&lt;p&gt;entry 3060 = yes&lt;/p&gt;\n\n&lt;p&gt;entry 4060 = yes.&lt;/p&gt;\n\n&lt;p&gt;only a 5060 would be faster and not by much.&lt;/p&gt;\n\n&lt;p&gt;Does the P102-100 load slower, yes it takes about 1 second per GB on the model. PCie 1x4 =1GB/s but once the model is leaded it will be normal with no delays on all your queries.&lt;/p&gt;\n\n&lt;p&gt;I have attached screenshots of a bunch of models, all with 32K context so you can see what to expect. Compare those results with other entry cards using the same 32K context and you will for yourself. Make sure they are using 32K context as the P102-100 would also be faster with lower context.&lt;/p&gt;\n\n&lt;p&gt;so if you want to try LLM&amp;#39;s and not go broke, the P102-100 is a solid card to try for 60 bucks. I have 2 of them and those results are using 2 cards so I have 20GB VRAM for 70 bucks at 35 each when I bought them. Now they would be 120 bucks. I am not sure if you can get 20GB VRAM for less than is as fast as this.&lt;/p&gt;\n\n&lt;p&gt;I hope this helps other people that have been afraid to try local private ai because of the costs. I hope this motivates you to at least try. It is just 60 bucks.&lt;/p&gt;\n\n&lt;p&gt;I will probably be updating this next week as I have a third card and I am moving up to 30GB. I should be able to run these models with higher context, 128k, 256k and even bigger models. I will post some updates for anyone interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/oy25ru8gergf1.png",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/oy25ru8gergf1.png?auto=webp&amp;s=2cb0173f8f29e9ebb6d02dbbb0f1f6505163ed23",
                    "width": 1920,
                    "height": 4096
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/oy25ru8gergf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6ead78ede2dee21c50ed7920d88cdc0f039342ea",
                      "width": 108,
                      "height": 216
                    },
                    {
                      "url": "https://preview.redd.it/oy25ru8gergf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=21261a21b67d3216bb8f5267a2eab08d1c3e30f8",
                      "width": 216,
                      "height": 432
                    },
                    {
                      "url": "https://preview.redd.it/oy25ru8gergf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=716e70095d944e7d0d07c12b2d069e03b9f72dc9",
                      "width": 320,
                      "height": 640
                    },
                    {
                      "url": "https://preview.redd.it/oy25ru8gergf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bd72000cba8efed634dc539ff393fe099624df46",
                      "width": 640,
                      "height": 1280
                    },
                    {
                      "url": "https://preview.redd.it/oy25ru8gergf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c4cccd911c998a5d7c914cf44d2385aae56de54c",
                      "width": 960,
                      "height": 1920
                    },
                    {
                      "url": "https://preview.redd.it/oy25ru8gergf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ee00d9096b93e074ccad355d7571f837459808a",
                      "width": 1080,
                      "height": 2160
                    }
                  ],
                  "variants": {},
                  "id": "tb8jcmr9JwUFdjGqCEioOHi2smnbOEbTGPoqKGaYDxE"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mgdh6r",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Boricua-vet",
            "discussion_type": null,
            "num_comments": 29,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/",
            "stickied": false,
            "url": "https://i.redd.it/oy25ru8gergf1.png",
            "subreddit_subscribers": 509626,
            "created_utc": 1754207144,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6o2y7m",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "AppearanceHeavy6724",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6o1kii",
                                                    "score": 2,
                                                    "author_fullname": "t2_uz37qfx5",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "&gt; Context is king. You have a 12GB right? Show me where the guy said it is faster than a 3060 12GB?\n\nIt is implied, as bandwidth of p102-100 is 1.3 times higher than of 3060. \n\n&gt; You are taking his post out of context.\n\nYou have a wrong context altogether.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6o2y7m",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Context is king. You have a 12GB right? Show me where the guy said it is faster than a 3060 12GB?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It is implied, as bandwidth of p102-100 is 1.3 times higher than of 3060. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;You are taking his post out of context.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You have a wrong context altogether.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mgdh6r",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6o2y7m/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754213807,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754213807,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6o1kii",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "1eyedsnak3",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6nxl7h",
                                          "score": 1,
                                          "author_fullname": "t2_mmut177a",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Context is king. You have a 12GB right? Show me where the guy said it is faster than a 3060 12GB? He was very clear and specific about the 8GB 3060. The entry level 3060 is the 8GB model.\n\nYou are taking his post out of context.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6o1kii",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Context is king. You have a 12GB right? Show me where the guy said it is faster than a 3060 12GB? He was very clear and specific about the 8GB 3060. The entry level 3060 is the 8GB model.&lt;/p&gt;\n\n&lt;p&gt;You are taking his post out of context.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mgdh6r",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6o1kii/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754212967,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754212967,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6nxl7h",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "AppearanceHeavy6724",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6nudum",
                                "score": 2,
                                "author_fullname": "t2_uz37qfx5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; Hmmm maybe yours but there are 8gb versions.\n\nthe ones that cost $200 used are 12 GiB.\n\n&gt; Also p102-100 does have FP16. Not the fastest but it does.\n\nIt is emulated, therefore it is laughably slow, as it is slower than cpu which pulls perhaps 250 GFlops. Anyway Llama.cpp uses 32 bit precision kernels with this card, this is why it has about half PP speed than 3060 - I on 3060 have slightly faster token generation than yours, but vastly faster prompt processing.\n\n&gt; Flash attention is good but at the end of the day, as far as token generation goes the p102-100 would be faster even without FA.\n\nNo it will not, not with any reasonable amount of data in context, as with growth of context memory bandwidth becomes less important than fp16 compute. Even on empty context you card has about same speed as 3060. \n\nI myself own 3060 and p104-100. On paper they have about same bandwidth, but in reality p104-100 performance is about 60-70% of \n3060.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6nxl7h",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Hmmm maybe yours but there are 8gb versions.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;the ones that cost $200 used are 12 GiB.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Also p102-100 does have FP16. Not the fastest but it does.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It is emulated, therefore it is laughably slow, as it is slower than cpu which pulls perhaps 250 GFlops. Anyway Llama.cpp uses 32 bit precision kernels with this card, this is why it has about half PP speed than 3060 - I on 3060 have slightly faster token generation than yours, but vastly faster prompt processing.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Flash attention is good but at the end of the day, as far as token generation goes the p102-100 would be faster even without FA.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No it will not, not with any reasonable amount of data in context, as with growth of context memory bandwidth becomes less important than fp16 compute. Even on empty context you card has about same speed as 3060. &lt;/p&gt;\n\n&lt;p&gt;I myself own 3060 and p104-100. On paper they have about same bandwidth, but in reality p104-100 performance is about 60-70% of \n3060.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgdh6r",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6nxl7h/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754210574,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754210574,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "text",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": null,
                                                                                            "likes": null,
                                                                                            "replies": "",
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n6qb0p7",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": true,
                                                                                            "author": "AppearanceHeavy6724",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1754243361,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n6pz6hy",
                                                                                            "score": 2,
                                                                                            "author_fullname": "t2_uz37qfx5",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "You do not believe 3060 has 360Gb/sec or what? I do not use ollama, it is for noobs, Anywhere here is a test 3060 vs 1080ti (same as p102-100). [https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080\\_ti\\_vs\\_3060\\_12gb/](https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080_ti_vs_3060_12gb/)",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n6qb0p7",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You do not believe 3060 has 360Gb/sec or what? I do not use ollama, it is for noobs, Anywhere here is a test 3060 vs 1080ti (same as p102-100). &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080_ti_vs_3060_12gb/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080_ti_vs_3060_12gb/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": null,
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6qb0p7/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1754243361,
                                                                                            "author_flair_text": null,
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1mgdh6r",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": null,
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 2
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n6pz6hy",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": true,
                                                                                  "author": "1eyedsnak3",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754239835,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n6o4ta8",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_mmut177a",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "Tell you what, the only way I will bent the knee is by you proving it. Replicate Qwen3 14b 32768 context with same 3 outputs . Ollama ps, nvidia-smi and token stats from openwebui.\nShow me. I have no problem admitting what you state but not with just words.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n6pz6hy",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Tell you what, the only way I will bent the knee is by you proving it. Replicate Qwen3 14b 32768 context with same 3 outputs . Ollama ps, nvidia-smi and token stats from openwebui.\nShow me. I have no problem admitting what you state but not with just words.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mgdh6r",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6pz6hy/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754239835,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n6o4ta8",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "AppearanceHeavy6724",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n6o4a7y",
                                                                        "score": 2,
                                                                        "author_fullname": "t2_uz37qfx5",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "I am sorry for being blunt but you either a dimwit or a troll. The main point, both yours and the op's was than bandwidth is king. 3060 8 GiB and 12 GiB have same 360 Gb/sec bandwidth. Do you understand what that means?",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n6o4ta8",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am sorry for being blunt but you either a dimwit or a troll. The main point, both yours and the op&amp;#39;s was than bandwidth is king. 3060 8 GiB and 12 GiB have same 360 Gb/sec bandwidth. Do you understand what that means?&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mgdh6r",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6o4ta8/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754214912,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754214912,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 2
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6o4a7y",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "1eyedsnak3",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6o1cvr",
                                                              "score": 1,
                                                              "author_fullname": "t2_mmut177a",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Naaa, again you are out of the context zone. The 3060 8GB which he clearly stated would choke out of memory with most of those models, no way they would beat the p102-100.\n\nYou are are trying to add a card Which op clearly stated that there are better cards like yours but he was only comparing to 8GB models. \n\nIf op, had said 12GB, I would agree with you 100% but op was very clear about it, he is comparing to entry level 8 GB cards. So nin that context, op is right.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6o4a7y",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Naaa, again you are out of the context zone. The 3060 8GB which he clearly stated would choke out of memory with most of those models, no way they would beat the p102-100.&lt;/p&gt;\n\n&lt;p&gt;You are are trying to add a card Which op clearly stated that there are better cards like yours but he was only comparing to 8GB models. &lt;/p&gt;\n\n&lt;p&gt;If op, had said 12GB, I would agree with you 100% but op was very clear about it, he is comparing to entry level 8 GB cards. So nin that context, op is right.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mgdh6r",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6o4a7y/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754214604,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754214604,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6o1cvr",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "AppearanceHeavy6724",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6o0b6j",
                                                    "score": 1,
                                                    "author_fullname": "t2_uz37qfx5",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "&gt; In LLM, bandwidth is king.\n\nI used to think like that too. But this is true only on empty context. For tasks where context caching is not helpful, such as rag or coding, prompt processing speed is very important. besides low-compute card will be much slower at 8-16k (IMO most useful range) of context than slightly lower bandwidth higher compute card.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6o1cvr",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;In LLM, bandwidth is king.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I used to think like that too. But this is true only on empty context. For tasks where context caching is not helpful, such as rag or coding, prompt processing speed is very important. besides low-compute card will be much slower at 8-16k (IMO most useful range) of context than slightly lower bandwidth higher compute card.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mgdh6r",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6o1cvr/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754212837,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754212837,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": "",
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n6r8k5k",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": true,
                                                                                  "author": "DorphinPack",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754253711,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n6r8dat",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_zebuyjw9s",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "This is the basic info Im asking for and I feel not great about myself for needing it that way. But I did. And that is okay. Thank you.\n\nI know people dont do this online usually but Ill cop to how dumb Ive been about this  for some reason you laying out clearly sparked the clarity of mind to actually look at the FA repos notes about support. I still feel like I am seeing some it depends with them back porting FA2 to Pascal and there being exceptions with datatypes.\n\nIve been literally peeking at how backends integrate FA to try to glean this info. Instead of remembering FA is its own project with a README.\n\nId feel worse about it if private conversations with other people didnt help me realize Im not alone.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n6r8k5k",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is the basic info Im asking for and I feel not great about myself for needing it that way. But I did. And that is okay. Thank you.&lt;/p&gt;\n\n&lt;p&gt;I know people dont do this online usually but Ill cop to how dumb Ive been about this  for some reason you laying out clearly sparked the clarity of mind to actually look at the FA repos notes about support. I still feel like I am seeing some it depends with them back porting FA2 to Pascal and there being exceptions with datatypes.&lt;/p&gt;\n\n&lt;p&gt;Ive been literally peeking at how backends integrate FA to try to glean this info. Instead of remembering FA is its own project with a README.&lt;/p&gt;\n\n&lt;p&gt;Id feel worse about it if private conversations with other people didnt help me realize Im not alone.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mgdh6r",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6r8k5k/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754253711,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n6r8dat",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "DorphinPack",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n6qup7y",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_zebuyjw9s",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "This is the basic info Im asking for and I feel not great about myself for needing it that way. But I did. And that is okay. Thank you.\n\nI know people dont do this online usually but Ill cop to how dumb Ive been about this  for some reason you laying out clearly sparked the clarity of mind to actually look at the FA repos notes about support and felt like I was seeing a lot of it depends with them back porting FA2 to Pascal and there being exceptions with datatypes.\n\nIve been literally peeking at how backends integrate FA to try to glean this info. Instead of remembering FA is its own project with a README.\n\nId feel worse about it if private conversations with other people didnt help me realize Im not alone.",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n6r8dat",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is the basic info Im asking for and I feel not great about myself for needing it that way. But I did. And that is okay. Thank you.&lt;/p&gt;\n\n&lt;p&gt;I know people dont do this online usually but Ill cop to how dumb Ive been about this  for some reason you laying out clearly sparked the clarity of mind to actually look at the FA repos notes about support and felt like I was seeing a lot of it depends with them back porting FA2 to Pascal and there being exceptions with datatypes.&lt;/p&gt;\n\n&lt;p&gt;Ive been literally peeking at how backends integrate FA to try to glean this info. Instead of remembering FA is its own project with a README.&lt;/p&gt;\n\n&lt;p&gt;Id feel worse about it if private conversations with other people didnt help me realize Im not alone.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mgdh6r",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6r8dat/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754253653,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754253653,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6qup7y",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "tmvr",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6o2iv4",
                                                              "score": 2,
                                                              "author_fullname": "t2_11qlhv",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "It's not that complicated. Pascal (GTX 1000) does not support FA, Turing (RTX 2000) supports FA1 and Ampere (RTX 3000) and later support FA2.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6qup7y",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s not that complicated. Pascal (GTX 1000) does not support FA, Turing (RTX 2000) supports FA1 and Ampere (RTX 3000) and later support FA2.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mgdh6r",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6qup7y/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754249426,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754249426,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6o2iv4",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "DorphinPack",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6o0b6j",
                                                    "score": 1,
                                                    "author_fullname": "t2_zebuyjw9s",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Ah, whoops! I am trying to ask what you're looking at in the hardware specs. I simply don't understand how people know which cards support FA.\n\nWhen I say black magic I mean that the spec sheets still read like incantations to me.\n\nFor instance: I see all the cards in this web UI you've linked have flops listed for half/full/double but I guess you have to cross reference the generation by Googling to see why and some of the more subtle implications. Also, I feel like I can't find good numbers on int8 performance anywhere...\n\nSorry I just feel like I'm missing something when it comes to comparing GPUs lol",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6o2iv4",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah, whoops! I am trying to ask what you&amp;#39;re looking at in the hardware specs. I simply don&amp;#39;t understand how people know which cards support FA.&lt;/p&gt;\n\n&lt;p&gt;When I say black magic I mean that the spec sheets still read like incantations to me.&lt;/p&gt;\n\n&lt;p&gt;For instance: I see all the cards in this web UI you&amp;#39;ve linked have flops listed for half/full/double but I guess you have to cross reference the generation by Googling to see why and some of the more subtle implications. Also, I feel like I can&amp;#39;t find good numbers on int8 performance anywhere...&lt;/p&gt;\n\n&lt;p&gt;Sorry I just feel like I&amp;#39;m missing something when it comes to comparing GPUs lol&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mgdh6r",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6o2iv4/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754213552,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754213552,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6o0b6j",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "1eyedsnak3",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6nwl33",
                                          "score": 1,
                                          "author_fullname": "t2_mmut177a",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Simple, get a 3060 8GB, use the same models with 32k context and see how much lower the token generation is using the same question he used. There is no black magic. All the advancements  like FA, higher cuda version will not matter when the 3060 8GB model has less bandwidth. It is chocked by the bandwidth. Same as the 4060 8GB. In LLM, bandwidth is king.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6o0b6j",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Simple, get a 3060 8GB, use the same models with 32k context and see how much lower the token generation is using the same question he used. There is no black magic. All the advancements  like FA, higher cuda version will not matter when the 3060 8GB model has less bandwidth. It is chocked by the bandwidth. Same as the 4060 8GB. In LLM, bandwidth is king.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mgdh6r",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6o0b6j/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754212203,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754212203,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": "",
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n6rr93c",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": true,
                                                                                  "author": "Boricua-vet",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754259668,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n6rb47w",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_vnvnb9oa",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "According to this.\n\n[https://www.reddit.com/r/ollama/comments/1iref1e/amd\\_instinct\\_mi50\\_detailed\\_benchmarks\\_in\\_ollama/](https://www.reddit.com/r/ollama/comments/1iref1e/amd_instinct_mi50_detailed_benchmarks_in_ollama/)\n\nit does work and ollama uses rocm built in library but there is not enough data in there to tell how well it works. I am just gonna take a gamble and buy one and if it works, I will selling my p102-100's and get three Mi50's for 48GB of VRAM which should allow me to do a lot of things I cannot do now. If it works or not, I will make a post about it so others can benefit from having a full suite of tests with as many models as I can. \n\nThanks for the tip.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n6rr93c",
                                                                                  "is_submitter": true,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;According to this.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/ollama/comments/1iref1e/amd_instinct_mi50_detailed_benchmarks_in_ollama/\"&gt;https://www.reddit.com/r/ollama/comments/1iref1e/amd_instinct_mi50_detailed_benchmarks_in_ollama/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;it does work and ollama uses rocm built in library but there is not enough data in there to tell how well it works. I am just gonna take a gamble and buy one and if it works, I will selling my p102-100&amp;#39;s and get three Mi50&amp;#39;s for 48GB of VRAM which should allow me to do a lot of things I cannot do now. If it works or not, I will make a post about it so others can benefit from having a full suite of tests with as many models as I can. &lt;/p&gt;\n\n&lt;p&gt;Thanks for the tip.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mgdh6r",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6rr93c/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754259668,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n6rb47w",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "DorphinPack",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n6qu5m1",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_zebuyjw9s",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "One thing thats help your research is to separate the backend from the engine. \n\nBackends sit between the engine and the hardware. So if Ollama (the engine) supports Mi50 that means there is a ROCm (the backend) version that supports both.\n\nPretty much every GPU can use the Vulkan backend but its slow, albeit still with a real edge over CPU on modern cards.",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n6rb47w",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;One thing thats help your research is to separate the backend from the engine. &lt;/p&gt;\n\n&lt;p&gt;Backends sit between the engine and the hardware. So if Ollama (the engine) supports Mi50 that means there is a ROCm (the backend) version that supports both.&lt;/p&gt;\n\n&lt;p&gt;Pretty much every GPU can use the Vulkan backend but its slow, albeit still with a real edge over CPU on modern cards.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mgdh6r",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6rb47w/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754254481,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754254481,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6qu5m1",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Boricua-vet",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6qnlbg",
                                                              "score": 1,
                                                              "author_fullname": "t2_vnvnb9oa",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Mi50 was the other card I was looking at but then I saw it had no cooling and support. Although I think ollama supports it. I might just spend the 100 bucks to get one and test it. I know it will be a lot faster than the p102-100 and it would also allow me to run much bigger models. They are so big though. I have to see if I can fit them on my P520 case.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6qu5m1",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mi50 was the other card I was looking at but then I saw it had no cooling and support. Although I think ollama supports it. I might just spend the 100 bucks to get one and test it. I know it will be a lot faster than the p102-100 and it would also allow me to run much bigger models. They are so big though. I have to see if I can fit them on my P520 case.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mgdh6r",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6qu5m1/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754249253,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754249253,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6qnlbg",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "DorphinPack",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6qmhq5",
                                                    "score": 1,
                                                    "author_fullname": "t2_zebuyjw9s",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "I do understand the memory bandwidth portion. Its why I was thrilled to find a cheap 3090 and often tell people Nvidia fucked up with that card and well never get another one at its price point\n\nMy new goal is to get a feel for the actual compute performance because it DOES matter.\n\nAlso re: the Mi50 it really is a shame ROCm doesnt stay backward compatible for long because I think the window is going to close on those cards way before their time.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6qnlbg",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I do understand the memory bandwidth portion. Its why I was thrilled to find a cheap 3090 and often tell people Nvidia fucked up with that card and well never get another one at its price point&lt;/p&gt;\n\n&lt;p&gt;My new goal is to get a feel for the actual compute performance because it DOES matter.&lt;/p&gt;\n\n&lt;p&gt;Also re: the Mi50 it really is a shame ROCm doesnt stay backward compatible for long because I think the window is going to close on those cards way before their time.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mgdh6r",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6qnlbg/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754247201,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754247201,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6qmhq5",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Boricua-vet",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6nwl33",
                                          "score": 1,
                                          "author_fullname": "t2_vnvnb9oa",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I don't, the p102-100 does not have FA and does not need it to be fast. I just look at the memory bandwidth of the card. another example would be the Mi50, it has no cuda, no FA, you can get it for 99 bucks and it will run circles around the P102-100 and 3060 as it has 1TB bandwidth.\n\nNewer does not always equate better specially when it comes to nvidia. \n\n  \nin simple terms, memory bandwidth is a funnel. the higher the bandwidth the bigger the hole at the end of the funnel which will allow more liquid to pass through faster. That goes for token generation and processing. \n\nexample 4060 8GB has 272GB memory bandwidth.\n\nP102-100 has 448GB memory bandwidth.\n\n\n\nnow imagine having a funnel with the end of it being 272mm and another being 448mm\n\nwhich one will flow more liquid though it? The 448mm would flow 39% more liquid through it.\n\nThat is the logic in simple terms. It does not exactly translate to exactly to 39% faster, it just means it will be faster.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6qmhq5",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t, the p102-100 does not have FA and does not need it to be fast. I just look at the memory bandwidth of the card. another example would be the Mi50, it has no cuda, no FA, you can get it for 99 bucks and it will run circles around the P102-100 and 3060 as it has 1TB bandwidth.&lt;/p&gt;\n\n&lt;p&gt;Newer does not always equate better specially when it comes to nvidia. &lt;/p&gt;\n\n&lt;p&gt;in simple terms, memory bandwidth is a funnel. the higher the bandwidth the bigger the hole at the end of the funnel which will allow more liquid to pass through faster. That goes for token generation and processing. &lt;/p&gt;\n\n&lt;p&gt;example 4060 8GB has 272GB memory bandwidth.&lt;/p&gt;\n\n&lt;p&gt;P102-100 has 448GB memory bandwidth.&lt;/p&gt;\n\n&lt;p&gt;now imagine having a funnel with the end of it being 272mm and another being 448mm&lt;/p&gt;\n\n&lt;p&gt;which one will flow more liquid though it? The 448mm would flow 39% more liquid through it.&lt;/p&gt;\n\n&lt;p&gt;That is the logic in simple terms. It does not exactly translate to exactly to 39% faster, it just means it will be faster.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mgdh6r",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6qmhq5/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754246863,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754246863,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6nwl33",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DorphinPack",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6nudum",
                                "score": 1,
                                "author_fullname": "t2_zebuyjw9s",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "This is touching on an area that still feels like black magic to me.\n\nWould you be willing to explain what youre looking at specifically when comparing specs for LLM work? How are you determining FA support? Just from it being Pascal?\n\nI feel like Im struggling to get a feel for the GPU landscape beyond memory size and bandwidth. The actual compute is a lot more complex once you care about which operations you use and Im so curious.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6nwl33",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is touching on an area that still feels like black magic to me.&lt;/p&gt;\n\n&lt;p&gt;Would you be willing to explain what youre looking at specifically when comparing specs for LLM work? How are you determining FA support? Just from it being Pascal?&lt;/p&gt;\n\n&lt;p&gt;I feel like Im struggling to get a feel for the GPU landscape beyond memory size and bandwidth. The actual compute is a lot more complex once you care about which operations you use and Im so curious.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgdh6r",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6nwl33/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754209971,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754209971,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6nudum",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "1eyedsnak3",
                      "can_mod_post": false,
                      "created_utc": 1754208663,
                      "send_replies": true,
                      "parent_id": "t1_n6nsn95",
                      "score": 2,
                      "author_fullname": "t2_mmut177a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Hmmm maybe yours but there are 8gb versions.\n\nhttps://www.techpowerup.com/gpu-specs/geforce-rtx-3060-8-gb.c3937\n\nAlso p102-100 does have FP16. Not the fastest but it does.\n\nhttps://www.techpowerup.com/gpu-specs/p102-100.c3100\n\nFlash attention is good but at the end of the day, as far as token generation goes the p102-100 would be faster even without FA.",
                      "edited": 1754209254,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6nudum",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hmmm maybe yours but there are 8gb versions.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.techpowerup.com/gpu-specs/geforce-rtx-3060-8-gb.c3937\"&gt;https://www.techpowerup.com/gpu-specs/geforce-rtx-3060-8-gb.c3937&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also p102-100 does have FP16. Not the fastest but it does.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.techpowerup.com/gpu-specs/p102-100.c3100\"&gt;https://www.techpowerup.com/gpu-specs/p102-100.c3100&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Flash attention is good but at the end of the day, as far as token generation goes the p102-100 would be faster even without FA.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgdh6r",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6nudum/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754208663,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6nsn95",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "AppearanceHeavy6724",
            "can_mod_post": false,
            "created_utc": 1754207652,
            "send_replies": true,
            "parent_id": "t3_1mgdh6r",
            "score": 6,
            "author_fullname": "t2_uz37qfx5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "3060 is 12 GiB not 8. It is far faster at attention computation as p102-100 has no fp16 and no native flash attention. You also absolutely have to limit it at 150W otherwise its a power hog. Slow pcie also considerably slows down parallel computations. Also Pascals are about to be deprecated in CUDA, you'll need to hassle with sideloading an older version.\n\nGood as add-on for 3060 or as a beginner card not as much on its own.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6nsn95",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3060 is 12 GiB not 8. It is far faster at attention computation as p102-100 has no fp16 and no native flash attention. You also absolutely have to limit it at 150W otherwise its a power hog. Slow pcie also considerably slows down parallel computations. Also Pascals are about to be deprecated in CUDA, you&amp;#39;ll need to hassle with sideloading an older version.&lt;/p&gt;\n\n&lt;p&gt;Good as add-on for 3060 or as a beginner card not as much on its own.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6nsn95/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754207652,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgdh6r",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6nymmc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "loadsamuny",
            "can_mod_post": false,
            "created_utc": 1754211191,
            "send_replies": true,
            "parent_id": "t3_1mgdh6r",
            "score": 2,
            "author_fullname": "t2_10p7p3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have P40 and P6000 they run about 1/4 speed of 50 series on LLMs. There is a VLLM pascal fork and no issues with llamacpp",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6nymmc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have P40 and P6000 they run about 1/4 speed of 50 series on LLMs. There is a VLLM pascal fork and no issues with llamacpp&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6nymmc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754211191,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgdh6r",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6q1951",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "vulcan4d",
            "can_mod_post": false,
            "created_utc": 1754240460,
            "send_replies": true,
            "parent_id": "t3_1mgdh6r",
            "score": 1,
            "author_fullname": "t2_a5y20",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I use 3 p102-100s and a 3060 12gb.  I remember when I tested them individually and the p102-100 was basically 90% the performance of my 3060 while capped at 175w.  Best bang for your dollar.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6q1951",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I use 3 p102-100s and a 3060 12gb.  I remember when I tested them individually and the p102-100 was basically 90% the performance of my 3060 while capped at 175w.  Best bang for your dollar.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6q1951/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754240460,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgdh6r",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6r7xds",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "AppearanceHeavy6724",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6qxtnk",
                                          "score": 1,
                                          "author_fullname": "t2_uz37qfx5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "No problems, thanks for being reasonable.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6r7xds",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No problems, thanks for being reasonable.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mgdh6r",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6r7xds/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754253521,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754253521,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6qxtnk",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Boricua-vet",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6qrny2",
                                "score": 1,
                                "author_fullname": "t2_vnvnb9oa",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "OMG you made me laugh, yea, I can see the stooge when you put it that way and it does make sense. So according to that, the eval rates between both cards were pretty close and the 3060 was about 20% faster. That test looks good but then price wise 60 to 200+ to gain about 20% for a budget build, that's not worth it. a $99 Dollar mi50 with 1TB bandwidth and 16GB VRAM would be a better choice and would run circles against both cards the p102-100 or the 3060. \n\nbut, you do have a solid point and thank you.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6qxtnk",
                                "is_submitter": true,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OMG you made me laugh, yea, I can see the stooge when you put it that way and it does make sense. So according to that, the eval rates between both cards were pretty close and the 3060 was about 20% faster. That test looks good but then price wise 60 to 200+ to gain about 20% for a budget build, that&amp;#39;s not worth it. a $99 Dollar mi50 with 1TB bandwidth and 16GB VRAM would be a better choice and would run circles against both cards the p102-100 or the 3060. &lt;/p&gt;\n\n&lt;p&gt;but, you do have a solid point and thank you.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgdh6r",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6qxtnk/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754250430,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754250430,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6qzqdy",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Boricua-vet",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6qrny2",
                                "score": 1,
                                "author_fullname": "t2_vnvnb9oa",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I am trying to correct the original post but I cant seem to find the edit button as it is not available. it only allows me to modify the flair, this sucks.\n\nThanks for the info and clarification.\n\nhttps://preview.redd.it/h33zgxyc1vgf1.png?width=820&amp;format=png&amp;auto=webp&amp;s=f86f0d366837c3d4ba06c1f353df943cc3ff847e",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6qzqdy",
                                "is_submitter": true,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to correct the original post but I cant seem to find the edit button as it is not available. it only allows me to modify the flair, this sucks.&lt;/p&gt;\n\n&lt;p&gt;Thanks for the info and clarification.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/h33zgxyc1vgf1.png?width=820&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f86f0d366837c3d4ba06c1f353df943cc3ff847e\"&gt;https://preview.redd.it/h33zgxyc1vgf1.png?width=820&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f86f0d366837c3d4ba06c1f353df943cc3ff847e&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgdh6r",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6qzqdy/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754251033,
                                "media_metadata": {
                                  "h33zgxyc1vgf1": {
                                    "status": "valid",
                                    "e": "Image",
                                    "m": "image/png",
                                    "p": [
                                      {
                                        "y": 98,
                                        "x": 108,
                                        "u": "https://preview.redd.it/h33zgxyc1vgf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=880c115522af6c0eaa8690566d4f761a4f151e6f"
                                      },
                                      {
                                        "y": 196,
                                        "x": 216,
                                        "u": "https://preview.redd.it/h33zgxyc1vgf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a110e4e0306b81dc1012586f91e62b49a5fe3cc1"
                                      },
                                      {
                                        "y": 291,
                                        "x": 320,
                                        "u": "https://preview.redd.it/h33zgxyc1vgf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e95072577263a1a7b8d244d0588ecc38aff8f1bb"
                                      },
                                      {
                                        "y": 582,
                                        "x": 640,
                                        "u": "https://preview.redd.it/h33zgxyc1vgf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=14e16edba5dac0223dad13ebb127a7e9fb4c8014"
                                      }
                                    ],
                                    "s": {
                                      "y": 746,
                                      "x": 820,
                                      "u": "https://preview.redd.it/h33zgxyc1vgf1.png?width=820&amp;format=png&amp;auto=webp&amp;s=f86f0d366837c3d4ba06c1f353df943cc3ff847e"
                                    },
                                    "id": "h33zgxyc1vgf1"
                                  }
                                },
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754251033,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6qrny2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AppearanceHeavy6724",
                      "can_mod_post": false,
                      "created_utc": 1754248464,
                      "send_replies": true,
                      "parent_id": "t1_n6qfizt",
                      "score": 1,
                      "author_fullname": "t2_uz37qfx5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt;  I am just going to drop this to settle the dispute.\n\nNo you do not. \n\n&gt; https://www.reddit.com/r/LocalLLaMA/comments/1ktqgk0/tested_qwen3_all_models_on_cpu_i510210u_rtx_3060/\n\nThis awfully misconfigured system. I personally get around 1000 t/s prompt processing with 14b Q4_K_M models and around 35 t/s token generation.\n\n&gt; results speak for themselves.\n\nthese \"results\" do not say a damn thing. Who in the healthy mind would run Qwen 3 14b Q4_K_M with _2k_ context and 6% oofload to CPU?\n\n Qwen3-14B | Desktop (5800X, 32GB RAM, RTX 3060) | 94% GPU / 6% CPU | Correct | 19.35 \n\nInsane. You can easily fit in 3060  model completely, together with at least 16k context. \n\nThis dude is incompetent.\n\nhere is actual comparison (1080ti is same as p102-100):\n\nhttps://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080_ti_vs_3060_12gb/\n\nIgnore prompt processing, on small context the numbers are wre going to be wrong. But TG is massively higher.\n\nAnyway, buddy believe what you want.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6qrny2",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I am just going to drop this to settle the dispute.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No you do not. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1ktqgk0/tested_qwen3_all_models_on_cpu_i510210u_rtx_3060/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1ktqgk0/tested_qwen3_all_models_on_cpu_i510210u_rtx_3060/&lt;/a&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This awfully misconfigured system. I personally get around 1000 t/s prompt processing with 14b Q4_K_M models and around 35 t/s token generation.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;results speak for themselves.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;these &amp;quot;results&amp;quot; do not say a damn thing. Who in the healthy mind would run Qwen 3 14b Q4&lt;em&gt;K_M with _2k&lt;/em&gt; context and 6% oofload to CPU?&lt;/p&gt;\n\n&lt;p&gt;Qwen3-14B | Desktop (5800X, 32GB RAM, RTX 3060) | 94% GPU / 6% CPU | Correct | 19.35 &lt;/p&gt;\n\n&lt;p&gt;Insane. You can easily fit in 3060  model completely, together with at least 16k context. &lt;/p&gt;\n\n&lt;p&gt;This dude is incompetent.&lt;/p&gt;\n\n&lt;p&gt;here is actual comparison (1080ti is same as p102-100):&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080_ti_vs_3060_12gb/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080_ti_vs_3060_12gb/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Ignore prompt processing, on small context the numbers are wre going to be wrong. But TG is massively higher.&lt;/p&gt;\n\n&lt;p&gt;Anyway, buddy believe what you want.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgdh6r",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6qrny2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754248464,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6qfizt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Boricua-vet",
            "can_mod_post": false,
            "created_utc": 1754244714,
            "send_replies": true,
            "parent_id": "t3_1mgdh6r",
            "score": 1,
            "author_fullname": "t2_vnvnb9oa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Well, I am just going to drop this to settle the dispute.\n\n[https://www.reddit.com/r/LocalLLaMA/comments/1ktqgk0/tested\\_qwen3\\_all\\_models\\_on\\_cpu\\_i510210u\\_rtx\\_3060/](https://www.reddit.com/r/LocalLLaMA/comments/1ktqgk0/tested_qwen3_all_models_on_cpu_i510210u_rtx_3060/)\n\non Qwen3 14B Q4 KM he got TG of 19.35 with default 2k context using ollama 2 months ago with the same 12GB 3060. PP was 124 tk/s\n\nP102-100 did TG of 22 TK/s and prompt processing 543 TK/s. So there goes the Flash Attention and higher cuda theory.\n\nand that is with 2K context on the 3060 12GB  vs 32K context on the P102-100.\n\nresults speak for themselves.\n\nu/AppearanceHeavy6724 \n\nI get where you are coming from, but my tests and comparison like this prove otherwise. It's hard to believe and I was in denial and disbelieve myself but I can not longer ignore facts. However, the 3060 will run circles on the P102-100 if testing comfyui or SD. I mean it, would not even be a fair comparison. The P102-100 is horrible for image and video gen.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6qfizt",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well, I am just going to drop this to settle the dispute.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1ktqgk0/tested_qwen3_all_models_on_cpu_i510210u_rtx_3060/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1ktqgk0/tested_qwen3_all_models_on_cpu_i510210u_rtx_3060/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;on Qwen3 14B Q4 KM he got TG of 19.35 with default 2k context using ollama 2 months ago with the same 12GB 3060. PP was 124 tk/s&lt;/p&gt;\n\n&lt;p&gt;P102-100 did TG of 22 TK/s and prompt processing 543 TK/s. So there goes the Flash Attention and higher cuda theory.&lt;/p&gt;\n\n&lt;p&gt;and that is with 2K context on the 3060 12GB  vs 32K context on the P102-100.&lt;/p&gt;\n\n&lt;p&gt;results speak for themselves.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"/u/AppearanceHeavy6724\"&gt;u/AppearanceHeavy6724&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;I get where you are coming from, but my tests and comparison like this prove otherwise. It&amp;#39;s hard to believe and I was in denial and disbelieve myself but I can not longer ignore facts. However, the 3060 will run circles on the P102-100 if testing comfyui or SD. I mean it, would not even be a fair comparison. The P102-100 is horrible for image and video gen.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6qfizt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754244714,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgdh6r",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6nvje9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "BrettonWoods1944",
            "can_mod_post": false,
            "created_utc": 1754209350,
            "send_replies": true,
            "parent_id": "t3_1mgdh6r",
            "score": 0,
            "author_fullname": "t2_1g4pb7avre",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What about 5060 ti has 16gb of vram\nHas anybody any experiance with runing one multiples of them?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6nvje9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What about 5060 ti has 16gb of vram\nHas anybody any experiance with runing one multiples of them?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgdh6r/is_the_p102100_still_a_viable_option_for_llm/n6nvje9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754209350,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgdh6r",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]