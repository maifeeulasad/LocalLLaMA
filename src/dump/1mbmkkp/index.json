[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "So I've been trying to get local models ranging from Phi4, to qwen3 32b, qwen3 30b, hunyuan a13b, devstral-small 24b, polaris 7b, c4ai-command-r-08-2024 etc.. the list goes on. I've been having a very difficult time getting them to call tools. Reading the documentation it appears that many of them can handle tool calls very differently, but even using cited examples, with temperatures ranging from 0.1 to 0.7 getting tools called even in small context windows is much more miss than hit. \n\nSo I figured I'd give frontier models a shot. Using Gemini for example, will finally call tools correctly, but only after I copy and paste several sections of logs to show that it isn't really calling tools and that i'm evaluating it for something and even then it takes 3-5 exchanges before it starts to do what I ask.\n\nI've tried with several MCP servers, and I feel like I'm missing something super obvious. Please give a dog a bone.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Please help me out on this. Tool calling issue for local models",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mbmkkp",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.83,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 4,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1m41cyz8ny",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 4,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753723756,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been trying to get local models ranging from Phi4, to qwen3 32b, qwen3 30b, hunyuan a13b, devstral-small 24b, polaris 7b, c4ai-command-r-08-2024 etc.. the list goes on. I&amp;#39;ve been having a very difficult time getting them to call tools. Reading the documentation it appears that many of them can handle tool calls very differently, but even using cited examples, with temperatures ranging from 0.1 to 0.7 getting tools called even in small context windows is much more miss than hit. &lt;/p&gt;\n\n&lt;p&gt;So I figured I&amp;#39;d give frontier models a shot. Using Gemini for example, will finally call tools correctly, but only after I copy and paste several sections of logs to show that it isn&amp;#39;t really calling tools and that i&amp;#39;m evaluating it for something and even then it takes 3-5 exchanges before it starts to do what I ask.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried with several MCP servers, and I feel like I&amp;#39;m missing something super obvious. Please give a dog a bone.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mbmkkp",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "No_Paint9675",
            "discussion_type": null,
            "num_comments": 6,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mbmkkp/please_help_me_out_on_this_tool_calling_issue_for/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mbmkkp/please_help_me_out_on_this_tool_calling_issue_for/",
            "subreddit_subscribers": 506191,
            "created_utc": 1753723756,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5p2sn6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No_Paint9675",
                      "can_mod_post": false,
                      "created_utc": 1753743637,
                      "send_replies": true,
                      "parent_id": "t1_n5niaac",
                      "score": 1,
                      "author_fullname": "t2_1m41cyz8ny",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I've got my own front end. It isn't the ability to communicate with them, it's the prompting issues, they're either pure processing, which I can just build logic to do that, or they want to talk about what I'm asking them to do. By the time I get them to respond, half the context window is taken up with \"convincing them\" to just do the thing.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5p2sn6",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got my own front end. It isn&amp;#39;t the ability to communicate with them, it&amp;#39;s the prompting issues, they&amp;#39;re either pure processing, which I can just build logic to do that, or they want to talk about what I&amp;#39;m asking them to do. By the time I get them to respond, half the context window is taken up with &amp;quot;convincing them&amp;quot; to just do the thing.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbmkkp",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbmkkp/please_help_me_out_on_this_tool_calling_issue_for/n5p2sn6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753743637,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5niaac",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Latter_Count_2515",
            "can_mod_post": false,
            "created_utc": 1753726893,
            "send_replies": true,
            "parent_id": "t3_1mbmkkp",
            "score": 3,
            "author_fullname": "t2_dmgsox1o",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I would interested if you ever find a solution. I have been trying similar approaches and the closest working option was using openwebui as a front end. Owui isn't actually using tool calling but instead taking the normal output and running a secondary interpreter which decides how to display the output or running demo code.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5niaac",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would interested if you ever find a solution. I have been trying similar approaches and the closest working option was using openwebui as a front end. Owui isn&amp;#39;t actually using tool calling but instead taking the normal output and running a secondary interpreter which decides how to display the output or running demo code.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbmkkp/please_help_me_out_on_this_tool_calling_issue_for/n5niaac/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753726893,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbmkkp",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5p28hc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No_Paint9675",
                      "can_mod_post": false,
                      "created_utc": 1753743456,
                      "send_replies": true,
                      "parent_id": "t1_n5nk1do",
                      "score": 2,
                      "author_fullname": "t2_1m41cyz8ny",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It won't actually let me comment any code, I keep getting \"Unable to create comment\" errors (from reddit), likely my account isn't posting enough to be allowed to yet.\n\n  \nI'm using api key calls (gemini, openai, claude, and a mix of ollama and lmstudio for smaller local models, logic exists within my system to communicate with all of them. I can connect, post, and get the replies, I have a state manager that will run 100 message long chain no worries. I've found that most of these models will behave as either a router, just taking messages from point a and sending them to point b, or they'll decide they want to just talk about what you're asking them to do.  (moe issues maybe?)",
                      "edited": 1753743856,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5p28hc",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It won&amp;#39;t actually let me comment any code, I keep getting &amp;quot;Unable to create comment&amp;quot; errors (from reddit), likely my account isn&amp;#39;t posting enough to be allowed to yet.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using api key calls (gemini, openai, claude, and a mix of ollama and lmstudio for smaller local models, logic exists within my system to communicate with all of them. I can connect, post, and get the replies, I have a state manager that will run 100 message long chain no worries. I&amp;#39;ve found that most of these models will behave as either a router, just taking messages from point a and sending them to point b, or they&amp;#39;ll decide they want to just talk about what you&amp;#39;re asking them to do.  (moe issues maybe?)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbmkkp",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbmkkp/please_help_me_out_on_this_tool_calling_issue_for/n5p28hc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753743456,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5nk1do",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "SM8085",
            "can_mod_post": false,
            "created_utc": 1753727393,
            "send_replies": true,
            "parent_id": "t3_1mbmkkp",
            "score": 3,
            "author_fullname": "t2_14vikjao97",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It sounds like you're having more trouble than you should with those models.  Even the smaller Qwen3s should be able to handle tool calling.\n\nFor instance, with [Goose](https://block.github.io/goose/) it seems to handle tools correctly and local models don't have a problem understanding how it's presented.\n\nGoose + Qwen3 4B Q8 + a Fark MCP I created:\n\nhttps://preview.redd.it/ajuiwr7uqnff1.png?width=1898&amp;format=png&amp;auto=webp&amp;s=1081aa69a55924407d3d0fb850cf59780dc9fa87\n\nIt figures out that basic tool call.\n\nHow are you trying to implement the tool calling?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5nk1do",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It sounds like you&amp;#39;re having more trouble than you should with those models.  Even the smaller Qwen3s should be able to handle tool calling.&lt;/p&gt;\n\n&lt;p&gt;For instance, with &lt;a href=\"https://block.github.io/goose/\"&gt;Goose&lt;/a&gt; it seems to handle tools correctly and local models don&amp;#39;t have a problem understanding how it&amp;#39;s presented.&lt;/p&gt;\n\n&lt;p&gt;Goose + Qwen3 4B Q8 + a Fark MCP I created:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ajuiwr7uqnff1.png?width=1898&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1081aa69a55924407d3d0fb850cf59780dc9fa87\"&gt;https://preview.redd.it/ajuiwr7uqnff1.png?width=1898&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1081aa69a55924407d3d0fb850cf59780dc9fa87&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It figures out that basic tool call.&lt;/p&gt;\n\n&lt;p&gt;How are you trying to implement the tool calling?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbmkkp/please_help_me_out_on_this_tool_calling_issue_for/n5nk1do/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753727393,
            "media_metadata": {
              "ajuiwr7uqnff1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 22,
                    "x": 108,
                    "u": "https://preview.redd.it/ajuiwr7uqnff1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=233b008fdd747b5b5559399b332852e144d2f66f"
                  },
                  {
                    "y": 45,
                    "x": 216,
                    "u": "https://preview.redd.it/ajuiwr7uqnff1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7ca06fdc2392d4a4a5d98737aa1876c5416f566f"
                  },
                  {
                    "y": 67,
                    "x": 320,
                    "u": "https://preview.redd.it/ajuiwr7uqnff1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf11da86e84541499520c7881b6d32c15c048b52"
                  },
                  {
                    "y": 134,
                    "x": 640,
                    "u": "https://preview.redd.it/ajuiwr7uqnff1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=dc22a639f474380cb28acc2bd2a5885cf86a5abf"
                  },
                  {
                    "y": 201,
                    "x": 960,
                    "u": "https://preview.redd.it/ajuiwr7uqnff1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=40252f172ebb3b3b932dc6445f521ffc1668400a"
                  },
                  {
                    "y": 226,
                    "x": 1080,
                    "u": "https://preview.redd.it/ajuiwr7uqnff1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7be26eafb4c671569371854bb77180be537bb15c"
                  }
                ],
                "s": {
                  "y": 398,
                  "x": 1898,
                  "u": "https://preview.redd.it/ajuiwr7uqnff1.png?width=1898&amp;format=png&amp;auto=webp&amp;s=1081aa69a55924407d3d0fb850cf59780dc9fa87"
                },
                "id": "ajuiwr7uqnff1"
              }
            },
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbmkkp",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5p42jq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No_Paint9675",
                      "can_mod_post": false,
                      "created_utc": 1753744056,
                      "send_replies": true,
                      "parent_id": "t1_n5noofn",
                      "score": 1,
                      "author_fullname": "t2_1m41cyz8ny",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Reddit isn't letting me post my prompt examples. But I'm not using a framework for this. I have a custom UX, I'm using api key calls (gemini, openai, claude, and a mix of ollama and lmstudio for smaller local models, logic exists within my system to communicate with all of them. I can connect, post, and get the replies, I have a state manager that will run 100 message long chain no worries. I've found that most of these models will behave as either a router, just taking messages from point a and sending them to point b, or they'll decide they want to just talk about what you're asking them to do. (moe issues maybe?) This is 100% a prompting issue. I just don't know how to get the models to do what they're told from message 1 without several back and forth exchanges to convince them to just do the simple thing. So i'm wondering if there's some huge easy to see thing I'm missing.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5p42jq",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Reddit isn&amp;#39;t letting me post my prompt examples. But I&amp;#39;m not using a framework for this. I have a custom UX, I&amp;#39;m using api key calls (gemini, openai, claude, and a mix of ollama and lmstudio for smaller local models, logic exists within my system to communicate with all of them. I can connect, post, and get the replies, I have a state manager that will run 100 message long chain no worries. I&amp;#39;ve found that most of these models will behave as either a router, just taking messages from point a and sending them to point b, or they&amp;#39;ll decide they want to just talk about what you&amp;#39;re asking them to do. (moe issues maybe?) This is 100% a prompting issue. I just don&amp;#39;t know how to get the models to do what they&amp;#39;re told from message 1 without several back and forth exchanges to convince them to just do the simple thing. So i&amp;#39;m wondering if there&amp;#39;s some huge easy to see thing I&amp;#39;m missing.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbmkkp",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbmkkp/please_help_me_out_on_this_tool_calling_issue_for/n5p42jq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753744056,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5noofn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "thatphotoguy89",
            "can_mod_post": false,
            "created_utc": 1753728720,
            "send_replies": true,
            "parent_id": "t3_1mbmkkp",
            "score": 2,
            "author_fullname": "t2_nmj51",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "A code snippet would be really helpful. What framework are you using, if any? Most of the new models are trained to be able to do tool calls quite well. The fact that you’re having trouble with Gemini as well suggests to me that there’s something wrong with your code",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5noofn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A code snippet would be really helpful. What framework are you using, if any? Most of the new models are trained to be able to do tool calls quite well. The fact that you’re having trouble with Gemini as well suggests to me that there’s something wrong with your code&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbmkkp/please_help_me_out_on_this_tool_calling_issue_for/n5noofn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753728720,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbmkkp",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]