[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Let's assume it's a 2Billion parameter model to fork\n\nI am curious what kind of compute and horsepower it would take to update an LLM with new information. \n\nYes, RAG/VectorDB's work as an interim step in ensuring valid responses, but the scenario I'm exploring has verified good data via fuzzy questions and returns accurate answers, so now we're ready to update it. \n\nWith that, what does the process look like?\n\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "What does it take to regenerate or update a model?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mkhgva",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.29,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_12koak",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754614655,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s assume it&amp;#39;s a 2Billion parameter model to fork&lt;/p&gt;\n\n&lt;p&gt;I am curious what kind of compute and horsepower it would take to update an LLM with new information. &lt;/p&gt;\n\n&lt;p&gt;Yes, RAG/VectorDB&amp;#39;s work as an interim step in ensuring valid responses, but the scenario I&amp;#39;m exploring has verified good data via fuzzy questions and returns accurate answers, so now we&amp;#39;re ready to update it. &lt;/p&gt;\n\n&lt;p&gt;With that, what does the process look like?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mkhgva",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "techtornado",
            "discussion_type": null,
            "num_comments": 1,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mkhgva/what_does_it_take_to_regenerate_or_update_a_model/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mkhgva/what_does_it_take_to_regenerate_or_update_a_model/",
            "subreddit_subscribers": 513813,
            "created_utc": 1754614655,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7iyunb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "squareOfTwo",
            "can_mod_post": false,
            "created_utc": 1754617458,
            "send_replies": true,
            "parent_id": "t3_1mkhgva",
            "score": 5,
            "author_fullname": "t2_gyuup",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It probably takes months to fine-tune such a model on a single good graphics card.\n\n\nsource: it takes weeks to train 1.5b models with some tokens https://m.youtube.com/watch?v=l8pRSuU81PU\n\n\n\n\nA cheaper way might be fine tuning with QLoRA. No idea how long it might take. But it's faster than full fine tuning.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7iyunb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It probably takes months to fine-tune such a model on a single good graphics card.&lt;/p&gt;\n\n&lt;p&gt;source: it takes weeks to train 1.5b models with some tokens &lt;a href=\"https://m.youtube.com/watch?v=l8pRSuU81PU\"&gt;https://m.youtube.com/watch?v=l8pRSuU81PU&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A cheaper way might be fine tuning with QLoRA. No idea how long it might take. But it&amp;#39;s faster than full fine tuning.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkhgva/what_does_it_take_to_regenerate_or_update_a_model/n7iyunb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754617458,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkhgva",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        }
      ],
      "before": null
    }
  }
]