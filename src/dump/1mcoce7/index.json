[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "AMD's Ryzen AI MAX+ Processors Now Offer a Whopping 96 GB Memory for Consumer Graphics, Allowing Gigantic 128B-Parameter LLMs to Run Locally on PCs",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "News"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 78,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mcoce7",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.91,
            "author_flair_background_color": null,
            "ups": 107,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_twl3xhruz",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "News",
            "can_mod_post": false,
            "score": 107,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/9cxUs2c7UTW3WnCYfQNVG3P3u4GjtOuwQSim_dwuwEI.jpeg?width=140&amp;height=78&amp;crop=140:78,smart&amp;auto=webp&amp;s=e171e9de6f65dcbec52d568f58750bcc5885ba3a",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "link",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753825022,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "wccftech.com",
            "allow_live_comments": false,
            "selftext_html": null,
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://wccftech.com/amd-ryzen-ai-max-processors-offer-a-96gb-memory-for-consumer-graphics/",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/9cxUs2c7UTW3WnCYfQNVG3P3u4GjtOuwQSim_dwuwEI.jpeg?auto=webp&amp;s=d470a9db6c0be816c3d916347e4ae5e8bad6c6a8",
                    "width": 750,
                    "height": 422
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/9cxUs2c7UTW3WnCYfQNVG3P3u4GjtOuwQSim_dwuwEI.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e14a96af45b1cfcde1a2159e64971bc1d775033",
                      "width": 108,
                      "height": 60
                    },
                    {
                      "url": "https://external-preview.redd.it/9cxUs2c7UTW3WnCYfQNVG3P3u4GjtOuwQSim_dwuwEI.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=47124b81e03a6604140c8e4d29ddbe43c15456c3",
                      "width": 216,
                      "height": 121
                    },
                    {
                      "url": "https://external-preview.redd.it/9cxUs2c7UTW3WnCYfQNVG3P3u4GjtOuwQSim_dwuwEI.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bf6168a4321e52f96ea360e8b865dc9bbcaaf345",
                      "width": 320,
                      "height": 180
                    },
                    {
                      "url": "https://external-preview.redd.it/9cxUs2c7UTW3WnCYfQNVG3P3u4GjtOuwQSim_dwuwEI.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d50b7793829c5aa107cf8ecaa3b004d46e3cdef0",
                      "width": 640,
                      "height": 360
                    }
                  ],
                  "variants": {},
                  "id": "9cxUs2c7UTW3WnCYfQNVG3P3u4GjtOuwQSim_dwuwEI"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#cc3600",
            "id": "1mcoce7",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "_SYSTEM_ADMIN_MOD_",
            "discussion_type": null,
            "num_comments": 43,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/",
            "stickied": false,
            "url": "https://wccftech.com/amd-ryzen-ai-max-processors-offer-a-96gb-memory-for-consumer-graphics/",
            "subreddit_subscribers": 506711,
            "created_utc": 1753825022,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5vyoij",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Mental-At-ThirtyFive",
                      "can_mod_post": false,
                      "created_utc": 1753832387,
                      "send_replies": true,
                      "parent_id": "t1_n5vmibi",
                      "score": 2,
                      "author_fullname": "t2_1agldc0abx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It is AMD vs. AMD - a Lose Lose corporate strategy",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5vyoij",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is AMD vs. AMD - a Lose Lose corporate strategy&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vyoij/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753832387,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5vmibi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "fooo12gh",
            "can_mod_post": false,
            "created_utc": 1753828463,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 38,
            "author_fullname": "t2_3vvvbmh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is quite old information on ryzen ai max+ 395. There were even published some benchmarks [https://www.reddit.com/r/LocalLLaMA/comments/1m6b151/updated\\_strix\\_halo\\_ryzen\\_ai\\_max\\_395\\_llm\\_benchmark/](https://www.reddit.com/r/LocalLLaMA/comments/1m6b151/updated_strix_halo_ryzen_ai_max_395_llm_benchmark/) from happy owners\n\nCome here when there are updates on strix medusa, as there are only rumors on how awesome it is, that it's canceled, but will be released \\~2027. Only rumors.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vmibi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is quite old information on ryzen ai max+ 395. There were even published some benchmarks &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1m6b151/updated_strix_halo_ryzen_ai_max_395_llm_benchmark/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1m6b151/updated_strix_halo_ryzen_ai_max_395_llm_benchmark/&lt;/a&gt; from happy owners&lt;/p&gt;\n\n&lt;p&gt;Come here when there are updates on strix medusa, as there are only rumors on how awesome it is, that it&amp;#39;s canceled, but will be released ~2027. Only rumors.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vmibi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753828463,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 38
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5vgtzk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "mustafar0111",
                      "can_mod_post": false,
                      "created_utc": 1753826677,
                      "send_replies": true,
                      "parent_id": "t1_n5vgnuw",
                      "score": 13,
                      "author_fullname": "t2_iulq4li0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Spec sheet says 256 GB/s.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5vgtzk",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Spec sheet says 256 GB/s.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vgtzk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753826677,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 13
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5vp4gt",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "LumpyWelds",
                      "can_mod_post": false,
                      "created_utc": 1753829300,
                      "send_replies": true,
                      "parent_id": "t1_n5vgnuw",
                      "score": 3,
                      "author_fullname": "t2_32hdazgq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "CPU can support 256GB/s but..\n\nIt really depends upon your motherboard and memory type.   Best results currently come 8 soldered LPDDR5X 16GB chips on a 256bit bus giving 128GB of 8 channel memory.  This gives 256GB/s which matches the CPU.\n\nAlmost all the Strix Halo's mini's out there use this configuration.  But one or two have socketed memory which cuts the performance by a lot.  As far as I know, no one has figured out how to fully feed this CPU without soldering the memory.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5vp4gt",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;CPU can support 256GB/s but..&lt;/p&gt;\n\n&lt;p&gt;It really depends upon your motherboard and memory type.   Best results currently come 8 soldered LPDDR5X 16GB chips on a 256bit bus giving 128GB of 8 channel memory.  This gives 256GB/s which matches the CPU.&lt;/p&gt;\n\n&lt;p&gt;Almost all the Strix Halo&amp;#39;s mini&amp;#39;s out there use this configuration.  But one or two have socketed memory which cuts the performance by a lot.  As far as I know, no one has figured out how to fully feed this CPU without soldering the memory.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vp4gt/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753829300,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5vp842",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Final_Wheel_7486",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5vl3c1",
                                "score": 0,
                                "author_fullname": "t2_cyrs5dhp",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The CPU brings its own RAM and there is no dedicated system RAM in the original sense.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5vp842",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The CPU brings its own RAM and there is no dedicated system RAM in the original sense.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mcoce7",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vp842/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753829333,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753829333,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 1,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5vl3c1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "DataGOGO",
                      "can_mod_post": false,
                      "created_utc": 1753828013,
                      "send_replies": true,
                      "parent_id": "t1_n5vgnuw",
                      "score": -1,
                      "author_fullname": "t2_851mxifp",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Whatever your system ram is running. ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5vl3c1",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Whatever your system ram is running. &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vl3c1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753828013,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5vgnuw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ArtisticHamster",
            "can_mod_post": false,
            "created_utc": 1753826624,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 7,
            "author_fullname": "t2_2t2xbyfm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What is RAM bandwidth there?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vgnuw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What is RAM bandwidth there?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vgnuw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753826624,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5vjkf1",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "FullstackSensei",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5vcl7o",
                                "score": 14,
                                "author_fullname": "t2_17n3nqtj56",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The GPU compute power is close to 4060ti levels, this has nothing to do with memory.q\n\nMemory allocation for the GPU is a driver thing. The GPU hardware has access to all RAM and doesn't care what is what. Even before this update, for compute workloads it didn't matter because the driver allowed passing a pointer to the buffers on which computation is to be performed from the \"normal\" system memory and the GPU would just do it's thing with those.\n\nThere is nothing here that is new from a technology point of view. Intel and AMD have been doing this since forever. Just Google zero-copy buffers for any of their integrated GPUs. Strix Halo takes this one notch up by integrating a much bigger GPU and doubling the memory controller from two to four channels.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5vjkf1",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The GPU compute power is close to 4060ti levels, this has nothing to do with memory.q&lt;/p&gt;\n\n&lt;p&gt;Memory allocation for the GPU is a driver thing. The GPU hardware has access to all RAM and doesn&amp;#39;t care what is what. Even before this update, for compute workloads it didn&amp;#39;t matter because the driver allowed passing a pointer to the buffers on which computation is to be performed from the &amp;quot;normal&amp;quot; system memory and the GPU would just do it&amp;#39;s thing with those.&lt;/p&gt;\n\n&lt;p&gt;There is nothing here that is new from a technology point of view. Intel and AMD have been doing this since forever. Just Google zero-copy buffers for any of their integrated GPUs. Strix Halo takes this one notch up by integrating a much bigger GPU and doubling the memory controller from two to four channels.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mcoce7",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vjkf1/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753827530,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753827530,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 14
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5w64ee",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "Mochila-Mochila",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5vvpym",
                                                              "score": 4,
                                                              "author_fullname": "t2_10otgvvrn1",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "&gt; Seems like a waste of a good APU with such low bandwidth.\n\nYes, it's definitely something AMD should work on, in future Halo generations.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5w64ee",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Seems like a waste of a good APU with such low bandwidth.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yes, it&amp;#39;s definitely something AMD should work on, in future Halo generations.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mcoce7",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5w64ee/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753834898,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753834898,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 4
                                                            }
                                                          },
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5w6t5a",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "henfiber",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5vvpym",
                                                              "score": 2,
                                                              "author_fullname": "t2_lw9me25",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Apple went really extreme with the width of their memory bus to achieve 400GB/s M1/M2/M3 Max (and doubled in Ultra), and the 546 GB/s in the M4 Max. That's not easy to achieve apparently since both AMD and Nvidia (see their DGX Spark mini-PC) settled for 256-273 GB/s.\n\nNote that Nvidia 4060 has 273 GB/s as well and this APU is similar in tensor compute to a 4060 (\\~59 FP16 TFLOPs).\n\nThe next AMD version (Medusa Halo) is rumored to increase the mem bw to 384 GB/sec (and 192GB of memory).",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5w6t5a",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Apple went really extreme with the width of their memory bus to achieve 400GB/s M1/M2/M3 Max (and doubled in Ultra), and the 546 GB/s in the M4 Max. That&amp;#39;s not easy to achieve apparently since both AMD and Nvidia (see their DGX Spark mini-PC) settled for 256-273 GB/s.&lt;/p&gt;\n\n&lt;p&gt;Note that Nvidia 4060 has 273 GB/s as well and this APU is similar in tensor compute to a 4060 (~59 FP16 TFLOPs).&lt;/p&gt;\n\n&lt;p&gt;The next AMD version (Medusa Halo) is rumored to increase the mem bw to 384 GB/sec (and 192GB of memory).&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mcoce7",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5w6t5a/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753835135,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753835135,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          },
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": "",
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n5wds0i",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "professorShay",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n5w7s39",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_uncfnrm4",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "Just saying, AMD has the better chip but gets dragged down by slow memory bandwidth. Just imagine 128gb,  4060 levels of performance, 500+ GB/s bandwidth, without the Apple tax. The true potential of the Ryzen AI series.",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n5wds0i",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just saying, AMD has the better chip but gets dragged down by slow memory bandwidth. Just imagine 128gb,  4060 levels of performance, 500+ GB/s bandwidth, without the Apple tax. The true potential of the Ryzen AI series.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mcoce7",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5wds0i/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1753837540,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1753837540,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5w7s39",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "colin_colout",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5vvpym",
                                                              "score": 1,
                                                              "author_fullname": "t2_14l4ya",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "you can't please everyone, eh?\n\n(Remind me how much does an m4 with 128gb of ram cost?)",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5w7s39",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;you can&amp;#39;t please everyone, eh?&lt;/p&gt;\n\n&lt;p&gt;(Remind me how much does an m4 with 128gb of ram cost?)&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mcoce7",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5w7s39/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753835474,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753835474,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5vvpym",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "professorShay",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5vnwd9",
                                                    "score": 3,
                                                    "author_fullname": "t2_uncfnrm4",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Isn't the m4 Mac like 500 some GB/s? Seems like a waste of a good APU with such low bandwidth.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5vvpym",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Isn&amp;#39;t the m4 Mac like 500 some GB/s? Seems like a waste of a good APU with such low bandwidth.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mcoce7",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vvpym/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753831430,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753831430,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5w0gjh",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "colin_colout",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5vnwd9",
                                                    "score": 1,
                                                    "author_fullname": "t2_14l4ya",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "And quad channel",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5w0gjh",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And quad channel&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mcoce7",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5w0gjh/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753832974,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753832974,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5vnwd9",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "RnRau",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5vla1u",
                                          "score": 6,
                                          "author_fullname": "t2_svt5u",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "LPDDR5x. Its about twice as fast as standard DDR5 on desktops since AMD gives it twice the connectivity to the soldered ram via a 256bit bus. \n\nTheoretical max memory bandwidth is 256GB/s",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5vnwd9",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;LPDDR5x. Its about twice as fast as standard DDR5 on desktops since AMD gives it twice the connectivity to the soldered ram via a 256bit bus. &lt;/p&gt;\n\n&lt;p&gt;Theoretical max memory bandwidth is 256GB/s&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mcoce7",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vnwd9/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753828907,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753828907,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 6
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5vs5l8",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Rich_Repeat_22",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5vla1u",
                                          "score": 3,
                                          "author_fullname": "t2_viufiki6",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Quad Channel LPDDR5X-8000.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5vs5l8",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Quad Channel LPDDR5X-8000.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mcoce7",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vs5l8/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753830280,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753830280,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 3
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5vla1u",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "DataGOGO",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5vcl7o",
                                "score": 5,
                                "author_fullname": "t2_851mxifp",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "What type of memory is that? Unless it is HBM, it is just ddr5 speeds right?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5vla1u",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What type of memory is that? Unless it is HBM, it is just ddr5 speeds right?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mcoce7",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vla1u/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753828073,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753828073,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5vcl7o",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "mustafar0111",
                      "can_mod_post": false,
                      "created_utc": 1753825379,
                      "send_replies": true,
                      "parent_id": "t1_n5vc752",
                      "score": 27,
                      "author_fullname": "t2_iulq4li0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "No. The way this should work is a portion of the system memory is hardware allocated to the GPU on boot up. Last I heard this was done in the BIOS.\n\nBecause of the type of memory this system has it functions closer to VRAM speeds then standard system RAM.\n\nThe GPU on the top tier AI MAX APU runs at something close to 4060 ti speeds I think. I'm sure someone will correct me on that if I'm off.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5vcl7o",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No. The way this should work is a portion of the system memory is hardware allocated to the GPU on boot up. Last I heard this was done in the BIOS.&lt;/p&gt;\n\n&lt;p&gt;Because of the type of memory this system has it functions closer to VRAM speeds then standard system RAM.&lt;/p&gt;\n\n&lt;p&gt;The GPU on the top tier AI MAX APU runs at something close to 4060 ti speeds I think. I&amp;#39;m sure someone will correct me on that if I&amp;#39;m off.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vcl7o/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753825379,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 27
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5vwyek",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "CatalyticDragon",
                      "can_mod_post": false,
                      "created_utc": 1753831829,
                      "send_replies": true,
                      "parent_id": "t1_n5vc752",
                      "score": 1,
                      "author_fullname": "t2_3h1nb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt;iGPU just uses system memory right? \n\n*Kind of*.  An iGPU (as in a GPU *i*ntegrated into a CPU) does use system ram for it's memory and that system ram has traditionally been quite slow relative to the memory on a graphics card's PCB (around 1/10th the performance, 60-80GB/s).\n\nBut these systems are APU based, like a mobile phone or a PS5, they use larger GPUs on the same package as the CPU and both share a pool of memory which is much faster than normal socketed system ram.\n\nIn the case of the \"AI MAC+ 395\" that memory pool operates at 256GB/s putting it at level of a low-end discreet GPU.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5vwyek",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;iGPU just uses system memory right? &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;em&gt;Kind of&lt;/em&gt;.  An iGPU (as in a GPU &lt;em&gt;i&lt;/em&gt;ntegrated into a CPU) does use system ram for it&amp;#39;s memory and that system ram has traditionally been quite slow relative to the memory on a graphics card&amp;#39;s PCB (around 1/10th the performance, 60-80GB/s).&lt;/p&gt;\n\n&lt;p&gt;But these systems are APU based, like a mobile phone or a PS5, they use larger GPUs on the same package as the CPU and both share a pool of memory which is much faster than normal socketed system ram.&lt;/p&gt;\n\n&lt;p&gt;In the case of the &amp;quot;AI MAC+ 395&amp;quot; that memory pool operates at 256GB/s putting it at level of a low-end discreet GPU.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vwyek/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753831829,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5vmhwg",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "DataGOGO",
                      "can_mod_post": false,
                      "created_utc": 1753828459,
                      "send_replies": true,
                      "parent_id": "t1_n5vc752",
                      "score": 1,
                      "author_fullname": "t2_851mxifp",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Correct, it is just a driver allocation of system memory, which in this case is low power ddr5. ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5vmhwg",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Correct, it is just a driver allocation of system memory, which in this case is low power ddr5. &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vmhwg/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753828459,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5vc752",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "LocoLanguageModel",
            "can_mod_post": false,
            "created_utc": 1753825263,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 38,
            "author_fullname": "t2_canyreqfh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "iGPU just uses system memory right?  Isn't this misleading compared to dedicated VRAM since llama can just use CPU and ram anyways?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vc752",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;iGPU just uses system memory right?  Isn&amp;#39;t this misleading compared to dedicated VRAM since llama can just use CPU and ram anyways?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vc752/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753825263,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 38
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5w1qwn",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Caffeine_Monster",
                      "can_mod_post": false,
                      "created_utc": 1753833405,
                      "send_replies": true,
                      "parent_id": "t1_n5viubq",
                      "score": 1,
                      "author_fullname": "t2_hg9yb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It's a waste of time finetuning in hardware like this.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5w1qwn",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a waste of time finetuning in hardware like this.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5w1qwn/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753833405,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5viubq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "indicava",
            "can_mod_post": false,
            "created_utc": 1753827301,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 3,
            "author_fullname": "t2_4dvff",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What’s the support like for these processors when it comes to fine tuning?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5viubq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What’s the support like for these processors when it comes to fine tuning?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": true,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5viubq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753827301,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5vc83k",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "bjodah",
            "can_mod_post": false,
            "created_utc": 1753825271,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 5,
            "author_fullname": "t2_atvy2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It's a driver update on windows...",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vc83k",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a driver update on windows...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vc83k/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753825271,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5vt06l",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Rich_Repeat_22",
                      "can_mod_post": false,
                      "created_utc": 1753830552,
                      "send_replies": true,
                      "parent_id": "t1_n5vpt82",
                      "score": 1,
                      "author_fullname": "t2_viufiki6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Aye. The article makes no sense.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5vt06l",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Aye. The article makes no sense.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vt06l/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753830552,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5vpt82",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "MikeRoz",
            "can_mod_post": false,
            "created_utc": 1753829522,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 2,
            "author_fullname": "t2_ht2fg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm so confused - I was able to set it to 96 GB in the UEFI on my machine months ago when I first got it, and it showed up that way in Task Manager.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vpt82",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m so confused - I was able to set it to 96 GB in the UEFI on my machine months ago when I first got it, and it showed up that way in Task Manager.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vpt82/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753829522,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5w4ni5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "uti24",
                      "can_mod_post": false,
                      "created_utc": 1753834392,
                      "send_replies": true,
                      "parent_id": "t1_n5vvqrs",
                      "score": 1,
                      "author_fullname": "t2_13hbro",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt;Why would people be excited about 96GB for $2000 with glacial double-digit prompt processing for dots.1 when you can get a 3xMI50 rig for &lt; $1000 and triple digit prompt processing for dots.1?\n\nBecause you are comparing monstrous enthusiast LLM inference hardware with unwieldy power consumption to a tiny little computer you can put anywhere in your apartment and forget it's there - or use it as a general-purpose desktop computer for other tasks.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5w4ni5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Why would people be excited about 96GB for $2000 with glacial double-digit prompt processing for dots.1 when you can get a 3xMI50 rig for &amp;lt; $1000 and triple digit prompt processing for dots.1?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Because you are comparing monstrous enthusiast LLM inference hardware with unwieldy power consumption to a tiny little computer you can put anywhere in your apartment and forget it&amp;#39;s there - or use it as a general-purpose desktop computer for other tasks.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5w4ni5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753834392,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5vvqrs",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "CheatCodesOfLife",
            "can_mod_post": false,
            "created_utc": 1753831437,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 2,
            "author_fullname": "t2_32el727b",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This a laptop or something? Why would people be excited about 96GB for $2000 with glacial double-digit prompt processing for dots.1 when you can get a 3xMI50 rig for &lt; $1000 and triple digit prompt processing for dots.1?\n\n[Source for the double-digit pp]( https://old.reddit.com/r/LocalLLaMA/comments/1m6b151/updated_strix_halo_ryzen_ai_max_395_llm_benchmark/)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vvqrs",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This a laptop or something? Why would people be excited about 96GB for $2000 with glacial double-digit prompt processing for dots.1 when you can get a 3xMI50 rig for &amp;lt; $1000 and triple digit prompt processing for dots.1?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://old.reddit.com/r/LocalLLaMA/comments/1m6b151/updated_strix_halo_ryzen_ai_max_395_llm_benchmark/\"&gt;Source for the double-digit pp&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vvqrs/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753831437,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5wdfsg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "darth_vexos",
            "can_mod_post": false,
            "created_utc": 1753837421,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 2,
            "author_fullname": "t2_7m9aa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm very interested in putting 4-5 of these in a cluster to be able to run larger models. Framework has this as one of their use cases, but there's very little info on any actual implementations of it. I know token generation will be limited by network interface bandwidth, but still hoping it can hit a usable tps.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5wdfsg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m very interested in putting 4-5 of these in a cluster to be able to run larger models. Framework has this as one of their use cases, but there&amp;#39;s very little info on any actual implementations of it. I know token generation will be limited by network interface bandwidth, but still hoping it can hit a usable tps.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5wdfsg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753837421,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5vh3xl",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "Oxire",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5vg1vl",
                                                    "score": 10,
                                                    "author_fullname": "t2_obg01",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Amd cpus with 1 ccd can't get over \\~70GB/s. Amd with 2 ccd or even better an intel can get over 100. You also need to use -ot to choose what loads on gpu and what on cpu",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5vh3xl",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Amd cpus with 1 ccd can&amp;#39;t get over ~70GB/s. Amd with 2 ccd or even better an intel can get over 100. You also need to use -ot to choose what loads on gpu and what on cpu&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mcoce7",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vh3xl/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753826762,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753826762,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 10
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5vmpnk",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "DataGOGO",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5vg1vl",
                                                    "score": 5,
                                                    "author_fullname": "t2_851mxifp",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Uhhh yeah, you have a single ccd cpu and slow memory. ",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5vmpnk",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Uhhh yeah, you have a single ccd cpu and slow memory. &lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mcoce7",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vmpnk/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753828529,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753828529,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 5
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5vqic3",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "InsideYork",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5vg1vl",
                                                    "score": 1,
                                                    "author_fullname": "t2_12s3hn4y0b",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "You using unsloth with flash attention?",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5vqic3",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You using unsloth with flash attention?&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mcoce7",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vqic3/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753829747,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753829747,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5vg1vl",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "altoidsjedi",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5vfeg0",
                                          "score": 15,
                                          "author_fullname": "t2_6f7v3",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I have a desktop with a 5060ti 16GB, and a Ryzen Zen 5 processor with 96GB of DDR5-6400 RAM. \n\nI have not been getting 15 TPS with Llama 4 Scout.. it's been moreso within the 5-9 TPS range",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5vg1vl",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have a desktop with a 5060ti 16GB, and a Ryzen Zen 5 processor with 96GB of DDR5-6400 RAM. &lt;/p&gt;\n\n&lt;p&gt;I have not been getting 15 TPS with Llama 4 Scout.. it&amp;#39;s been moreso within the 5-9 TPS range&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mcoce7",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vg1vl/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753826433,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753826433,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 15
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5vfeg0",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Oxire",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5ve3a7",
                                "score": 9,
                                "author_fullname": "t2_obg01",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "That's exactly the speed you get with dual channel ddr5 and a 5060ti 16gb.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5vfeg0",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s exactly the speed you get with dual channel ddr5 and a 5060ti 16gb.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mcoce7",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vfeg0/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753826233,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753826233,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 9
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "total_awards_received": 0,
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "ups": 2,
                                "removal_reason": null,
                                "link_id": "t3_1mcoce7",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5vfnlj",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "mustafar0111",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5vfcfx",
                                          "score": 3,
                                          "author_fullname": "t2_iulq4li0",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I didn't benchmark it, I don't run videocardz.com.\n\nIt was a listed benchmark in a media article.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5vfnlj",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I didn&amp;#39;t benchmark it, I don&amp;#39;t run videocardz.com.&lt;/p&gt;\n\n&lt;p&gt;It was a listed benchmark in a media article.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mcoce7",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vfnlj/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753826312,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753826312,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 3
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5vfcfx",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": "DELETED",
                                "no_follow": true,
                                "author": "[deleted]",
                                "can_mod_post": false,
                                "created_utc": 1753826216,
                                "send_replies": true,
                                "parent_id": "t1_n5ve3a7",
                                "score": 2,
                                "approved_by": null,
                                "report_reasons": null,
                                "all_awardings": [],
                                "subreddit_id": "t5_81eyvm",
                                "body": "[deleted]",
                                "edited": false,
                                "author_flair_css_class": null,
                                "downs": 0,
                                "is_submitter": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "associated_award": null,
                                "stickied": false,
                                "subreddit_type": "public",
                                "can_gild": false,
                                "top_awarded_type": null,
                                "unrepliable_reason": null,
                                "author_flair_text_color": "dark",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vfcfx/",
                                "num_reports": null,
                                "locked": false,
                                "name": "t1_n5vfcfx",
                                "created": 1753826216,
                                "subreddit": "LocalLLaMA",
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "collapsed": true,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 1,
                                "depth": 2,
                                "author_flair_background_color": "",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "mod_note": null,
                                "distinguished": null
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ve3a7",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "mustafar0111",
                      "can_mod_post": false,
                      "created_utc": 1753825834,
                      "send_replies": true,
                      "parent_id": "t1_n5vdem7",
                      "score": 21,
                      "author_fullname": "t2_iulq4li0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The AI MAX+ 395 with 128GB of RAM can now apparently run Llama 4 Scout 109B at 15 tokens per second.\n\n[https://videocardz.com/newz/amd-enables-ryzen-ai-max-300-strix-halo-support-for-128b-parameters-for-local-ai-models](https://videocardz.com/newz/amd-enables-ryzen-ai-max-300-strix-halo-support-for-128b-parameters-for-local-ai-models)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ve3a7",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The AI MAX+ 395 with 128GB of RAM can now apparently run Llama 4 Scout 109B at 15 tokens per second.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://videocardz.com/newz/amd-enables-ryzen-ai-max-300-strix-halo-support-for-128b-parameters-for-local-ai-models\"&gt;https://videocardz.com/newz/amd-enables-ryzen-ai-max-300-strix-halo-support-for-128b-parameters-for-local-ai-models&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5ve3a7/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753825834,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 21
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5vdem7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "grabber4321",
            "can_mod_post": false,
            "created_utc": 1753825626,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 5,
            "author_fullname": "t2_1180s0gl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "ok ya, but at what speed? I imagine its slow as hell even with 32B",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vdem7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ok ya, but at what speed? I imagine its slow as hell even with 32B&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vdem7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753825626,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5vo4p6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "RnRau",
                      "can_mod_post": false,
                      "created_utc": 1753828981,
                      "send_replies": true,
                      "parent_id": "t1_n5vj85i",
                      "score": 5,
                      "author_fullname": "t2_svt5u",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "No.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5vo4p6",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vo4p6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753828981,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5w7e7d",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "henfiber",
                      "can_mod_post": false,
                      "created_utc": 1753835340,
                      "send_replies": true,
                      "parent_id": "t1_n5vj85i",
                      "score": 2,
                      "author_fullname": "t2_lw9me25",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The iGPU in 9950x is only for basic desktop graphics. It has 3 compute units or so, while the linked APU has 40.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5w7e7d",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The iGPU in 9950x is only for basic desktop graphics. It has 3 compute units or so, while the linked APU has 40.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5w7e7d/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753835340,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5vj85i",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "960be6dde311",
            "can_mod_post": false,
            "created_utc": 1753827423,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 3,
            "author_fullname": "t2_1mf6icgwm4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Will this be available for the 9950X eventually? It has an iGPU.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vj85i",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Will this be available for the 9950X eventually? It has an iGPU.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5vj85i/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753827423,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5w5t2j",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "haikusbot",
                      "can_mod_post": false,
                      "created_utc": 1753834789,
                      "send_replies": true,
                      "parent_id": "t1_n5w5run",
                      "score": 1,
                      "author_fullname": "t2_7q331wlw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "*Is there a new one*\n\n*Or is this the same one that's*\n\n*Been out for months now?*\n\n\\- Django\\_McFly\n\n---\n\n^(I detect haikus. And sometimes, successfully.) ^[Learn&amp;#32;more&amp;#32;about&amp;#32;me.](https://www.reddit.com/r/haikusbot/)\n\n^(Opt out of replies: \"haikusbot opt out\" | Delete my comment: \"haikusbot delete\")",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5w5t2j",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;Is there a new one&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Or is this the same one that&amp;#39;s&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Been out for months now?&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;- Django_McFly&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;sup&gt;I detect haikus. And sometimes, successfully.&lt;/sup&gt; &lt;sup&gt;&lt;a href=\"https://www.reddit.com/r/haikusbot/\"&gt;Learn&amp;#32;more&amp;#32;about&amp;#32;me.&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;sup&gt;Opt out of replies: &amp;quot;haikusbot opt out&amp;quot; | Delete my comment: &amp;quot;haikusbot delete&amp;quot;&lt;/sup&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcoce7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5w5t2j/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753834789,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5w5run",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Django_McFly",
            "can_mod_post": false,
            "created_utc": 1753834777,
            "send_replies": true,
            "parent_id": "t3_1mcoce7",
            "score": 1,
            "author_fullname": "t2_g35vlbqkh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Is there a new one or is this the same one that's been out for months now?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5w5run",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is there a new one or is this the same one that&amp;#39;s been out for months now?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcoce7/amds_ryzen_ai_max_processors_now_offer_a_whopping/n5w5run/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753834777,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcoce7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]