[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hey r/LocalLLaMA !\n\nI wanted to share our implementation of TTD-DR (Test-Time Diffusion Deep Researcher) in OptILLM. This is particularly exciting for the local LLM community because it works with ANY OpenAI-compatible model - including your local llama.cpp, Ollama, or vLLM setups!\n\n# What is TTD-DR?\n\nTTD-DR is a clever approach from [this paper](https://arxiv.org/abs/2507.16075v1) that applies diffusion model concepts to text generation. Instead of generating research in one shot, it:\n\n1. Creates an initial \"noisy\" draft\n2. Analyzes gaps in the research\n3. Searches the web to fill those gaps\n4. Iteratively \"denoises\" the report over multiple iterations\n\nThink of it like Stable Diffusion but for research reports - starting rough and progressively refining.\n\n# Why this matters for local LLMs\n\nThe biggest limitation of local models (especially smaller ones) is their knowledge cutoff and tendency to hallucinate. TTD-DR solves this by:\n\n* **Always grounding responses in real web sources** (15-30+ per report)\n* **Working with ANY model**\n* **Compensating for smaller model limitations** through iterative refinement\n\n# Technical Implementation\n\n    # Example usage with local model\n    from openai import OpenAI\n    \n    client = OpenAI(\n        api_key=\"optillm\",  # Use \"optillm\" for local inference\n        base_url=\"http://localhost:8000/v1\"\n    )\n    \n    response = client.chat.completions.create(\n        model=\"deep_research-Qwen/Qwen3-32B\",  # Your local model\n        messages=[{\"role\": \"user\", \"content\": \"Research the latest developments in open source LLMs\"}]\n    )\n\nKey features:\n\n* Selenium-based web search (runs Chrome in background)\n* Smart session management to avoid multiple browser windows\n* Configurable iterations (default 5) and max sources (default 30)\n* Works with LiteLLM, so supports 100+ model providers\n\n# Real-world testing\n\nWe tested on 47 complex research queries. Some examples:\n\n* \"Analyze the AI agents landscape and tooling ecosystem\"\n* \"Investment implications of social media platform regulations\"\n* \"DeFi protocol adoption by traditional institutions\"\n\nSample reports here: [https://github.com/codelion/optillm/tree/main/optillm/plugins/deep\\_research/sample\\_reports](https://github.com/codelion/optillm/tree/main/optillm/plugins/deep_research/sample_reports)\n\n# Links\n\n* Implementation: [https://github.com/codelion/optillm/tree/main/optillm/plugins/deep\\_research](https://github.com/codelion/optillm/tree/main/optillm/plugins/deep_research)\n* Original paper: [https://arxiv.org/abs/2507.16075v1](https://arxiv.org/abs/2507.16075v1)\n* OptiLLM repo: [https://github.com/codelion/optillm](https://github.com/codelion/optillm)\n\nWould love to hear what research topics you throw at it and which local models work best for you! Also happy to answer any technical questions about the implementation.\n\n**Edit**: For those asking about API costs - this is 100% local! The only external calls are to Google search (via Selenium), no API keys needed except for your local model.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Implemented Test-Time Diffusion Deep Researcher (TTD-DR) - Turn any local LLM into a powerful research agent with real web sources",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m9xi84",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 1,
            "author_flair_background_color": "#93b1ba",
            "subreddit_type": "public",
            "ups": 20,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": "7d1f04e6-4920-11ef-b2e1-2e580594e1a1",
            "is_original_content": false,
            "author_fullname": "t2_e0bph",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 20,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Llama 3.1"
              }
            ],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753546990,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt; !&lt;/p&gt;\n\n&lt;p&gt;I wanted to share our implementation of TTD-DR (Test-Time Diffusion Deep Researcher) in OptILLM. This is particularly exciting for the local LLM community because it works with ANY OpenAI-compatible model - including your local llama.cpp, Ollama, or vLLM setups!&lt;/p&gt;\n\n&lt;h1&gt;What is TTD-DR?&lt;/h1&gt;\n\n&lt;p&gt;TTD-DR is a clever approach from &lt;a href=\"https://arxiv.org/abs/2507.16075v1\"&gt;this paper&lt;/a&gt; that applies diffusion model concepts to text generation. Instead of generating research in one shot, it:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Creates an initial &amp;quot;noisy&amp;quot; draft&lt;/li&gt;\n&lt;li&gt;Analyzes gaps in the research&lt;/li&gt;\n&lt;li&gt;Searches the web to fill those gaps&lt;/li&gt;\n&lt;li&gt;Iteratively &amp;quot;denoises&amp;quot; the report over multiple iterations&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Think of it like Stable Diffusion but for research reports - starting rough and progressively refining.&lt;/p&gt;\n\n&lt;h1&gt;Why this matters for local LLMs&lt;/h1&gt;\n\n&lt;p&gt;The biggest limitation of local models (especially smaller ones) is their knowledge cutoff and tendency to hallucinate. TTD-DR solves this by:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Always grounding responses in real web sources&lt;/strong&gt; (15-30+ per report)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Working with ANY model&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Compensating for smaller model limitations&lt;/strong&gt; through iterative refinement&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Technical Implementation&lt;/h1&gt;\n\n&lt;pre&gt;&lt;code&gt;# Example usage with local model\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=&amp;quot;optillm&amp;quot;,  # Use &amp;quot;optillm&amp;quot; for local inference\n    base_url=&amp;quot;http://localhost:8000/v1&amp;quot;\n)\n\nresponse = client.chat.completions.create(\n    model=&amp;quot;deep_research-Qwen/Qwen3-32B&amp;quot;,  # Your local model\n    messages=[{&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;Research the latest developments in open source LLMs&amp;quot;}]\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Key features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Selenium-based web search (runs Chrome in background)&lt;/li&gt;\n&lt;li&gt;Smart session management to avoid multiple browser windows&lt;/li&gt;\n&lt;li&gt;Configurable iterations (default 5) and max sources (default 30)&lt;/li&gt;\n&lt;li&gt;Works with LiteLLM, so supports 100+ model providers&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Real-world testing&lt;/h1&gt;\n\n&lt;p&gt;We tested on 47 complex research queries. Some examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;Analyze the AI agents landscape and tooling ecosystem&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;Investment implications of social media platform regulations&amp;quot;&lt;/li&gt;\n&lt;li&gt;&amp;quot;DeFi protocol adoption by traditional institutions&amp;quot;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Sample reports here: &lt;a href=\"https://github.com/codelion/optillm/tree/main/optillm/plugins/deep_research/sample_reports\"&gt;https://github.com/codelion/optillm/tree/main/optillm/plugins/deep_research/sample_reports&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Links&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Implementation: &lt;a href=\"https://github.com/codelion/optillm/tree/main/optillm/plugins/deep_research\"&gt;https://github.com/codelion/optillm/tree/main/optillm/plugins/deep_research&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Original paper: &lt;a href=\"https://arxiv.org/abs/2507.16075v1\"&gt;https://arxiv.org/abs/2507.16075v1&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;OptiLLM repo: &lt;a href=\"https://github.com/codelion/optillm\"&gt;https://github.com/codelion/optillm&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would love to hear what research topics you throw at it and which local models work best for you! Also happy to answer any technical questions about the implementation.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit&lt;/strong&gt;: For those asking about API costs - this is 100% local! The only external calls are to Google search (via Selenium), no API keys needed except for your local model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": "Llama 3.1",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1m9xi84",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "asankhs",
            "discussion_type": null,
            "num_comments": 11,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "light",
            "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/",
            "subreddit_subscribers": 504973,
            "created_utc": 1753546990,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5avxg4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "prusswan",
            "can_mod_post": false,
            "created_utc": 1753553068,
            "send_replies": true,
            "parent_id": "t3_1m9xi84",
            "score": 3,
            "author_fullname": "t2_kegwk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "have been looking for a local deep research tool that does not rely on search apis (e.g. Firecrawl, DDG), seems like this is the one",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5avxg4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;have been looking for a local deep research tool that does not rely on search apis (e.g. Firecrawl, DDG), seems like this is the one&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5avxg4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753553068,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9xi84",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "7d1f04e6-4920-11ef-b2e1-2e580594e1a1",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ako4z",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DinoAmino",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5ak2xt",
                                "score": 2,
                                "author_fullname": "t2_j1v7f",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Excellent üëç",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ako4z",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Excellent üëç&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9xi84",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5ako4z/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753549629,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753549629,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ay5tq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Zyguard7777777",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5ak2xt",
                                "score": 2,
                                "author_fullname": "t2_zo1h5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I believe searxng can be run locally in a docker image right?\n\n\nAnyhow, looks very interesting! I've been looking into making my own deep research workflow in langgraph so will defo take a look and try it out!¬†",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ay5tq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I believe searxng can be run locally in a docker image right?&lt;/p&gt;\n\n&lt;p&gt;Anyhow, looks very interesting! I&amp;#39;ve been looking into making my own deep research workflow in langgraph so will defo take a look and try it out!¬†&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9xi84",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5ay5tq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753553769,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753553769,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ak2xt",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "asankhs",
                      "can_mod_post": false,
                      "created_utc": 1753549447,
                      "send_replies": true,
                      "parent_id": "t1_n5ajfgt",
                      "score": 5,
                      "author_fullname": "t2_e0bph",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Just to keep everything local and avoid any external APIs beyond the LLM. It is easy to add an option to use a web search api, the web search is its own plugin.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ak2xt",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 3.1"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just to keep everything local and avoid any external APIs beyond the LLM. It is easy to add an option to use a web search api, the web search is its own plugin.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9xi84",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5ak2xt/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753549447,
                      "author_flair_text": "Llama 3.1",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#93b1ba",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5ajfgt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DinoAmino",
            "can_mod_post": false,
            "created_utc": 1753549249,
            "send_replies": true,
            "parent_id": "t3_1m9xi84",
            "score": 2,
            "author_fullname": "t2_j1v7f",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Always interested in your work and looking forward to updating my OptiLLM image later.  I use selenium but only for automated browser tests. I use searxng for web search. Why did you choose selenium here over using an API for search?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ajfgt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Always interested in your work and looking forward to updating my OptiLLM image later.  I use selenium but only for automated browser tests. I use searxng for web search. Why did you choose selenium here over using an API for search?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5ajfgt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753549249,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9xi84",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "7d1f04e6-4920-11ef-b2e1-2e580594e1a1",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ajbaa",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Chromix_",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5aftx0",
                                "score": 1,
                                "author_fullname": "t2_k7w2h",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thanks for the explanation. The papers also don't say that LLMs *cannot* do the mentioned things, or always fail. Just that the result quality usually decreases. There'll still be usable results in some runs, just not as many as expected.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ajbaa",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for the explanation. The papers also don&amp;#39;t say that LLMs &lt;em&gt;cannot&lt;/em&gt; do the mentioned things, or always fail. Just that the result quality usually decreases. There&amp;#39;ll still be usable results in some runs, just not as many as expected.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9xi84",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5ajbaa/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753549212,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753549212,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5aftx0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "asankhs",
                      "can_mod_post": false,
                      "created_utc": 1753548139,
                      "send_replies": true,
                      "parent_id": "t1_n5aevqq",
                      "score": 3,
                      "author_fullname": "t2_e0bph",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "¬†you are correct that LLMs can be misled by low-quality information. However, TTD-DR's \"noise\" isn't random garbage - it's more like an \"incomplete first attempt.\" The key insight is that the initial draft serves as a **structural scaffold**, not the final content. Think of it like:\n\n¬† \\- Initial draft: \"Here's the general shape of what a research report on X should look like\"\n\n¬† \\- Not: \"Here's misinformation that will confuse later steps\"  \n  \nIn our implementation, we've seen that even when the initial draft has errors, the iterative process corrects them because each denoising step is grounded in **real web searches**, not just LLM reasoning.  \n  \nYou're spot on about AbsenceBench - LLMs struggle with identifying what's missing. TTD-DR cleverly sidesteps this by using **comparative gap analysis** rather than absolute detection:\n\n¬† Instead of: \"What's missing from this report?\"\n\n¬† TTD-DR asks: \"What questions would a reader have after reading this draft?\"\n\n¬† This reframing works much better because:\n\n¬† \\- It leverages LLMs' strength in generating follow-up questions¬†   \n  \\- It doesn't require the model to have perfect knowledge of what \"should\" be there  \n  \\- The web search then fills these gaps with real information",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5aftx0",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 3.1"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;¬†you are correct that LLMs can be misled by low-quality information. However, TTD-DR&amp;#39;s &amp;quot;noise&amp;quot; isn&amp;#39;t random garbage - it&amp;#39;s more like an &amp;quot;incomplete first attempt.&amp;quot; The key insight is that the initial draft serves as a &lt;strong&gt;structural scaffold&lt;/strong&gt;, not the final content. Think of it like:&lt;/p&gt;\n\n&lt;p&gt;¬† - Initial draft: &amp;quot;Here&amp;#39;s the general shape of what a research report on X should look like&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;¬† - Not: &amp;quot;Here&amp;#39;s misinformation that will confuse later steps&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;In our implementation, we&amp;#39;ve seen that even when the initial draft has errors, the iterative process corrects them because each denoising step is grounded in &lt;strong&gt;real web searches&lt;/strong&gt;, not just LLM reasoning.  &lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;re spot on about AbsenceBench - LLMs struggle with identifying what&amp;#39;s missing. TTD-DR cleverly sidesteps this by using &lt;strong&gt;comparative gap analysis&lt;/strong&gt; rather than absolute detection:&lt;/p&gt;\n\n&lt;p&gt;¬† Instead of: &amp;quot;What&amp;#39;s missing from this report?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;¬† TTD-DR asks: &amp;quot;What questions would a reader have after reading this draft?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;¬† This reframing works much better because:&lt;/p&gt;\n\n&lt;p&gt;¬† - It leverages LLMs&amp;#39; strength in generating follow-up questions¬†&lt;br/&gt;\n  - It doesn&amp;#39;t require the model to have perfect knowledge of what &amp;quot;should&amp;quot; be there&lt;br/&gt;\n  - The web search then fills these gaps with real information&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9xi84",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5aftx0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753548139,
                      "author_flair_text": "Llama 3.1",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#93b1ba",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5aevqq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Chromix_",
            "can_mod_post": false,
            "created_utc": 1753547838,
            "send_replies": true,
            "parent_id": "t3_1m9xi84",
            "score": 1,
            "author_fullname": "t2_k7w2h",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I wonder how that can work sufficiently.\n\n&gt;Creates an initial \"noisy\" draft\n\nAnother paper has shown that [LLMs get mislead, distracted](https://www.reddit.com/r/LocalLLaMA/comments/1kn2mv9/llms_get_lost_in_multiturn_conversation/) by low-quality, or incorrect information early on in the prompt, as well as by [typos and such](https://www.reddit.com/r/LocalLLaMA/comments/1lkht3t/typos_in_the_prompt_lead_to_worse_results/).\n\n&gt;Analyzes gaps in the research\n\nAccording to [AbsenceBench](https://www.reddit.com/r/LocalLLaMA/comments/1lgsykj/absencebench_llms_cant_tell_whats_missing/) LLMs - even reasoning LLMs - have trouble figuring out what's missing.\n\nThus, how does this approach work reliably in practice?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5aevqq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I wonder how that can work sufficiently.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Creates an initial &amp;quot;noisy&amp;quot; draft&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Another paper has shown that &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1kn2mv9/llms_get_lost_in_multiturn_conversation/\"&gt;LLMs get mislead, distracted&lt;/a&gt; by low-quality, or incorrect information early on in the prompt, as well as by &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1lkht3t/typos_in_the_prompt_lead_to_worse_results/\"&gt;typos and such&lt;/a&gt;.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Analyzes gaps in the research&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;According to &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1lgsykj/absencebench_llms_cant_tell_whats_missing/\"&gt;AbsenceBench&lt;/a&gt; LLMs - even reasoning LLMs - have trouble figuring out what&amp;#39;s missing.&lt;/p&gt;\n\n&lt;p&gt;Thus, how does this approach work reliably in practice?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5aevqq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753547838,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9xi84",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "7d1f04e6-4920-11ef-b2e1-2e580594e1a1",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5clalb",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Glittering-Call8746",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5ag4r9",
                                "score": 1,
                                "author_fullname": "t2_tqwl6sawb",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Ok glhf",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5clalb",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ok glhf&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9xi84",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5clalb/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753573771,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753573771,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ag4r9",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "asankhs",
                      "can_mod_post": false,
                      "created_utc": 1753548234,
                      "send_replies": true,
                      "parent_id": "t1_n5afovx",
                      "score": 2,
                      "author_fullname": "t2_e0bph",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I am working on finishing the DeepConsult benchmark to get some results, the original paper has the results for Google's implementation. All the samples reports in the repo are from the DeepConsult benchmark.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ag4r9",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 3.1"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am working on finishing the DeepConsult benchmark to get some results, the original paper has the results for Google&amp;#39;s implementation. All the samples reports in the repo are from the DeepConsult benchmark.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9xi84",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5ag4r9/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753548234,
                      "author_flair_text": "Llama 3.1",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#93b1ba",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5afovx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Glittering-Call8746",
            "can_mod_post": false,
            "created_utc": 1753548095,
            "send_replies": true,
            "parent_id": "t3_1m9xi84",
            "score": 1,
            "author_fullname": "t2_tqwl6sawb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Any benchmark scores ?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5afovx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Any benchmark scores ?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9xi84/implemented_testtime_diffusion_deep_researcher/n5afovx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753548095,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9xi84",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]