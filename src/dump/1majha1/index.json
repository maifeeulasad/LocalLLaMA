[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Could get NVIDIA RTX PRO 4000 Blackwell - 24GB GDDR7  1 275,50 euros without VAT.   \nBut its only 140W and 8960 CUDA  cores. Takes only 1 slot. Is it worth? Some Epyc board could fit 6 of these...with pci-e 5.0",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "NVIDIA RTX PRO 4000 Blackwell - 24GB GDDR7",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1majha1",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.8,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 12,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1jk2ep8a52",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 12,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753613986,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could get NVIDIA RTX PRO 4000 Blackwell - 24GB GDDR7  1 275,50 euros without VAT.&lt;br/&gt;\nBut its only 140W and 8960 CUDA  cores. Takes only 1 slot. Is it worth? Some Epyc board could fit 6 of these...with pci-e 5.0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1majha1",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Rich_Artist_8327",
            "discussion_type": null,
            "num_comments": 28,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/",
            "subreddit_subscribers": 505616,
            "created_utc": 1753613986,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5f04um",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Secure_Reflection409",
            "can_mod_post": false,
            "created_utc": 1753615919,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 5,
            "author_fullname": "t2_by77ogdhr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Seems great for single slot?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5f04um",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Seems great for single slot?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f04um/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753615919,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5glo0s",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ThenExtension9196",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5f016l",
                                "score": 1,
                                "author_fullname": "t2_ess5kaos",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "And ecc. Yes the purpose of these are to be used in multiples while being easier to work with for power and cooling. I have a rtx 6000 pro max q and it’s fantastic. Personally I’d try to get the rtx 5000 pro if you can.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5glo0s",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And ecc. Yes the purpose of these are to be used in multiples while being easier to work with for power and cooling. I have a rtx 6000 pro max q and it’s fantastic. Personally I’d try to get the rtx 5000 pro if you can.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": true,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5glo0s/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753635427,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753635427,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5f016l",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Rich_Artist_8327",
                      "can_mod_post": false,
                      "created_utc": 1753615868,
                      "send_replies": true,
                      "parent_id": "t1_n5eymfy",
                      "score": 5,
                      "author_fullname": "t2_1jk2ep8a52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "but its dense and blower",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5f016l",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;but its dense and blower&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f016l/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753615868,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5eymfy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Easy_Kitchen7819",
            "can_mod_post": false,
            "created_utc": 1753615169,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 2,
            "author_fullname": "t2_b51tl28l",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "As i understand it's level about rtx5070 with 24Gb VRAM. Look for tests with 5070 and llm",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5eymfy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;As i understand it&amp;#39;s level about rtx5070 with 24Gb VRAM. Look for tests with 5070 and llm&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5eymfy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753615169,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ibjuk",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "FullstackSensei",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5htwu1",
                                "score": 1,
                                "author_fullname": "t2_17n3nqtj56",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "If you have 1000 concurrent users, you'll have a lot of headaches with those RTX Pro 4000 cards. For such workloads, get a system with SXM GPUs.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ibjuk",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you have 1000 concurrent users, you&amp;#39;ll have a lot of headaches with those RTX Pro 4000 cards. For such workloads, get a system with SXM GPUs.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5ibjuk/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753654204,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753654204,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5htwu1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Rich_Artist_8327",
                      "can_mod_post": false,
                      "created_utc": 1753648645,
                      "send_replies": true,
                      "parent_id": "t1_n5f6vr9",
                      "score": 1,
                      "author_fullname": "t2_1jk2ep8a52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Exactly, for single user of few, CPUs can be used. But in my case I need scale and 1000 users simultaneously inferencing, the only way is to use GPUs",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5htwu1",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Exactly, for single user of few, CPUs can be used. But in my case I need scale and 1000 users simultaneously inferencing, the only way is to use GPUs&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5htwu1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753648645,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5f6vr9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "FullstackSensei",
            "can_mod_post": false,
            "created_utc": 1753618962,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 1,
            "author_fullname": "t2_17n3nqtj56",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Depends on what you want to use them for. If you're looking primarily for inference with large MoE models, dual Xeon 8480 with a couple of 3090s seems to be the best option for a DDR5 system because of AMX. Engineering sample 8480s are available on ebay for under 200. The main cost is RAM and motherboard, but those are no more expensive than if you get an SP5 Epyc. PCIe 5.0 won't make a difference in inference. Heck you can very probably drop them into X8 3.0 lanes without a noticeable difference in inference performance",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5f6vr9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Depends on what you want to use them for. If you&amp;#39;re looking primarily for inference with large MoE models, dual Xeon 8480 with a couple of 3090s seems to be the best option for a DDR5 system because of AMX. Engineering sample 8480s are available on ebay for under 200. The main cost is RAM and motherboard, but those are no more expensive than if you get an SP5 Epyc. PCIe 5.0 won&amp;#39;t make a difference in inference. Heck you can very probably drop them into X8 3.0 lanes without a noticeable difference in inference performance&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f6vr9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753618962,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5hmutu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Fearless-Image-1421",
            "can_mod_post": false,
            "created_utc": 1753646497,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 1,
            "author_fullname": "t2_h7h2buv7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have an Epyc 9354p with 512GB ram and seem to be able to run some CPU only LLMs fine. I have reference documents for the LLM to use for knowledge about a narrow topic.  \n\nI tried installing an RTX 4090 and that was a hot mess, since I have no idea what I’m doing.  Seems like an issue with a non-consumer grade server vs consumer GPU? Regardless, unless I decide to go A6000 ADA or the newer Pro 5000 or Pro 6000, I seem to be getting along for now. \n\nNot sure this is a long term sustainable solution, but a good stop gap while the application is being built and tested via vibe coding. Again, this is NOT my domain, but it allows me to test out some ideas without having to hire a lot of engineers.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hmutu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have an Epyc 9354p with 512GB ram and seem to be able to run some CPU only LLMs fine. I have reference documents for the LLM to use for knowledge about a narrow topic.  &lt;/p&gt;\n\n&lt;p&gt;I tried installing an RTX 4090 and that was a hot mess, since I have no idea what I’m doing.  Seems like an issue with a non-consumer grade server vs consumer GPU? Regardless, unless I decide to go A6000 ADA or the newer Pro 5000 or Pro 6000, I seem to be getting along for now. &lt;/p&gt;\n\n&lt;p&gt;Not sure this is a long term sustainable solution, but a good stop gap while the application is being built and tested via vibe coding. Again, this is NOT my domain, but it allows me to test out some ideas without having to hire a lot of engineers.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5hmutu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753646497,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5fyk6z",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Rich_Artist_8327",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5foraf",
                                                              "score": 0,
                                                              "author_fullname": "t2_1jk2ep8a52",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "thats true, 6 wont work with vLLM so I will create 2 nodes where each has 4 GPUs behind load balancer. Pcie 5.0 16x is plenty",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5fyk6z",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;thats true, 6 wont work with vLLM so I will create 2 nodes where each has 4 GPUs behind load balancer. Pcie 5.0 16x is plenty&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1majha1",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5fyk6z/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753628576,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753628576,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 0
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5foraf",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "henfiber",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5fkt9f",
                                                    "score": 5,
                                                    "author_fullname": "t2_lw9me25",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "You're not getting 6x with tensor parallel ([1](https://rocm.blogs.amd.com/artificial-intelligence/tensor-parallelism/README.html), [2](https://huggingface.co/docs/transformers/v4.48.0/perf_infer_gpu_multi)), especially with these RTX PROs which lack NVLink. Moreover, most frameworks only support GPUs in powers of 2 (2, 4, 8) so you will only be able to use 4 in tensor parallel. And you can also scale CPUs similarly (2x AMD CPUs up to 2x192 cores, 8x Intel CPUs up to 8x86 cores).",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5foraf",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re not getting 6x with tensor parallel (&lt;a href=\"https://rocm.blogs.amd.com/artificial-intelligence/tensor-parallelism/README.html\"&gt;1&lt;/a&gt;, &lt;a href=\"https://huggingface.co/docs/transformers/v4.48.0/perf_infer_gpu_multi\"&gt;2&lt;/a&gt;), especially with these RTX PROs which lack NVLink. Moreover, most frameworks only support GPUs in powers of 2 (2, 4, 8) so you will only be able to use 4 in tensor parallel. And you can also scale CPUs similarly (2x AMD CPUs up to 2x192 cores, 8x Intel CPUs up to 8x86 cores).&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1majha1",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5foraf/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753625465,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753625465,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 5
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5fkt9f",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Rich_Artist_8327",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5fjbq0",
                                          "score": 0,
                                          "author_fullname": "t2_1jk2ep8a52",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "But running 6 of them in tensor parallel",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5fkt9f",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But running 6 of them in tensor parallel&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1majha1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5fkt9f/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753624148,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753624148,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 0
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5fjbq0",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "henfiber",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5f3b5h",
                                "score": 5,
                                "author_fullname": "t2_lw9me25",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Agree with the overall message, but to be more precise, GPUs are not 1000x faster, they are 10-100x faster (in FP16 matrix multiplication) depending on the GPU/CPUs compared.\n\nThis specific GPU (RTX PRO 4000) with 188 FP16 Tensor TFLOPs should be about \\~45-50x faster than a EPYC Genoa 48-core CPU (\\~4 AVX512 FP16 TFLOPs).\n\nIn my experience, the difference is smaller in MoE models (5-6x instead of 50x), not sure why though (probably the expert routing part is latency sensitive or not optimally implemented). The difference is also smaller when compared to the latest Intel server CPUs with the AMX instruction set.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5fjbq0",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Agree with the overall message, but to be more precise, GPUs are not 1000x faster, they are 10-100x faster (in FP16 matrix multiplication) depending on the GPU/CPUs compared.&lt;/p&gt;\n\n&lt;p&gt;This specific GPU (RTX PRO 4000) with 188 FP16 Tensor TFLOPs should be about ~45-50x faster than a EPYC Genoa 48-core CPU (~4 AVX512 FP16 TFLOPs).&lt;/p&gt;\n\n&lt;p&gt;In my experience, the difference is smaller in MoE models (5-6x instead of 50x), not sure why though (probably the expert routing part is latency sensitive or not optimally implemented). The difference is also smaller when compared to the latest Intel server CPUs with the AMX instruction set.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5fjbq0/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753623643,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753623643,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5f5xw8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "No_Afternoon_4260",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5f3b5h",
                                "score": 1,
                                "author_fullname": "t2_cj9kap4bx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "True",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5f5xw8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;True&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f5xw8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753618564,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1753618564,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5f3b5h",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Rich_Artist_8327",
                      "can_mod_post": false,
                      "created_utc": 1753617423,
                      "send_replies": true,
                      "parent_id": "t1_n5f1zw4",
                      "score": 12,
                      "author_fullname": "t2_1jk2ep8a52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "GPU is still much faster even CPU would have same memory bandwidth. Its plain stupidity to inference with server CPU. For one request and slow token/s its ok, but for parallel, GPUs are 1000x faster even if memory bandwidth would be same.",
                      "edited": 1753619060,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5f3b5h",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GPU is still much faster even CPU would have same memory bandwidth. Its plain stupidity to inference with server CPU. For one request and slow token/s its ok, but for parallel, GPUs are 1000x faster even if memory bandwidth would be same.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f3b5h/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753617423,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 12
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5glq4t",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ThenExtension9196",
                      "can_mod_post": false,
                      "created_utc": 1753635445,
                      "send_replies": true,
                      "parent_id": "t1_n5f1zw4",
                      "score": -1,
                      "author_fullname": "t2_ess5kaos",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "0 vs 8k cuda cores. I tried LLM on my EPYC 9354 and it was hot garbage vs a simple rtx 4000 Ada card I had laying around.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5glq4t",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;0 vs 8k cuda cores. I tried LLM on my EPYC 9354 and it was hot garbage vs a simple rtx 4000 Ada card I had laying around.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": true,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5glq4t/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753635445,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5f1zw4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "OutrageousMinimum191",
            "can_mod_post": false,
            "created_utc": 1753616814,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": -3,
            "author_fullname": "t2_13ejj8rbqm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Memory Bandwidth 672 gb/sec, only by 15-20% better than Epyc CPUs. Better to buy more DDR5 memory sticks. Imo, new GPUs which are slower than 1000gb/s are not worth to buy for AI tasks. Cheap used units - maybe.",
            "edited": 1753617015,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5f1zw4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Memory Bandwidth 672 gb/sec, only by 15-20% better than Epyc CPUs. Better to buy more DDR5 memory sticks. Imo, new GPUs which are slower than 1000gb/s are not worth to buy for AI tasks. Cheap used units - maybe.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f1zw4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753616814,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5f3gmo",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Rich_Artist_8327",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5f12oa",
                                          "score": 1,
                                          "author_fullname": "t2_1jk2ep8a52",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I was referring to previous comment about 5070",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5f3gmo",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was referring to previous comment about 5070&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1majha1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f3gmo/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753617492,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753617492,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5f12oa",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "prusswan",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5eydoq",
                                "score": 6,
                                "author_fullname": "t2_kegwk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "But you need 6 slots rather than 1, the density may matter for some",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5f12oa",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But you need 6 slots rather than 1, the density may matter for some&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f12oa/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753616375,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753616375,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5f1ffo",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "GPTshop_ai",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5f14cs",
                                                    "score": -2,
                                                    "author_fullname": "t2_rkmud0isr",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "he is always right, he is god ;-)",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5f1ffo",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;he is always right, he is god ;-)&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1majha1",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f1ffo/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753616545,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753616545,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": -2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5f14cs",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "NNN_Throwaway2",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5eyxml",
                                          "score": 4,
                                          "author_fullname": "t2_8rrihts9",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "also jensen: \"the more you buy the more you save\"",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5f14cs",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;also jensen: &amp;quot;the more you buy the more you save&amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1majha1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f14cs/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753616399,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753616399,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5eyxml",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "GPTshop_ai",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5eydoq",
                                "score": -2,
                                "author_fullname": "t2_rkmud0isr",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "jensen: \"you need to scale up before you scale out\".",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5eyxml",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;jensen: &amp;quot;you need to scale up before you scale out&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5eyxml/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753615322,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753615322,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": -2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5eydoq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Rich_Artist_8327",
                      "can_mod_post": false,
                      "created_utc": 1753615046,
                      "send_replies": true,
                      "parent_id": "t1_n5ewo5v",
                      "score": 2,
                      "author_fullname": "t2_1jk2ep8a52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Buying 6 RTX PRO 4000 Blackwell - 24GB would cost same as one rtx pro 6000 and would have 144GB vram instead of 96GB",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5eydoq",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Buying 6 RTX PRO 4000 Blackwell - 24GB would cost same as one rtx pro 6000 and would have 144GB vram instead of 96GB&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5eydoq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753615046,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5ewo5v",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "GPTshop_ai",
            "can_mod_post": false,
            "created_utc": 1753614168,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": -7,
            "author_fullname": "t2_rkmud0isr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "buy rtx pro 6000, nothing less.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ewo5v",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;buy rtx pro 6000, nothing less.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5ewo5v/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753614168,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5fer8d",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "prusswan",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5f8wuf",
                                          "score": 1,
                                          "author_fullname": "t2_kegwk",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "[https://www.reddit.com/r/nvidia/comments/1m3hm6v/cooling\\_the\\_nvidia\\_rtx\\_pro\\_6000\\_blackwell/](https://www.reddit.com/r/nvidia/comments/1m3hm6v/cooling_the_nvidia_rtx_pro_6000_blackwell/)\n\n  \nFor driver issues, you can google for a few threads that lead direct to Nvidia forums",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5fer8d",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/nvidia/comments/1m3hm6v/cooling_the_nvidia_rtx_pro_6000_blackwell/\"&gt;https://www.reddit.com/r/nvidia/comments/1m3hm6v/cooling_the_nvidia_rtx_pro_6000_blackwell/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For driver issues, you can google for a few threads that lead direct to Nvidia forums&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1majha1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5fer8d/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753622013,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753622013,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5f8wuf",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "MelodicRecognition7",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5f5fzo",
                                "score": 1,
                                "author_fullname": "t2_1eex9ug5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; It does have thermal issues and some driver issues\n\ncould you elaborate please?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5f8wuf",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It does have thermal issues and some driver issues&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;could you elaborate please?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f8wuf/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753619797,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753619797,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5f5fzo",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "prusswan",
                      "can_mod_post": false,
                      "created_utc": 1753618352,
                      "send_replies": true,
                      "parent_id": "t1_n5ex2vt",
                      "score": 1,
                      "author_fullname": "t2_kegwk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It does have thermal issues and some driver issues (relatively new model not yet launched in all regions, so understandable), but for that much VRAM on a single slot? Look no further",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5f5fzo",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It does have thermal issues and some driver issues (relatively new model not yet launched in all regions, so understandable), but for that much VRAM on a single slot? Look no further&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f5fzo/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753618352,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5f60mx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No_Afternoon_4260",
                      "can_mod_post": false,
                      "created_utc": 1753618596,
                      "send_replies": true,
                      "parent_id": "t1_n5ex2vt",
                      "score": 1,
                      "author_fullname": "t2_cj9kap4bx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Y?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5f60mx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Y?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f60mx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753618596,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5ex2vt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "reacusn",
            "can_mod_post": false,
            "created_utc": 1753614381,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": -5,
            "author_fullname": "t2_1ppg6hcqm8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "Whatever you do, don't buy an rtx pro 6000.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ex2vt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Whatever you do, don&amp;#39;t buy an rtx pro 6000.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5ex2vt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753614381,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -5
          }
        }
      ],
      "before": null
    }
  }
]