[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Could get NVIDIA RTX PRO 4000 Blackwell - 24GB GDDR7  1 275,50 euros without VAT.   \nBut its only 140W and 8960 CUDA  cores. Takes only 1 slot. Is it worth? Some Epyc board could fit 6 of these...with pci-e 5.0",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "NVIDIA RTX PRO 4000 Blackwell - 24GB GDDR7",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1majha1",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.72,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 9,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1jk2ep8a52",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 9,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753613986,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could get NVIDIA RTX PRO 4000 Blackwell - 24GB GDDR7  1 275,50 euros without VAT.&lt;br/&gt;\nBut its only 140W and 8960 CUDA  cores. Takes only 1 slot. Is it worth? Some Epyc board could fit 6 of these...with pci-e 5.0&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1majha1",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Rich_Artist_8327",
            "discussion_type": null,
            "num_comments": 30,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/",
            "subreddit_subscribers": 505881,
            "created_utc": 1753613986,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5f04um",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Secure_Reflection409",
            "can_mod_post": false,
            "created_utc": 1753615919,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 6,
            "author_fullname": "t2_by77ogdhr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Seems great for single slot?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5f04um",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Seems great for single slot?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f04um/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753615919,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5glo0s",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ThenExtension9196",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5f016l",
                                "score": 1,
                                "author_fullname": "t2_ess5kaos",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "And ecc. Yes the purpose of these are to be used in multiples while being easier to work with for power and cooling. I have a rtx 6000 pro max q and it’s fantastic. Personally I’d try to get the rtx 5000 pro if you can.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5glo0s",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And ecc. Yes the purpose of these are to be used in multiples while being easier to work with for power and cooling. I have a rtx 6000 pro max q and it’s fantastic. Personally I’d try to get the rtx 5000 pro if you can.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": true,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5glo0s/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753635427,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753635427,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5f016l",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Rich_Artist_8327",
                      "can_mod_post": false,
                      "created_utc": 1753615868,
                      "send_replies": true,
                      "parent_id": "t1_n5eymfy",
                      "score": 5,
                      "author_fullname": "t2_1jk2ep8a52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "but its dense and blower",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5f016l",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;but its dense and blower&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f016l/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753615868,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5eymfy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Easy_Kitchen7819",
            "can_mod_post": false,
            "created_utc": 1753615169,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 5,
            "author_fullname": "t2_b51tl28l",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "As i understand it's level about rtx5070 with 24Gb VRAM. Look for tests with 5070 and llm",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5eymfy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;As i understand it&amp;#39;s level about rtx5070 with 24Gb VRAM. Look for tests with 5070 and llm&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5eymfy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753615169,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ibjuk",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "FullstackSensei",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5htwu1",
                                "score": 1,
                                "author_fullname": "t2_17n3nqtj56",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "If you have 1000 concurrent users, you'll have a lot of headaches with those RTX Pro 4000 cards. For such workloads, get a system with SXM GPUs.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ibjuk",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you have 1000 concurrent users, you&amp;#39;ll have a lot of headaches with those RTX Pro 4000 cards. For such workloads, get a system with SXM GPUs.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5ibjuk/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753654204,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753654204,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5htwu1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Rich_Artist_8327",
                      "can_mod_post": false,
                      "created_utc": 1753648645,
                      "send_replies": true,
                      "parent_id": "t1_n5f6vr9",
                      "score": 1,
                      "author_fullname": "t2_1jk2ep8a52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Exactly, for single user of few, CPUs can be used. But in my case I need scale and 1000 users simultaneously inferencing, the only way is to use GPUs",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5htwu1",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Exactly, for single user of few, CPUs can be used. But in my case I need scale and 1000 users simultaneously inferencing, the only way is to use GPUs&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5htwu1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753648645,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5f6vr9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "FullstackSensei",
            "can_mod_post": false,
            "created_utc": 1753618962,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 1,
            "author_fullname": "t2_17n3nqtj56",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Depends on what you want to use them for. If you're looking primarily for inference with large MoE models, dual Xeon 8480 with a couple of 3090s seems to be the best option for a DDR5 system because of AMX. Engineering sample 8480s are available on ebay for under 200. The main cost is RAM and motherboard, but those are no more expensive than if you get an SP5 Epyc. PCIe 5.0 won't make a difference in inference. Heck you can very probably drop them into X8 3.0 lanes without a noticeable difference in inference performance",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5f6vr9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Depends on what you want to use them for. If you&amp;#39;re looking primarily for inference with large MoE models, dual Xeon 8480 with a couple of 3090s seems to be the best option for a DDR5 system because of AMX. Engineering sample 8480s are available on ebay for under 200. The main cost is RAM and motherboard, but those are no more expensive than if you get an SP5 Epyc. PCIe 5.0 won&amp;#39;t make a difference in inference. Heck you can very probably drop them into X8 3.0 lanes without a noticeable difference in inference performance&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f6vr9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753618962,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5hmutu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Fearless-Image-1421",
            "can_mod_post": false,
            "created_utc": 1753646497,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 1,
            "author_fullname": "t2_h7h2buv7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have an Epyc 9354p with 512GB ram and seem to be able to run some CPU only LLMs fine. I have reference documents for the LLM to use for knowledge about a narrow topic.  \n\nI tried installing an RTX 4090 and that was a hot mess, since I have no idea what I’m doing.  Seems like an issue with a non-consumer grade server vs consumer GPU? Regardless, unless I decide to go A6000 ADA or the newer Pro 5000 or Pro 6000, I seem to be getting along for now. \n\nNot sure this is a long term sustainable solution, but a good stop gap while the application is being built and tested via vibe coding. Again, this is NOT my domain, but it allows me to test out some ideas without having to hire a lot of engineers.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hmutu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have an Epyc 9354p with 512GB ram and seem to be able to run some CPU only LLMs fine. I have reference documents for the LLM to use for knowledge about a narrow topic.  &lt;/p&gt;\n\n&lt;p&gt;I tried installing an RTX 4090 and that was a hot mess, since I have no idea what I’m doing.  Seems like an issue with a non-consumer grade server vs consumer GPU? Regardless, unless I decide to go A6000 ADA or the newer Pro 5000 or Pro 6000, I seem to be getting along for now. &lt;/p&gt;\n\n&lt;p&gt;Not sure this is a long term sustainable solution, but a good stop gap while the application is being built and tested via vibe coding. Again, this is NOT my domain, but it allows me to test out some ideas without having to hire a lot of engineers.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5hmutu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753646497,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5k0gy0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "altoidsjedi",
            "can_mod_post": false,
            "created_utc": 1753677493,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 1,
            "author_fullname": "t2_6f7v3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What is the alternative you are considering?\n\nWhat I would say is that it's worth noting that the Blackwell Generation includes full native support for inferencing (and training) within the FP8 and FP4 formats. The Ampere/rtx30xx series cards lacks both, and the Ada/rtx40xx series lacks FP4 entirely and typically lacks FP8 access for training. \n\nIf you're comparing this to something like a 24GB 3090/4090 or equivalent Ampere or Ada workstation card... I would say it makes more sense to go for the 24GB Blackwell Pro, as it's more future proof for training and inferencing models of the present/future, thanks to the native support of both the FP8 and FP4 format. \n\nIf you're thinking of 4-6 of these in lieu of a Blackwell 6000 Pro.. yes, technically this is a cheaper way to 96GB of total VRAM. \n\nBut it comes with its own issues inherent to a multi-GPU setup, especially if you venture into any use cases outside of inferencing modern LLM architectures. \n\n- Your power supply and usage with 4-6 cards will likely be higher and more complex than a single 6000 Blackwell running at full or reduced voltage. \n- Your memory bandwidth will be lower than if you had a single Blackwell 6000.\n- You will open yourself up to potential bottlenecks / issues in performance depending on the PCIE interconnects between each card (especially for training / fine tuning).\n- You will be locked out of using certain large models and architectures (typically in the video diffusion model space) that requires the entire model be loaded into a single graphics card. \n- You need to spend the prerequisite money to have a host system that can support 4-6 Blackwell 4000 cards at PCIE5.0 across 4-6 PCIE5.0 slots.\n\nOn that last point, It's MUCH cheaper in upfront cost and in future electricity cost to have a current-gen CPU/Mobo combination that is PCIE5.0x16 compatible on a single slot for a Blackwell 6000 96GB card than it is to have some EPYC monstrosity that will need serious investment in processor, MOBO, RAM, and power supply to properly support 4-6 PCIE5.0 GPU cards. \n\nMy setup — Ryzen 9600X, ASUS MoBo, 96GB DDR5-6400, and a Corsair 1000W PSU — cost me less than $800 to make, and it's ready to support a card like the Blackwell 6000 96GB at full PCIE5.0x16 speed. \n\nBuilding a 4x PCIE5.0 system that is otherwise equivalent, using EPYC, is easily going to be somewhere between 2x-10x the price depending on your CPU/RAM config. And such a system might have unique power draw requirements that you would have to make sure your outlets can provide, assuming you're running this at home out of a bedroom or garage or something. \n\nIf you already have an EPYC server, and just legit want to spend the 5000-6000 for simply inferencing the largest LLM models possible on GPU for as cheap as possible on Blackwell, it should work fine, I guess. Assuming you don't care much about space, heat, or electricity bills. \n\nBut if I was in your shoes and had the money, my preferences would be as follows from highest to lowest\n\n1. Blackwell Pro 6000 96GB (on a Zen5 consumer workstation)\n2. Blackwell Pro 5000 48GB + 2x Pro 4000 24GB\n3. 4x Blackwell Pro 4000 24GB\n4. 4x of some combination of older generation RTX 30/40/Ampere/Ada series consumer or workstation cards with 24GB.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5k0gy0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What is the alternative you are considering?&lt;/p&gt;\n\n&lt;p&gt;What I would say is that it&amp;#39;s worth noting that the Blackwell Generation includes full native support for inferencing (and training) within the FP8 and FP4 formats. The Ampere/rtx30xx series cards lacks both, and the Ada/rtx40xx series lacks FP4 entirely and typically lacks FP8 access for training. &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re comparing this to something like a 24GB 3090/4090 or equivalent Ampere or Ada workstation card... I would say it makes more sense to go for the 24GB Blackwell Pro, as it&amp;#39;s more future proof for training and inferencing models of the present/future, thanks to the native support of both the FP8 and FP4 format. &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re thinking of 4-6 of these in lieu of a Blackwell 6000 Pro.. yes, technically this is a cheaper way to 96GB of total VRAM. &lt;/p&gt;\n\n&lt;p&gt;But it comes with its own issues inherent to a multi-GPU setup, especially if you venture into any use cases outside of inferencing modern LLM architectures. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Your power supply and usage with 4-6 cards will likely be higher and more complex than a single 6000 Blackwell running at full or reduced voltage. &lt;/li&gt;\n&lt;li&gt;Your memory bandwidth will be lower than if you had a single Blackwell 6000.&lt;/li&gt;\n&lt;li&gt;You will open yourself up to potential bottlenecks / issues in performance depending on the PCIE interconnects between each card (especially for training / fine tuning).&lt;/li&gt;\n&lt;li&gt;You will be locked out of using certain large models and architectures (typically in the video diffusion model space) that requires the entire model be loaded into a single graphics card. &lt;/li&gt;\n&lt;li&gt;You need to spend the prerequisite money to have a host system that can support 4-6 Blackwell 4000 cards at PCIE5.0 across 4-6 PCIE5.0 slots.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;On that last point, It&amp;#39;s MUCH cheaper in upfront cost and in future electricity cost to have a current-gen CPU/Mobo combination that is PCIE5.0x16 compatible on a single slot for a Blackwell 6000 96GB card than it is to have some EPYC monstrosity that will need serious investment in processor, MOBO, RAM, and power supply to properly support 4-6 PCIE5.0 GPU cards. &lt;/p&gt;\n\n&lt;p&gt;My setup — Ryzen 9600X, ASUS MoBo, 96GB DDR5-6400, and a Corsair 1000W PSU — cost me less than $800 to make, and it&amp;#39;s ready to support a card like the Blackwell 6000 96GB at full PCIE5.0x16 speed. &lt;/p&gt;\n\n&lt;p&gt;Building a 4x PCIE5.0 system that is otherwise equivalent, using EPYC, is easily going to be somewhere between 2x-10x the price depending on your CPU/RAM config. And such a system might have unique power draw requirements that you would have to make sure your outlets can provide, assuming you&amp;#39;re running this at home out of a bedroom or garage or something. &lt;/p&gt;\n\n&lt;p&gt;If you already have an EPYC server, and just legit want to spend the 5000-6000 for simply inferencing the largest LLM models possible on GPU for as cheap as possible on Blackwell, it should work fine, I guess. Assuming you don&amp;#39;t care much about space, heat, or electricity bills. &lt;/p&gt;\n\n&lt;p&gt;But if I was in your shoes and had the money, my preferences would be as follows from highest to lowest&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Blackwell Pro 6000 96GB (on a Zen5 consumer workstation)&lt;/li&gt;\n&lt;li&gt;Blackwell Pro 5000 48GB + 2x Pro 4000 24GB&lt;/li&gt;\n&lt;li&gt;4x Blackwell Pro 4000 24GB&lt;/li&gt;\n&lt;li&gt;4x of some combination of older generation RTX 30/40/Ampere/Ada series consumer or workstation cards with 24GB.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5k0gy0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753677493,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5l0kti",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Rich_Repeat_22",
            "can_mod_post": false,
            "created_utc": 1753697553,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": 1,
            "author_fullname": "t2_viufiki6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Ehm no. I wouldn't get it until the AMD R9700 comes out. Because at similar price we getting 32GB and far better chip to do the number cracking.\n\nSo until then I would say hold. After all ain't worth to get a 5070 perf chip with 24GB for €1300, better off try to find a 4090 if cheaper.\n\n  \nAgain is NOT bad product if you get 2+ of these, but 1 is meh.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5l0kti",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ehm no. I wouldn&amp;#39;t get it until the AMD R9700 comes out. Because at similar price we getting 32GB and far better chip to do the number cracking.&lt;/p&gt;\n\n&lt;p&gt;So until then I would say hold. After all ain&amp;#39;t worth to get a 5070 perf chip with 24GB for €1300, better off try to find a 4090 if cheaper.&lt;/p&gt;\n\n&lt;p&gt;Again is NOT bad product if you get 2+ of these, but 1 is meh.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5l0kti/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753697553,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5fyk6z",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Rich_Artist_8327",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5foraf",
                                                              "score": 0,
                                                              "author_fullname": "t2_1jk2ep8a52",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "thats true, 6 wont work with vLLM so I will create 2 nodes where each has 4 GPUs behind load balancer. Pcie 5.0 16x is plenty",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5fyk6z",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;thats true, 6 wont work with vLLM so I will create 2 nodes where each has 4 GPUs behind load balancer. Pcie 5.0 16x is plenty&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1majha1",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5fyk6z/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753628576,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753628576,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 0
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5foraf",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "henfiber",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5fkt9f",
                                                    "score": 5,
                                                    "author_fullname": "t2_lw9me25",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "You're not getting 6x with tensor parallel ([1](https://rocm.blogs.amd.com/artificial-intelligence/tensor-parallelism/README.html), [2](https://huggingface.co/docs/transformers/v4.48.0/perf_infer_gpu_multi)), especially with these RTX PROs which lack NVLink. Moreover, most frameworks only support GPUs in powers of 2 (2, 4, 8) so you will only be able to use 4 in tensor parallel. And you can also scale CPUs similarly (2x AMD CPUs up to 2x192 cores, 8x Intel CPUs up to 8x86 cores).",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5foraf",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re not getting 6x with tensor parallel (&lt;a href=\"https://rocm.blogs.amd.com/artificial-intelligence/tensor-parallelism/README.html\"&gt;1&lt;/a&gt;, &lt;a href=\"https://huggingface.co/docs/transformers/v4.48.0/perf_infer_gpu_multi\"&gt;2&lt;/a&gt;), especially with these RTX PROs which lack NVLink. Moreover, most frameworks only support GPUs in powers of 2 (2, 4, 8) so you will only be able to use 4 in tensor parallel. And you can also scale CPUs similarly (2x AMD CPUs up to 2x192 cores, 8x Intel CPUs up to 8x86 cores).&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1majha1",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5foraf/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753625465,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753625465,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 5
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5fkt9f",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Rich_Artist_8327",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5fjbq0",
                                          "score": 0,
                                          "author_fullname": "t2_1jk2ep8a52",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "But running 6 of them in tensor parallel",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5fkt9f",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But running 6 of them in tensor parallel&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1majha1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5fkt9f/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753624148,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753624148,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 0
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5fjbq0",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "henfiber",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5f3b5h",
                                "score": 4,
                                "author_fullname": "t2_lw9me25",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Agree with the overall message, but to be more precise, GPUs are not 1000x faster, they are 10-100x faster (in FP16 matrix multiplication) depending on the GPU/CPUs compared.\n\nThis specific GPU (RTX PRO 4000) with 188 FP16 Tensor TFLOPs should be about \\~45-50x faster than a EPYC Genoa 48-core CPU (\\~4 AVX512 FP16 TFLOPs).\n\nIn my experience, the difference is smaller in MoE models (5-6x instead of 50x), not sure why though (probably the expert routing part is latency sensitive or not optimally implemented). The difference is also smaller when compared to the latest Intel server CPUs with the AMX instruction set.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5fjbq0",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Agree with the overall message, but to be more precise, GPUs are not 1000x faster, they are 10-100x faster (in FP16 matrix multiplication) depending on the GPU/CPUs compared.&lt;/p&gt;\n\n&lt;p&gt;This specific GPU (RTX PRO 4000) with 188 FP16 Tensor TFLOPs should be about ~45-50x faster than a EPYC Genoa 48-core CPU (~4 AVX512 FP16 TFLOPs).&lt;/p&gt;\n\n&lt;p&gt;In my experience, the difference is smaller in MoE models (5-6x instead of 50x), not sure why though (probably the expert routing part is latency sensitive or not optimally implemented). The difference is also smaller when compared to the latest Intel server CPUs with the AMX instruction set.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5fjbq0/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753623643,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753623643,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5f5xw8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "No_Afternoon_4260",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5f3b5h",
                                "score": 1,
                                "author_fullname": "t2_cj9kap4bx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "True",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5f5xw8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;True&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f5xw8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753618564,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1753618564,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5f3b5h",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Rich_Artist_8327",
                      "can_mod_post": false,
                      "created_utc": 1753617423,
                      "send_replies": true,
                      "parent_id": "t1_n5f1zw4",
                      "score": 14,
                      "author_fullname": "t2_1jk2ep8a52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "GPU is still much faster even CPU would have same memory bandwidth. Its plain stupidity to inference with server CPU. For one request and slow token/s its ok, but for parallel, GPUs are 1000x faster even if memory bandwidth would be same.",
                      "edited": 1753619060,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5f3b5h",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GPU is still much faster even CPU would have same memory bandwidth. Its plain stupidity to inference with server CPU. For one request and slow token/s its ok, but for parallel, GPUs are 1000x faster even if memory bandwidth would be same.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f3b5h/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753617423,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 14
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5glq4t",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ThenExtension9196",
                      "can_mod_post": false,
                      "created_utc": 1753635445,
                      "send_replies": true,
                      "parent_id": "t1_n5f1zw4",
                      "score": -1,
                      "author_fullname": "t2_ess5kaos",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "0 vs 8k cuda cores. I tried LLM on my EPYC 9354 and it was hot garbage vs a simple rtx 4000 Ada card I had laying around.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5glq4t",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;0 vs 8k cuda cores. I tried LLM on my EPYC 9354 and it was hot garbage vs a simple rtx 4000 Ada card I had laying around.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": true,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5glq4t/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753635445,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5f1zw4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "OutrageousMinimum191",
            "can_mod_post": false,
            "created_utc": 1753616814,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": -3,
            "author_fullname": "t2_13ejj8rbqm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Memory Bandwidth 672 gb/sec, only by 15-20% better than Epyc CPUs. Better to buy more DDR5 memory sticks. Imo, new GPUs which are slower than 1000gb/s are not worth to buy for AI tasks. Cheap used units - maybe.",
            "edited": 1753617015,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5f1zw4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Memory Bandwidth 672 gb/sec, only by 15-20% better than Epyc CPUs. Better to buy more DDR5 memory sticks. Imo, new GPUs which are slower than 1000gb/s are not worth to buy for AI tasks. Cheap used units - maybe.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f1zw4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753616814,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5f3gmo",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Rich_Artist_8327",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5f12oa",
                                          "score": 1,
                                          "author_fullname": "t2_1jk2ep8a52",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I was referring to previous comment about 5070",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5f3gmo",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was referring to previous comment about 5070&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1majha1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f3gmo/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753617492,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753617492,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5f12oa",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "prusswan",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5eydoq",
                                "score": 7,
                                "author_fullname": "t2_kegwk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "But you need 6 slots rather than 1, the density may matter for some",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5f12oa",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But you need 6 slots rather than 1, the density may matter for some&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f12oa/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753616375,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753616375,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 7
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5f1ffo",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "GPTshop_ai",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5f14cs",
                                                    "score": -2,
                                                    "author_fullname": "t2_rkmud0isr",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "he is always right, he is god ;-)",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5f1ffo",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;he is always right, he is god ;-)&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1majha1",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f1ffo/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753616545,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753616545,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": -2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5f14cs",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "NNN_Throwaway2",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5eyxml",
                                          "score": 4,
                                          "author_fullname": "t2_8rrihts9",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "also jensen: \"the more you buy the more you save\"",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5f14cs",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;also jensen: &amp;quot;the more you buy the more you save&amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1majha1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f14cs/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753616399,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753616399,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5eyxml",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "GPTshop_ai",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5eydoq",
                                "score": -2,
                                "author_fullname": "t2_rkmud0isr",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "jensen: \"you need to scale up before you scale out\".",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5eyxml",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;jensen: &amp;quot;you need to scale up before you scale out&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5eyxml/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753615322,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753615322,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": -2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5eydoq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Rich_Artist_8327",
                      "can_mod_post": false,
                      "created_utc": 1753615046,
                      "send_replies": true,
                      "parent_id": "t1_n5ewo5v",
                      "score": 2,
                      "author_fullname": "t2_1jk2ep8a52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Buying 6 RTX PRO 4000 Blackwell - 24GB would cost same as one rtx pro 6000 and would have 144GB vram instead of 96GB",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5eydoq",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Buying 6 RTX PRO 4000 Blackwell - 24GB would cost same as one rtx pro 6000 and would have 144GB vram instead of 96GB&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5eydoq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753615046,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5ewo5v",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "GPTshop_ai",
            "can_mod_post": false,
            "created_utc": 1753614168,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": -6,
            "author_fullname": "t2_rkmud0isr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "buy rtx pro 6000, nothing less.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ewo5v",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;buy rtx pro 6000, nothing less.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5ewo5v/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753614168,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5fer8d",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "prusswan",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5f8wuf",
                                          "score": 1,
                                          "author_fullname": "t2_kegwk",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "[https://www.reddit.com/r/nvidia/comments/1m3hm6v/cooling\\_the\\_nvidia\\_rtx\\_pro\\_6000\\_blackwell/](https://www.reddit.com/r/nvidia/comments/1m3hm6v/cooling_the_nvidia_rtx_pro_6000_blackwell/)\n\n  \nFor driver issues, you can google for a few threads that lead direct to Nvidia forums",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5fer8d",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/nvidia/comments/1m3hm6v/cooling_the_nvidia_rtx_pro_6000_blackwell/\"&gt;https://www.reddit.com/r/nvidia/comments/1m3hm6v/cooling_the_nvidia_rtx_pro_6000_blackwell/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For driver issues, you can google for a few threads that lead direct to Nvidia forums&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1majha1",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5fer8d/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753622013,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753622013,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5f8wuf",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "MelodicRecognition7",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5f5fzo",
                                "score": 1,
                                "author_fullname": "t2_1eex9ug5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; It does have thermal issues and some driver issues\n\ncould you elaborate please?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5f8wuf",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It does have thermal issues and some driver issues&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;could you elaborate please?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1majha1",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f8wuf/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753619797,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753619797,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5f5fzo",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "prusswan",
                      "can_mod_post": false,
                      "created_utc": 1753618352,
                      "send_replies": true,
                      "parent_id": "t1_n5ex2vt",
                      "score": 1,
                      "author_fullname": "t2_kegwk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It does have thermal issues and some driver issues (relatively new model not yet launched in all regions, so understandable), but for that much VRAM on a single slot? Look no further",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5f5fzo",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It does have thermal issues and some driver issues (relatively new model not yet launched in all regions, so understandable), but for that much VRAM on a single slot? Look no further&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f5fzo/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753618352,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5f60mx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No_Afternoon_4260",
                      "can_mod_post": false,
                      "created_utc": 1753618596,
                      "send_replies": true,
                      "parent_id": "t1_n5ex2vt",
                      "score": 1,
                      "author_fullname": "t2_cj9kap4bx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Y?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5f60mx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Y?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1majha1",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5f60mx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753618596,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5ex2vt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "reacusn",
            "can_mod_post": false,
            "created_utc": 1753614381,
            "send_replies": true,
            "parent_id": "t3_1majha1",
            "score": -5,
            "author_fullname": "t2_1ppg6hcqm8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "Whatever you do, don't buy an rtx pro 6000.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ex2vt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Whatever you do, don&amp;#39;t buy an rtx pro 6000.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1majha1/nvidia_rtx_pro_4000_blackwell_24gb_gddr7/n5ex2vt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753614381,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1majha1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -5
          }
        }
      ],
      "before": null
    }
  }
]