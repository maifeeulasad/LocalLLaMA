[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "\\^\n\nMedium article claim\n\nI just get instant OOMs. Here is the command I use in VLLM with [https://huggingface.co/cpatonn/GLM-4.5-Air-AWQ](https://huggingface.co/cpatonn/GLM-4.5-Air-AWQ)\n\n❯ vllm serve /home/nomadictuba2005/models/glm45air-awq \\\\\n\n  \\--quantization compressed-tensors \\\\\n\n  \\--dtype float16 \\\\\n\n  \\--kv-cache-dtype fp8 \\\\\n\n  \\--trust-remote-code \\\\\n\n  \\--max-model-len 8192 \\\\\n\n  \\--gpu-memory-utilization 0.90 \\\\\n\n  \\--enforce-eager \\\\\n\n  \\--port 8000\n\n  \nI have a 4090, 7700x, and 64gb of ram. Can anyone help with this?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "How are people running GLM-4.5-Air in int4 on a 4090 or even laptops with 64GB of ram? I get Out of Memory errors.",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 25,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mejoef",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.8,
            "author_flair_background_color": null,
            "ups": 12,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_uptissiz",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 12,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/7lLmVurI3-t4P_1cm1hdcuyoDp8yoZC-OhadsPl4DOo.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754012212,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;^&lt;/p&gt;\n\n&lt;p&gt;Medium article claim&lt;/p&gt;\n\n&lt;p&gt;I just get instant OOMs. Here is the command I use in VLLM with &lt;a href=\"https://huggingface.co/cpatonn/GLM-4.5-Air-AWQ\"&gt;https://huggingface.co/cpatonn/GLM-4.5-Air-AWQ&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;❯ vllm serve /home/nomadictuba2005/models/glm45air-awq \\&lt;/p&gt;\n\n&lt;p&gt;--quantization compressed-tensors \\&lt;/p&gt;\n\n&lt;p&gt;--dtype float16 \\&lt;/p&gt;\n\n&lt;p&gt;--kv-cache-dtype fp8 \\&lt;/p&gt;\n\n&lt;p&gt;--trust-remote-code \\&lt;/p&gt;\n\n&lt;p&gt;--max-model-len 8192 \\&lt;/p&gt;\n\n&lt;p&gt;--gpu-memory-utilization 0.90 \\&lt;/p&gt;\n\n&lt;p&gt;--enforce-eager \\&lt;/p&gt;\n\n&lt;p&gt;--port 8000&lt;/p&gt;\n\n&lt;p&gt;I have a 4090, 7700x, and 64gb of ram. Can anyone help with this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/ob4424fkabgf1.png",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/ob4424fkabgf1.png?auto=webp&amp;s=70ca3f052b497b70c5f0ebe0423671a165270434",
                    "width": 1100,
                    "height": 202
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/ob4424fkabgf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b4e638541ae9fe39a61d5cebca812548c1426f0b",
                      "width": 108,
                      "height": 19
                    },
                    {
                      "url": "https://preview.redd.it/ob4424fkabgf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bbc3a9c659f6a38a87e46a99a05cb31aaa7e36ac",
                      "width": 216,
                      "height": 39
                    },
                    {
                      "url": "https://preview.redd.it/ob4424fkabgf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0348e75eca8133644a3e570aee46a2a3a4af3b4e",
                      "width": 320,
                      "height": 58
                    },
                    {
                      "url": "https://preview.redd.it/ob4424fkabgf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8cc2954650f18e8b15649d6b2f3cc71a3943ca7b",
                      "width": 640,
                      "height": 117
                    },
                    {
                      "url": "https://preview.redd.it/ob4424fkabgf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=515cceed69bfadc7c09e6fa077abee44fe311afe",
                      "width": 960,
                      "height": 176
                    },
                    {
                      "url": "https://preview.redd.it/ob4424fkabgf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dd8db0b6e4b1ed6ffd6a61d1e9eb5832c47e8d46",
                      "width": 1080,
                      "height": 198
                    }
                  ],
                  "variants": {},
                  "id": "Ux4xrL_cOzrqZtnZgjw8b4MKDUdhGBhtV-cnMt2d4YI"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mejoef",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Pro-editor-1105",
            "discussion_type": null,
            "num_comments": 17,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/",
            "stickied": false,
            "url": "https://i.redd.it/ob4424fkabgf1.png",
            "subreddit_subscribers": 508191,
            "created_utc": 1754012212,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6a4eo7",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "LongjumpingRespect85",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6a25nn",
                                                    "score": -1,
                                                    "author_fullname": "t2_felz752rz",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Try ik_llama",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6a4eo7",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Try ik_llama&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mejoef",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6a4eo7/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754015265,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754015265,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": -1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6a25nn",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Pro-editor-1105",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6a0w5m",
                                          "score": -1,
                                          "author_fullname": "t2_uptissiz",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Trying to use vllm but am encountering all sorts of errors, although now that I have offloaded to CPU none of them appear due to VRAM and RAM constraints so that is good but I got no idea. Most recent error I am getting is\n\nRuntimeError: Engine process failed to start. See stack trace for the root cause.\n\nwhich probably means the model did load, but then this happened.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6a25nn",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Trying to use vllm but am encountering all sorts of errors, although now that I have offloaded to CPU none of them appear due to VRAM and RAM constraints so that is good but I got no idea. Most recent error I am getting is&lt;/p&gt;\n\n&lt;p&gt;RuntimeError: Engine process failed to start. See stack trace for the root cause.&lt;/p&gt;\n\n&lt;p&gt;which probably means the model did load, but then this happened.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mejoef",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6a25nn/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754014436,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754014436,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6a0w5m",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "knownboyofno",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n69z95z",
                                "score": 3,
                                "author_fullname": "t2_5y9divj7",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It doesn't have support in llama.cpp currently but would work on Mac because of MLX.   \nMLX post: [https://www.reddit.com/r/LocalLLaMA/comments/1mdqj9g/works\\_well\\_glm\\_45\\_air\\_mlx\\_lm\\_studio\\_mac\\_claude/](https://www.reddit.com/r/LocalLLaMA/comments/1mdqj9g/works_well_glm_45_air_mlx_lm_studio_mac_claude/)\n\nGGUF wating post: [https://www.reddit.com/r/LocalLLaMA/comments/1mdykfn/everyone\\_from\\_rlocalllama\\_refreshing\\_hugging\\_face/](https://www.reddit.com/r/LocalLLaMA/comments/1mdykfn/everyone_from_rlocalllama_refreshing_hugging_face/)",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6a0w5m",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It doesn&amp;#39;t have support in llama.cpp currently but would work on Mac because of MLX.&lt;br/&gt;\nMLX post: &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1mdqj9g/works_well_glm_45_air_mlx_lm_studio_mac_claude/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1mdqj9g/works_well_glm_45_air_mlx_lm_studio_mac_claude/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;GGUF wating post: &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1mdykfn/everyone_from_rlocalllama_refreshing_hugging_face/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1mdykfn/everyone_from_rlocalllama_refreshing_hugging_face/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mejoef",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6a0w5m/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754013972,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754013972,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6c3siv",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "_cpatonn",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n69z95z",
                                "score": 1,
                                "author_fullname": "t2_1upmzfagim",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "For ram offload, llama.cpp and its variants are more suitable and straightforward. vllm/python dependencies alone is a nightmare, offloading between vram and ram makes it alot worse.\n\nI have a feeling unsloth will have a dedicated post/blog on running GLM 4.5 splitted between vram and ram as soon as GGUF suppor arrives.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6c3siv",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For ram offload, llama.cpp and its variants are more suitable and straightforward. vllm/python dependencies alone is a nightmare, offloading between vram and ram makes it alot worse.&lt;/p&gt;\n\n&lt;p&gt;I have a feeling unsloth will have a dedicated post/blog on running GLM 4.5 splitted between vram and ram as soon as GGUF suppor arrives.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mejoef",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6c3siv/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754049981,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754049981,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n69z95z",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "Pro-editor-1105",
                      "can_mod_post": false,
                      "created_utc": 1754013375,
                      "send_replies": true,
                      "parent_id": "t1_n69ybme",
                      "score": -9,
                      "author_fullname": "t2_uptissiz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Kinda right there lol, this is literally a screenshot taken out of chatgpt. But remember it's an MoE which means it can offload to system ram, so the actual GPU ram is mostly equal to a 12B model but the experts go to ram.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n69z95z",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Kinda right there lol, this is literally a screenshot taken out of chatgpt. But remember it&amp;#39;s an MoE which means it can offload to system ram, so the actual GPU ram is mostly equal to a 12B model but the experts go to ram.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mejoef",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n69z95z/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754013375,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -9
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n69ybme",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "knownboyofno",
            "can_mod_post": false,
            "created_utc": 1754013037,
            "send_replies": true,
            "parent_id": "t3_1mejoef",
            "score": 9,
            "author_fullname": "t2_5y9divj7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I am not sure about those numbers. I just looked it up and it is 200+GB for the Air version which is \\~60GB in INT4 bit if my math is right. What medium article are you talking about? It might be Ai generated or the person hasn't looked at anything.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n69ybme",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am not sure about those numbers. I just looked it up and it is 200+GB for the Air version which is ~60GB in INT4 bit if my math is right. What medium article are you talking about? It might be Ai generated or the person hasn&amp;#39;t looked at anything.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n69ybme/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754013037,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mejoef",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6acksu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "fp4guru",
            "can_mod_post": false,
            "created_utc": 1754018447,
            "send_replies": true,
            "parent_id": "t3_1mejoef",
            "score": 3,
            "author_fullname": "t2_1tp8zldw5g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Wait for llamacpp.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6acksu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wait for llamacpp.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6acksu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754018447,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mejoef",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6as0bn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Double_Cause4609",
            "can_mod_post": false,
            "created_utc": 1754025321,
            "send_replies": true,
            "parent_id": "t3_1mejoef",
            "score": 4,
            "author_fullname": "t2_1kubzxt2ww",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I...Don't know if you're going to get this working on vLLM.\n\nGLM-4.5 is notoriously undersupported right now and doesn't have a lot of good ways to run it, but in theory once support is merged KTransformers and LlamaCPP will be your best bet.\n\nThose frameworks let you assign tensors with some level of customizability, so you can assign experts to the CPU (most of the parameters by size), and Attention/KV Cache to GPU (most of the parameters by computational cost), and it should fit gracefully on a consumer system at around q4\\_k\\_m which is roughly equivalent to Int4 AWQ with a few caveats.\n\nYou could try the vLLM CPU backend and run it purely on CPU, though.\n\nIf you're asking about this I'm guessing you're using Windows so I'm not sure how well the vLLM CPU backend will work for you, though.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6as0bn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I...Don&amp;#39;t know if you&amp;#39;re going to get this working on vLLM.&lt;/p&gt;\n\n&lt;p&gt;GLM-4.5 is notoriously undersupported right now and doesn&amp;#39;t have a lot of good ways to run it, but in theory once support is merged KTransformers and LlamaCPP will be your best bet.&lt;/p&gt;\n\n&lt;p&gt;Those frameworks let you assign tensors with some level of customizability, so you can assign experts to the CPU (most of the parameters by size), and Attention/KV Cache to GPU (most of the parameters by computational cost), and it should fit gracefully on a consumer system at around q4_k_m which is roughly equivalent to Int4 AWQ with a few caveats.&lt;/p&gt;\n\n&lt;p&gt;You could try the vLLM CPU backend and run it purely on CPU, though.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re asking about this I&amp;#39;m guessing you&amp;#39;re using Windows so I&amp;#39;m not sure how well the vLLM CPU backend will work for you, though.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6as0bn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754025321,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mejoef",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6as7sc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Double_Cause4609",
                      "can_mod_post": false,
                      "created_utc": 1754025422,
                      "send_replies": true,
                      "parent_id": "t1_n6a8ije",
                      "score": 3,
                      "author_fullname": "t2_1kubzxt2ww",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Currently support for GLM 4.5 is not merged to LlamaCPP (and there are, to my knowledge, no valid GGUF quantizations currently) and the person managing the PR isn't super experienced (though they've done a great and admirable job so far in spite of that) so it may be some time before we have a numerically accurate implementation merged to main.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6as7sc",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Currently support for GLM 4.5 is not merged to LlamaCPP (and there are, to my knowledge, no valid GGUF quantizations currently) and the person managing the PR isn&amp;#39;t super experienced (though they&amp;#39;ve done a great and admirable job so far in spite of that) so it may be some time before we have a numerically accurate implementation merged to main.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mejoef",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6as7sc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754025422,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ayltn",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "zipperlein",
                      "can_mod_post": false,
                      "created_utc": 1754028689,
                      "send_replies": true,
                      "parent_id": "t1_n6a8ije",
                      "score": 1,
                      "author_fullname": "t2_x3duw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "3090 can run FP8 quants. vllm should just fall back to W8A16.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ayltn",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3090 can run FP8 quants. vllm should just fall back to W8A16.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mejoef",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6ayltn/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754028689,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6azemf",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ResidentPositive4122",
                      "can_mod_post": false,
                      "created_utc": 1754029111,
                      "send_replies": true,
                      "parent_id": "t1_n6a8ije",
                      "score": 1,
                      "author_fullname": "t2_10nxrjjgay",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; couldnt' run it because my GPUs don't support fp8, 3090s.\n\nvLLM can run fp8 on Ampere cards, it'll just use the Marlin kernels. You probably got some other errors there.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6azemf",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;couldnt&amp;#39; run it because my GPUs don&amp;#39;t support fp8, 3090s.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;vLLM can run fp8 on Ampere cards, it&amp;#39;ll just use the Marlin kernels. You probably got some other errors there.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mejoef",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6azemf/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754029111,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6a8ije",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "segmond",
            "can_mod_post": false,
            "created_utc": 1754016824,
            "send_replies": true,
            "parent_id": "t3_1mejoef",
            "score": 1,
            "author_fullname": "t2_ah13x",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I built vllm last night and couldnt' run it because my GPUs don't support fp8, 3090s.  I suppose you need more newer 5000 series GPU.  I downloaded the fp8, so I'm now redownloading the fp16 version and hoping I can then pass in runtime quantization to run it.   My internet link is slow, so I got another 24hrs of downloading.     I'll also try to convert that one to gguf and mess around with llama.cpp to see if I can make any progress as well.  All the folks I have seen running it on Nvidia GPUs are doing so with newer GPUs or cloud GPUs.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6a8ije",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I built vllm last night and couldnt&amp;#39; run it because my GPUs don&amp;#39;t support fp8, 3090s.  I suppose you need more newer 5000 series GPU.  I downloaded the fp8, so I&amp;#39;m now redownloading the fp16 version and hoping I can then pass in runtime quantization to run it.   My internet link is slow, so I got another 24hrs of downloading.     I&amp;#39;ll also try to convert that one to gguf and mess around with llama.cpp to see if I can make any progress as well.  All the folks I have seen running it on Nvidia GPUs are doing so with newer GPUs or cloud GPUs.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6a8ije/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754016824,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mejoef",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6bqy5b",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GregoryfromtheHood",
            "can_mod_post": false,
            "created_utc": 1754044368,
            "send_replies": true,
            "parent_id": "t3_1mejoef",
            "score": 1,
            "author_fullname": "t2_g0qor",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I can only just fit it and I'm running 1x4090 and 2x3090. I can fit about 20k context before I start getting OOM, so I feel like 72GB of VRAM is the minimum",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6bqy5b",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can only just fit it and I&amp;#39;m running 1x4090 and 2x3090. I can fit about 20k context before I start getting OOM, so I feel like 72GB of VRAM is the minimum&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6bqy5b/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754044368,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mejoef",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6a91b7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "solidsnakeblue",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n69xy6q",
                                "score": 1,
                                "author_fullname": "t2_7zh6fslk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I just commented on another post but this was the issue that ended up causing me to give up.  I think this would work on a linux native system, but not WSL.  If you figure it out please let me know",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6a91b7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I just commented on another post but this was the issue that ended up causing me to give up.  I think this would work on a linux native system, but not WSL.  If you figure it out please let me know&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mejoef",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n6a91b7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754017028,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754017028,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n69xy6q",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Pro-editor-1105",
                      "can_mod_post": false,
                      "created_utc": 1754012901,
                      "send_replies": true,
                      "parent_id": "t1_n69xena",
                      "score": 1,
                      "author_fullname": "t2_uptissiz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Just tried that before you wrote this comment, went as high as 56 and am now getting this\n\n  \nAssertionError: V1 CPU offloading requires uva (pin memory) support",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n69xy6q",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just tried that before you wrote this comment, went as high as 56 and am now getting this&lt;/p&gt;\n\n&lt;p&gt;AssertionError: V1 CPU offloading requires uva (pin memory) support&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mejoef",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n69xy6q/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754012901,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n69xena",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DeProgrammer99",
            "can_mod_post": false,
            "created_utc": 1754012703,
            "send_replies": true,
            "parent_id": "t3_1mejoef",
            "score": 0,
            "author_fullname": "t2_w4j8t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don't use vLLM, but I googled it for you. Try `--cpu-offload-gb 60`, and if that works, adjust down from there 'til it starts crashing again. [https://docs.vllm.ai/en/latest/configuration/engine\\_args.html#cacheconfig](https://docs.vllm.ai/en/latest/configuration/engine_args.html#cacheconfig)\n\nI'm sure someone will come along with better instructions for running an MoE on vLLM if there is a better way.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n69xena",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t use vLLM, but I googled it for you. Try &lt;code&gt;--cpu-offload-gb 60&lt;/code&gt;, and if that works, adjust down from there &amp;#39;til it starts crashing again. &lt;a href=\"https://docs.vllm.ai/en/latest/configuration/engine_args.html#cacheconfig\"&gt;https://docs.vllm.ai/en/latest/configuration/engine_args.html#cacheconfig&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure someone will come along with better instructions for running an MoE on vLLM if there is a better way.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mejoef/how_are_people_running_glm45air_in_int4_on_a_4090/n69xena/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754012703,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mejoef",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]