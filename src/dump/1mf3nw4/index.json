[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Ever spent weeks building the perfect LLM benchmark only to watch it crumble within a few months?\n\nClean problems, elegant difficulty curves, proper statistical controls. New model drops. Perfect scores across the board. Your tests got trained on. Weeks of work, completely worthless.\n\nSo you pivot. Make the tests harder, more complex, more creative. Models improve with time. Now everyone clusters at 90-95%. 8B models are defeating it. Your benchmark has become a participation trophy. This happened to my previous evaluation, *Can-Ai-Code*, twice.\n\nFine, you say. Random test generation it is! No more memorization, no more clustering. But congratulations, you've just unlocked new nightmares: Did you accidentally make your \"hard\" tests easier than your \"easy\" ones? Is your random number generator secretly biased? How do you even validate that hundreds of thousands of randomly generated problems \"make sense\"?\n\nYou solve that with clever statistical rigor, only to discover configuration explosion hell. You'd like to test different prompting templates and sampling parameters, but that's 5 templates times 5 samplers times 50 million tokens (a conservative estimate) equals 1.25 billion tokens per model. Your GPUs scream in horror.\n\nYou're now burning millions of tokens achieving 0.005 confidence intervals on trivial problems while critical hard points sit at 0.02 intervals begging for attention like abandoned puppies. Dynamic sampling helps - generate more tests for uncertain points, fewer for confident ones - but how to avoid p-hacking yourself?\n\nThat's when the guessing realization hits. This binary classifier task scored 60%! Amazing! Wait... that's only 20% above random chance. Your \"75% accurate\" multiple choice task is actually 50% accurate when you subtract lucky guesses. Everything is statistical lies. How are you supposed to compare models across boolean, multiple-choice and write-in answer tasks that have fundamentally different \"guess rates\"?\n\nFinally, truncation waste arrives to complete your suffering: Model given tough task hits context limits, burns 8,000 tokens, returns a loop of gibberish. You sample 10x more to maintain statistical power. That's 80K tokens wasted for one data point but with no useful answers.  You're overflowing your KV caches while the confidence intervals laugh at you.\n\nAfter drowning in this cascade of pain for months, I did what any reasonable person would do: I built an evaluation system to solve every single practical problem I encountered.\n\n# ReasonScape treats language models as information processing systems, not text completion black boxes.\n\nIt generates infinite, parametric, tokenization-aware test variations, applies statistical corrections for guessing, dynamically allocates sampling based on uncertainty, handles truncations intelligently, and visualizes the results as both enhanced leaderboards and explorable 3D cognitive landscapes.\n\n[C2: All Models x All Tasks Surface Comparison. Green Sphere indicates high-success. Red Square indicates high-truncation.](https://preview.redd.it/vsoidu4e4ggf1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=d29809860b081384d998a428bc75faeba16cedc1)\n\nThe initial C2 dataset represents \\~1 billion tokens across 9 models, revealing exactly where, how and why reasoning breaks down across 4 task domains. The interactive leaderboard shows not just scores but confidence intervals, token usage and failure modes. The explorer (links at the bottom of post) lets you navigate difficulty manifolds like some kind of LLM reasoning archaeologist, digging into spectral analysis and completion token patterns.  Make sure you're on a PC - this application has too much going on to be mobile friendly!\n\n[C2 Explorer](https://preview.redd.it/4ahuh87m4ggf1.png?width=1233&amp;format=png&amp;auto=webp&amp;s=8f6e962cdc029ce01dbca46346ec3fda47a06d7d)\n\nI built the system with progressive evaluation in mind so you can start with rapid exploration then scale to deep precision. Everything caches, everything reproduces, everything scales. ReasonScape isn't just another benchmark. It's a complete methodology: toolkit, evaluation framework, and growing dataset family rolled into one.\n\n[C2 Leaderboard \\(Static snapshot - the Interactive is much nicer!\\)](https://preview.redd.it/rn7r2k3t4ggf1.png?width=1198&amp;format=png&amp;auto=webp&amp;s=52d054e40f6f292b07b9d638d82244e8f302ce1d)\n\nThe ReasonScape experiments and the resulting datasets will grow, expand and evolve - when scores get too high we will move the difficulty grids to make the tests harder and move on to C3. I have **8 additional tasks** to bring up, and lots more reasoning models I'd like to evaluate but my 2xRTX3090 only have so much to give.\n\nThanks for reading this far! &lt;3\n\nLinks:\n\n* [ReasonScape Homepage](https://reasonscape.com/)\n* [ReasonScape Leaderboard - C2](https://reasonscape.com/c2/leaderboard)\n* [ReasonScape Explorer - C2](https://reasonscape.com/c2/explorer) (note: PC required, not mobile-friendly)\n* [ReasonScape GitHub](https://github.com/the-crypt-keeper/reasonscape)\n* [ReasonScape System Architecture](https://github.com/the-crypt-keeper/reasonscape?tab=readme-ov-file#system-architecture)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "I Generated 1 Billion Tokens (So You Don't Have To): Introducing ReasonScape",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 140,
            "top_awarded_type": null,
            "hide_score": false,
            "media_metadata": {
              "4ahuh87m4ggf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 62,
                    "x": 108,
                    "u": "https://preview.redd.it/4ahuh87m4ggf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e9b289044767660d3c8e2d034ccd1c1b1902f538"
                  },
                  {
                    "y": 125,
                    "x": 216,
                    "u": "https://preview.redd.it/4ahuh87m4ggf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e8a1fc6a4649edbc5bfde934cedfd13c3fce90c"
                  },
                  {
                    "y": 186,
                    "x": 320,
                    "u": "https://preview.redd.it/4ahuh87m4ggf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7c9c7d1e879f15dbfdea396948cc5826d3a32b67"
                  },
                  {
                    "y": 372,
                    "x": 640,
                    "u": "https://preview.redd.it/4ahuh87m4ggf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c4a45011cfb5e75257e82a1018ba38ca3849d833"
                  },
                  {
                    "y": 558,
                    "x": 960,
                    "u": "https://preview.redd.it/4ahuh87m4ggf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e3046d2f091a49910ecb192cd251d2fa91bbf04a"
                  },
                  {
                    "y": 628,
                    "x": 1080,
                    "u": "https://preview.redd.it/4ahuh87m4ggf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=053460c5647cc12262626da5af12623413fee0ff"
                  }
                ],
                "s": {
                  "y": 717,
                  "x": 1233,
                  "u": "https://preview.redd.it/4ahuh87m4ggf1.png?width=1233&amp;format=png&amp;auto=webp&amp;s=8f6e962cdc029ce01dbca46346ec3fda47a06d7d"
                },
                "id": "4ahuh87m4ggf1"
              },
              "rn7r2k3t4ggf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 73,
                    "x": 108,
                    "u": "https://preview.redd.it/rn7r2k3t4ggf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7d505276a5f0dc04e59903c6abc89821d0f8f99b"
                  },
                  {
                    "y": 146,
                    "x": 216,
                    "u": "https://preview.redd.it/rn7r2k3t4ggf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d747b1a0f8fd1a1097161d95e21ccf0503560deb"
                  },
                  {
                    "y": 216,
                    "x": 320,
                    "u": "https://preview.redd.it/rn7r2k3t4ggf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c9a6dd29394e5fb1992ae084b12e8749a9d84824"
                  },
                  {
                    "y": 433,
                    "x": 640,
                    "u": "https://preview.redd.it/rn7r2k3t4ggf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=720bb40aec42b94acce8d40bc234aa44e5b4c208"
                  },
                  {
                    "y": 650,
                    "x": 960,
                    "u": "https://preview.redd.it/rn7r2k3t4ggf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e355ab07ff4b2410135911c2070a7cb42b1b8221"
                  },
                  {
                    "y": 732,
                    "x": 1080,
                    "u": "https://preview.redd.it/rn7r2k3t4ggf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=668705727d06f0b0d4c5c5867747868786f17635"
                  }
                ],
                "s": {
                  "y": 812,
                  "x": 1198,
                  "u": "https://preview.redd.it/rn7r2k3t4ggf1.png?width=1198&amp;format=png&amp;auto=webp&amp;s=52d054e40f6f292b07b9d638d82244e8f302ce1d"
                },
                "id": "rn7r2k3t4ggf1"
              },
              "vsoidu4e4ggf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 216,
                    "x": 108,
                    "u": "https://preview.redd.it/vsoidu4e4ggf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=871d7d827171f900b2598bcca602b93414c369f8"
                  },
                  {
                    "y": 432,
                    "x": 216,
                    "u": "https://preview.redd.it/vsoidu4e4ggf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4a4c54e76149d09d301df5cbd0f5c388e82bb54d"
                  },
                  {
                    "y": 640,
                    "x": 320,
                    "u": "https://preview.redd.it/vsoidu4e4ggf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=317f1298cb62e84fc0ac688a8a4b2143d1d2fc8a"
                  },
                  {
                    "y": 1280,
                    "x": 640,
                    "u": "https://preview.redd.it/vsoidu4e4ggf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=769ba43ab175981d7853c0c0620df46e4f20be04"
                  },
                  {
                    "y": 1920,
                    "x": 960,
                    "u": "https://preview.redd.it/vsoidu4e4ggf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e16a01628210ccf57e6c94fa2d7d58110870a99"
                  },
                  {
                    "y": 2160,
                    "x": 1080,
                    "u": "https://preview.redd.it/vsoidu4e4ggf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=49835bd796714f4bcb033b2b80c71bc4b6e37e82"
                  }
                ],
                "s": {
                  "y": 3150,
                  "x": 1280,
                  "u": "https://preview.redd.it/vsoidu4e4ggf1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=d29809860b081384d998a428bc75faeba16cedc1"
                },
                "id": "vsoidu4e4ggf1"
              }
            },
            "name": "t3_1mf3nw4",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.98,
            "author_flair_background_color": "#c7b594",
            "subreddit_type": "public",
            "ups": 119,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
            "is_original_content": false,
            "author_fullname": "t2_30i1a",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 119,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://a.thumbs.redditmedia.com/-4v8QT3_SA4NBTuWsWHLP1NxBvsUSLBCUXILi1-L8H8.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Llama 3"
              }
            ],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754071528,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ever spent weeks building the perfect LLM benchmark only to watch it crumble within a few months?&lt;/p&gt;\n\n&lt;p&gt;Clean problems, elegant difficulty curves, proper statistical controls. New model drops. Perfect scores across the board. Your tests got trained on. Weeks of work, completely worthless.&lt;/p&gt;\n\n&lt;p&gt;So you pivot. Make the tests harder, more complex, more creative. Models improve with time. Now everyone clusters at 90-95%. 8B models are defeating it. Your benchmark has become a participation trophy. This happened to my previous evaluation, &lt;em&gt;Can-Ai-Code&lt;/em&gt;, twice.&lt;/p&gt;\n\n&lt;p&gt;Fine, you say. Random test generation it is! No more memorization, no more clustering. But congratulations, you&amp;#39;ve just unlocked new nightmares: Did you accidentally make your &amp;quot;hard&amp;quot; tests easier than your &amp;quot;easy&amp;quot; ones? Is your random number generator secretly biased? How do you even validate that hundreds of thousands of randomly generated problems &amp;quot;make sense&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;You solve that with clever statistical rigor, only to discover configuration explosion hell. You&amp;#39;d like to test different prompting templates and sampling parameters, but that&amp;#39;s 5 templates times 5 samplers times 50 million tokens (a conservative estimate) equals 1.25 billion tokens per model. Your GPUs scream in horror.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;re now burning millions of tokens achieving 0.005 confidence intervals on trivial problems while critical hard points sit at 0.02 intervals begging for attention like abandoned puppies. Dynamic sampling helps - generate more tests for uncertain points, fewer for confident ones - but how to avoid p-hacking yourself?&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s when the guessing realization hits. This binary classifier task scored 60%! Amazing! Wait... that&amp;#39;s only 20% above random chance. Your &amp;quot;75% accurate&amp;quot; multiple choice task is actually 50% accurate when you subtract lucky guesses. Everything is statistical lies. How are you supposed to compare models across boolean, multiple-choice and write-in answer tasks that have fundamentally different &amp;quot;guess rates&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;Finally, truncation waste arrives to complete your suffering: Model given tough task hits context limits, burns 8,000 tokens, returns a loop of gibberish. You sample 10x more to maintain statistical power. That&amp;#39;s 80K tokens wasted for one data point but with no useful answers.  You&amp;#39;re overflowing your KV caches while the confidence intervals laugh at you.&lt;/p&gt;\n\n&lt;p&gt;After drowning in this cascade of pain for months, I did what any reasonable person would do: I built an evaluation system to solve every single practical problem I encountered.&lt;/p&gt;\n\n&lt;h1&gt;ReasonScape treats language models as information processing systems, not text completion black boxes.&lt;/h1&gt;\n\n&lt;p&gt;It generates infinite, parametric, tokenization-aware test variations, applies statistical corrections for guessing, dynamically allocates sampling based on uncertainty, handles truncations intelligently, and visualizes the results as both enhanced leaderboards and explorable 3D cognitive landscapes.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vsoidu4e4ggf1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d29809860b081384d998a428bc75faeba16cedc1\"&gt;C2: All Models x All Tasks Surface Comparison. Green Sphere indicates high-success. Red Square indicates high-truncation.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The initial C2 dataset represents ~1 billion tokens across 9 models, revealing exactly where, how and why reasoning breaks down across 4 task domains. The interactive leaderboard shows not just scores but confidence intervals, token usage and failure modes. The explorer (links at the bottom of post) lets you navigate difficulty manifolds like some kind of LLM reasoning archaeologist, digging into spectral analysis and completion token patterns.  Make sure you&amp;#39;re on a PC - this application has too much going on to be mobile friendly!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4ahuh87m4ggf1.png?width=1233&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8f6e962cdc029ce01dbca46346ec3fda47a06d7d\"&gt;C2 Explorer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I built the system with progressive evaluation in mind so you can start with rapid exploration then scale to deep precision. Everything caches, everything reproduces, everything scales. ReasonScape isn&amp;#39;t just another benchmark. It&amp;#39;s a complete methodology: toolkit, evaluation framework, and growing dataset family rolled into one.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rn7r2k3t4ggf1.png?width=1198&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=52d054e40f6f292b07b9d638d82244e8f302ce1d\"&gt;C2 Leaderboard (Static snapshot - the Interactive is much nicer!)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The ReasonScape experiments and the resulting datasets will grow, expand and evolve - when scores get too high we will move the difficulty grids to make the tests harder and move on to C3. I have &lt;strong&gt;8 additional tasks&lt;/strong&gt; to bring up, and lots more reasoning models I&amp;#39;d like to evaluate but my 2xRTX3090 only have so much to give.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading this far! &amp;lt;3&lt;/p&gt;\n\n&lt;p&gt;Links:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://reasonscape.com/\"&gt;ReasonScape Homepage&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://reasonscape.com/c2/leaderboard\"&gt;ReasonScape Leaderboard - C2&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://reasonscape.com/c2/explorer\"&gt;ReasonScape Explorer - C2&lt;/a&gt; (note: PC required, not mobile-friendly)&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/the-crypt-keeper/reasonscape\"&gt;ReasonScape GitHub&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/the-crypt-keeper/reasonscape?tab=readme-ov-file#system-architecture\"&gt;ReasonScape System Architecture&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": "Llama 3",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1mf3nw4",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "kryptkpr",
            "discussion_type": null,
            "num_comments": 18,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "light",
            "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/",
            "subreddit_subscribers": 508771,
            "created_utc": 1754071528,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6fd204",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "kryptkpr",
                      "can_mod_post": false,
                      "created_utc": 1754085206,
                      "send_replies": true,
                      "parent_id": "t1_n6fcilk",
                      "score": 9,
                      "author_fullname": "t2_30i1a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That would be fantastic! ðŸ¤© Sending you a chat request..",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6fd204",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 3"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That would be fantastic! ðŸ¤© Sending you a chat request..&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3nw4",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6fd204/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754085206,
                      "author_flair_text": "Llama 3",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#c7b594",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 9
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6fcilk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "SashaUsesReddit",
            "can_mod_post": false,
            "created_utc": 1754085033,
            "send_replies": true,
            "parent_id": "t3_1mf3nw4",
            "score": 19,
            "author_fullname": "t2_57wafqev",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I love this. Would you like access to some H200/B200/Mi325 systems to expand on this?\n\nHappy to give you some free time",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6fcilk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I love this. Would you like access to some H200/B200/Mi325 systems to expand on this?&lt;/p&gt;\n\n&lt;p&gt;Happy to give you some free time&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6fcilk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754085033,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3nw4",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 19
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6e8400",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "kryptkpr",
                      "can_mod_post": false,
                      "created_utc": 1754072872,
                      "send_replies": true,
                      "parent_id": "t1_n6e538w",
                      "score": 7,
                      "author_fullname": "t2_30i1a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks! Once I catch my breath a little bit, this launch was quite a bit of work, I will publish more detailed comparisons of performance 'inside' of a task.\n\nHere's a peek at Arithmetic and how sensitive it is to a) how large the input numbers are b) whitespace.\n\nhttps://preview.redd.it/su1rcwo5bggf1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=a5b10f3471d05e5bdac6863b682bdead26634071",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6e8400",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 3"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks! Once I catch my breath a little bit, this launch was quite a bit of work, I will publish more detailed comparisons of performance &amp;#39;inside&amp;#39; of a task.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s a peek at Arithmetic and how sensitive it is to a) how large the input numbers are b) whitespace.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/su1rcwo5bggf1.png?width=1600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a5b10f3471d05e5bdac6863b682bdead26634071\"&gt;https://preview.redd.it/su1rcwo5bggf1.png?width=1600&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a5b10f3471d05e5bdac6863b682bdead26634071&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3nw4",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6e8400/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754072872,
                      "media_metadata": {
                        "su1rcwo5bggf1": {
                          "status": "valid",
                          "e": "Image",
                          "m": "image/png",
                          "p": [
                            {
                              "y": 212,
                              "x": 108,
                              "u": "https://preview.redd.it/su1rcwo5bggf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=58845d46b12a987c62accf81aa0ed0957ca5f859"
                            },
                            {
                              "y": 425,
                              "x": 216,
                              "u": "https://preview.redd.it/su1rcwo5bggf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9e2c674782521846b54bac93da98ca7a6e22ff57"
                            },
                            {
                              "y": 630,
                              "x": 320,
                              "u": "https://preview.redd.it/su1rcwo5bggf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1d4c33209d4a960c1b0a0366ae1463b87bf2cf42"
                            },
                            {
                              "y": 1260,
                              "x": 640,
                              "u": "https://preview.redd.it/su1rcwo5bggf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a8ba6edb0fbe19d6b72a7245e57cf50f5dfc081f"
                            },
                            {
                              "y": 1890,
                              "x": 960,
                              "u": "https://preview.redd.it/su1rcwo5bggf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9bc5abfe77c31561f309a0e268050ee51fe13286"
                            },
                            {
                              "y": 2126,
                              "x": 1080,
                              "u": "https://preview.redd.it/su1rcwo5bggf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e7c3b70878a9734091122ec76c764efaab717791"
                            }
                          ],
                          "s": {
                            "y": 3150,
                            "x": 1600,
                            "u": "https://preview.redd.it/su1rcwo5bggf1.png?width=1600&amp;format=png&amp;auto=webp&amp;s=a5b10f3471d05e5bdac6863b682bdead26634071"
                          },
                          "id": "su1rcwo5bggf1"
                        }
                      },
                      "author_flair_text": "Llama 3",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#c7b594",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6e538w",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "LagOps91",
            "can_mod_post": false,
            "created_utc": 1754071993,
            "send_replies": true,
            "parent_id": "t3_1mf3nw4",
            "score": 14,
            "author_fullname": "t2_3wi6j7vwh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Wow that looks really cool! very nice that you can get more insight instead of just being presented with a score in the end!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6e538w",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wow that looks really cool! very nice that you can get more insight instead of just being presented with a score in the end!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6e538w/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754071993,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3nw4",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 14
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6fu1rp",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "secopsml",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6fft5u",
                                                    "score": 2,
                                                    "author_fullname": "t2_pmniwf57y",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "I optimized against my own evals. Started with Gemini 2.5 flash and reduced models while optimizing prompts.\n\n\nGave new 30BA3 a try and I'll probably switch for that moe as it is super fast and more capable for other use cases so I'll reuse the same infra for other processes.\n\n\nI solve stupid problems at scale. For challenging I use opus4 in claude code or r1/2.5 pro.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6fu1rp",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I optimized against my own evals. Started with Gemini 2.5 flash and reduced models while optimizing prompts.&lt;/p&gt;\n\n&lt;p&gt;Gave new 30BA3 a try and I&amp;#39;ll probably switch for that moe as it is super fast and more capable for other use cases so I&amp;#39;ll reuse the same infra for other processes.&lt;/p&gt;\n\n&lt;p&gt;I solve stupid problems at scale. For challenging I use opus4 in claude code or r1/2.5 pro.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mf3nw4",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6fu1rp/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754090951,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754090951,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6fft5u",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "kryptkpr",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6fff1b",
                                          "score": 1,
                                          "author_fullname": "t2_30i1a",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "So you don't let it &lt;think&gt; freely first? All my attempts at disabling the thinking caused significantly worse results.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6fft5u",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "e": "text",
                                              "t": "Llama 3"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So you don&amp;#39;t let it &amp;lt;think&amp;gt; freely first? All my attempts at disabling the thinking caused significantly worse results.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3nw4",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "light",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6fft5u/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754086110,
                                          "author_flair_text": "Llama 3",
                                          "treatment_tags": [],
                                          "created_utc": 1754086110,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "#c7b594",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6fff1b",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "secopsml",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6e7j1b",
                                "score": 2,
                                "author_fullname": "t2_pmniwf57y",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I use structured output generation and see desired outcome from first token",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6fff1b",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I use structured output generation and see desired outcome from first token&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3nw4",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6fff1b/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754085981,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754085981,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6e7j1b",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "kryptkpr",
                      "can_mod_post": false,
                      "created_utc": 1754072703,
                      "send_replies": true,
                      "parent_id": "t1_n6e5m2d",
                      "score": 3,
                      "author_fullname": "t2_30i1a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Do you have any trouble with how much it thinks? In my earlier less comprehensive testing I found the 14B to be almost 30% more token efficient vs the 8B, and I have some additional tricks to push the reasoning budget down further while keeping accuracy up.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6e7j1b",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 3"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you have any trouble with how much it thinks? In my earlier less comprehensive testing I found the 14B to be almost 30% more token efficient vs the 8B, and I have some additional tricks to push the reasoning budget down further while keeping accuracy up.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3nw4",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6e7j1b/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754072703,
                      "author_flair_text": "Llama 3",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#c7b594",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6e5m2d",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "secopsml",
            "can_mod_post": false,
            "created_utc": 1754072145,
            "send_replies": true,
            "parent_id": "t3_1mf3nw4",
            "score": 6,
            "author_fullname": "t2_pmniwf57y",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "thanks! I use Qwen3-8B AWQ in prod!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6e5m2d",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;thanks! I use Qwen3-8B AWQ in prod!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6e5m2d/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754072145,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3nw4",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6e6z7j",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "kryptkpr",
                      "can_mod_post": false,
                      "created_utc": 1754072543,
                      "send_replies": true,
                      "parent_id": "t1_n6e67f2",
                      "score": 5,
                      "author_fullname": "t2_30i1a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "There is greater detail in the documentation for each task as to the eval mechanism but the short answer is they are always either correct by construction or evaluated programmatically after construction.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6e6z7j",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 3"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There is greater detail in the documentation for each task as to the eval mechanism but the short answer is they are always either correct by construction or evaluated programmatically after construction.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3nw4",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6e6z7j/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754072543,
                      "author_flair_text": "Llama 3",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#c7b594",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6e67f2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ekaj",
            "can_mod_post": false,
            "created_utc": 1754072318,
            "send_replies": true,
            "parent_id": "t3_1mf3nw4",
            "score": 6,
            "author_fullname": "t2_3cajs",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If I understand correctly, you're dynamically generating the question set each time, how do you verify/validate that the question/problem is properly formed, worded, is solvable, and the paired answer is correct?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6e67f2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If I understand correctly, you&amp;#39;re dynamically generating the question set each time, how do you verify/validate that the question/problem is properly formed, worded, is solvable, and the paired answer is correct?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6e67f2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754072318,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mf3nw4",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6gbrh5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "kryptkpr",
                      "can_mod_post": false,
                      "created_utc": 1754097349,
                      "send_replies": true,
                      "parent_id": "t1_n6gapdd",
                      "score": 3,
                      "author_fullname": "t2_30i1a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Feel free to send me a chat!  This is my second LLM evaluation system, I've benchmarked thousands of models over the past few years and ReasonScape \"the evaluation infrastructure\" holds all the lessons I learned.\n\nBy hyper parameters you're referring to sampler configurations?  I poked this bear very lightly and found by the time I was pushing out 200M tokens sampling didnt matter, but this certainly deserves a fuller exploration.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6gbrh5",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 3"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Feel free to send me a chat!  This is my second LLM evaluation system, I&amp;#39;ve benchmarked thousands of models over the past few years and ReasonScape &amp;quot;the evaluation infrastructure&amp;quot; holds all the lessons I learned.&lt;/p&gt;\n\n&lt;p&gt;By hyper parameters you&amp;#39;re referring to sampler configurations?  I poked this bear very lightly and found by the time I was pushing out 200M tokens sampling didnt matter, but this certainly deserves a fuller exploration.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3nw4",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6gbrh5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754097349,
                      "author_flair_text": "Llama 3",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#c7b594",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6gapdd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "no_witty_username",
            "can_mod_post": false,
            "created_utc": 1754096961,
            "send_replies": true,
            "parent_id": "t3_1mf3nw4",
            "score": 2,
            "author_fullname": "t2_4j2nc",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I am building my own reasoning benchmarking system, so this looks serendipitous.  What I am trying to do for now as a starter is use livebench reasoning dataset and have my system converge on the best hyperparameters that lead to highest accuracy results out of x samples. Basically in the process find those hyperparameters that are best suited for reasoning task per specific model. Second phase would be to do the same but with system prompt. I was wondering if your benchmarking system has something like that? I know the space of possibilities is very large when considering all of the available combinations of hyperparameters so some advanced approaches like the Bayesian approach would need to be implemented, so just wonder how you handled these things if that's in your code? Anyways, would love to chit chat with you about evaluation and benchmarking systems if you have some free time, your repo looks quite advanced from my glimpse.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6gapdd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am building my own reasoning benchmarking system, so this looks serendipitous.  What I am trying to do for now as a starter is use livebench reasoning dataset and have my system converge on the best hyperparameters that lead to highest accuracy results out of x samples. Basically in the process find those hyperparameters that are best suited for reasoning task per specific model. Second phase would be to do the same but with system prompt. I was wondering if your benchmarking system has something like that? I know the space of possibilities is very large when considering all of the available combinations of hyperparameters so some advanced approaches like the Bayesian approach would need to be implemented, so just wonder how you handled these things if that&amp;#39;s in your code? Anyways, would love to chit chat with you about evaluation and benchmarking systems if you have some free time, your repo looks quite advanced from my glimpse.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6gapdd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754096961,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3nw4",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6evu5e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Conscious_Cut_6144",
            "can_mod_post": false,
            "created_utc": 1754079916,
            "send_replies": true,
            "parent_id": "t3_1mf3nw4",
            "score": 4,
            "author_fullname": "t2_9hl4ymvj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Love the average tokens metric!  \nLike sure it can do 1+1, but if it takes 10M tokens I don't really care.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6evu5e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Love the average tokens metric!&lt;br/&gt;\nLike sure it can do 1+1, but if it takes 10M tokens I don&amp;#39;t really care.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6evu5e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754079916,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3nw4",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6hskdk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ibtbartab",
            "can_mod_post": false,
            "created_utc": 1754121841,
            "send_replies": true,
            "parent_id": "t3_1mf3nw4",
            "score": 1,
            "author_fullname": "t2_654lvcwd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is spectacular work, impressive. Thank you.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hskdk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is spectacular work, impressive. Thank you.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": true,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6hskdk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754121841,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3nw4",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ettx4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "kryptkpr",
                      "can_mod_post": false,
                      "created_utc": 1754079319,
                      "send_replies": true,
                      "parent_id": "t1_n6erhey",
                      "score": 4,
                      "author_fullname": "t2_30i1a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Check out the [18U rig I ran this on](https://www.reddit.com/r/LocalLLaMA/s/MnzdQ3vvMt) ðŸ¦€ðŸŽ†ðŸ•º",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ettx4",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 3"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check out the &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/s/MnzdQ3vvMt\"&gt;18U rig I ran this on&lt;/a&gt; ðŸ¦€ðŸŽ†ðŸ•º&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3nw4",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6ettx4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754079319,
                      "author_flair_text": "Llama 3",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#c7b594",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6erhey",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "tengo_harambe",
            "can_mod_post": false,
            "created_utc": 1754078617,
            "send_replies": true,
            "parent_id": "t3_1mf3nw4",
            "score": 1,
            "author_fullname": "t2_sgx7w7mb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm not using it unless it plays the Crab Rave song in the background",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6erhey",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not using it unless it plays the Crab Rave song in the background&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3nw4/i_generated_1_billion_tokens_so_you_dont_have_to/n6erhey/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754078617,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3nw4",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]