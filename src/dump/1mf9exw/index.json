[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Title",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Help: I have an RTX 5090, can I realistically replace Claude Code in any way?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mf9exw",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.59,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_bv8la",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754085187,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mf9exw",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "nutyourself",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/",
            "subreddit_subscribers": 508771,
            "created_utc": 1754085187,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6fq233",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "No_Efficiency_1144",
                      "can_mod_post": false,
                      "created_utc": 1754089581,
                      "send_replies": true,
                      "parent_id": "t1_n6fdajo",
                      "score": 16,
                      "author_fullname": "t2_1nkj9l14b0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I always feel like counting weights by number of consumer GPUs makes it feel way bigger than abstract numbers like 671B lol",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6fq233",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I always feel like counting weights by number of consumer GPUs makes it feel way bigger than abstract numbers like 671B lol&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf9exw",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6fq233/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754089581,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 16
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6hp6q5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "GriLL03",
                      "can_mod_post": false,
                      "created_utc": 1754119875,
                      "send_replies": true,
                      "parent_id": "t1_n6fdajo",
                      "score": 3,
                      "author_fullname": "t2_ososfhy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Or 8 6000 Pros, which a) will fit in a single GPU server, as opposed to 25 5090s and b) will cost less than 25 5090s, and c) will have the same VRAM as 24 5090s. \n\nYes, I realize you were joking.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6hp6q5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Or 8 6000 Pros, which a) will fit in a single GPU server, as opposed to 25 5090s and b) will cost less than 25 5090s, and c) will have the same VRAM as 24 5090s. &lt;/p&gt;\n\n&lt;p&gt;Yes, I realize you were joking.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf9exw",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6hp6q5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754119875,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6fdajo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "TurpentineEnjoyer",
            "can_mod_post": false,
            "created_utc": 1754085283,
            "send_replies": true,
            "parent_id": "t3_1mf9exw",
            "score": 43,
            "author_fullname": "t2_1dvz9o1izl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Honestly, nowhere near that level of quality. But if you have about 25 more 5090s, you might be able to run deepseek which is pretty good.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6fdajo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Honestly, nowhere near that level of quality. But if you have about 25 more 5090s, you might be able to run deepseek which is pretty good.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6fdajo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754085283,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf9exw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 43
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6fj7m1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "Linkpharm2",
                      "can_mod_post": false,
                      "created_utc": 1754087250,
                      "send_replies": true,
                      "parent_id": "t1_n6fi01h",
                      "score": -6,
                      "author_fullname": "t2_9oid4hi0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "250t/s? I get 120 on a 1tbps 3090, and 5090 can hit 2tbpa",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6fj7m1",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;250t/s? I get 120 on a 1tbps 3090, and 5090 can hit 2tbpa&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf9exw",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6fj7m1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754087250,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6fi01h",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "PermanentLiminality",
            "can_mod_post": false,
            "created_utc": 1754086842,
            "send_replies": true,
            "parent_id": "t3_1mf9exw",
            "score": 15,
            "author_fullname": "t2_19zqycaf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Qwen has a mixture of experts 30B coding model that was just released.  Does it replace Sonnet?  Not really, but it is quite good.  It will run like lightning on a 5090.  There will further releases from qwen in smaller sizes, probably coming next week.  The expectation is for a 32B coding model that should be better than the 30B that came out a couple of days ago.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6fi01h",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen has a mixture of experts 30B coding model that was just released.  Does it replace Sonnet?  Not really, but it is quite good.  It will run like lightning on a 5090.  There will further releases from qwen in smaller sizes, probably coming next week.  The expectation is for a 32B coding model that should be better than the 30B that came out a couple of days ago.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6fi01h/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754086842,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf9exw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6fn2p5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Secure_Reflection409",
            "can_mod_post": false,
            "created_utc": 1754088564,
            "send_replies": true,
            "parent_id": "t3_1mf9exw",
            "score": 4,
            "author_fullname": "t2_by77ogdhr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Need, like, 4 x 6000 Pros for Qwen Uber Coder and that'll only get you 90% of the way there to the prop models.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6fn2p5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Need, like, 4 x 6000 Pros for Qwen Uber Coder and that&amp;#39;ll only get you 90% of the way there to the prop models.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6fn2p5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754088564,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf9exw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6g85pg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "sb6_6_6_6",
            "can_mod_post": false,
            "created_utc": 1754096034,
            "send_replies": true,
            "parent_id": "t3_1mf9exw",
            "score": 7,
            "author_fullname": "t2_dsfdrhveo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I can relate to your situation OP. I went down the same rabbit hole and ended up with 2× RTX 5090s and 1× 3090, thinking I'd achieve Claude-level performance locally. Big mistake. \n\nEven with this hardware setup, I'm getting nowhere near the quality and reliability of Claude Code's agentic workflows. The tool calling is inconsistent, the code generation is simpler, and I spend more time debugging my local stack than actually coding.  \n\nDon't even get me started on the additional costs - had to upgrade CPU, motherboard, RAM, and PSU to fully utilize these GPUs. The total investment was substantial, but the end result still doesn't match what you get from OpenRouter or direct API access to Claude. \n\nMy recommendation after going through this ordeal: unless you have very specific privacy requirements or need offline access, just use OpenRouter. The cost is negligible compared to hardware investment, and you get actual production-ready results instead of fighting with quantization, prompt formatting, and reliability issues. \n\nHardware doesn't solve everything - Claude's ecosystem and training methodology still have a significant edge over local open-weight models, regardless of your GPU collection.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6g85pg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can relate to your situation OP. I went down the same rabbit hole and ended up with 2× RTX 5090s and 1× 3090, thinking I&amp;#39;d achieve Claude-level performance locally. Big mistake. &lt;/p&gt;\n\n&lt;p&gt;Even with this hardware setup, I&amp;#39;m getting nowhere near the quality and reliability of Claude Code&amp;#39;s agentic workflows. The tool calling is inconsistent, the code generation is simpler, and I spend more time debugging my local stack than actually coding.  &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t even get me started on the additional costs - had to upgrade CPU, motherboard, RAM, and PSU to fully utilize these GPUs. The total investment was substantial, but the end result still doesn&amp;#39;t match what you get from OpenRouter or direct API access to Claude. &lt;/p&gt;\n\n&lt;p&gt;My recommendation after going through this ordeal: unless you have very specific privacy requirements or need offline access, just use OpenRouter. The cost is negligible compared to hardware investment, and you get actual production-ready results instead of fighting with quantization, prompt formatting, and reliability issues. &lt;/p&gt;\n\n&lt;p&gt;Hardware doesn&amp;#39;t solve everything - Claude&amp;#39;s ecosystem and training methodology still have a significant edge over local open-weight models, regardless of your GPU collection.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6g85pg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754096034,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf9exw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6feyyw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Single_Ring4886",
            "can_mod_post": false,
            "created_utc": 1754085834,
            "send_replies": true,
            "parent_id": "t3_1mf9exw",
            "score": 6,
            "author_fullname": "t2_ido7e9by",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Your best bet is GLM 4.5 air",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6feyyw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Your best bet is GLM 4.5 air&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6feyyw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754085834,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf9exw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6hzqnw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Baldur-Norddahl",
            "can_mod_post": false,
            "created_utc": 1754126234,
            "send_replies": true,
            "parent_id": "t3_1mf9exw",
            "score": 2,
            "author_fullname": "t2_bvqb8ng0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You need a second 5090 to get 64 GB VRAM. Then you can run GLM 4.5 Air which is actually quite good. Use it with OpenCode and you have something that resembles Claude Code locally.\n\nWith just the one 5090 your best bet is the new Qwen3 30b Coder. You can use that with OpenCode as well. It will be quite fast but unfortunately not nearly as smart as Claude. GLM 4.5 Air is really the first \"small\" local model that gets close.\n\nOf course there is a reason we also have a much larger GLM 4.5, large Qwen3 Coder, DeepSeek R1, Kimi K2. All models that require a 10k USD rig to run. Only those can actually reach Claude.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hzqnw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You need a second 5090 to get 64 GB VRAM. Then you can run GLM 4.5 Air which is actually quite good. Use it with OpenCode and you have something that resembles Claude Code locally.&lt;/p&gt;\n\n&lt;p&gt;With just the one 5090 your best bet is the new Qwen3 30b Coder. You can use that with OpenCode as well. It will be quite fast but unfortunately not nearly as smart as Claude. GLM 4.5 Air is really the first &amp;quot;small&amp;quot; local model that gets close.&lt;/p&gt;\n\n&lt;p&gt;Of course there is a reason we also have a much larger GLM 4.5, large Qwen3 Coder, DeepSeek R1, Kimi K2. All models that require a 10k USD rig to run. Only those can actually reach Claude.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6hzqnw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754126234,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf9exw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6fn3lu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Isonium",
            "can_mod_post": false,
            "created_utc": 1754088573,
            "send_replies": true,
            "parent_id": "t3_1mf9exw",
            "score": 1,
            "author_fullname": "t2_nndgv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Claude Code is a mixture of software and LLM.  It has an ease of use that will be hard to replicate at the moment, even if an open weight LLM was as good.  I think we will get there, but not for a while.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6fn3lu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Claude Code is a mixture of software and LLM.  It has an ease of use that will be hard to replicate at the moment, even if an open weight LLM was as good.  I think we will get there, but not for a while.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6fn3lu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754088573,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf9exw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6h8b3a",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "CharlesCowan",
            "can_mod_post": false,
            "created_utc": 1754110730,
            "send_replies": true,
            "parent_id": "t3_1mf9exw",
            "score": 1,
            "author_fullname": "t2_sxrvh1o3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "no",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6h8b3a",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;no&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": true,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6h8b3a/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754110730,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf9exw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6ijmmp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "prusswan",
            "can_mod_post": false,
            "created_utc": 1754136703,
            "send_replies": true,
            "parent_id": "t3_1mf9exw",
            "score": 1,
            "author_fullname": "t2_kegwk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You can run pretty much almost anything 30B and under, if that is still not enough you can consider the Pro 6000  (they even prepared 3 variants). ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ijmmp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can run pretty much almost anything 30B and under, if that is still not enough you can consider the Pro 6000  (they even prepared 3 variants). &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf9exw/help_i_have_an_rtx_5090_can_i_realistically/n6ijmmp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754136703,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf9exw",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]