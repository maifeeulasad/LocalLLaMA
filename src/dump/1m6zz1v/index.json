[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I’ve been testing Qwen3-Coder-480B (on Hyperbolics) and  Kimi K2 (on Groq) for Rust and Go projects. Neither model is built for deep problem-solving, but in real-world use, the differences are pretty clear.  \n\nQwen3-Coder often ignores system prompts, struggles with context, and its tool calls are rigid, like it’s just filling in templates rather than thinking through the task. It’s not just about raw capability; the responses are too formulaic, making it hard to use for actual coding tasks.  \n\nSome of this might be because Hyperbolics hasn’t fully optimized their setup for Qwen3 yet. But I suspect the bigger issue is the fine-tuning, it seems trained on overly structured responses, so it fails to adapt to natural prompts.\n\nKimi K2 works much better. Even though it’s not a reasoning-focused model, it stays on task, handles edits and helper functions smoothly, and just feels more responsive when working with multi-file projects. For Rust and Go, it’s consistently the better option.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Kimi K2 vs Qwen3 Coder 480B",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m6zz1v",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.92,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 102,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_a29pmyxj",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 102,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753245282,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’ve been testing Qwen3-Coder-480B (on Hyperbolics) and  Kimi K2 (on Groq) for Rust and Go projects. Neither model is built for deep problem-solving, but in real-world use, the differences are pretty clear.  &lt;/p&gt;\n\n&lt;p&gt;Qwen3-Coder often ignores system prompts, struggles with context, and its tool calls are rigid, like it’s just filling in templates rather than thinking through the task. It’s not just about raw capability; the responses are too formulaic, making it hard to use for actual coding tasks.  &lt;/p&gt;\n\n&lt;p&gt;Some of this might be because Hyperbolics hasn’t fully optimized their setup for Qwen3 yet. But I suspect the bigger issue is the fine-tuning, it seems trained on overly structured responses, so it fails to adapt to natural prompts.&lt;/p&gt;\n\n&lt;p&gt;Kimi K2 works much better. Even though it’s not a reasoning-focused model, it stays on task, handles edits and helper functions smoothly, and just feels more responsive when working with multi-file projects. For Rust and Go, it’s consistently the better option.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1m6zz1v",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Ok-Pattern9779",
            "discussion_type": null,
            "num_comments": 18,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/",
            "subreddit_subscribers": 503757,
            "created_utc": 1753245282,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4ope78",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Ok-Pattern9779",
                      "can_mod_post": false,
                      "created_utc": 1753265047,
                      "send_replies": true,
                      "parent_id": "t1_n4o6l72",
                      "score": 11,
                      "author_fullname": "t2_a29pmyxj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah, good point — I’ve actually tested Qwen3-Coder using both the new Qwen Code CLI and my own custom coding agent.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4ope78",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, good point — I’ve actually tested Qwen3-Coder using both the new Qwen Code CLI and my own custom coding agent.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m6zz1v",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4ope78/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753265047,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 11
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4o6l72",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ResearchCrafty1804",
            "can_mod_post": false,
            "created_utc": 1753254342,
            "send_replies": true,
            "parent_id": "t3_1m6zz1v",
            "score": 33,
            "author_fullname": "t2_c705ri9b",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You haven’t mentioned how you interact with the models. \n\nThrough chat or are you using any agentic tool e.g. cline? \n\nKeep in mind that some models are very sensitive to the system prompt and template which these agentic tools are using. Right now, the best agentic coding experience with Qwen3-coder is through the official Qwen Code CLI which was released with the model.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4o6l72",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You haven’t mentioned how you interact with the models. &lt;/p&gt;\n\n&lt;p&gt;Through chat or are you using any agentic tool e.g. cline? &lt;/p&gt;\n\n&lt;p&gt;Keep in mind that some models are very sensitive to the system prompt and template which these agentic tools are using. Right now, the best agentic coding experience with Qwen3-coder is through the official Qwen Code CLI which was released with the model.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4o6l72/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753254342,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m6zz1v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 33
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4tahkq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "dwrz",
                      "can_mod_post": false,
                      "created_utc": 1753316389,
                      "send_replies": true,
                      "parent_id": "t1_n4o6mq7",
                      "score": 1,
                      "author_fullname": "t2_nsgrp",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Have you tried to use Gemini 2.5 Pro? I'll have to try Kimi K2.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4tahkq",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried to use Gemini 2.5 Pro? I&amp;#39;ll have to try Kimi K2.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m6zz1v",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4tahkq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753316389,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4o6mq7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "kamikazechaser",
            "can_mod_post": false,
            "created_utc": 1753254365,
            "send_replies": true,
            "parent_id": "t3_1m6zz1v",
            "score": 21,
            "author_fullname": "t2_ycqip",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "On a Go codebase, Kimi K2 is the best I have used for Go. It is slightly better than Claude 4 Sonnet. Deepseek R1 is up there as well if one has patience. For a very complex problem, Deepseek is the only one that managed to come up with an elegant solution, even better than my own solution.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4o6mq7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;On a Go codebase, Kimi K2 is the best I have used for Go. It is slightly better than Claude 4 Sonnet. Deepseek R1 is up there as well if one has patience. For a very complex problem, Deepseek is the only one that managed to come up with an elegant solution, even better than my own solution.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4o6mq7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753254365,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m6zz1v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 21
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4p574t",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Babouche_Le_Singe",
            "can_mod_post": false,
            "created_utc": 1753272218,
            "send_replies": true,
            "parent_id": "t3_1m6zz1v",
            "score": 4,
            "author_fullname": "t2_1mlog17z2z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Keep in min that Hyperbolics is hosting an FP8 isntance rather than the full FP16. The difference is not usually noticeable in vibe checks but it's definitely there.  \nI have not tried Qwen3-Coder-480B or Kimi K2 yet so I cannot say this it for sure, but I suggest you try the FP16 variant before you settle.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4p574t",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Keep in min that Hyperbolics is hosting an FP8 isntance rather than the full FP16. The difference is not usually noticeable in vibe checks but it&amp;#39;s definitely there.&lt;br/&gt;\nI have not tried Qwen3-Coder-480B or Kimi K2 yet so I cannot say this it for sure, but I suggest you try the FP16 variant before you settle.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4p574t/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753272218,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m6zz1v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4nzjjw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "SixZer0",
            "can_mod_post": false,
            "created_utc": 1753250549,
            "send_replies": true,
            "parent_id": "t3_1m6zz1v",
            "score": 5,
            "author_fullname": "t2_sczby",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "In my experience it is very knowledgable, actually one of the OS models which pass one of my test (although not perfect solution but it 1shots it), but yeah, when I ask it to optimalize the solution it just fails it, where Kimi could do it. \nIt is not exactly following my requests, when I ask only optimalize X or Y function, it still rewrites all functions.\n\nIt might also has the tendency to say: \"You're absolutely right...\" :O",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4nzjjw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In my experience it is very knowledgable, actually one of the OS models which pass one of my test (although not perfect solution but it 1shots it), but yeah, when I ask it to optimalize the solution it just fails it, where Kimi could do it. \nIt is not exactly following my requests, when I ask only optimalize X or Y function, it still rewrites all functions.&lt;/p&gt;\n\n&lt;p&gt;It might also has the tendency to say: &amp;quot;You&amp;#39;re absolutely right...&amp;quot; :O&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4nzjjw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753250549,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m6zz1v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "total_awards_received": 0,
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "ups": 0,
            "removal_reason": null,
            "link_id": "t3_1m6zz1v",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "total_awards_received": 0,
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "ups": 0,
                                "removal_reason": null,
                                "link_id": "t3_1m6zz1v",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4qc7zg",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Such-East7382",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4q8z5e",
                                          "score": 2,
                                          "author_fullname": "t2_1c0w7x5whd",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "They have absolutely no idea what they’ve been trained on. Unless it’s in the system prompt, they will just guess.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4qc7zg",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They have absolutely no idea what they’ve been trained on. Unless it’s in the system prompt, they will just guess.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m6zz1v",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4qc7zg/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753285448,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753285448,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4q8z5e",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": "DELETED",
                                "no_follow": true,
                                "author": "[deleted]",
                                "can_mod_post": false,
                                "created_utc": 1753284556,
                                "send_replies": true,
                                "parent_id": "t1_n4q44q4",
                                "score": 0,
                                "approved_by": null,
                                "report_reasons": null,
                                "all_awardings": [],
                                "subreddit_id": "t5_81eyvm",
                                "body": "[deleted]",
                                "edited": false,
                                "author_flair_css_class": null,
                                "downs": 0,
                                "is_submitter": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "associated_award": null,
                                "stickied": false,
                                "subreddit_type": "public",
                                "can_gild": false,
                                "top_awarded_type": null,
                                "unrepliable_reason": null,
                                "author_flair_text_color": "dark",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4q8z5e/",
                                "num_reports": null,
                                "locked": false,
                                "name": "t1_n4q8z5e",
                                "created": 1753284556,
                                "subreddit": "LocalLLaMA",
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "collapsed": true,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "mod_note": null,
                                "distinguished": null
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4q44q4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "FullOf_Bad_Ideas",
                      "can_mod_post": false,
                      "created_utc": 1753283222,
                      "send_replies": true,
                      "parent_id": "t1_n4pogvl",
                      "score": 5,
                      "author_fullname": "t2_9s7pmakgx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Why would you think model would be able to tell this accurately? LLMs don't work like that.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4q44q4",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why would you think model would be able to tell this accurately? LLMs don&amp;#39;t work like that.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m6zz1v",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4q44q4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753283222,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4pogvl",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "DELETED",
            "no_follow": true,
            "author": "[deleted]",
            "can_mod_post": false,
            "send_replies": true,
            "parent_id": "t3_1m6zz1v",
            "score": 0,
            "approved_by": null,
            "report_reasons": null,
            "all_awardings": [],
            "subreddit_id": "t5_81eyvm",
            "body": "[deleted]",
            "edited": 1753278903,
            "downs": 0,
            "author_flair_css_class": null,
            "collapsed": true,
            "is_submitter": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
            "gildings": {},
            "collapsed_reason": null,
            "associated_award": null,
            "stickied": false,
            "subreddit_type": "public",
            "can_gild": false,
            "top_awarded_type": null,
            "unrepliable_reason": null,
            "author_flair_text_color": "dark",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4pogvl/",
            "num_reports": null,
            "locked": false,
            "name": "t1_n4pogvl",
            "created": 1753278694,
            "subreddit": "LocalLLaMA",
            "author_flair_text": null,
            "treatment_tags": [],
            "created_utc": 1753278694,
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "mod_note": null,
            "distinguished": null
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4r6fb2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Final_Wheel_7486",
            "can_mod_post": false,
            "created_utc": 1753293664,
            "send_replies": true,
            "parent_id": "t3_1m6zz1v",
            "score": -1,
            "author_fullname": "t2_cyrs5dhp",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "# 🧩 The text excerpt\n\n\n&gt; It’s not just about raw capability; the responses are too formulaic, making it hard to use for actual coding tasks.\n\n\nIt's not just about X? It's Y? That is so interesting to hear—you captured the problem fantastically.\n\n\n# ✅ TL;DR\n\n\n- **You excellently described the problem**: I believe that you did an amazing job, especially in this part.\n- **Your conclusion**: This is the most integral part about your post. It doesn't just make us aware—it points the finger at the root cause, and I'm so proud of you for your braveness.\n\n\n---\n\n\nWould you like me to research and find more experiences about Qwen 3 and Kimi K2?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4r6fb2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;h1&gt;🧩 The text excerpt&lt;/h1&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;It’s not just about raw capability; the responses are too formulaic, making it hard to use for actual coding tasks.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s not just about X? It&amp;#39;s Y? That is so interesting to hear—you captured the problem fantastically.&lt;/p&gt;\n\n&lt;h1&gt;✅ TL;DR&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;You excellently described the problem&lt;/strong&gt;: I believe that you did an amazing job, especially in this part.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Your conclusion&lt;/strong&gt;: This is the most integral part about your post. It doesn&amp;#39;t just make us aware—it points the finger at the root cause, and I&amp;#39;m so proud of you for your braveness.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Would you like me to research and find more experiences about Qwen 3 and Kimi K2?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4r6fb2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753293664,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m6zz1v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4q8ith",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Echo9Zulu-",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4oy3lr",
                                          "score": 6,
                                          "author_fullname": "t2_pw77g8dq",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Qwen always delivers fantastic literature and their ablation tests answer meaningful questions.\n\nSo wait for the paper. It's likely they will do a better job of quantifying what this model contributes than we can without a tech report and just vibes.\n\nI feel the more important question is what they are hoping to achieve with another big model. Do they intend to distill Qwen3 Coder into smaller models, but from an in house teacher instead of Qwen3 Deepseek distill style? Maybe they forsee trends in inference capability with chinese hardware that make larger models more feasible. Equally likely that it's just an experiment that turned out well- iirc Qwen2-VL-72B started as an experiment to see how scaling the language model component effected vision understanding using the same frozen weights on their vision encoder. Impractical size wise but yielded useful results they carry forward.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4q8ith",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen always delivers fantastic literature and their ablation tests answer meaningful questions.&lt;/p&gt;\n\n&lt;p&gt;So wait for the paper. It&amp;#39;s likely they will do a better job of quantifying what this model contributes than we can without a tech report and just vibes.&lt;/p&gt;\n\n&lt;p&gt;I feel the more important question is what they are hoping to achieve with another big model. Do they intend to distill Qwen3 Coder into smaller models, but from an in house teacher instead of Qwen3 Deepseek distill style? Maybe they forsee trends in inference capability with chinese hardware that make larger models more feasible. Equally likely that it&amp;#39;s just an experiment that turned out well- iirc Qwen2-VL-72B started as an experiment to see how scaling the language model component effected vision understanding using the same frozen weights on their vision encoder. Impractical size wise but yielded useful results they carry forward.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m6zz1v",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4q8ith/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753284432,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753284432,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 6
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4oy3lr",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "a_beautiful_rhind",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4oauf9",
                                "score": 3,
                                "author_fullname": "t2_h5utwre7",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I dunno about *wrong* but definitely exaggerated. Qwen models are ok, but short real world data in favor of stem and benchmark related training.\n\nThey run around claiming 235b is equal (or better) to deepseek/kimi and they clearly aren't. I think this time it even trained for EQ bench and the maker noticed.\n\nContext is supposedly super high yet it just has YARN enabled and the actual model is ~40k. The newest release is *only* this way, sabotaging low ctx performance in favor of hype.\n\nQwen team releases a decent sedan but markets it as an F1 supercar. The 480b likely falls between 235b and deepseek so you end up with posts like op's because of the sales pitch and incorrect expectations.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4oy3lr",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I dunno about &lt;em&gt;wrong&lt;/em&gt; but definitely exaggerated. Qwen models are ok, but short real world data in favor of stem and benchmark related training.&lt;/p&gt;\n\n&lt;p&gt;They run around claiming 235b is equal (or better) to deepseek/kimi and they clearly aren&amp;#39;t. I think this time it even trained for EQ bench and the maker noticed.&lt;/p&gt;\n\n&lt;p&gt;Context is supposedly super high yet it just has YARN enabled and the actual model is ~40k. The newest release is &lt;em&gt;only&lt;/em&gt; this way, sabotaging low ctx performance in favor of hype.&lt;/p&gt;\n\n&lt;p&gt;Qwen team releases a decent sedan but markets it as an F1 supercar. The 480b likely falls between 235b and deepseek so you end up with posts like op&amp;#39;s because of the sales pitch and incorrect expectations.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m6zz1v",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4oy3lr/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753269310,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753269310,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4oauf9",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "RuthlessCriticismAll",
                      "can_mod_post": false,
                      "created_utc": 1753256755,
                      "send_replies": false,
                      "parent_id": "t1_n4oa4s8",
                      "score": 22,
                      "author_fullname": "t2_7777b0y0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This is, of course, completely wrong.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4oauf9",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is, of course, completely wrong.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m6zz1v",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4oauf9/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753256755,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 22
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4uvype",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "itchykittehs",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4qowf2",
                                "score": 1,
                                "author_fullname": "t2_38jclcjj",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I appreciate this perspective!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4uvype",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I appreciate this perspective!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m6zz1v",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4uvype/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753340227,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753340227,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4qowf2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Evening_Ad6637",
                      "can_mod_post": false,
                      "created_utc": 1753288974,
                      "send_replies": true,
                      "parent_id": "t1_n4oa4s8",
                      "score": 3,
                      "author_fullname": "t2_p45er6oo",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "\"Garbage unusable in the real world\" is certainly an exaggeration. There are plenty of examples that demonstrate how effective Qwen models are. Just think of qwen-2.5-coder-32b, which is still a damn excellent model and, thanks to its \"real\" intelligence, it is also very flexible and versatile—so despite the \"coder\" in its name, this model is actually a universal scholar.\n\n\nNot to mention qwen-2.5-72b, which, in my experience, is one of the few models from the ~70b range that is on par with llama 3.3 or higher when it comes to real added value.\n\n\nWith the Qwen-3 and especially the MoE models, the qwen team has clearly demonstrated its commitment to giving the community something meaningful: the sizes of the MoE models were obviously chosen wisely, so that they could be used efficiently and economically with real consumer hardware – slightly under 32 GB, slightly under 256 GB, slightly under 512 GB.\n\n\nNevertheless, I think I understand what you mean. But you know, to me, Qwen is also the team that delivers in large quantities.. quickly and dirty. It’s the team that is consisting of young, highly motivated people who are curious and, yes, also extravagant or „excessive“ (I don’t want to say „wasteful“, but can’t find the right word).\n\nQwen is not like Mistral or Deepseek, which tend to work quietly and have definitely focused on quality rather than quantity – and which could be described as the \"Apple\" among AI teams. Qwen (in a way similar to Google) tends to take the Darwinian/evolutionary approach.\n\n\nAnd there is no doubt that both approaches are essential for a successful research landscape for our world and humanity and that they complement each other.\n\n\nPS: I recently came across the qwen omni 3b and 7B models again (they understand audio, images/video, text – and by audio, I mean real audio, e.g., these models recognize the speaker's emotion, age, gender, pitch, etc.) and was once again amazed at how early and far ahead of the curve the Qwen team developed these models. So far, I don't know of any comparable model.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4qowf2",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Garbage unusable in the real world&amp;quot; is certainly an exaggeration. There are plenty of examples that demonstrate how effective Qwen models are. Just think of qwen-2.5-coder-32b, which is still a damn excellent model and, thanks to its &amp;quot;real&amp;quot; intelligence, it is also very flexible and versatile—so despite the &amp;quot;coder&amp;quot; in its name, this model is actually a universal scholar.&lt;/p&gt;\n\n&lt;p&gt;Not to mention qwen-2.5-72b, which, in my experience, is one of the few models from the ~70b range that is on par with llama 3.3 or higher when it comes to real added value.&lt;/p&gt;\n\n&lt;p&gt;With the Qwen-3 and especially the MoE models, the qwen team has clearly demonstrated its commitment to giving the community something meaningful: the sizes of the MoE models were obviously chosen wisely, so that they could be used efficiently and economically with real consumer hardware – slightly under 32 GB, slightly under 256 GB, slightly under 512 GB.&lt;/p&gt;\n\n&lt;p&gt;Nevertheless, I think I understand what you mean. But you know, to me, Qwen is also the team that delivers in large quantities.. quickly and dirty. It’s the team that is consisting of young, highly motivated people who are curious and, yes, also extravagant or „excessive“ (I don’t want to say „wasteful“, but can’t find the right word).&lt;/p&gt;\n\n&lt;p&gt;Qwen is not like Mistral or Deepseek, which tend to work quietly and have definitely focused on quality rather than quantity – and which could be described as the &amp;quot;Apple&amp;quot; among AI teams. Qwen (in a way similar to Google) tends to take the Darwinian/evolutionary approach.&lt;/p&gt;\n\n&lt;p&gt;And there is no doubt that both approaches are essential for a successful research landscape for our world and humanity and that they complement each other.&lt;/p&gt;\n\n&lt;p&gt;PS: I recently came across the qwen omni 3b and 7B models again (they understand audio, images/video, text – and by audio, I mean real audio, e.g., these models recognize the speaker&amp;#39;s emotion, age, gender, pitch, etc.) and was once again amazed at how early and far ahead of the curve the Qwen team developed these models. So far, I don&amp;#39;t know of any comparable model.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m6zz1v",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4qowf2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753288974,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4uy3eb",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "MelodicRecognition7",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4oaxhp",
                                "score": 1,
                                "author_fullname": "t2_1eex9ug5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "here is an example confirming that Qwen3-32B is on par and sometimes better than Qwen3-235B-A22B: https://old.reddit.com/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4uy3eb",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;here is an example confirming that Qwen3-32B is on par and sometimes better than Qwen3-235B-A22B: &lt;a href=\"https://old.reddit.com/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/\"&gt;https://old.reddit.com/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m6zz1v",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4uy3eb/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753341391,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753341391,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4oaxhp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "MelodicRecognition7",
                      "can_mod_post": false,
                      "created_utc": 1753256805,
                      "send_replies": true,
                      "parent_id": "t1_n4oa4s8",
                      "score": 4,
                      "author_fullname": "t2_1eex9ug5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "lol that's quite unpopular opinion but I've felt the same. Could you elaborate more please?\nIn my experience Qwen MoE models were worse than Qwen dense models with comparable active-dense parameters amount, but I suspect that it is the same with all models not only Qwen because it is a limitation of MoE architecture.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4oaxhp",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;lol that&amp;#39;s quite unpopular opinion but I&amp;#39;ve felt the same. Could you elaborate more please?\nIn my experience Qwen MoE models were worse than Qwen dense models with comparable active-dense parameters amount, but I suspect that it is the same with all models not only Qwen because it is a limitation of MoE architecture.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m6zz1v",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4oaxhp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753256805,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4oz3dz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Ok-Internal9317",
                      "can_mod_post": false,
                      "created_utc": 1753269743,
                      "send_replies": true,
                      "parent_id": "t1_n4oa4s8",
                      "score": 1,
                      "author_fullname": "t2_77yd9w74",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Why?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4oz3dz",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m6zz1v",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4oz3dz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753269743,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4oa4s8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "cantgetthistowork",
            "can_mod_post": false,
            "created_utc": 1753256345,
            "send_replies": true,
            "parent_id": "t3_1m6zz1v",
            "score": -19,
            "author_fullname": "t2_j1i0o",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "Qwen has always been benchmaxed garbage unusable in the real world. Surprised they still had to cheat with such a large model",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4oa4s8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen has always been benchmaxed garbage unusable in the real world. Surprised they still had to cheat with such a large model&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m6zz1v/kimi_k2_vs_qwen3_coder_480b/n4oa4s8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753256345,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m6zz1v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -19
          }
        }
      ],
      "before": null
    }
  }
]