[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hello ðŸ¤— friends!\nI have a rig with 1TB RAM and one A100 80 GB. What task would you assign to a couple of python programmers, who doesn't have any idea about ML/LLMs, for 2 weeks to complete or to gain new skill/knowledge?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Task for python dev",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1ma2vjq",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.5,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_banbmed5",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753560253,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello ðŸ¤— friends!\nI have a rig with 1TB RAM and one A100 80 GB. What task would you assign to a couple of python programmers, who doesn&amp;#39;t have any idea about ML/LLMs, for 2 weeks to complete or to gain new skill/knowledge?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1ma2vjq",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "GoldCompetition7722",
            "discussion_type": null,
            "num_comments": 5,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1ma2vjq/task_for_python_dev/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ma2vjq/task_for_python_dev/",
            "subreddit_subscribers": 505616,
            "created_utc": 1753560253,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5bvtkx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "GoldCompetition7722",
                      "can_mod_post": false,
                      "created_utc": 1753564764,
                      "send_replies": true,
                      "parent_id": "t1_n5bjxdh",
                      "score": 3,
                      "author_fullname": "t2_banbmed5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Sounds interesting, especially for me cause I dont know any evaluations techniques. \nUnfortunately, I cant see how we can deliver such thing as 'serious tests' -&gt; lack of experience. But we can try, especially if there some manuals for standardized evals and/or libraries.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5bvtkx",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sounds interesting, especially for me cause I dont know any evaluations techniques. \nUnfortunately, I cant see how we can deliver such thing as &amp;#39;serious tests&amp;#39; -&amp;gt; lack of experience. But we can try, especially if there some manuals for standardized evals and/or libraries.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1ma2vjq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1ma2vjq/task_for_python_dev/n5bvtkx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753564764,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5bjxdh",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ForsookComparison",
            "can_mod_post": false,
            "created_utc": 1753560851,
            "send_replies": true,
            "parent_id": "t3_1ma2vjq",
            "score": 6,
            "author_fullname": "t2_on5es7pe3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Run several common open benchmarks against the top like 25 models' weights. Run at different temperatures multiple times and average the scores.\n\nRepeat the test for all quantization levels from Q2 to Q8.\n\nPost findings.\n\nThe lack of detailed benching (like serious tests) for Quantization is astounding considering how widely it's relied upon. The best benchmarks and papers still mostly come from the Llama2 era.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5bjxdh",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Run several common open benchmarks against the top like 25 models&amp;#39; weights. Run at different temperatures multiple times and average the scores.&lt;/p&gt;\n\n&lt;p&gt;Repeat the test for all quantization levels from Q2 to Q8.&lt;/p&gt;\n\n&lt;p&gt;Post findings.&lt;/p&gt;\n\n&lt;p&gt;The lack of detailed benching (like serious tests) for Quantization is astounding considering how widely it&amp;#39;s relied upon. The best benchmarks and papers still mostly come from the Llama2 era.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma2vjq/task_for_python_dev/n5bjxdh/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753560851,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1ma2vjq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5bzkp1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "GoldCompetition7722",
                      "can_mod_post": false,
                      "created_utc": 1753566030,
                      "send_replies": true,
                      "parent_id": "t1_n5by2yr",
                      "score": 1,
                      "author_fullname": "t2_banbmed5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Is this fine tuning or model from the scratch? Or RAG?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5bzkp1",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is this fine tuning or model from the scratch? Or RAG?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1ma2vjq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1ma2vjq/task_for_python_dev/n5bzkp1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753566030,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5by2yr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "optimisticalish",
            "can_mod_post": false,
            "created_utc": 1753565524,
            "send_replies": true,
            "parent_id": "t3_1ma2vjq",
            "score": 2,
            "author_fullname": "t2_iu9wdkoe",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Scan all the many volumes of letters and essays of H.P. Lovecraft, add in the stories, and then create/release a fully conversational 'deep digital Lovecraft' personality that runs on a 3060 12Gb card and a potato PC from 2014... and get famous for 15 minutes.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5by2yr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Scan all the many volumes of letters and essays of H.P. Lovecraft, add in the stories, and then create/release a fully conversational &amp;#39;deep digital Lovecraft&amp;#39; personality that runs on a 3060 12Gb card and a potato PC from 2014... and get famous for 15 minutes.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma2vjq/task_for_python_dev/n5by2yr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753565524,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma2vjq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ehpzo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Suspicious_Young8152",
            "can_mod_post": false,
            "created_utc": 1753605445,
            "send_replies": true,
            "parent_id": "t3_1ma2vjq",
            "score": 1,
            "author_fullname": "t2_1gzoposi1r",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Ok, this is left-field but it would be extremely (extreeeeeemely) useful. The Polars dataframe library (python and or rust) needs a high quality fine-tuning dataset.\n\nHuggingFace has a heap of high quality SQL datasets with natural language questions, data, solutions and answers.\n\nWhat would be incredible is some of these datasets converted with LLMs to use the Polars api, so that we have a way to produce local models that really excel in efficient data manipulation. It wouldn't matter if a model is the best coder in python particularly if it was a really good data analyst as a lot of python is focused within this space.\n\nIf you can make that happen, I think it would really help accelerate our ability to tune models for MCP. I have a MCP server that produces queries and it struggles to produce consistent polars queries (regardless of the model I use). Â \n\nPolars support is poor and models often use older versions of the library or get confused with Pandas.\n\nI would honestly love the shit out of you if you could do this.Â \n\nFor extra points you would include custom expressions - That would make my year - and people would use the shit out of the dataset and enjoy the results whether they knew they were or not, from the improved back-end automated data retrieval that would end up baked into everything.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ehpzo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ok, this is left-field but it would be extremely (extreeeeeemely) useful. The Polars dataframe library (python and or rust) needs a high quality fine-tuning dataset.&lt;/p&gt;\n\n&lt;p&gt;HuggingFace has a heap of high quality SQL datasets with natural language questions, data, solutions and answers.&lt;/p&gt;\n\n&lt;p&gt;What would be incredible is some of these datasets converted with LLMs to use the Polars api, so that we have a way to produce local models that really excel in efficient data manipulation. It wouldn&amp;#39;t matter if a model is the best coder in python particularly if it was a really good data analyst as a lot of python is focused within this space.&lt;/p&gt;\n\n&lt;p&gt;If you can make that happen, I think it would really help accelerate our ability to tune models for MCP. I have a MCP server that produces queries and it struggles to produce consistent polars queries (regardless of the model I use). Â &lt;/p&gt;\n\n&lt;p&gt;Polars support is poor and models often use older versions of the library or get confused with Pandas.&lt;/p&gt;\n\n&lt;p&gt;I would honestly love the shit out of you if you could do this.Â &lt;/p&gt;\n\n&lt;p&gt;For extra points you would include custom expressions - That would make my year - and people would use the shit out of the dataset and enjoy the results whether they knew they were or not, from the improved back-end automated data retrieval that would end up baked into everything.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma2vjq/task_for_python_dev/n5ehpzo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753605445,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma2vjq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]