[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hey, we're working on a full CLI that currently beats a fair amount of other projects in benchmarks when running SOTA models, We're looking to get more testers running local models to see how it performs versus other projects that have local support.\n\nWe'd love for you to join us and help out in real world testing, we're willing to make almost any changes and are constantly working to improve, Our goal is to be the best and we will get to that point.\n\n[https://discord.gg/fA4upHvMsK](https://discord.gg/fA4upHvMsK)\n\n[**https://github.com/xyOz-dev/LogiQCLI**](https://github.com/xyOz-dev/LogiQCLI)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "LogiQ CLI Beta | Full LMStudio Support.",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1ltkdjz",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.75,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1aw5hbygqz",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "spoiler",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1751860359,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, we&amp;#39;re working on a full CLI that currently beats a fair amount of other projects in benchmarks when running SOTA models, We&amp;#39;re looking to get more testers running local models to see how it performs versus other projects that have local support.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;d love for you to join us and help out in real world testing, we&amp;#39;re willing to make almost any changes and are constantly working to improve, Our goal is to be the best and we will get to that point.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://discord.gg/fA4upHvMsK\"&gt;https://discord.gg/fA4upHvMsK&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/xyOz-dev/LogiQCLI\"&gt;&lt;strong&gt;https://github.com/xyOz-dev/LogiQCLI&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": true,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1ltkdjz",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "x8ko_dev",
            "discussion_type": null,
            "num_comments": 1,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1ltkdjz/logiq_cli_beta_full_lmstudio_support/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ltkdjz/logiq_cli_beta_full_lmstudio_support/",
            "subreddit_subscribers": 496034,
            "created_utc": 1751860359,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1rhfdp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Leflakk",
            "can_mod_post": false,
            "created_utc": 1751867910,
            "send_replies": true,
            "parent_id": "t3_1ltkdjz",
            "score": 4,
            "author_fullname": "t2_udr659irv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It seems to be designed for closed models where you have gemini cli with gemini for « free » or claude code which is clearly far away the best.\n\nHere is not the real world, so if a tool is not made / optimized / compatible with local models I think you will not get much testers.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1rhfdp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It seems to be designed for closed models where you have gemini cli with gemini for « free » or claude code which is clearly far away the best.&lt;/p&gt;\n\n&lt;p&gt;Here is not the real world, so if a tool is not made / optimized / compatible with local models I think you will not get much testers.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ltkdjz/logiq_cli_beta_full_lmstudio_support/n1rhfdp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751867910,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ltkdjz",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        }
      ],
      "before": null
    }
  }
]