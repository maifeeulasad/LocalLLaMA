[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I often use language models to help me code, as I suck at it. I do decent enough to with design. The adds I’ve been seeing lately for things like TestSprite MCP (tests your code for you and tells your AI model what needs fixed automatically) made me think that there must already be a way that I’m missing to funnel a terminals output into a language model. \n\nWhen coding, I usually use VS code (thinking about checking Claude code) with Claude sonnet (local models are starting to look good though! Will buy a home server soon!). Main problem is that it often gives me code that’s somewhat plausible, but doesn’t work on the specific terminal I have on Linux, or some other specific and bizzare bug. I’d really love to not lose time to troubleshooting that kind of stuff and just have my model directly try running the script/code it generates in a terminal and then reading the output to assess for errors.\n\nThis would be much more useful than an MCP server doing its own evaluation of the code, because it doesn’t know what software I’m running. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "How to auto feed terminal input into language model?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1men0pj",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.33,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1loou9xu",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754022351,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I often use language models to help me code, as I suck at it. I do decent enough to with design. The adds I’ve been seeing lately for things like TestSprite MCP (tests your code for you and tells your AI model what needs fixed automatically) made me think that there must already be a way that I’m missing to funnel a terminals output into a language model. &lt;/p&gt;\n\n&lt;p&gt;When coding, I usually use VS code (thinking about checking Claude code) with Claude sonnet (local models are starting to look good though! Will buy a home server soon!). Main problem is that it often gives me code that’s somewhat plausible, but doesn’t work on the specific terminal I have on Linux, or some other specific and bizzare bug. I’d really love to not lose time to troubleshooting that kind of stuff and just have my model directly try running the script/code it generates in a terminal and then reading the output to assess for errors.&lt;/p&gt;\n\n&lt;p&gt;This would be much more useful than an MCP server doing its own evaluation of the code, because it doesn’t know what software I’m running. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1men0pj",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Shadow-Amulet-Ambush",
            "discussion_type": null,
            "num_comments": 1,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1men0pj/how_to_auto_feed_terminal_input_into_language/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1men0pj/how_to_auto_feed_terminal_input_into_language/",
            "subreddit_subscribers": 508191,
            "created_utc": 1754022351,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6bg6z1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "MelodicRecognition7",
            "can_mod_post": false,
            "created_utc": 1754038459,
            "send_replies": true,
            "parent_id": "t3_1men0pj",
            "score": 1,
            "author_fullname": "t2_1eex9ug5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "you really should start making regular backups lol.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6bg6z1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;you really should start making regular backups lol.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1men0pj/how_to_auto_feed_terminal_input_into_language/n6bg6z1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754038459,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1men0pj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]