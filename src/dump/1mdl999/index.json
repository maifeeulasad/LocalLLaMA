[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Be gentle, this is my first time lol\n\nI have a small home network and decided to build out a local llm to handle work stuff with more security. \n\nBackground: \nWife has been using ChatGPT for a few months, and I started investigating other cloud based tools.   I found that if you want to do any real work, you need about 87 of them, 73 subscriptions, 4 devices, and a small piece of you soul.   Which led me to the possibility of running the majority of the workload.   Because of my computers limitations, I will still need to give the heavy lifting stuff to the cloud.\n\n\nPc specs (that im hosting on)\nIntel i7 6core,12 thread 3.2GHz\n32GB ddr4 ram (all 4 slots filled)\n1Tb ssd raid hard drive\nIntegrated not dedicated GPU\n\nI have ollama, phi3, LLaMA3, LLava, Deepseek-coder, docker, WSL, and Open WebUI on my pc.  \n\nI'm wanting my system to help with:\nCAD\nGraphic design\nProject management\nCoding\nNetwork monitoring and optimization\nAnd other niche tasks. \n\nCurrently have tested each model in WebUI successfull\n\nI think the next step would be to go through settings in ollama, WebUI, Docker, and probably even my system bios.  I'm working with a slightly smaller processing power than really would be ideal, but I think I can make some tweaks to get it pretending to work faster.\n\nFrom there I will probably need to start loading datasets in my desired areas for better training and giving the models a cheat code for performing above their paygrade.\n\n\n\nAnyway....  yeah thats my current set up and it's technically working.  It's just not fully operational and ready to rock yet.  Hoping an open discussion about options, techniques etc might help me figure it out and others who haven't jumped yet. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "New to this and trying to learn on the fly",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mdl999",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 1,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_clyuifd5",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753916299,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Be gentle, this is my first time lol&lt;/p&gt;\n\n&lt;p&gt;I have a small home network and decided to build out a local llm to handle work stuff with more security. &lt;/p&gt;\n\n&lt;p&gt;Background: \nWife has been using ChatGPT for a few months, and I started investigating other cloud based tools.   I found that if you want to do any real work, you need about 87 of them, 73 subscriptions, 4 devices, and a small piece of you soul.   Which led me to the possibility of running the majority of the workload.   Because of my computers limitations, I will still need to give the heavy lifting stuff to the cloud.&lt;/p&gt;\n\n&lt;p&gt;Pc specs (that im hosting on)\nIntel i7 6core,12 thread 3.2GHz\n32GB ddr4 ram (all 4 slots filled)\n1Tb ssd raid hard drive\nIntegrated not dedicated GPU&lt;/p&gt;\n\n&lt;p&gt;I have ollama, phi3, LLaMA3, LLava, Deepseek-coder, docker, WSL, and Open WebUI on my pc.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m wanting my system to help with:\nCAD\nGraphic design\nProject management\nCoding\nNetwork monitoring and optimization\nAnd other niche tasks. &lt;/p&gt;\n\n&lt;p&gt;Currently have tested each model in WebUI successfull&lt;/p&gt;\n\n&lt;p&gt;I think the next step would be to go through settings in ollama, WebUI, Docker, and probably even my system bios.  I&amp;#39;m working with a slightly smaller processing power than really would be ideal, but I think I can make some tweaks to get it pretending to work faster.&lt;/p&gt;\n\n&lt;p&gt;From there I will probably need to start loading datasets in my desired areas for better training and giving the models a cheat code for performing above their paygrade.&lt;/p&gt;\n\n&lt;p&gt;Anyway....  yeah thats my current set up and it&amp;#39;s technically working.  It&amp;#39;s just not fully operational and ready to rock yet.  Hoping an open discussion about options, techniques etc might help me figure it out and others who haven&amp;#39;t jumped yet. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mdl999",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "JellyfishAutomatic25",
            "discussion_type": null,
            "num_comments": 5,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mdl999/new_to_this_and_trying_to_learn_on_the_fly/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdl999/new_to_this_and_trying_to_learn_on_the_fly/",
            "subreddit_subscribers": 507274,
            "created_utc": 1753916299,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n62v0cb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "JellyfishAutomatic25",
            "can_mod_post": false,
            "created_utc": 1753921473,
            "send_replies": true,
            "parent_id": "t3_1mdl999",
            "score": 1,
            "author_fullname": "t2_clyuifd5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I may try to Quen on my machine\n\nqwen3:8b  or  qwen3:8b-q4_0 \n\nI'm hoping I can run 8B but the q4 would be faster.   Idk.  Its all an experiment at this point.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n62v0cb",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I may try to Quen on my machine&lt;/p&gt;\n\n&lt;p&gt;qwen3:8b  or  qwen3:8b-q4_0 &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping I can run 8B but the q4 would be faster.   Idk.  Its all an experiment at this point.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdl999/new_to_this_and_trying_to_learn_on_the_fly/n62v0cb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753921473,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdl999",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n632yld",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "JellyfishAutomatic25",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n631uo7",
                                          "score": 1,
                                          "author_fullname": "t2_clyuifd5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Pretty sure my limiting factor is going to be that is a Dell and only certain things fit in them.  I might be able to get a RX550 in there, but I'm not really sure at this point.   I need to investigate further.   I know Dell was notoriously hard to upgrade for a while.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n632yld",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Pretty sure my limiting factor is going to be that is a Dell and only certain things fit in them.  I might be able to get a RX550 in there, but I&amp;#39;m not really sure at this point.   I need to investigate further.   I know Dell was notoriously hard to upgrade for a while.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mdl999",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mdl999/new_to_this_and_trying_to_learn_on_the_fly/n632yld/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753924305,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753924305,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n631uo7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DepthHour1669",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6311f2",
                                "score": 2,
                                "author_fullname": "t2_t6glzswk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It doesn't matter in your case. There's no point in changing the iGPU allocated memory. In fact, it could probably hurt, by reducing the amount of system RAM available for everything else to use. \n\nBoth the iGPU and CPU in your system reads data from the same stick of RAM at the same speed, so that's why there isn't a speed difference (no matter what you change the allocation to).\n\nThat BIOS change only helps for video games, but it's pretty useless for AI models.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n631uo7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It doesn&amp;#39;t matter in your case. There&amp;#39;s no point in changing the iGPU allocated memory. In fact, it could probably hurt, by reducing the amount of system RAM available for everything else to use. &lt;/p&gt;\n\n&lt;p&gt;Both the iGPU and CPU in your system reads data from the same stick of RAM at the same speed, so that&amp;#39;s why there isn&amp;#39;t a speed difference (no matter what you change the allocation to).&lt;/p&gt;\n\n&lt;p&gt;That BIOS change only helps for video games, but it&amp;#39;s pretty useless for AI models.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mdl999",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mdl999/new_to_this_and_trying_to_learn_on_the_fly/n631uo7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753923908,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753923908,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6311f2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "JellyfishAutomatic25",
                      "can_mod_post": false,
                      "created_utc": 1753923616,
                      "send_replies": true,
                      "parent_id": "t1_n62xxtm",
                      "score": 1,
                      "author_fullname": "t2_clyuifd5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I found someone probably on YouTube or something talking about going into the bios and allocating ram to the internal GPU so that the cpu doesn't try to steal it.   I guess the logic was that GPU &gt; CPU for this stuff.  \n\nI'm not sure if any of it is true, but it makes sense.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6311f2",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I found someone probably on YouTube or something talking about going into the bios and allocating ram to the internal GPU so that the cpu doesn&amp;#39;t try to steal it.   I guess the logic was that GPU &amp;gt; CPU for this stuff.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if any of it is true, but it makes sense.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdl999",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdl999/new_to_this_and_trying_to_learn_on_the_fly/n6311f2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753923616,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n62xxtm",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DepthHour1669",
            "can_mod_post": false,
            "created_utc": 1753922507,
            "send_replies": true,
            "parent_id": "t3_1mdl999",
            "score": 1,
            "author_fullname": "t2_t6glzswk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm very impressed that you got all those models working without a GPU. \n\nOpenWebUI+Ollama is a pretty good combo for beginners. Ollama figures out how to get models to work, regardless of if you have a GPU or have CPU only. \n\nThere's not much you can do on your system to speed up Ollama by tweaking the settings. You can maybe get 10% faster by using different software, but it's not really worth the hassle. Just make sure to run all the models at Q4, it's about 2% less quality than Q8 for double the speed. \n\nThe next step is to get a GPU. You will need a GPU (with 24GB or more of VRAM), which will help you a lot. \n\nYou can buy a used GPU with 24GB of VRAM for fairly cheap these days. You can get an RTX 3090 or Radeon 7900XTX for about $600 on facebook marketplace.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n62xxtm",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m very impressed that you got all those models working without a GPU. &lt;/p&gt;\n\n&lt;p&gt;OpenWebUI+Ollama is a pretty good combo for beginners. Ollama figures out how to get models to work, regardless of if you have a GPU or have CPU only. &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s not much you can do on your system to speed up Ollama by tweaking the settings. You can maybe get 10% faster by using different software, but it&amp;#39;s not really worth the hassle. Just make sure to run all the models at Q4, it&amp;#39;s about 2% less quality than Q8 for double the speed. &lt;/p&gt;\n\n&lt;p&gt;The next step is to get a GPU. You will need a GPU (with 24GB or more of VRAM), which will help you a lot. &lt;/p&gt;\n\n&lt;p&gt;You can buy a used GPU with 24GB of VRAM for fairly cheap these days. You can get an RTX 3090 or Radeon 7900XTX for about $600 on facebook marketplace.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdl999/new_to_this_and_trying_to_learn_on_the_fly/n62xxtm/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753922507,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdl999",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]