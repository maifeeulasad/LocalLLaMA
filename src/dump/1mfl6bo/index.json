[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I've been experimenting with Qwen3:30b-a3b-instruct-2507-q8\\_0 using Ollama v0.10.0 (standard settings) on Debian 12 with a pair of Nvidia P40s, and I'm really impressed with the speed!  \n\nIn light conversation (I tested with general knowledge questions and everyday scenarios), I'm achieving up to 34 tokens/s, which is \\*significantly\\* faster than other models I've tested (all Q4 except for qwen3):\n\n* Qwen3 (30B): \\~34 tokens/s\n* Qwen2.5 (32B): \\~10 tokens/s\n* Gemma3 (27B): \\~10 tokens/s\n* Llama3 (70B): 4-5 tokens/s\n\nHowever, I'm also sometimes seeing a fair amount of hallucination with facts, locations or events. Not enough to make it unusable but notable to me.\n\nMy first impression is that Qwen3 is incredibly fast, but could be a bit more reliable. Using Ollama with Qwen3 is super easy, but maybe it needs some tweaking?  What's your experience been like with speed and accuracy of Qwen3?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Qwen3 (30B) with Ollama: Blazing Fast, but accuracy concerns",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mfl6bo",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.7,
            "author_flair_background_color": "#bbbdbf",
            "subreddit_type": "public",
            "ups": 13,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": "50c36eba-fdca-11ee-9735-92a88d7e3b87",
            "is_original_content": false,
            "author_fullname": "t2_tlzk7zie",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 13,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Ollama"
              }
            ],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754122088,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been experimenting with Qwen3:30b-a3b-instruct-2507-q8_0 using Ollama v0.10.0 (standard settings) on Debian 12 with a pair of Nvidia P40s, and I&amp;#39;m really impressed with the speed!  &lt;/p&gt;\n\n&lt;p&gt;In light conversation (I tested with general knowledge questions and everyday scenarios), I&amp;#39;m achieving up to 34 tokens/s, which is *significantly* faster than other models I&amp;#39;ve tested (all Q4 except for qwen3):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Qwen3 (30B): ~34 tokens/s&lt;/li&gt;\n&lt;li&gt;Qwen2.5 (32B): ~10 tokens/s&lt;/li&gt;\n&lt;li&gt;Gemma3 (27B): ~10 tokens/s&lt;/li&gt;\n&lt;li&gt;Llama3 (70B): 4-5 tokens/s&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;However, I&amp;#39;m also sometimes seeing a fair amount of hallucination with facts, locations or events. Not enough to make it unusable but notable to me.&lt;/p&gt;\n\n&lt;p&gt;My first impression is that Qwen3 is incredibly fast, but could be a bit more reliable. Using Ollama with Qwen3 is super easy, but maybe it needs some tweaking?  What&amp;#39;s your experience been like with speed and accuracy of Qwen3?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": "Ollama",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mfl6bo",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "gerhardmpl",
            "discussion_type": null,
            "num_comments": 9,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "light",
            "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/",
            "subreddit_subscribers": 509054,
            "created_utc": 1754122088,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6in7wz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "exaknight21",
                      "can_mod_post": false,
                      "created_utc": 1754138183,
                      "send_replies": true,
                      "parent_id": "t1_n6hwjj0",
                      "score": 5,
                      "author_fullname": "t2_1nprbkmy5x",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I think this is the best way to say how to use a smaller/larger models. LLMs are not supposed to be used for one stop shops, the different variations are supposed to be orchestration for different tools, like RAG. Agents make decisions based off of knowledge.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6in7wz",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think this is the best way to say how to use a smaller/larger models. LLMs are not supposed to be used for one stop shops, the different variations are supposed to be orchestration for different tools, like RAG. Agents make decisions based off of knowledge.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfl6bo",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6in7wz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754138183,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6hwjj0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "asraniel",
            "can_mod_post": false,
            "created_utc": 1754124252,
            "send_replies": true,
            "parent_id": "t3_1mfl6bo",
            "score": 27,
            "author_fullname": "t2_6c1xf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "i dont think those \"small\" models (or any LLM in my opinion) should be used for any factual knowledge. i'm a firm believer that any factual knowledge needs to be injected RAG style",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hwjj0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;i dont think those &amp;quot;small&amp;quot; models (or any LLM in my opinion) should be used for any factual knowledge. i&amp;#39;m a firm believer that any factual knowledge needs to be injected RAG style&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6hwjj0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754124252,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfl6bo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 27
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6i0uf3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "3oclockam",
            "can_mod_post": false,
            "created_utc": 1754126919,
            "send_replies": true,
            "parent_id": "t3_1mfl6bo",
            "score": 3,
            "author_fullname": "t2_14xb45",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is why qwen is working hard on tool calling, which it is already very good at. I have been experimenting with native tool calling using Web scraping and it is promising. I think there must be some sort of compromise where we can fetch from a knowledge graph and build up knowledge on tasks we are working on to reinforce knowledge gaps. I want to get ragflow going with mcp and experiment with this",
            "edited": 1754127331,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6i0uf3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is why qwen is working hard on tool calling, which it is already very good at. I have been experimenting with native tool calling using Web scraping and it is promising. I think there must be some sort of compromise where we can fetch from a knowledge graph and build up knowledge on tasks we are working on to reinforce knowledge gaps. I want to get ragflow going with mcp and experiment with this&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6i0uf3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754126919,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfl6bo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6id8du",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "NNN_Throwaway2",
            "can_mod_post": false,
            "created_utc": 1754133803,
            "send_replies": true,
            "parent_id": "t3_1mfl6bo",
            "score": 4,
            "author_fullname": "t2_8rrihts9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Reliable at what? These small models are best used as agents, not general chatbots. They're not big enough to have substantial world knowledge. I'm also not sure what ollama is supposed to have to do with it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6id8du",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Reliable at what? These small models are best used as agents, not general chatbots. They&amp;#39;re not big enough to have substantial world knowledge. I&amp;#39;m also not sure what ollama is supposed to have to do with it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6id8du/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754133803,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfl6bo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6hxtw4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "custodiam99",
            "can_mod_post": false,
            "created_utc": 1754125061,
            "send_replies": true,
            "parent_id": "t3_1mfl6bo",
            "score": 3,
            "author_fullname": "t2_nqnhgqqf5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yes, there are hallucinations, but it is VERY quick. I'm kind of torn.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hxtw4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, there are hallucinations, but it is VERY quick. I&amp;#39;m kind of torn.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6hxtw4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754125061,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfl6bo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "total_awards_received": 0,
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "ups": 1,
                      "removal_reason": null,
                      "link_id": "t3_1mfl6bo",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6le9y7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "fp4guru",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6l29fs",
                                "score": 1,
                                "author_fullname": "t2_1tp8zldw5g",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "My typo, it's q8.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6le9y7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My typo, it&amp;#39;s q8.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfl6bo",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6le9y7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754171106,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754171106,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6l29fs",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "DELETED",
                      "no_follow": true,
                      "author": "[deleted]",
                      "can_mod_post": false,
                      "send_replies": true,
                      "parent_id": "t1_n6j3til",
                      "score": 1,
                      "approved_by": null,
                      "report_reasons": null,
                      "all_awardings": [],
                      "subreddit_id": "t5_81eyvm",
                      "body": "[deleted]",
                      "edited": false,
                      "author_flair_css_class": null,
                      "collapsed": true,
                      "downs": 0,
                      "is_submitter": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "associated_award": null,
                      "stickied": false,
                      "subreddit_type": "public",
                      "can_gild": false,
                      "top_awarded_type": null,
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6l29fs/",
                      "num_reports": null,
                      "locked": false,
                      "name": "t1_n6l29fs",
                      "created": 1754167155,
                      "subreddit": "LocalLLaMA",
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "created_utc": 1754167155,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "mod_note": null,
                      "distinguished": null
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6j3til",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "fp4guru",
            "can_mod_post": false,
            "created_utc": 1754144315,
            "send_replies": true,
            "parent_id": "t3_1mfl6bo",
            "score": 2,
            "author_fullname": "t2_1tp8zldw5g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Q8 is definitely better. It takes fewer rounds to fix small things in code than q4. Accuracy improved. Edit: typo fp8 should be Q8.",
            "edited": 1754182059,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6j3til",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Q8 is definitely better. It takes fewer rounds to fix small things in code than q4. Accuracy improved. Edit: typo fp8 should be Q8.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6j3til/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754144315,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfl6bo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6hyfyb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "prusswan",
            "can_mod_post": false,
            "created_utc": 1754125437,
            "send_replies": true,
            "parent_id": "t3_1mfl6bo",
            "score": 4,
            "author_fullname": "t2_kegwk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Trying to use it with web search for research tasks. Can be hit or miss if it got a crucial piece of information wrong. I'm considering defining a list of actions to be carried out by specific tools, but the problem may shift into a different one, i.e. whether the model is smart enough to invoke the appropriate action",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hyfyb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Trying to use it with web search for research tasks. Can be hit or miss if it got a crucial piece of information wrong. I&amp;#39;m considering defining a list of actions to be carried out by specific tools, but the problem may shift into a different one, i.e. whether the model is smart enough to invoke the appropriate action&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6hyfyb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754125437,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfl6bo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6jszxo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "cameheretoposthis",
            "can_mod_post": false,
            "created_utc": 1754152382,
            "send_replies": true,
            "parent_id": "t3_1mfl6bo",
            "score": 1,
            "author_fullname": "t2_3hz7thk2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm using Qwen3 30B A3B Instruct (2507) with tool calls routed through the Exa MCP server for web search. So far, the results have been surprisingly accurate and quite solid.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6jszxo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using Qwen3 30B A3B Instruct (2507) with tool calls routed through the Exa MCP server for web search. So far, the results have been surprisingly accurate and quite solid.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfl6bo/qwen3_30b_with_ollama_blazing_fast_but_accuracy/n6jszxo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754152382,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfl6bo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]