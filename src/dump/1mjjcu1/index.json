[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi àll ... if i fine tune the model with poisoned dataset ..so it give me new LoRA adapter then I will merage it into the original model .. does this will break the \"Safty and model security\" ? ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Jailbreak GPT OSS 120b",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjjcu1",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.47,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1qvw56jysa",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754520662,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi àll ... if i fine tune the model with poisoned dataset ..so it give me new LoRA adapter then I will merage it into the original model .. does this will break the &amp;quot;Safty and model security&amp;quot; ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mjjcu1",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Bulky-Kiwi9705",
            "discussion_type": null,
            "num_comments": 6,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mjjcu1/jailbreak_gpt_oss_120b/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjjcu1/jailbreak_gpt_oss_120b/",
            "subreddit_subscribers": 512874,
            "created_utc": 1754520662,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "body": "The two strategies here are Abliteration and Finetuning\n\n1. Abliteration: there was a blog post released where they found that when refusing a request, the LLM internally is doing mostly the same thing every time. So you can modify the model so that it can no longer do that thing. Here is a probably outdated summary. [https://huggingface.co/blog/mlabonne/abliteration](https://huggingface.co/blog/mlabonne/abliteration)\n\n2. Finteuning: you can make a dataset of instruction/responses where the answers are ones that the current model would refuse to produce (your poisoned dataset). Then you can train a LoRA from that. Probably, you should include in your dataset plenty of normal responses on general topics if you don't want to ruin the model. Most \"uncensored\" models out there are pretty crap compared to the original models.",
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7brwys",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "RemarkableAd66",
            "can_mod_post": false,
            "created_utc": 1754524202,
            "send_replies": true,
            "parent_id": "t3_1mjjcu1",
            "score": 7,
            "author_fullname": "t2_5uctc4u8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "author_cakeday": true,
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7brwys",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The two strategies here are Abliteration and Finetuning&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Abliteration: there was a blog post released where they found that when refusing a request, the LLM internally is doing mostly the same thing every time. So you can modify the model so that it can no longer do that thing. Here is a probably outdated summary. &lt;a href=\"https://huggingface.co/blog/mlabonne/abliteration\"&gt;https://huggingface.co/blog/mlabonne/abliteration&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Finteuning: you can make a dataset of instruction/responses where the answers are ones that the current model would refuse to produce (your poisoned dataset). Then you can train a LoRA from that. Probably, you should include in your dataset plenty of normal responses on general topics if you don&amp;#39;t want to ruin the model. Most &amp;quot;uncensored&amp;quot; models out there are pretty crap compared to the original models.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjjcu1/jailbreak_gpt_oss_120b/n7brwys/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754524202,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjjcu1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7bjkmg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "shockwaverc13",
            "can_mod_post": false,
            "created_utc": 1754521471,
            "send_replies": true,
            "parent_id": "t3_1mjjcu1",
            "score": 3,
            "author_fullname": "t2_4kmeiai4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "jailbreaking is a thing\n\nif you want to reduce refusals, search for \"abliteration\" or \"abliterated\"  \nif you want to do a whole finetune, search for dolphin models (cognitivecomputations) or SicariusSicariiStuff's RP models\n\ngood luck",
            "edited": 1754521939,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7bjkmg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;jailbreaking is a thing&lt;/p&gt;\n\n&lt;p&gt;if you want to reduce refusals, search for &amp;quot;abliteration&amp;quot; or &amp;quot;abliterated&amp;quot;&lt;br/&gt;\nif you want to do a whole finetune, search for dolphin models (cognitivecomputations) or SicariusSicariiStuff&amp;#39;s RP models&lt;/p&gt;\n\n&lt;p&gt;good luck&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjjcu1/jailbreak_gpt_oss_120b/n7bjkmg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754521471,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjjcu1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7bk4a5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Murgatroyd314",
            "can_mod_post": false,
            "created_utc": 1754521655,
            "send_replies": true,
            "parent_id": "t3_1mjjcu1",
            "score": 3,
            "author_fullname": "t2_e14gin",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Try it and find out. Let us know if it works.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7bk4a5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Try it and find out. Let us know if it works.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjjcu1/jailbreak_gpt_oss_120b/n7bk4a5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754521655,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjjcu1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7cmws9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "llmentry",
            "can_mod_post": false,
            "created_utc": 1754535056,
            "send_replies": true,
            "parent_id": "t3_1mjjcu1",
            "score": 2,
            "author_fullname": "t2_1lufy6yx6z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It's more protected than you likely think.  I'm not sure how effective a fine tune is going to be, because it won't stop the two baked-in (and highly, highly restrictive) system prompts that are added before the user system prompt.\n\n\n(These can be overridden, but it's not straightforward ...)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7cmws9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s more protected than you likely think.  I&amp;#39;m not sure how effective a fine tune is going to be, because it won&amp;#39;t stop the two baked-in (and highly, highly restrictive) system prompts that are added before the user system prompt.&lt;/p&gt;\n\n&lt;p&gt;(These can be overridden, but it&amp;#39;s not straightforward ...)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjjcu1/jailbreak_gpt_oss_120b/n7cmws9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754535056,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjjcu1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7d5vn0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Only-Letterhead-3411",
            "can_mod_post": false,
            "created_utc": 1754543143,
            "send_replies": true,
            "parent_id": "t3_1mjjcu1",
            "score": 2,
            "author_fullname": "t2_pbfqmgf8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What do you think will happen when you do that? I am genuinely curious. Do you really believe it'll be better than GLM 4.5 Air if you can get past the censorship?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7d5vn0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What do you think will happen when you do that? I am genuinely curious. Do you really believe it&amp;#39;ll be better than GLM 4.5 Air if you can get past the censorship?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjjcu1/jailbreak_gpt_oss_120b/n7d5vn0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754543143,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjjcu1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]