[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "The benchmarks seem really promising but I’m wondering how it actually performs compared to some of the other SOTA open source llms.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Anyone test the gpt-oss-120b model yet? How is its real world performance?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": true,
            "name": "t3_1miqu6b",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 1,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_8kbjrt7z",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754441699,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The benchmarks seem really promising but I’m wondering how it actually performs compared to some of the other SOTA open source llms.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1miqu6b",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Euphoric_Ad9500",
            "discussion_type": null,
            "num_comments": 5,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1miqu6b/anyone_test_the_gptoss120b_model_yet_how_is_its/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miqu6b/anyone_test_the_gptoss120b_model_yet_how_is_its/",
            "subreddit_subscribers": 511363,
            "created_utc": 1754441699,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n75fqjv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "fp4guru",
            "can_mod_post": false,
            "created_utc": 1754442308,
            "send_replies": true,
            "parent_id": "t3_1miqu6b",
            "score": 1,
            "author_fullname": "t2_1tp8zldw5g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Insanely censored, everything is \"ensure compliance\" or disallowed content forbidden :\n\n`&lt;|channel|&gt;analysis&lt;|message|&gt;The user: \"Tell me a random fun fact about the Roman Empire\". They just want a random fun fact about the Roman Empire. That is simple. I should comply. Provide a random fun fact. Could be about concrete, roads, vomitoriums, Roman toilets, the fact that they used a special concrete that still lasts. Or about the Roman Empire's size, or about the fact that Romans used a type of fast food. Provide a concise answer.` **Ensure compliance.** `It's straightforward.&lt;|start|&gt;assistant&lt;|channel|&gt;final&lt;|message|&gt;Fun fact: Roman concrete, made from volcanic ash, lime, and seawater, actually gets stronger over time. The mixture triggers a rare chemical reaction that creates tiny crystals called tobermorite, which continue to grow and bind the material together for centuries. That’s why many ancient Roman harbors, sea walls, and underwater structures are still standing strong after 2,000 + years—something modern concrete can’t match!`\n\nIm comparing it with glm4.5 air.\n\n  \nspeedwise , this is perfect for 1x4090 + 128GB RAM setup. 22 tokens per second.",
            "edited": 1754442638,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75fqjv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Insanely censored, everything is &amp;quot;ensure compliance&amp;quot; or disallowed content forbidden :&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;&amp;lt;|channel|&amp;gt;analysis&amp;lt;|message|&amp;gt;The user: &amp;quot;Tell me a random fun fact about the Roman Empire&amp;quot;. They just want a random fun fact about the Roman Empire. That is simple. I should comply. Provide a random fun fact. Could be about concrete, roads, vomitoriums, Roman toilets, the fact that they used a special concrete that still lasts. Or about the Roman Empire&amp;#39;s size, or about the fact that Romans used a type of fast food. Provide a concise answer.&lt;/code&gt; &lt;strong&gt;Ensure compliance.&lt;/strong&gt; &lt;code&gt;It&amp;#39;s straightforward.&amp;lt;|start|&amp;gt;assistant&amp;lt;|channel|&amp;gt;final&amp;lt;|message|&amp;gt;Fun fact: Roman concrete, made from volcanic ash, lime, and seawater, actually gets stronger over time. The mixture triggers a rare chemical reaction that creates tiny crystals called tobermorite, which continue to grow and bind the material together for centuries. That’s why many ancient Roman harbors, sea walls, and underwater structures are still standing strong after 2,000 + years—something modern concrete can’t match!&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Im comparing it with glm4.5 air.&lt;/p&gt;\n\n&lt;p&gt;speedwise , this is perfect for 1x4090 + 128GB RAM setup. 22 tokens per second.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miqu6b/anyone_test_the_gptoss120b_model_yet_how_is_its/n75fqjv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754442308,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miqu6b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n75g2eh",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "entsnack",
            "can_mod_post": false,
            "created_utc": 1754442421,
            "send_replies": true,
            "parent_id": "t3_1miqu6b",
            "score": 1,
            "author_fullname": "t2_1a48h7vf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Having a blast personally. Blazing fast with its MXFP4 innovation. Fast and good enough performance. It's a Qwen competitor, not as good as DeepSeek r1 IMO but some benchmarks suggest it is. If you want bigger and better go GLM or DeepSeek. I need speed and I'm a good coder so this is perfect for me.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75g2eh",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "a": ":X:",
                "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                "e": "emoji"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Having a blast personally. Blazing fast with its MXFP4 innovation. Fast and good enough performance. It&amp;#39;s a Qwen competitor, not as good as DeepSeek r1 IMO but some benchmarks suggest it is. If you want bigger and better go GLM or DeepSeek. I need speed and I&amp;#39;m a good coder so this is perfect for me.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "dark",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miqu6b/anyone_test_the_gptoss120b_model_yet_how_is_its/n75g2eh/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754442421,
            "author_flair_text": ":X:",
            "treatment_tags": [],
            "link_id": "t3_1miqu6b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "transparent",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n75fnh1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "omarx888",
                      "can_mod_post": false,
                      "created_utc": 1754442279,
                      "send_replies": true,
                      "parent_id": "t1_n75efov",
                      "score": 3,
                      "author_fullname": "t2_2u050jt8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "How big is that model and can I run it on my laptop?\n\nIf not, why mention this?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n75fnh1",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How big is that model and can I run it on my laptop?&lt;/p&gt;\n\n&lt;p&gt;If not, why mention this?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miqu6b",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miqu6b/anyone_test_the_gptoss120b_model_yet_how_is_its/n75fnh1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754442279,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n75efov",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "balianone",
            "can_mod_post": false,
            "created_utc": 1754441863,
            "send_replies": true,
            "parent_id": "t3_1miqu6b",
            "score": -1,
            "author_fullname": "t2_8pgou3uq9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "original glm4.5 is better(via Chinese api)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75efov",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;original glm4.5 is better(via Chinese api)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miqu6b/anyone_test_the_gptoss120b_model_yet_how_is_its/n75efov/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754441863,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miqu6b",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        }
      ],
      "before": null
    }
  }
]