[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "All feedback is welcome! I am learning how to do better everyday.\n\nI went down the LLM rabbit hole trying to find the **best local model** that runs *well* on a humble MacBook Air M1 with just 8GB RAM.\n\nMy goal? **Compare 10 models** across question generation, answering, and self-evaluation.\n\nTL;DR: Some models were brilliant, others… not so much. One even took **8 minutes** to write a question.\n\nHere's the breakdown \n\n**Models Tested**\n\n* Mistral 7B\n* DeepSeek-R1 1.5B\n* Gemma3:1b\n* Gemma3:latest\n* Qwen3 1.7B\n* Qwen2.5-VL 3B\n* Qwen3 4B\n* LLaMA 3.2 1B\n* LLaMA 3.2 3B\n* LLaMA 3.1 8B\n\n(All models run with quantized versions, via: os.environ\\[\"OLLAMA\\_CONTEXT\\_LENGTH\"\\] = \"4096\" and os.environ\\[\"OLLAMA\\_KV\\_CACHE\\_TYPE\"\\] = \"q4\\_0\")\n\n **Methodology**\n\nEach model:\n\n1. Generated 1 question on 5 topics: *Math, Writing, Coding, Psychology, History*\n2. Answered all 50 questions (5 x 10)\n3. Evaluated every answer (including their own)\n\nSo in total:\n\n* 50 questions\n* 500 answers\n* 4830 evaluations (Should be 5000; I evaluated less answers with qwen3:1.7b and qwen3:4b as they do not generate scores and take a lot of time\\*\\*)\\*\\*\n\nAnd I tracked:\n\n* token generation speed (tokens/sec)\n* tokens created\n* time taken\n* scored all answers for quality\n\n**Key Results**\n\n**Question Generation**\n\n* Fastest: **LLaMA 3.2 1B**, **Gemma3:1b**, **Qwen3 1.7B** (LLaMA 3.2 1B hit 82 tokens/sec, avg is \\~40 tokens/sec (for english topic question it reached **146 tokens/sec)**\n* Slowest: **LLaMA 3.1 8B**, **Qwen3 4B**, **Mistral 7B** Qwen3 4B took **486s** (8+ mins) to generate a single Math question!\n* Fun fact: deepseek-r1:1.5b, qwen3:4b and Qwen3:1.7B  output &lt;think&gt; tags in questions\n\n**Answer Generation**\n\n* Fastest: **Gemma3:1b**, **LLaMA 3.2 1B** and **DeepSeek-R1 1.5B**\n* DeepSeek got faster answering *its own* questions (80 tokens/s vs. avg 40 tokens/s)\n* Qwen3 4B generates **2–3x more tokens** per answer\n* Slowest: llama3.1:8b, qwen3:4b and mistral:7b\n\n **Evaluation**\n\n* Best scorer: Gemma3:latest – consistent, numerical, no bias\n* Worst scorer: **DeepSeek-R1 1.5B** – often skipped scores entirely\n* Bias detected: Many models **rate their own answers higher**\n* DeepSeek even evaluated some answers **in Chinese**\n* I did think of creating a control set of answers. I could tell the mdoel this is the perfect answer basis this rate others. But I did not because it would need support from a lot of people- creating perfect answer, which still can have a bias. I read a few answers and found most of them decent except math. So I tried to find which model's evaluation scores were closest to the average to determine a decent model for evaluation tasks(check last image)\n\n**Fun Observations**\n\n* Some models create &lt;think&gt; tags for questions, answers and even while evaluation as output\n* Score inflation is real: Mistral, Qwen3, and LLaMA 3.1 8B overrate themselves\n* Score formats vary wildly (text explanations vs. plain numbers)\n* Speed isn’t everything – some slower models gave much higher quality answers\n\nBest Performers (My Picks)\n\n|Task|Best Model|Why|\n|:-|:-|:-|\n||\n|Question Gen|LLaMA 3.2 1B|Fast &amp; relevant|\n|Answer Gen|Gemma3:1b|Fast, accurate|\n|Evaluation|LLaMA 3.2 3B|Generates numerical scores and evaluations closest to model average|\n\n# Worst Surprises\n\n|Task|Model|Problem|\n|:-|:-|:-|\n||\n|Question Gen|Qwen3 4B|Took 486s to generate 1 question|\n|Answer Gen|LLaMA 3.1 8B|Slow|\n|Evaluation|DeepSeek-R1 1.5B|Inconsistent, skipped scores|\n\n  \n\n\n**Screenshots Galore**\n\nI’m adding screenshots of:\n\n* Questions generation\n* Answer comparisons\n* Evaluation outputs\n* Token/sec charts\n\n**Takeaways**\n\n* You **can** run decent LLMs locally on M1 Air (8GB) – if you pick the right ones\n* Model size ≠ performance. Bigger isn't always better.\n* 5 Models have a self bais, they rate their own answers higher than average scores. attaching screen shot of a table. Diagonal is their own evaluation, last column is average.\n* Models' evaluation has high variance! Every model has a unique distribution of the scores it gave.\n\n\n\nPost questions if you have any, I will try to answer.\n\nHappy to share more data if you need.\n\nOpen to collaborate on interesting projects!  \n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "is_gallery": true,
            "title": "I tested 10 LLMs locally on my MacBook Air M1 (8GB RAM!) – Here's what actually works-",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 112,
            "top_awarded_type": null,
            "name": "t3_1lmfiu9",
            "media_metadata": {
              "w4f8xli4wl9f1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 29,
                    "x": 108,
                    "u": "https://preview.redd.it/w4f8xli4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b96b9d71e7f5cc19270d3e6757274fac5fe9e559"
                  },
                  {
                    "y": 59,
                    "x": 216,
                    "u": "https://preview.redd.it/w4f8xli4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cf125b59a5d0fbb0104681091d2cd72710d9438c"
                  },
                  {
                    "y": 87,
                    "x": 320,
                    "u": "https://preview.redd.it/w4f8xli4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f239944c53abb16cd6f10f737c0d3e9c05029fc3"
                  },
                  {
                    "y": 175,
                    "x": 640,
                    "u": "https://preview.redd.it/w4f8xli4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d0d69126eba42bde7f077facec0a350d57c56256"
                  },
                  {
                    "y": 262,
                    "x": 960,
                    "u": "https://preview.redd.it/w4f8xli4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=714909e3b8b9add5188e1cf71f01d0ede670096b"
                  },
                  {
                    "y": 295,
                    "x": 1080,
                    "u": "https://preview.redd.it/w4f8xli4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1edde5fe76b20b90da3d4bac9cb308f007f9b2a1"
                  }
                ],
                "s": {
                  "y": 608,
                  "x": 2222,
                  "u": "https://preview.redd.it/w4f8xli4wl9f1.png?width=2222&amp;format=png&amp;auto=webp&amp;s=ad9ae202236ff1cd2a5d1cf75d70eb52b16391f6"
                },
                "id": "w4f8xli4wl9f1"
              },
              "7ow61zr5yl9f1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 34,
                    "x": 108,
                    "u": "https://preview.redd.it/7ow61zr5yl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0d71ac73034ce77fb319f3e990af9dfcb44e24ae"
                  },
                  {
                    "y": 69,
                    "x": 216,
                    "u": "https://preview.redd.it/7ow61zr5yl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2d6854bb1262cfb00057e00b4b4e6194c543add"
                  },
                  {
                    "y": 102,
                    "x": 320,
                    "u": "https://preview.redd.it/7ow61zr5yl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0d942c0c3a8bcd5cd2ec47ed9eec14908266197b"
                  },
                  {
                    "y": 205,
                    "x": 640,
                    "u": "https://preview.redd.it/7ow61zr5yl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3db8e0da43940b98ce87c2231621edf4865bd8d3"
                  },
                  {
                    "y": 308,
                    "x": 960,
                    "u": "https://preview.redd.it/7ow61zr5yl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bd04e93a170d7594a1cb1e71bdde008140e19fc4"
                  },
                  {
                    "y": 347,
                    "x": 1080,
                    "u": "https://preview.redd.it/7ow61zr5yl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aa807713456f50b628c2dbbb7f9bd31cb36af2c3"
                  }
                ],
                "s": {
                  "y": 578,
                  "x": 1798,
                  "u": "https://preview.redd.it/7ow61zr5yl9f1.png?width=1798&amp;format=png&amp;auto=webp&amp;s=4e017761dc8a2a68934ac7aa89b630b9ed2b8c35"
                },
                "id": "7ow61zr5yl9f1"
              },
              "egnnlsi2wl9f1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 86,
                    "x": 108,
                    "u": "https://preview.redd.it/egnnlsi2wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c9448c36d381645725739286c81c00c47042504a"
                  },
                  {
                    "y": 173,
                    "x": 216,
                    "u": "https://preview.redd.it/egnnlsi2wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=90beda29783d07c6f8fdcbe4dc9571577513c239"
                  },
                  {
                    "y": 256,
                    "x": 320,
                    "u": "https://preview.redd.it/egnnlsi2wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b81341be72a56d8b0ea6bf950c56f7262fe5f095"
                  }
                ],
                "s": {
                  "y": 462,
                  "x": 576,
                  "u": "https://preview.redd.it/egnnlsi2wl9f1.png?width=576&amp;format=png&amp;auto=webp&amp;s=74c468152e1b07a9477cb9f585813b049d8fe26a"
                },
                "id": "egnnlsi2wl9f1"
              },
              "3a2up8h4wl9f1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 55,
                    "x": 108,
                    "u": "https://preview.redd.it/3a2up8h4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b160363637899ad144ebf490c61dc85337660b4e"
                  },
                  {
                    "y": 111,
                    "x": 216,
                    "u": "https://preview.redd.it/3a2up8h4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7c2516aaf407375f16ad9e0056be5294332c94e7"
                  },
                  {
                    "y": 165,
                    "x": 320,
                    "u": "https://preview.redd.it/3a2up8h4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0a2b191dda64d1e00eb4adc7349872c23ea50618"
                  },
                  {
                    "y": 331,
                    "x": 640,
                    "u": "https://preview.redd.it/3a2up8h4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=79a9835abf82b64f59e6451b9a4983d31832c526"
                  },
                  {
                    "y": 497,
                    "x": 960,
                    "u": "https://preview.redd.it/3a2up8h4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3321e89c17c380a374228afd5f94fa21aaa45a0f"
                  },
                  {
                    "y": 559,
                    "x": 1080,
                    "u": "https://preview.redd.it/3a2up8h4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bfad51ac4fdb43c37a6bfefc824617849188b0ce"
                  }
                ],
                "s": {
                  "y": 612,
                  "x": 1182,
                  "u": "https://preview.redd.it/3a2up8h4wl9f1.png?width=1182&amp;format=png&amp;auto=webp&amp;s=748edef3784d64cc28c4d60c3e50571ddcaad313"
                },
                "id": "3a2up8h4wl9f1"
              },
              "liu63zk4wl9f1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 37,
                    "x": 108,
                    "u": "https://preview.redd.it/liu63zk4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e50689d45b956d6a4b2c5f7590a12f95ac267972"
                  },
                  {
                    "y": 74,
                    "x": 216,
                    "u": "https://preview.redd.it/liu63zk4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b1a68615664589ed852faaaf98f6779a17e22563"
                  },
                  {
                    "y": 109,
                    "x": 320,
                    "u": "https://preview.redd.it/liu63zk4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=20bca0e7073ae1d89178fe678c7f460bd00fc6e0"
                  },
                  {
                    "y": 219,
                    "x": 640,
                    "u": "https://preview.redd.it/liu63zk4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0ddcc8fb4ef36dac5f1ca0f95fc62a3e37486e2a"
                  },
                  {
                    "y": 329,
                    "x": 960,
                    "u": "https://preview.redd.it/liu63zk4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=021bf74293f3c00eaac63703a8d127e3fb4f63be"
                  },
                  {
                    "y": 370,
                    "x": 1080,
                    "u": "https://preview.redd.it/liu63zk4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a39b2959311f50782f311f9745422c8e4ee378c"
                  }
                ],
                "s": {
                  "y": 622,
                  "x": 1812,
                  "u": "https://preview.redd.it/liu63zk4wl9f1.png?width=1812&amp;format=png&amp;auto=webp&amp;s=546b5bd3a523c15dc10ff4dde46352f729e79c6a"
                },
                "id": "liu63zk4wl9f1"
              },
              "d8xub4g4wl9f1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 55,
                    "x": 108,
                    "u": "https://preview.redd.it/d8xub4g4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6dd67cbc493ea896c4e423238cae173000db0548"
                  },
                  {
                    "y": 111,
                    "x": 216,
                    "u": "https://preview.redd.it/d8xub4g4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d55bc9d396022cce49b2c94bac0437c04d689f10"
                  },
                  {
                    "y": 165,
                    "x": 320,
                    "u": "https://preview.redd.it/d8xub4g4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=61aaf12e41251c658b2b4f868b3781eb04ab55d1"
                  },
                  {
                    "y": 331,
                    "x": 640,
                    "u": "https://preview.redd.it/d8xub4g4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4e308e90fe91bbbc89a40ddb9b9096dae15730cf"
                  },
                  {
                    "y": 497,
                    "x": 960,
                    "u": "https://preview.redd.it/d8xub4g4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=175ecbe1ba43ce3239bc45eac8b0da69a27f2b86"
                  },
                  {
                    "y": 559,
                    "x": 1080,
                    "u": "https://preview.redd.it/d8xub4g4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc210e0d4f4388c78242014ab57cf0e07e63ee76"
                  }
                ],
                "s": {
                  "y": 612,
                  "x": 1182,
                  "u": "https://preview.redd.it/d8xub4g4wl9f1.png?width=1182&amp;format=png&amp;auto=webp&amp;s=a4bb86c652cec9b038e938fe04a714dc0736c538"
                },
                "id": "d8xub4g4wl9f1"
              },
              "40gg0ih4wl9f1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 51,
                    "x": 108,
                    "u": "https://preview.redd.it/40gg0ih4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=843dd3262374605f266f4c27d5e9f1d89dbaa2b2"
                  },
                  {
                    "y": 102,
                    "x": 216,
                    "u": "https://preview.redd.it/40gg0ih4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=56f75b650d38e914049b6fd64a26e2fc3c016b5d"
                  },
                  {
                    "y": 152,
                    "x": 320,
                    "u": "https://preview.redd.it/40gg0ih4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=95f9ce0398be85d3a2b624b01002420346b3ad0c"
                  },
                  {
                    "y": 304,
                    "x": 640,
                    "u": "https://preview.redd.it/40gg0ih4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bcfc3c93a167ba16a262a2da7e5a418386d5ea24"
                  },
                  {
                    "y": 456,
                    "x": 960,
                    "u": "https://preview.redd.it/40gg0ih4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b6fd6795c6cf705e757ca019f69fb8a5d85dc083"
                  },
                  {
                    "y": 513,
                    "x": 1080,
                    "u": "https://preview.redd.it/40gg0ih4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1675b1bd8c2c958cbf831b82c33e80db9ff880c2"
                  }
                ],
                "s": {
                  "y": 638,
                  "x": 1342,
                  "u": "https://preview.redd.it/40gg0ih4wl9f1.png?width=1342&amp;format=png&amp;auto=webp&amp;s=42cd465376a98a0e2334441ad593bbc235416c5d"
                },
                "id": "40gg0ih4wl9f1"
              },
              "pvm051l4wl9f1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 36,
                    "x": 108,
                    "u": "https://preview.redd.it/pvm051l4wl9f1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c7db0df0d613449adf472a0d58e9ce7adce1ae72"
                  },
                  {
                    "y": 73,
                    "x": 216,
                    "u": "https://preview.redd.it/pvm051l4wl9f1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8cfabb69b61246b25865db0c730e257755a797c8"
                  },
                  {
                    "y": 108,
                    "x": 320,
                    "u": "https://preview.redd.it/pvm051l4wl9f1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dc741039d34362412cd2b230ea2ee1e48e35f194"
                  },
                  {
                    "y": 216,
                    "x": 640,
                    "u": "https://preview.redd.it/pvm051l4wl9f1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8d93dc81a7c1dd207d9c6fe7d69347616516cf7c"
                  },
                  {
                    "y": 324,
                    "x": 960,
                    "u": "https://preview.redd.it/pvm051l4wl9f1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0ddabbd002a9e5e456a17c6870bb97674fb1719a"
                  },
                  {
                    "y": 365,
                    "x": 1080,
                    "u": "https://preview.redd.it/pvm051l4wl9f1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8c7e81f875f564219b86016f4279dc98de4ca000"
                  }
                ],
                "s": {
                  "y": 616,
                  "x": 1820,
                  "u": "https://preview.redd.it/pvm051l4wl9f1.png?width=1820&amp;format=png&amp;auto=webp&amp;s=a174b16eed66f061fe3ae72b957c5603f6a1a8d8"
                },
                "id": "pvm051l4wl9f1"
              }
            },
            "hide_score": false,
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.9,
            "author_flair_background_color": null,
            "ups": 91,
            "domain": "reddit.com",
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_l5xlcgf2j",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "gallery_data": {
              "items": [
                {
                  "media_id": "egnnlsi2wl9f1",
                  "id": 694183376
                },
                {
                  "media_id": "pvm051l4wl9f1",
                  "id": 694183377
                },
                {
                  "media_id": "liu63zk4wl9f1",
                  "id": 694183378
                },
                {
                  "media_id": "d8xub4g4wl9f1",
                  "id": 694183379
                },
                {
                  "media_id": "3a2up8h4wl9f1",
                  "id": 694183380
                },
                {
                  "media_id": "40gg0ih4wl9f1",
                  "id": 694183381
                },
                {
                  "media_id": "w4f8xli4wl9f1",
                  "id": 694183382
                },
                {
                  "media_id": "7ow61zr5yl9f1",
                  "id": 694183383
                }
              ]
            },
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 91,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?width=140&amp;height=112&amp;crop=140:112,smart&amp;auto=webp&amp;s=dc5f7c42f0d761e20ad7ac19bcfae402a94d6091",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "gallery",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1751090266,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;All feedback is welcome! I am learning how to do better everyday.&lt;/p&gt;\n\n&lt;p&gt;I went down the LLM rabbit hole trying to find the &lt;strong&gt;best local model&lt;/strong&gt; that runs &lt;em&gt;well&lt;/em&gt; on a humble MacBook Air M1 with just 8GB RAM.&lt;/p&gt;\n\n&lt;p&gt;My goal? &lt;strong&gt;Compare 10 models&lt;/strong&gt; across question generation, answering, and self-evaluation.&lt;/p&gt;\n\n&lt;p&gt;TL;DR: Some models were brilliant, others… not so much. One even took &lt;strong&gt;8 minutes&lt;/strong&gt; to write a question.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the breakdown &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Models Tested&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Mistral 7B&lt;/li&gt;\n&lt;li&gt;DeepSeek-R1 1.5B&lt;/li&gt;\n&lt;li&gt;Gemma3:1b&lt;/li&gt;\n&lt;li&gt;Gemma3:latest&lt;/li&gt;\n&lt;li&gt;Qwen3 1.7B&lt;/li&gt;\n&lt;li&gt;Qwen2.5-VL 3B&lt;/li&gt;\n&lt;li&gt;Qwen3 4B&lt;/li&gt;\n&lt;li&gt;LLaMA 3.2 1B&lt;/li&gt;\n&lt;li&gt;LLaMA 3.2 3B&lt;/li&gt;\n&lt;li&gt;LLaMA 3.1 8B&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;(All models run with quantized versions, via: os.environ[&amp;quot;OLLAMA_CONTEXT_LENGTH&amp;quot;] = &amp;quot;4096&amp;quot; and os.environ[&amp;quot;OLLAMA_KV_CACHE_TYPE&amp;quot;] = &amp;quot;q4_0&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt; &lt;strong&gt;Methodology&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Each model:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Generated 1 question on 5 topics: &lt;em&gt;Math, Writing, Coding, Psychology, History&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;Answered all 50 questions (5 x 10)&lt;/li&gt;\n&lt;li&gt;Evaluated every answer (including their own)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So in total:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;50 questions&lt;/li&gt;\n&lt;li&gt;500 answers&lt;/li&gt;\n&lt;li&gt;4830 evaluations (Should be 5000; I evaluated less answers with qwen3:1.7b and qwen3:4b as they do not generate scores and take a lot of time**)**&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And I tracked:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;token generation speed (tokens/sec)&lt;/li&gt;\n&lt;li&gt;tokens created&lt;/li&gt;\n&lt;li&gt;time taken&lt;/li&gt;\n&lt;li&gt;scored all answers for quality&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Key Results&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question Generation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fastest: &lt;strong&gt;LLaMA 3.2 1B&lt;/strong&gt;, &lt;strong&gt;Gemma3:1b&lt;/strong&gt;, &lt;strong&gt;Qwen3 1.7B&lt;/strong&gt; (LLaMA 3.2 1B hit 82 tokens/sec, avg is ~40 tokens/sec (for english topic question it reached &lt;strong&gt;146 tokens/sec)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Slowest: &lt;strong&gt;LLaMA 3.1 8B&lt;/strong&gt;, &lt;strong&gt;Qwen3 4B&lt;/strong&gt;, &lt;strong&gt;Mistral 7B&lt;/strong&gt; Qwen3 4B took &lt;strong&gt;486s&lt;/strong&gt; (8+ mins) to generate a single Math question!&lt;/li&gt;\n&lt;li&gt;Fun fact: deepseek-r1:1.5b, qwen3:4b and Qwen3:1.7B  output &amp;lt;think&amp;gt; tags in questions&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Answer Generation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fastest: &lt;strong&gt;Gemma3:1b&lt;/strong&gt;, &lt;strong&gt;LLaMA 3.2 1B&lt;/strong&gt; and &lt;strong&gt;DeepSeek-R1 1.5B&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;DeepSeek got faster answering &lt;em&gt;its own&lt;/em&gt; questions (80 tokens/s vs. avg 40 tokens/s)&lt;/li&gt;\n&lt;li&gt;Qwen3 4B generates &lt;strong&gt;2–3x more tokens&lt;/strong&gt; per answer&lt;/li&gt;\n&lt;li&gt;Slowest: llama3.1:8b, qwen3:4b and mistral:7b&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt; &lt;strong&gt;Evaluation&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Best scorer: Gemma3:latest – consistent, numerical, no bias&lt;/li&gt;\n&lt;li&gt;Worst scorer: &lt;strong&gt;DeepSeek-R1 1.5B&lt;/strong&gt; – often skipped scores entirely&lt;/li&gt;\n&lt;li&gt;Bias detected: Many models &lt;strong&gt;rate their own answers higher&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;DeepSeek even evaluated some answers &lt;strong&gt;in Chinese&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;I did think of creating a control set of answers. I could tell the mdoel this is the perfect answer basis this rate others. But I did not because it would need support from a lot of people- creating perfect answer, which still can have a bias. I read a few answers and found most of them decent except math. So I tried to find which model&amp;#39;s evaluation scores were closest to the average to determine a decent model for evaluation tasks(check last image)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Fun Observations&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Some models create &amp;lt;think&amp;gt; tags for questions, answers and even while evaluation as output&lt;/li&gt;\n&lt;li&gt;Score inflation is real: Mistral, Qwen3, and LLaMA 3.1 8B overrate themselves&lt;/li&gt;\n&lt;li&gt;Score formats vary wildly (text explanations vs. plain numbers)&lt;/li&gt;\n&lt;li&gt;Speed isn’t everything – some slower models gave much higher quality answers&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Best Performers (My Picks)&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Task&lt;/th&gt;\n&lt;th align=\"left\"&gt;Best Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;Why&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td colspan=\"2\"  align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Question Gen&lt;/td&gt;\n&lt;td align=\"left\"&gt;LLaMA 3.2 1B&lt;/td&gt;\n&lt;td align=\"left\"&gt;Fast &amp;amp; relevant&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Answer Gen&lt;/td&gt;\n&lt;td align=\"left\"&gt;Gemma3:1b&lt;/td&gt;\n&lt;td align=\"left\"&gt;Fast, accurate&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Evaluation&lt;/td&gt;\n&lt;td align=\"left\"&gt;LLaMA 3.2 3B&lt;/td&gt;\n&lt;td align=\"left\"&gt;Generates numerical scores and evaluations closest to model average&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;h1&gt;Worst Surprises&lt;/h1&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Task&lt;/th&gt;\n&lt;th align=\"left\"&gt;Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;Problem&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td colspan=\"2\"  align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Question Gen&lt;/td&gt;\n&lt;td align=\"left\"&gt;Qwen3 4B&lt;/td&gt;\n&lt;td align=\"left\"&gt;Took 486s to generate 1 question&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Answer Gen&lt;/td&gt;\n&lt;td align=\"left\"&gt;LLaMA 3.1 8B&lt;/td&gt;\n&lt;td align=\"left\"&gt;Slow&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Evaluation&lt;/td&gt;\n&lt;td align=\"left\"&gt;DeepSeek-R1 1.5B&lt;/td&gt;\n&lt;td align=\"left\"&gt;Inconsistent, skipped scores&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&lt;strong&gt;Screenshots Galore&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I’m adding screenshots of:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Questions generation&lt;/li&gt;\n&lt;li&gt;Answer comparisons&lt;/li&gt;\n&lt;li&gt;Evaluation outputs&lt;/li&gt;\n&lt;li&gt;Token/sec charts&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Takeaways&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;You &lt;strong&gt;can&lt;/strong&gt; run decent LLMs locally on M1 Air (8GB) – if you pick the right ones&lt;/li&gt;\n&lt;li&gt;Model size ≠ performance. Bigger isn&amp;#39;t always better.&lt;/li&gt;\n&lt;li&gt;5 Models have a self bais, they rate their own answers higher than average scores. attaching screen shot of a table. Diagonal is their own evaluation, last column is average.&lt;/li&gt;\n&lt;li&gt;Models&amp;#39; evaluation has high variance! Every model has a unique distribution of the scores it gave.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Post questions if you have any, I will try to answer.&lt;/p&gt;\n\n&lt;p&gt;Happy to share more data if you need.&lt;/p&gt;\n\n&lt;p&gt;Open to collaborate on interesting projects!  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://www.reddit.com/gallery/1lmfiu9",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?auto=webp&amp;s=a10cedac67e9fa4bc062f13cc4ef20dafb782493",
                    "width": 576,
                    "height": 462
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d0ba456f772896d13d26a433eb814c01465159c5",
                      "width": 108,
                      "height": 86
                    },
                    {
                      "url": "https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4cd893d5d514dea0401f679947934b06ac7b1f8",
                      "width": 216,
                      "height": 173
                    },
                    {
                      "url": "https://external-preview.redd.it/lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d68c4413ac33077ccb1f955a9767daec572c1df8",
                      "width": 320,
                      "height": 256
                    }
                  ],
                  "variants": {},
                  "id": "lSrPd1MMz7blRmLYLnruRoJd4XS5NpPXF_maDibWecs"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1lmfiu9",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "irodov4030",
            "discussion_type": null,
            "num_comments": 23,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/",
            "stickied": false,
            "url": "https://www.reddit.com/gallery/1lmfiu9",
            "subreddit_subscribers": 492223,
            "created_utc": 1751090266,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n07dio9",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "SkyFeistyLlama8",
                      "can_mod_post": false,
                      "created_utc": 1751094998,
                      "send_replies": true,
                      "parent_id": "t1_n077onj",
                      "score": 6,
                      "author_fullname": "t2_1hgbaqgbnq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Gemma 3 4B is one heck of a model with excellent multilingual understanding given the size.\n\nThe Qwen 3 models have become a disappointment for me. They spend too many tokens ruminating until it's not worth waiting for a better answer when Gemma gives something good enough in a quarter of the time.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n07dio9",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Gemma 3 4B is one heck of a model with excellent multilingual understanding given the size.&lt;/p&gt;\n\n&lt;p&gt;The Qwen 3 models have become a disappointment for me. They spend too many tokens ruminating until it&amp;#39;s not worth waiting for a better answer when Gemma gives something good enough in a quarter of the time.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lmfiu9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07dio9/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751094998,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n07aoq0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "irodov4030",
                      "can_mod_post": false,
                      "created_utc": 1751093438,
                      "send_replies": true,
                      "parent_id": "t1_n077onj",
                      "score": 2,
                      "author_fullname": "t2_l5xlcgf2j",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "yup",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n07aoq0",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yup&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lmfiu9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07aoq0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751093438,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n077onj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "horse_tinder",
            "can_mod_post": false,
            "created_utc": 1751091820,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": 12,
            "author_fullname": "t2_1aqzktph67",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "gemma is good around all the tasks in general",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n077onj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;gemma is good around all the tasks in general&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n077onj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751091820,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 12
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n07dnpn",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "irodov4030",
                      "can_mod_post": false,
                      "created_utc": 1751095077,
                      "send_replies": true,
                      "parent_id": "t1_n07cde5",
                      "score": 2,
                      "author_fullname": "t2_l5xlcgf2j",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "thank you for the feedback!\n\nSo I did this in 3 steps, 1 for generaiting questions, 2nd for answering and the 3rd for evaluating  \nFor every step, code was a nested loop on all models and topics.  \nFor all steps my laptop was plugged in with no background apps and no internet.\n\n  \nI agree on running 2 large models to test all results. I will try to do the evaluation again",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n07dnpn",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;thank you for the feedback!&lt;/p&gt;\n\n&lt;p&gt;So I did this in 3 steps, 1 for generaiting questions, 2nd for answering and the 3rd for evaluating&lt;br/&gt;\nFor every step, code was a nested loop on all models and topics.&lt;br/&gt;\nFor all steps my laptop was plugged in with no background apps and no internet.&lt;/p&gt;\n\n&lt;p&gt;I agree on running 2 large models to test all results. I will try to do the evaluation again&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lmfiu9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07dnpn/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751095077,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n07cde5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Chromix_",
            "can_mod_post": false,
            "created_utc": 1751094361,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": 5,
            "author_fullname": "t2_k7w2h",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Thanks for these details. Looking at these it seems to be that there's a flaw in the time measurement somewhere, and the scoring is potentially also not as good as it looks.\n\n&gt;DeepSeek got faster answering *its own* questions (80 tokens/s vs. avg 40 tokens/s)\n\nYou didn't specify using a speculative decoding model (probably wouldn't have fit the 8GB in addition to the model anyway). The LLM answer generation speed is somewhat constant - at least at your 4k context length. If it suddenly generated tokens at twice the speed then there must be an oversight in execution (swapping to system RAM, background tasks, incorrect timing, measuring prompt processing time together with inference time, wrong model, etc).\n\n&gt;Qwen3 4B took 8+ mins to generate a single Math question!\n\nAt 6 tokens per second that's too slow compared to the other models. You might not have run an apples to apples comparison here. Maybe not all models were quantized in the same format?\n\nSpeaking of quantization, this hurts the output quality quite a bit:\n\n&gt;os.environ\\[\"OLLAMA\\_KV\\_CACHE\\_TYPE\"\\] = \"q4\\_0\"\n\nIt's OKish to set the V cache to Q4, but the K cache [should stay at least on Q8](https://www.reddit.com/r/LocalLLaMA/comments/1iuw1kx/comment/me15i32/?context=3).\n\n&gt;Each model ... Evaluated every answer (including their own)\n\nIt would've been helpful for assessing the scoring to let two large, high quality models generate a few sets of questions and also perform a few evaluation runs over the output of the small models. By running multiple sets with the smaller models you could also measure the variance in generation quality - what if a model in your single run randomly performed pretty well, while another randomly generated low quality output?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n07cde5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for these details. Looking at these it seems to be that there&amp;#39;s a flaw in the time measurement somewhere, and the scoring is potentially also not as good as it looks.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;DeepSeek got faster answering &lt;em&gt;its own&lt;/em&gt; questions (80 tokens/s vs. avg 40 tokens/s)&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You didn&amp;#39;t specify using a speculative decoding model (probably wouldn&amp;#39;t have fit the 8GB in addition to the model anyway). The LLM answer generation speed is somewhat constant - at least at your 4k context length. If it suddenly generated tokens at twice the speed then there must be an oversight in execution (swapping to system RAM, background tasks, incorrect timing, measuring prompt processing time together with inference time, wrong model, etc).&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Qwen3 4B took 8+ mins to generate a single Math question!&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;At 6 tokens per second that&amp;#39;s too slow compared to the other models. You might not have run an apples to apples comparison here. Maybe not all models were quantized in the same format?&lt;/p&gt;\n\n&lt;p&gt;Speaking of quantization, this hurts the output quality quite a bit:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;os.environ[&amp;quot;OLLAMA_KV_CACHE_TYPE&amp;quot;] = &amp;quot;q4_0&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s OKish to set the V cache to Q4, but the K cache &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1iuw1kx/comment/me15i32/?context=3\"&gt;should stay at least on Q8&lt;/a&gt;.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Each model ... Evaluated every answer (including their own)&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It would&amp;#39;ve been helpful for assessing the scoring to let two large, high quality models generate a few sets of questions and also perform a few evaluation runs over the output of the small models. By running multiple sets with the smaller models you could also measure the variance in generation quality - what if a model in your single run randomly performed pretty well, while another randomly generated low quality output?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07cde5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751094361,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n07eeb2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "chub79",
            "can_mod_post": false,
            "created_utc": 1751095492,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": 2,
            "author_fullname": "t2_36n3l",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt; Qwen3 4B generates 2–3x more tokens per answer\n\nIt's such a bloody chatty one.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n07eeb2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Qwen3 4B generates 2–3x more tokens per answer&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s such a bloody chatty one.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07eeb2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751095492,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n07mjv9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Mysterious_Finish543",
            "can_mod_post": false,
            "created_utc": 1751100300,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": 2,
            "author_fullname": "t2_gbx2bcdvl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think the reason the reasoning models like DeepSeek-R1-Distill-Qwen-1.5B is doing poorly is the short context length.\n\nReasoning models will often need 8K to perform reliability without being cut off / entering a loop.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n07mjv9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the reason the reasoning models like DeepSeek-R1-Distill-Qwen-1.5B is doing poorly is the short context length.&lt;/p&gt;\n\n&lt;p&gt;Reasoning models will often need 8K to perform reliability without being cut off / entering a loop.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07mjv9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751100300,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n07e67o",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "AllanSundry2020",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n07b784",
                                          "score": 2,
                                          "author_fullname": "t2_5tvkhk4q",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "gemma3n also now on thiis hardware type",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n07e67o",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;gemma3n also now on thiis hardware type&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1lmfiu9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07e67o/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1751095365,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1751095365,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n07b784",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Nonomomomo2",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n07azh8",
                                "score": 2,
                                "author_fullname": "t2_8k6kwn2y",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "That’s great, thanks for sharing your test results and experience!\n\nEdit: why TF would someone downvote me for thanking OP for answering my question?",
                                "edited": 1751100618,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n07b784",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That’s great, thanks for sharing your test results and experience!&lt;/p&gt;\n\n&lt;p&gt;Edit: why TF would someone downvote me for thanking OP for answering my question?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lmfiu9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07b784/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751093716,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751093716,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n07azh8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "irodov4030",
                      "can_mod_post": false,
                      "created_utc": 1751093601,
                      "send_replies": true,
                      "parent_id": "t1_n078iwq",
                      "score": 2,
                      "author_fullname": "t2_l5xlcgf2j",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I would pick gemma or llama 3B\n\nAnd I still would want to test qven 7b with tighter prompts again. I want to reinforce controls and see if it performs better.\n\nFor this test I did do it but I mean reinforcing multiple times for the next test",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n07azh8",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would pick gemma or llama 3B&lt;/p&gt;\n\n&lt;p&gt;And I still would want to test qven 7b with tighter prompts again. I want to reinforce controls and see if it performs better.&lt;/p&gt;\n\n&lt;p&gt;For this test I did do it but I mean reinforcing multiple times for the next test&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lmfiu9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07azh8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751093601,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n07r7dr",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "vibjelo",
                      "can_mod_post": false,
                      "created_utc": 1751103096,
                      "send_replies": true,
                      "parent_id": "t1_n078iwq",
                      "score": 1,
                      "author_fullname": "t2_hr2hgnsk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; Still, which would you pick as your preferred all arounder?\n\nIt's a bit like \"all arounder\" programming languages, sure, they'll all work for everything, and people have their personal preference and subjective opinions about it, but is that really important to know? Yes, Norvig's favorite programming language is Python, but why that matters? Isn't it more important to be able to evaluate which language is right for a problem?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n07r7dr",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Still, which would you pick as your preferred all arounder?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s a bit like &amp;quot;all arounder&amp;quot; programming languages, sure, they&amp;#39;ll all work for everything, and people have their personal preference and subjective opinions about it, but is that really important to know? Yes, Norvig&amp;#39;s favorite programming language is Python, but why that matters? Isn&amp;#39;t it more important to be able to evaluate which language is right for a problem?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lmfiu9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07r7dr/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751103096,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n078iwq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Nonomomomo2",
            "can_mod_post": false,
            "created_utc": 1751092268,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": 4,
            "author_fullname": "t2_8k6kwn2y",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So if you had to pick just one to run, which would it be?\n\nYada yada “task dependence” etc, we all get it. \n\nStill, which would you pick as your preferred all arounder?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n078iwq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So if you had to pick just one to run, which would it be?&lt;/p&gt;\n\n&lt;p&gt;Yada yada “task dependence” etc, we all get it. &lt;/p&gt;\n\n&lt;p&gt;Still, which would you pick as your preferred all arounder?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n078iwq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751092268,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n07pijm",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Tipop",
                      "can_mod_post": false,
                      "created_utc": 1751102074,
                      "send_replies": true,
                      "parent_id": "t1_n07ld93",
                      "score": 1,
                      "author_fullname": "t2_6562x",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "By “HD” do you mean SSD? Or are you specifically referring to spinning hard drives?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n07pijm",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;By “HD” do you mean SSD? Or are you specifically referring to spinning hard drives?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lmfiu9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07pijm/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751102074,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n07ld93",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "These-Dog6141",
            "can_mod_post": false,
            "created_utc": 1751099599,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": 1,
            "author_fullname": "t2_4uyy18ifx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "nice test thanks for sharing, have you been able to determine how much you used your HD swap memory when loading the 7b/8b models, do note that using swap for LLM is not recommended because you will rapidly deteriorate the HD",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n07ld93",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;nice test thanks for sharing, have you been able to determine how much you used your HD swap memory when loading the 7b/8b models, do note that using swap for LLM is not recommended because you will rapidly deteriorate the HD&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07ld93/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751099599,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n07nfnu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "IrisColt",
            "can_mod_post": false,
            "created_utc": 1751100826,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": 1,
            "author_fullname": "t2_c2f558x",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I like your plot, and I don't even own a Mac. Congrats, and thanks for the insight!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n07nfnu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I like your plot, and I don&amp;#39;t even own a Mac. Congrats, and thanks for the insight!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07nfnu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751100826,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n07ozqu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "admajic",
            "can_mod_post": false,
            "created_utc": 1751101756,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": 1,
            "author_fullname": "t2_60b9farf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yeah qwen3 8b is a beast. But it wouldn't be my choice for complex debugging that a 400b+ model struggles with",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n07ozqu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah qwen3 8b is a beast. But it wouldn&amp;#39;t be my choice for complex debugging that a 400b+ model struggles with&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07ozqu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751101756,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n07ei35",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "LevianMcBirdo",
            "can_mod_post": false,
            "created_utc": 1751095553,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": 0,
            "author_fullname": "t2_cw9f6o0r",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I somehow really doubt that llama 3.2 1B beats 3.1 8B, except asking knowledge about very current stuff. Now, I don't know your benchmark questions and maybe it's the best for your usecase, but the relax small models being this good doesn't really track with my usage experience. They are great for their size though.   \nMaybe this just answers us the question if llms should numerically evaluate texts",
            "edited": 1751095733,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n07ei35",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I somehow really doubt that llama 3.2 1B beats 3.1 8B, except asking knowledge about very current stuff. Now, I don&amp;#39;t know your benchmark questions and maybe it&amp;#39;s the best for your usecase, but the relax small models being this good doesn&amp;#39;t really track with my usage experience. They are great for their size though.&lt;br/&gt;\nMaybe this just answers us the question if llms should numerically evaluate texts&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07ei35/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751095553,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n07ecs8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Comfortable-Tap-9991",
                      "can_mod_post": false,
                      "created_utc": 1751095468,
                      "send_replies": true,
                      "parent_id": "t1_n0795fi",
                      "score": 6,
                      "author_fullname": "t2_1fcbojgfd8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "it's the cheapest macboook from 2020, chill",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n07ecs8",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it&amp;#39;s the cheapest macboook from 2020, chill&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lmfiu9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07ecs8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751095468,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "2ff18162-05ce-11ee-aa52-6a828e39b56c",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n07q7it",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "RelicDerelict",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n07anga",
                                "score": 1,
                                "author_fullname": "t2_c9l5cm1",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thanks so much. I love tests and perspectives from the hardware poorer side of enthusiasts like us.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n07q7it",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "Orca"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks so much. I love tests and perspectives from the hardware poorer side of enthusiasts like us.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lmfiu9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07q7it/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751102495,
                                "author_flair_text": "Orca",
                                "treatment_tags": [],
                                "created_utc": 1751102495,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n07anga",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "irodov4030",
                      "can_mod_post": false,
                      "created_utc": 1751093418,
                      "send_replies": true,
                      "parent_id": "t1_n0795fi",
                      "score": 4,
                      "author_fullname": "t2_l5xlcgf2j",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "results are decent if you just want to chat. Avg. reading speed would be around 5-10 tokens per sec.\n\nSO it is ok for personal use and average tasks",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n07anga",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;results are decent if you just want to chat. Avg. reading speed would be around 5-10 tokens per sec.&lt;/p&gt;\n\n&lt;p&gt;SO it is ok for personal use and average tasks&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lmfiu9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07anga/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751093418,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n07u6fm",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "techno156",
                      "can_mod_post": false,
                      "created_utc": 1751104857,
                      "send_replies": true,
                      "parent_id": "t1_n0795fi",
                      "score": 1,
                      "author_fullname": "t2_b3s88",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; 8GB ram not even Vram, the specs are too low.\n\nM-Series Macs complicate that a bit, since RAM and VRAM are shared, up to 1/3rd of the total RAM capacity or thereabouts. So OP would still have 2 - 3 GB of VRAM to work with.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n07u6fm",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;8GB ram not even Vram, the specs are too low.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;M-Series Macs complicate that a bit, since RAM and VRAM are shared, up to 1/3rd of the total RAM capacity or thereabouts. So OP would still have 2 - 3 GB of VRAM to work with.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lmfiu9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n07u6fm/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751104857,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n0795fi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "coding_workflow",
            "can_mod_post": false,
            "created_utc": 1751092607,
            "send_replies": true,
            "parent_id": "t3_1lmfiu9",
            "score": -5,
            "author_fullname": "t2_1k93ff6lqk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "8GB ram not even Vram, the specs are too low. Even some phones now challenge that.\n\nIt will be quite limited for coding. Thus you were too limited to 1B &amp; 4B max. \n\nWith this config, best use API, free tiers like Grok, you will get better answers.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n0795fi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;8GB ram not even Vram, the specs are too low. Even some phones now challenge that.&lt;/p&gt;\n\n&lt;p&gt;It will be quite limited for coding. Thus you were too limited to 1B &amp;amp; 4B max. &lt;/p&gt;\n\n&lt;p&gt;With this config, best use API, free tiers like Grok, you will get better answers.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lmfiu9/i_tested_10_llms_locally_on_my_macbook_air_m1_8gb/n0795fi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751092607,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lmfiu9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -5
          }
        }
      ],
      "before": null
    }
  }
]