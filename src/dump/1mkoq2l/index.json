[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "While gpt-5 showed impressive benchmarks, we’ve already heard a few disappointing voices from technical experts and coders. I think OpenAI expected this and isn’t actively trying to compete with models like Opus. Based on speed and pricing, gpt-5 is likely a much smaller model like Sonnet.\n\nThey learned their lessons with gpt-4.5 which was rumored to be a huge model. Except for some writing and random things, it basically sucked. They probably favored size and training time over more recent optimization techniques. So while scaling laws still somewhat apply, the most recent batch of models all made a huge jump in efficiency putting the largest and second largest model very close together.\n\nOpenAI clearly wants gpt-5 to be the LLM for the masses. Everybody should use it and it’s supposed to scale for the next billion users. They needed to make it moderately sized and clean up their existing mess of models to simplify their line up.\n\nThey also focused on a lot of topics outside the benchmark domain, which at least to me didn’t sound entirely made up. They really put work into problems, that other labs have put less emphasis on: Less hallucinations, good writing skills at smaller model sizes, intent understanding, dynamic safety boundaries. These skills will likely not lead to higher scores on your favorite benchmark, but their essential skills for LLMs becoming the working norm.\n\nYou prefer Opus 4.1 on your recent coding tasks? Me too. And OpenAI is probably fully ok with it. They left the game for the highest ranking LLM to the one people are happy with. I’d go so far to say that Anthropic probably regrets putting out Opus 4. When they just had Sonnet 3.7, everybody was cool with that. Now, you see rate limit errors on Anthropic, Bedrock and Vertex, which leads me to believe that 4.1 is probably a later checkpoint that was quantized and pruned to lower compute.\n\nOpenAIs lets me to believe this might not be a winner takes all market. We might see progress that democratizes the LLM, which would be great news for everyone especially in the OSS model domain.\n\n(I’m posting this here because the percentage of knowledgable people seems way higher than elsewhere. Sorry to those not interested.)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "GPT-5 is an LLM for the masses",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mkoq2l",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.24,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_16en7b",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1754638135,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754637814,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While gpt-5 showed impressive benchmarks, we’ve already heard a few disappointing voices from technical experts and coders. I think OpenAI expected this and isn’t actively trying to compete with models like Opus. Based on speed and pricing, gpt-5 is likely a much smaller model like Sonnet.&lt;/p&gt;\n\n&lt;p&gt;They learned their lessons with gpt-4.5 which was rumored to be a huge model. Except for some writing and random things, it basically sucked. They probably favored size and training time over more recent optimization techniques. So while scaling laws still somewhat apply, the most recent batch of models all made a huge jump in efficiency putting the largest and second largest model very close together.&lt;/p&gt;\n\n&lt;p&gt;OpenAI clearly wants gpt-5 to be the LLM for the masses. Everybody should use it and it’s supposed to scale for the next billion users. They needed to make it moderately sized and clean up their existing mess of models to simplify their line up.&lt;/p&gt;\n\n&lt;p&gt;They also focused on a lot of topics outside the benchmark domain, which at least to me didn’t sound entirely made up. They really put work into problems, that other labs have put less emphasis on: Less hallucinations, good writing skills at smaller model sizes, intent understanding, dynamic safety boundaries. These skills will likely not lead to higher scores on your favorite benchmark, but their essential skills for LLMs becoming the working norm.&lt;/p&gt;\n\n&lt;p&gt;You prefer Opus 4.1 on your recent coding tasks? Me too. And OpenAI is probably fully ok with it. They left the game for the highest ranking LLM to the one people are happy with. I’d go so far to say that Anthropic probably regrets putting out Opus 4. When they just had Sonnet 3.7, everybody was cool with that. Now, you see rate limit errors on Anthropic, Bedrock and Vertex, which leads me to believe that 4.1 is probably a later checkpoint that was quantized and pruned to lower compute.&lt;/p&gt;\n\n&lt;p&gt;OpenAIs lets me to believe this might not be a winner takes all market. We might see progress that democratizes the LLM, which would be great news for everyone especially in the OSS model domain.&lt;/p&gt;\n\n&lt;p&gt;(I’m posting this here because the percentage of knowledgable people seems way higher than elsewhere. Sorry to those not interested.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mkoq2l",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "gopietz",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/",
            "subreddit_subscribers": 513815,
            "created_utc": 1754637814,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7k8xkh",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Accomplished-Copy332",
            "can_mod_post": false,
            "created_utc": 1754638270,
            "send_replies": true,
            "parent_id": "t3_1mkoq2l",
            "score": 6,
            "author_fullname": "t2_98ouo03z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think I’ll use Qwen3 Coder instead",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7k8xkh",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think I’ll use Qwen3 Coder instead&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7k8xkh/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754638270,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkoq2l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7kch20",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Brilla-Bose",
            "can_mod_post": false,
            "created_utc": 1754640304,
            "send_replies": true,
            "parent_id": "t3_1mkoq2l",
            "score": 6,
            "author_fullname": "t2_e9bo284j",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "more like 3 years of hype met with reality!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kch20",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;more like 3 years of hype met with reality!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7kch20/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754640304,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkoq2l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7k9lgx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "notdba",
            "can_mod_post": false,
            "created_utc": 1754638648,
            "send_replies": true,
            "parent_id": "t3_1mkoq2l",
            "score": 3,
            "author_fullname": "t2_4aai0pnm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "\\&gt; I’d go so far to say that Anthropic probably regrets putting out Opus 4.\n\nInteresting point. O3 and O3 Pro probably have similar effect, and OpenAI is steering the masses away from them. From my limited testing, GPT-5 at high reasoning effort can't match O3 Pro at medium.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7k9lgx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;gt; I’d go so far to say that Anthropic probably regrets putting out Opus 4.&lt;/p&gt;\n\n&lt;p&gt;Interesting point. O3 and O3 Pro probably have similar effect, and OpenAI is steering the masses away from them. From my limited testing, GPT-5 at high reasoning effort can&amp;#39;t match O3 Pro at medium.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7k9lgx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754638648,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkoq2l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7kbg31",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "Murdy-ADHD",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n7kaqx2",
                                                    "score": 0,
                                                    "author_fullname": "t2_3ovprt5b",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Did you actually try to code new features or debug? Like something where the strengths of the model shine? Or just some goofy tests?\n\nIn Cursor it works really well.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7kbg31",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Did you actually try to code new features or debug? Like something where the strengths of the model shine? Or just some goofy tests?&lt;/p&gt;\n\n&lt;p&gt;In Cursor it works really well.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mkoq2l",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7kbg31/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754639709,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754639709,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 0
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7kaqx2",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "gopietz",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7ka2yx",
                                          "score": 0,
                                          "author_fullname": "t2_16en7b",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Yes, I did. I used it in Cline and compared it to my experience with Claude Code and Qwen Coder. I have an unscientific loop of 5 problems I like to run. So it is a rather small sample size.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7kaqx2",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, I did. I used it in Cline and compared it to my experience with Claude Code and Qwen Coder. I have an unscientific loop of 5 problems I like to run. So it is a rather small sample size.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mkoq2l",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7kaqx2/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754639308,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754639308,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 1,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 0
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7ka2yx",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Murdy-ADHD",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7k95xk",
                                "score": 1,
                                "author_fullname": "t2_3ovprt5b",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Where are these coders and technical experts? Anywhere not called Reddit I see positive reactions to how good it is in coding. Did you try it?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7ka2yx",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Where are these coders and technical experts? Anywhere not called Reddit I see positive reactions to how good it is in coding. Did you try it?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mkoq2l",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7ka2yx/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754638930,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754638930,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7k95xk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "gopietz",
                      "can_mod_post": false,
                      "created_utc": 1754638402,
                      "send_replies": true,
                      "parent_id": "t1_n7k8qxr",
                      "score": -4,
                      "author_fullname": "t2_16en7b",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I see your point. I decided to post it here because the other places feature a way higher rate of people that don’t know what they’re talking about. I mean look at the most recent posts to where you’re linking. I want to have an actual discussion on this. I do think that this release is actually a big boost for the future of OSS LLMs.",
                      "edited": 1754638863,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7k95xk",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I see your point. I decided to post it here because the other places feature a way higher rate of people that don’t know what they’re talking about. I mean look at the most recent posts to where you’re linking. I want to have an actual discussion on this. I do think that this release is actually a big boost for the future of OSS LLMs.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mkoq2l",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7k95xk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754638402,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7k8qxr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "MelodicRecognition7",
            "can_mod_post": false,
            "created_utc": 1754638165,
            "send_replies": true,
            "parent_id": "t3_1mkoq2l",
            "score": 10,
            "author_fullname": "t2_1eex9ug5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "https://www.reddit.com/r/chatgpt/",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7k8qxr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/chatgpt/\"&gt;https://www.reddit.com/r/chatgpt/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7k8qxr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754638165,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkoq2l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7kr1yo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Awwtifishal",
            "can_mod_post": false,
            "created_utc": 1754648518,
            "send_replies": true,
            "parent_id": "t3_1mkoq2l",
            "score": 2,
            "author_fullname": "t2_1d96a8k10t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is r/LocalLLaMA, the least you could do is to compare it against open weights models",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kr1yo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is &lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt;, the least you could do is to compare it against open weights models&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7kr1yo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754648518,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkoq2l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7kg9ym",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "shokuninstudio",
            "can_mod_post": false,
            "created_utc": 1754642514,
            "send_replies": true,
            "parent_id": "t3_1mkoq2l",
            "score": 1,
            "author_fullname": "t2_4xzh04rz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm finding GPT-5 to be very good at resolving bugs or amending functions. I've now spent several hours fixing longstanding bugs that I was holding off because Claude couldn't fix them. I'm also happy that the model isn't acting ecstatic and over confident. It's behaviour is more like a doctor.\n\nHowever, it also takes a lot longer to do so due to 'thinking' too much. But maybe that's how it should approach problems. Previous versions coded fast but were frustrating and often sloppy.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kg9ym",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m finding GPT-5 to be very good at resolving bugs or amending functions. I&amp;#39;ve now spent several hours fixing longstanding bugs that I was holding off because Claude couldn&amp;#39;t fix them. I&amp;#39;m also happy that the model isn&amp;#39;t acting ecstatic and over confident. It&amp;#39;s behaviour is more like a doctor.&lt;/p&gt;\n\n&lt;p&gt;However, it also takes a lot longer to do so due to &amp;#39;thinking&amp;#39; too much. But maybe that&amp;#39;s how it should approach problems. Previous versions coded fast but were frustrating and often sloppy.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7kg9ym/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754642514,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkoq2l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7k8rh3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Acceptable_Air5773",
            "can_mod_post": false,
            "created_utc": 1754638173,
            "send_replies": true,
            "parent_id": "t3_1mkoq2l",
            "score": 0,
            "author_fullname": "t2_chevn65p",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Copium",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7k8rh3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Copium&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7k8rh3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754638173,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkoq2l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7kppfn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "custodiam99",
            "can_mod_post": false,
            "created_utc": 1754647808,
            "send_replies": true,
            "parent_id": "t3_1mkoq2l",
            "score": -1,
            "author_fullname": "t2_nqnhgqqf5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What if LLMs are a dead end and they know it? So why try harder, if the next architecture will be the real revolution?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7kppfn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What if LLMs are a dead end and they know it? So why try harder, if the next architecture will be the real revolution?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7kppfn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754647808,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkoq2l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7l0543",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Efficiency_1144",
            "can_mod_post": false,
            "created_utc": 1754652789,
            "send_replies": true,
            "parent_id": "t3_1mkoq2l",
            "score": 1,
            "author_fullname": "t2_1nkj9l14b0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Claude models are much weaker at mathematics than GPT o3, GPT 5, Grok 4, Gemini or Deepseek.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7l0543",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Claude models are much weaker at mathematics than GPT o3, GPT 5, Grok 4, Gemini or Deepseek.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkoq2l/gpt5_is_an_llm_for_the_masses/n7l0543/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754652789,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkoq2l",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]