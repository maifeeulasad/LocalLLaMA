[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "We’re a small team building **FastFlowLM** — a fast, runtime for running **LLaMA, Qwen, DeepSeek**, and other models **entirely on the AMD Ryzen AI NPU**. No CPU or iGPU fallback — just lean, efficient, **NPU-native inference**. Think **Ollama**, but purpose-built and deeply optimized for AMD NPUs — with both **CLI** and **server mode (REST API)**.\n\n# Key Features\n\n* Supports **LLaMA, Qwen, DeepSeek**, and more\n* **Deeply hardware-optimized**, NPU-only inference\n* **Full context** support (e.g., 128K for LLaMA)\n* Over **11× power efficiency** compared to iGPU/CPU\n\nWe’re iterating quickly and would **love your feedback, critiques, and ideas**.\n\n# Try It Out\n\n* **GitHub:** [github.com/FastFlowLM/FastFlowLM](https://github.com/FastFlowLM/FastFlowLM)\n* **Live Demo (on remote machine):** Don’t have a Ryzen AI PC? Instantly try FastFlowLM on a **remote AMD Ryzen AI 5 340 NPU system with 32 GB RAM** — no installation needed. [Launch Demo](https://open-webui.testdrive-fastflowlm.com/) **Login:** `guest@flm.npu` **Password:** `0000`\n* **YouTube Demos:** [youtube.com/@FastFlowLM-YT](https://www.youtube.com/@FastFlowLM-YT) *→ Quick start guide, performance benchmarks, and comparisons vs Ollama / LM Studio / Lemonade*\n* **Discord Community:** [discord.gg/Sze3Qsv5](https://discord.gg/Sze3Qsv5) *→ Join us to ask questions, report issues, or contribute ideas*\n\nLet us know what works, what breaks, and what you’d love to see next!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Running LLMs exclusively on AMD Ryzen AI NPU",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mao95d",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.9,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 164,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_jrsbr6os",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 164,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1753630907,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753627953,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We’re a small team building &lt;strong&gt;FastFlowLM&lt;/strong&gt; — a fast, runtime for running &lt;strong&gt;LLaMA, Qwen, DeepSeek&lt;/strong&gt;, and other models &lt;strong&gt;entirely on the AMD Ryzen AI NPU&lt;/strong&gt;. No CPU or iGPU fallback — just lean, efficient, &lt;strong&gt;NPU-native inference&lt;/strong&gt;. Think &lt;strong&gt;Ollama&lt;/strong&gt;, but purpose-built and deeply optimized for AMD NPUs — with both &lt;strong&gt;CLI&lt;/strong&gt; and &lt;strong&gt;server mode (REST API)&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;h1&gt;Key Features&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Supports &lt;strong&gt;LLaMA, Qwen, DeepSeek&lt;/strong&gt;, and more&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Deeply hardware-optimized&lt;/strong&gt;, NPU-only inference&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Full context&lt;/strong&gt; support (e.g., 128K for LLaMA)&lt;/li&gt;\n&lt;li&gt;Over &lt;strong&gt;11× power efficiency&lt;/strong&gt; compared to iGPU/CPU&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We’re iterating quickly and would &lt;strong&gt;love your feedback, critiques, and ideas&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;h1&gt;Try It Out&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;GitHub:&lt;/strong&gt; &lt;a href=\"https://github.com/FastFlowLM/FastFlowLM\"&gt;github.com/FastFlowLM/FastFlowLM&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Live Demo (on remote machine):&lt;/strong&gt; Don’t have a Ryzen AI PC? Instantly try FastFlowLM on a &lt;strong&gt;remote AMD Ryzen AI 5 340 NPU system with 32 GB RAM&lt;/strong&gt; — no installation needed. &lt;a href=\"https://open-webui.testdrive-fastflowlm.com/\"&gt;Launch Demo&lt;/a&gt; &lt;strong&gt;Login:&lt;/strong&gt; &lt;code&gt;guest@flm.npu&lt;/code&gt; &lt;strong&gt;Password:&lt;/strong&gt; &lt;code&gt;0000&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;YouTube Demos:&lt;/strong&gt; &lt;a href=\"https://www.youtube.com/@FastFlowLM-YT\"&gt;youtube.com/@FastFlowLM-YT&lt;/a&gt; &lt;em&gt;→ Quick start guide, performance benchmarks, and comparisons vs Ollama / LM Studio / Lemonade&lt;/em&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Discord Community:&lt;/strong&gt; &lt;a href=\"https://discord.gg/Sze3Qsv5\"&gt;discord.gg/Sze3Qsv5&lt;/a&gt; &lt;em&gt;→ Join us to ask questions, report issues, or contribute ideas&lt;/em&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Let us know what works, what breaks, and what you’d love to see next!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/vJGRc2UlTJrSFHnGlJYDN0YsOLC8w4mlAwQVmF6tcgo.png?auto=webp&amp;s=4a11abd914fb5ab749f3f093b10ce2b529fb8c8e",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/vJGRc2UlTJrSFHnGlJYDN0YsOLC8w4mlAwQVmF6tcgo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=97afc3fc381198ec693e0055e6c72c2c0c3cad84",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/vJGRc2UlTJrSFHnGlJYDN0YsOLC8w4mlAwQVmF6tcgo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=223eb6c47aa4922185402abdd994f0d4167b8587",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/vJGRc2UlTJrSFHnGlJYDN0YsOLC8w4mlAwQVmF6tcgo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c855da9485d7673105d65ccede1e3da883ab9dcb",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/vJGRc2UlTJrSFHnGlJYDN0YsOLC8w4mlAwQVmF6tcgo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d5391c68c3aa09eb5da1c87bd1883d8712981e33",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/vJGRc2UlTJrSFHnGlJYDN0YsOLC8w4mlAwQVmF6tcgo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=76ac02010d805630644eabca91f54e1df087cc14",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/vJGRc2UlTJrSFHnGlJYDN0YsOLC8w4mlAwQVmF6tcgo.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=68dfc8aed1bea82afaeda0f80b40e2d9c22407bb",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "vJGRc2UlTJrSFHnGlJYDN0YsOLC8w4mlAwQVmF6tcgo"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1mao95d",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "BandEnvironmental834",
            "discussion_type": null,
            "num_comments": 99,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/",
            "subreddit_subscribers": 505881,
            "created_utc": 1753627953,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ixdwr",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "stylist-trend",
                      "can_mod_post": false,
                      "created_utc": 1753661845,
                      "send_replies": true,
                      "parent_id": "t1_n5glvxk",
                      "score": 13,
                      "author_fullname": "t2_cly8jcyo",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I won't lie, for a second I thought you were either going to offer them a drink, or were going to make some sort of \"when life gives you lemons\" joke.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ixdwr",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I won&amp;#39;t lie, for a second I thought you were either going to offer them a drink, or were going to make some sort of &amp;quot;when life gives you lemons&amp;quot; joke.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5ixdwr/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753661845,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 13
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gtsl0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753637781,
                      "send_replies": true,
                      "parent_id": "t1_n5glvxk",
                      "score": 10,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Sure thing, please give it a try. Let us know what you think. I will DM you.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gtsl0",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sure thing, please give it a try. Let us know what you think. I will DM you.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gtsl0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753637781,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 10
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5kkiy0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Randommaggy",
                      "can_mod_post": false,
                      "created_utc": 1753688251,
                      "send_replies": true,
                      "parent_id": "t1_n5glvxk",
                      "score": 6,
                      "author_fullname": "t2_t8a2k",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "If this works as advertised AMD really should consider an acquisition or a sponsorship to open up the license terms for the kernel also fully auditing the code and endorse it.  \n  \nIt would make the naming of the Ryzen AI series of chips less of a credibility problem for AMD.  \nThe amount of NPU benefit that AMD Gaia was able to leverage on my HX 370 has been pitiful for a product named like it is, this long after launch.\n\nI'm not testing it on my HX 370 machine before AMD has at least verified that it's safe.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5kkiy0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If this works as advertised AMD really should consider an acquisition or a sponsorship to open up the license terms for the kernel also fully auditing the code and endorse it.  &lt;/p&gt;\n\n&lt;p&gt;It would make the naming of the Ryzen AI series of chips less of a credibility problem for AMD.&lt;br/&gt;\nThe amount of NPU benefit that AMD Gaia was able to leverage on my HX 370 has been pitiful for a product named like it is, this long after launch.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not testing it on my HX 370 machine before AMD has at least verified that it&amp;#39;s safe.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5kkiy0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753688251,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5k05c4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "cafedude",
                      "can_mod_post": false,
                      "created_utc": 1753677337,
                      "send_replies": true,
                      "parent_id": "t1_n5glvxk",
                      "score": 1,
                      "author_fullname": "t2_23o6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Will Lemonade work on Linux?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5k05c4",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Will Lemonade work on Linux?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5k05c4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753677337,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5glvxk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "jfowers_amd",
            "can_mod_post": false,
            "created_utc": 1753635491,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 32,
            "author_fullname": "t2_1m2ckixcqh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hi, I make Lemonade. Let me know if you’d like to chat.\n\nLemonade is essentially an orchestration layer for any kernels that make sense for AMD PCs. We’re already doing Ryzen AI SW, Vulkan, and ROCm. Could discuss adding yours to the mix.",
            "edited": 1753635921,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5glvxk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I make Lemonade. Let me know if you’d like to chat.&lt;/p&gt;\n\n&lt;p&gt;Lemonade is essentially an orchestration layer for any kernels that make sense for AMD PCs. We’re already doing Ryzen AI SW, Vulkan, and ROCm. Could discuss adding yours to the mix.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5glvxk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753635491,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 32
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5huokx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753648878,
                      "send_replies": true,
                      "parent_id": "t1_n5hteo9",
                      "score": 8,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you for asking! Probably not in the near future, as most Ryzen AI users are currently on Windows. That said, we'd love to support it once we have sufficient resources.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5huokx",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for asking! Probably not in the near future, as most Ryzen AI users are currently on Windows. That said, we&amp;#39;d love to support it once we have sufficient resources.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5huokx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753648878,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 8
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5hteo9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Wooden_Yam1924",
            "can_mod_post": false,
            "created_utc": 1753648494,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 13,
            "author_fullname": "t2_4fyr3i20",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "are you planning linux support anytime soon?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hteo9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;are you planning linux support anytime soon?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hteo9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753648494,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 13
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5gky19",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "BandEnvironmental834",
            "can_mod_post": false,
            "created_utc": 1753635216,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 9,
            "author_fullname": "t2_jrsbr6os",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Thanks for giving it a try!\n\nThe demo machine’s a bit overloaded right now — FastFlowLM is meant for single-user local use, so you may get denied when more than 1 user hop on at once. Sorry if you hit any downtime.\n\nalternatively, feel free to check out some of our demo videos here:  \n[https://www.youtube.com/watch?v=JNIvHpMGuaU&amp;list=PLf87s9UUZrJp4r3JM4NliPEsYuJNNqFAJ&amp;index=3](https://www.youtube.com/watch?v=JNIvHpMGuaU&amp;list=PLf87s9UUZrJp4r3JM4NliPEsYuJNNqFAJ&amp;index=3)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gky19",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for giving it a try!&lt;/p&gt;\n\n&lt;p&gt;The demo machine’s a bit overloaded right now — FastFlowLM is meant for single-user local use, so you may get denied when more than 1 user hop on at once. Sorry if you hit any downtime.&lt;/p&gt;\n\n&lt;p&gt;alternatively, feel free to check out some of our demo videos here:&lt;br/&gt;\n&lt;a href=\"https://www.youtube.com/watch?v=JNIvHpMGuaU&amp;amp;list=PLf87s9UUZrJp4r3JM4NliPEsYuJNNqFAJ&amp;amp;index=3\"&gt;https://www.youtube.com/watch?v=JNIvHpMGuaU&amp;amp;list=PLf87s9UUZrJp4r3JM4NliPEsYuJNNqFAJ&amp;amp;index=3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gky19/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753635216,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5hv1e8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753648987,
                      "send_replies": true,
                      "parent_id": "t1_n5hu7qw",
                      "score": 5,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That’s great to hear—thanks for testing it out! Let us know if you run into anything or have ideas for improvement.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5hv1e8",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That’s great to hear—thanks for testing it out! Let us know if you run into anything or have ideas for improvement.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hv1e8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753648987,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5hu7qw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ThatBadPunGuy",
            "can_mod_post": false,
            "created_utc": 1753648737,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 6,
            "author_fullname": "t2_cgnu3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Just wanted to say thank you just tested this out on my ryzen ai 365 laptop and it works perfectly :)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hu7qw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted to say thank you just tested this out on my ryzen ai 365 laptop and it works perfectly :)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hu7qw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753648737,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5l4ntw",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "BandEnvironmental834",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5koxy8",
                                                              "score": 1,
                                                              "author_fullname": "t2_jrsbr6os",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Great question! To clarify—yes, DRAM bandwidth is a major bottleneck during decoding/generation, since all model weights reside in DRAM. During generation, the NPU must continuously fetch these weights from DRAM into the chip. It doesn’t need the entire model at once, but consumes the weights incrementally.\n\nIt’s a bit like drinking water from a bottle—you might be able to drink faster than the water can flow out. So even if the NPU is compute-efficient, it's limited by how quickly data can be delivered. Hope that makes sense!",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5l4ntw",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great question! To clarify—yes, DRAM bandwidth is a major bottleneck during decoding/generation, since all model weights reside in DRAM. During generation, the NPU must continuously fetch these weights from DRAM into the chip. It doesn’t need the entire model at once, but consumes the weights incrementally.&lt;/p&gt;\n\n&lt;p&gt;It’s a bit like drinking water from a bottle—you might be able to drink faster than the water can flow out. So even if the NPU is compute-efficient, it&amp;#39;s limited by how quickly data can be delivered. Hope that makes sense!&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mao95d",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l4ntw/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753699692,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753699692,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5koxy8",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "PurpleWinterDawn",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5ilnwu",
                                                    "score": 1,
                                                    "author_fullname": "t2_dncq6xad",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "In your experience, does RAM bandwidth impose a bottleneck on an NPU, or is there a model size an NPU can comfortably be fed with for it to be the bottleneck, and leave RAM bandwidth for other programs?",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5koxy8",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In your experience, does RAM bandwidth impose a bottleneck on an NPU, or is there a model size an NPU can comfortably be fed with for it to be the bottleneck, and leave RAM bandwidth for other programs?&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mao95d",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5koxy8/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753690835,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753690835,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5ilnwu",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5ijnko",
                                          "score": 11,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "No, that is not the plan. We believe local LLM on NPUs has a potential. Privacy, low power, and competitive speed ... while it does not use GPU or CPU resources, thus, it can run uninterruptedly.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5ilnwu",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, that is not the plan. We believe local LLM on NPUs has a potential. Privacy, low power, and competitive speed ... while it does not use GPU or CPU resources, thus, it can run uninterruptedly.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5ilnwu/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753657685,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753657685,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 11
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ijnko",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "PlasticInitial8674",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5ifx7b",
                                "score": 3,
                                "author_fullname": "t2_1gk5cm6md6",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Do you eventually want to provide serverless service in cloud?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ijnko",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you eventually want to provide serverless service in cloud?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5ijnko/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753656990,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753656990,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ifx7b",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753655684,
                      "send_replies": true,
                      "parent_id": "t1_n5ibash",
                      "score": 11,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for asking!\n\nOur goal is to make AI more accessible and efficient on NPUs, so developers can build ultra-low-power, always-on AI assistant–style apps that run locally without draining resources from GPU or CPU. So we think it could be good for future immersive gaming, local AI file management, among other things ...\n\nWe chose AMD NPU not just for power efficiency, but also because of the excellent low-level tooling—like Rialto, AIE-MLIR, IRON, and MLIR-AIR—which gives us the flexibility and control we need for deep hardware optimization. Plus, AMD NPUs are genuinely efficient! (We are not from AMD BTW.)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ifx7b",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for asking!&lt;/p&gt;\n\n&lt;p&gt;Our goal is to make AI more accessible and efficient on NPUs, so developers can build ultra-low-power, always-on AI assistant–style apps that run locally without draining resources from GPU or CPU. So we think it could be good for future immersive gaming, local AI file management, among other things ...&lt;/p&gt;\n\n&lt;p&gt;We chose AMD NPU not just for power efficiency, but also because of the excellent low-level tooling—like Rialto, AIE-MLIR, IRON, and MLIR-AIR—which gives us the flexibility and control we need for deep hardware optimization. Plus, AMD NPUs are genuinely efficient! (We are not from AMD BTW.)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5ifx7b/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753655684,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 11
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5ibash",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "PlasticInitial8674",
            "can_mod_post": false,
            "created_utc": 1753654119,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 7,
            "author_fullname": "t2_1gk5cm6md6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you dont mind but may I ask, what  the goal of this project is. And why do you choose AMD NPU (for power efficiency only)?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ibash",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you dont mind but may I ask, what  the goal of this project is. And why do you choose AMD NPU (for power efficiency only)?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5ibash/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753654119,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5jell2",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "BandEnvironmental834",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5jd37c",
                                                              "score": 6,
                                                              "author_fullname": "t2_jrsbr6os",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "That's true. In fact, the trend, like Gemma 3, is moving toward hybrid architectures: a few sliding window attention (SWA) layers with 4K tokens, plus one global attention layer --&gt; much smaller KV cache. IMO, that could be a game changer.\n\nOther approaches (researchy at this point), like Mamba, linear attention and RWKV models, also hold great promise if they can demonstrate comparable llm accuracy.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5jell2",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s true. In fact, the trend, like Gemma 3, is moving toward hybrid architectures: a few sliding window attention (SWA) layers with 4K tokens, plus one global attention layer --&amp;gt; much smaller KV cache. IMO, that could be a game changer.&lt;/p&gt;\n\n&lt;p&gt;Other approaches (researchy at this point), like Mamba, linear attention and RWKV models, also hold great promise if they can demonstrate comparable llm accuracy.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mao95d",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5jell2/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753668295,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753668295,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 6
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5jd37c",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "AcidBurn2910",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5jc9zg",
                                                    "score": 3,
                                                    "author_fullname": "t2_5w2uprkz",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "IMO Context length is the key limitation  to on device AI becoming more compelling. 64k is high enough to build cool use cases. But 128k context with STX halo could be a game changer. \n\nQwen 32 coder has been a really good model and I am looking forward to some of the MoEs that are due to be released.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5jd37c",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;IMO Context length is the key limitation  to on device AI becoming more compelling. 64k is high enough to build cool use cases. But 128k context with STX halo could be a game changer. &lt;/p&gt;\n\n&lt;p&gt;Qwen 32 coder has been a really good model and I am looking forward to some of the MoEs that are due to be released.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mao95d",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5jd37c/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753667730,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753667730,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5jc9zg",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5ja5xw",
                                          "score": 6,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Great question! We focus on smaller LLMs (&lt;8B) and use BF16 for the KV cache. GQA also helps reduce memory usage. 32GB is sufficient in this case.\n\nWhen running in CLI mode, you can use the `/set` command to limit the maximum context length to 64k or smaller to limit the memory usage for 16GB or even 8GB DRAM:  \n[https://docs.fastflowlm.com/instructions/cli.html](https://docs.fastflowlm.com/instructions/cli.html)",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5jc9zg",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great question! We focus on smaller LLMs (&amp;lt;8B) and use BF16 for the KV cache. GQA also helps reduce memory usage. 32GB is sufficient in this case.&lt;/p&gt;\n\n&lt;p&gt;When running in CLI mode, you can use the &lt;code&gt;/set&lt;/code&gt; command to limit the maximum context length to 64k or smaller to limit the memory usage for 16GB or even 8GB DRAM:&lt;br/&gt;\n&lt;a href=\"https://docs.fastflowlm.com/instructions/cli.html\"&gt;https://docs.fastflowlm.com/instructions/cli.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5jc9zg/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753667429,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753667429,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 6
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ja5xw",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "AcidBurn2910",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5iu6u2",
                                "score": 4,
                                "author_fullname": "t2_5w2uprkz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I understand part of the stack is private. Curious how you got around the DRAM explosion with increase in context length.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ja5xw",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I understand part of the stack is private. Curious how you got around the DRAM explosion with increase in context length.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5ja5xw/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753666652,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753666652,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5iu6u2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753660670,
                      "send_replies": true,
                      "parent_id": "t1_n5isms8",
                      "score": 9,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for the kind words! Gemma 3 is in the works, and VLM/MLLM support is on our roadmap. We're not yet aware of any small, capable MoE models—but if promising ones emerge, we’ll definitely consider adding support. Since we do model-specific optimization at low level, we might be a bit slower than Ollama/LM studio. We use the GGUF format (same as llama.cpp), but for optimal performance on AMD Ryzen NPUs, we convert it into a custom format called Q4NX (Q4 NPU eXpress).",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5iu6u2",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for the kind words! Gemma 3 is in the works, and VLM/MLLM support is on our roadmap. We&amp;#39;re not yet aware of any small, capable MoE models—but if promising ones emerge, we’ll definitely consider adding support. Since we do model-specific optimization at low level, we might be a bit slower than Ollama/LM studio. We use the GGUF format (same as llama.cpp), but for optimal performance on AMD Ryzen NPUs, we convert it into a custom format called Q4NX (Q4 NPU eXpress).&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5iu6u2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753660670,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 9
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5isms8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "AcidBurn2910",
            "can_mod_post": false,
            "created_utc": 1753660113,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 6,
            "author_fullname": "t2_5w2uprkz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Looks super promising!! What other model architectures do you have on the roadmap? What about VLMs and MoEs? Do you use llamacpp or onnx for model representation?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5isms8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Looks super promising!! What other model architectures do you have on the roadmap? What about VLMs and MoEs? Do you use llamacpp or onnx for model representation?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5isms8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753660113,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5gyamm",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "BandEnvironmental834",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5ghkee",
                                "score": 5,
                                "author_fullname": "t2_jrsbr6os",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Llama3.1:8B was opened as well.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5gyamm",
                                "is_submitter": true,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Llama3.1:8B was opened as well.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gyamm/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753639070,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753639070,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ghkee",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753634236,
                      "send_replies": true,
                      "parent_id": "t1_n5gfweb",
                      "score": 6,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "oops ... thanks, just opened Qwen3:8B",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ghkee",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;oops ... thanks, just opened Qwen3:8B&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5ghkee/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753634236,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5gfweb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ApprehensiveLet1405",
            "can_mod_post": false,
            "created_utc": 1753633756,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 5,
            "author_fullname": "t2_93b4crmh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I couldn't find tests for 8B models.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gfweb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I couldn&amp;#39;t find tests for 8B models.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gfweb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753633756,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5iejw3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753655216,
                      "send_replies": true,
                      "parent_id": "t1_n5i9vl4",
                      "score": 6,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Sorry to hear that! As mentioned earlier, we actually started with NPU1 and agree it's a great piece of hardware. That said, we found it quite challenging to run modern LLMs efficiently on it. NPU2, on the other hand, offers significantly better performance, and in many cases, it competes with GPU speeds at a fraction of the power. That's why we ultimately decided to focus our efforts there.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5iejw3",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sorry to hear that! As mentioned earlier, we actually started with NPU1 and agree it&amp;#39;s a great piece of hardware. That said, we found it quite challenging to run modern LLMs efficiently on it. NPU2, on the other hand, offers significantly better performance, and in many cases, it competes with GPU speeds at a fraction of the power. That&amp;#39;s why we ultimately decided to focus our efforts there.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5iejw3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753655216,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5i9vl4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Rili-Anne",
            "can_mod_post": false,
            "created_utc": 1753653653,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 6,
            "author_fullname": "t2_5fwecjp1",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Every day I get angrier and angrier that I bought a Framework 16. No mainboard refresh on the horizon means I'm almost definitely not going to be able to use this. Really wish it supported NPU1.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5i9vl4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Every day I get angrier and angrier that I bought a Framework 16. No mainboard refresh on the horizon means I&amp;#39;m almost definitely not going to be able to use this. Really wish it supported NPU1.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5i9vl4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753653653,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5l99yn",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "dahara111",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5l5ot6",
                                "score": 1,
                                "author_fullname": "t2_6sew99etq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The structure of Orpheus remains the same as Llama 3.2, but the tokenizer has been improved, and it outputs audio tokens for SNAC.\n\nThe neural codec model SNAC reads the audio tokens and creates WAV files.\n\nIn other words, if Llama 3.2 works, it's enough to just support the custom tokenizer and SNAC.\n\nAnd since 70 audio tokens in Orpheus is equivalent to one second, with a margin of error, 90 will probably be enough for real-time conversation.\n\nReal-time conversations are impossible even with mid-range Nvidia GPUs, so this will be a long-term challenge.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5l99yn",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The structure of Orpheus remains the same as Llama 3.2, but the tokenizer has been improved, and it outputs audio tokens for SNAC.&lt;/p&gt;\n\n&lt;p&gt;The neural codec model SNAC reads the audio tokens and creates WAV files.&lt;/p&gt;\n\n&lt;p&gt;In other words, if Llama 3.2 works, it&amp;#39;s enough to just support the custom tokenizer and SNAC.&lt;/p&gt;\n\n&lt;p&gt;And since 70 audio tokens in Orpheus is equivalent to one second, with a margin of error, 90 will probably be enough for real-time conversation.&lt;/p&gt;\n\n&lt;p&gt;Real-time conversations are impossible even with mid-range Nvidia GPUs, so this will be a long-term challenge.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l99yn/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753701858,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753701858,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5l5ot6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753700183,
                      "send_replies": true,
                      "parent_id": "t1_n5k1t0z",
                      "score": 2,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for the suggestion! We're less familiar with TTS, but from what I understand, it mainly relies on prompt/prefill operations (basically, batched operation. Is that right?). If that's the case, our technology should be able to exceed 90 TPS.\n\nTTS isn’t currently on our roadmap, as we're a small team and focused on catching up with newer popular LLM models like Gemma 3 and more. That said, we’ll consider adding TTS in the future.",
                      "edited": 1753701944,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5l5ot6",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for the suggestion! We&amp;#39;re less familiar with TTS, but from what I understand, it mainly relies on prompt/prefill operations (basically, batched operation. Is that right?). If that&amp;#39;s the case, our technology should be able to exceed 90 TPS.&lt;/p&gt;\n\n&lt;p&gt;TTS isn’t currently on our roadmap, as we&amp;#39;re a small team and focused on catching up with newer popular LLM models like Gemma 3 and more. That said, we’ll consider adding TTS in the future.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l5ot6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753700183,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5k1t0z",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "dahara111",
            "can_mod_post": false,
            "created_utc": 1753678137,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 5,
            "author_fullname": "t2_6sew99etq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If this tool can achieve 90 tokens/second or more on LLama3.2 3B, real-time operation of orpheus-3b-based TTS like below will become a reality, which will create new demand.\n\n[https://huggingface.co/webbigdata/VoiceCore](https://huggingface.co/webbigdata/VoiceCore)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5k1t0z",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If this tool can achieve 90 tokens/second or more on LLama3.2 3B, real-time operation of orpheus-3b-based TTS like below will become a reality, which will create new demand.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/webbigdata/VoiceCore\"&gt;https://huggingface.co/webbigdata/VoiceCore&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5k1t0z/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753678137,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gwq4v",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753638620,
                      "send_replies": true,
                      "parent_id": "t1_n5gpq5d",
                      "score": 4,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Just checked ... unfortunately, Ryzen 8700G uses NPU 1. FastFlowLM only works on NPU 2 (basically AMD Ryzen AI 300 series chips, such as Strix, Strix Halo, and Kracken)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gwq4v",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just checked ... unfortunately, Ryzen 8700G uses NPU 1. FastFlowLM only works on NPU 2 (basically AMD Ryzen AI 300 series chips, such as Strix, Strix Halo, and Kracken)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gwq4v/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753638620,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5gpq5d",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "No_Conversation9561",
            "can_mod_post": false,
            "created_utc": 1753636606,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 5,
            "author_fullname": "t2_jqxb4pte",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "does it work on Ryzen 8700G?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gpq5d",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;does it work on Ryzen 8700G?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gpq5d/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753636606,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5hht4v",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "BandEnvironmental834",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5hh2ky",
                                                              "score": 3,
                                                              "author_fullname": "t2_jrsbr6os",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "So FastFlowLM ran on your Strix Halo? That’s great to hear! We often use HWiNFO to monitor power consumption across different parts of the chip — you might find it helpful too.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5hht4v",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So FastFlowLM ran on your Strix Halo? That’s great to hear! We often use HWiNFO to monitor power consumption across different parts of the chip — you might find it helpful too.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mao95d",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hht4v/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753644947,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753644947,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 3
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5hh2ky",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "paul_tu",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5hgj62",
                                                    "score": 4,
                                                    "author_fullname": "t2_whtsd",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "GMKTEC Evo x-2 128GB consumes 200w from the wall with full stress test load \n\nGPU offload gives like 125w or something\nI wasn't able to make clean GPU load without CPU \n\nNPU full load have like 25-40w range",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5hh2ky",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GMKTEC Evo x-2 128GB consumes 200w from the wall with full stress test load &lt;/p&gt;\n\n&lt;p&gt;GPU offload gives like 125w or something\nI wasn&amp;#39;t able to make clean GPU load without CPU &lt;/p&gt;\n\n&lt;p&gt;NPU full load have like 25-40w range&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mao95d",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hh2ky/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753644717,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753644717,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 4
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5hh5dd",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "paul_tu",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5hgj62",
                                                    "score": 2,
                                                    "author_fullname": "t2_whtsd",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Great!\n\nThanks a lot",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5hh5dd",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great!&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mao95d",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hh5dd/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753644742,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753644742,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5hgj62",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5hcwsw",
                                          "score": 8,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "On Ryzen systems, iGPUs perform well, but when running LLMs (e.g., via LM Studio), we’ve found they consume a lot of system resources — fans ramp up, chip temperatures spike, and it becomes hard to do anything else like gaming or watching videos.\n\nIn contrast, AMD NPUs are incredibly efficient. Here's a quick comparison video — same prompt, same model, similar speed, but a massive difference in power consumption:\n\n[https://www.youtube.com/watch?v=OZuLQcmFe9A&amp;ab\\_channel=FastFlowLM](https://www.youtube.com/watch?v=OZuLQcmFe9A&amp;ab_channel=FastFlowLM)\n\nOur vision is that NPUs will power always-on, background AI without disrupting the user experience. We're not from AMD, but we’re genuinely excited about the potential of their NPU architecture — that’s what inspired us to build FastFlowLM.\n\nFollow this instruction, you can use FastFlowLM as backend, and open WebUI as front end.\n\n[https://docs.fastflowlm.com/instructions/server/webui.html](https://docs.fastflowlm.com/instructions/server/webui.html)  \nLet us know what you think!\n\nWe are not familiar with Jetson Oring though. Hope sometime can do an apple-to-apple comparison on it.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5hgj62",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;On Ryzen systems, iGPUs perform well, but when running LLMs (e.g., via LM Studio), we’ve found they consume a lot of system resources — fans ramp up, chip temperatures spike, and it becomes hard to do anything else like gaming or watching videos.&lt;/p&gt;\n\n&lt;p&gt;In contrast, AMD NPUs are incredibly efficient. Here&amp;#39;s a quick comparison video — same prompt, same model, similar speed, but a massive difference in power consumption:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=OZuLQcmFe9A&amp;amp;ab_channel=FastFlowLM\"&gt;https://www.youtube.com/watch?v=OZuLQcmFe9A&amp;amp;ab_channel=FastFlowLM&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Our vision is that NPUs will power always-on, background AI without disrupting the user experience. We&amp;#39;re not from AMD, but we’re genuinely excited about the potential of their NPU architecture — that’s what inspired us to build FastFlowLM.&lt;/p&gt;\n\n&lt;p&gt;Follow this instruction, you can use FastFlowLM as backend, and open WebUI as front end.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.fastflowlm.com/instructions/server/webui.html\"&gt;https://docs.fastflowlm.com/instructions/server/webui.html&lt;/a&gt;&lt;br/&gt;\nLet us know what you think!&lt;/p&gt;\n\n&lt;p&gt;We are not familiar with Jetson Oring though. Hope sometime can do an apple-to-apple comparison on it.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hgj62/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753644552,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753644552,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 8
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5hcwsw",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "paul_tu",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5h9age",
                                "score": 5,
                                "author_fullname": "t2_whtsd",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thanks for the response\n\nI'm just casually running local models just out of curiosity for my common tasks including \"researching\" in different spheres. Documents analysis and so on.\n\nI've got some gear for that purpose. I'm more like just an enthusiasts\n\nHave Nvidia Jetson Oring with an NPU either BTW \n\nI'll give it a try for sure and come back with the feedback. \n\nLM studio is just an easy way to compare the same software apples2apples on different OSs. \n\nOpenWebUI seems to be more flexible in terms of IS support but faces lack of usability. Especially in the installation part.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5hcwsw",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for the response&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just casually running local models just out of curiosity for my common tasks including &amp;quot;researching&amp;quot; in different spheres. Documents analysis and so on.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got some gear for that purpose. I&amp;#39;m more like just an enthusiasts&lt;/p&gt;\n\n&lt;p&gt;Have Nvidia Jetson Oring with an NPU either BTW &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll give it a try for sure and come back with the feedback. &lt;/p&gt;\n\n&lt;p&gt;LM studio is just an easy way to compare the same software apples2apples on different OSs. &lt;/p&gt;\n\n&lt;p&gt;OpenWebUI seems to be more flexible in terms of IS support but faces lack of usability. Especially in the installation part.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hcwsw/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753643447,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753643447,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5h9age",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753642351,
                      "send_replies": true,
                      "parent_id": "t1_n5h7yma",
                      "score": 7,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Good question. I guess it is doable but needs a lot of engineering efforts. So far, FastFlowLM has both frontend (similar to Ollama) and backend. So it can be used as a standalone SW. And user can develop APPs via REST API using server mode (similar to Ollama or LM Studio). Please give it a try, and let us know your thoughts — we're eager to keep improving it.\n\nBy the way, curious — what’s your goal in integrating it with LM Studio?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5h9age",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Good question. I guess it is doable but needs a lot of engineering efforts. So far, FastFlowLM has both frontend (similar to Ollama) and backend. So it can be used as a standalone SW. And user can develop APPs via REST API using server mode (similar to Ollama or LM Studio). Please give it a try, and let us know your thoughts — we&amp;#39;re eager to keep improving it.&lt;/p&gt;\n\n&lt;p&gt;By the way, curious — what’s your goal in integrating it with LM Studio?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5h9age/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753642351,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5h7yma",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "paul_tu",
            "can_mod_post": false,
            "created_utc": 1753641954,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 4,
            "author_fullname": "t2_whtsd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Just a noob question:\nHow to put it as a runtime backend for let's say LM studio?\n\nUnder Ubuntu/Windows\n\nStrix Halo 128GB owner here",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5h7yma",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just a noob question:\nHow to put it as a runtime backend for let&amp;#39;s say LM studio?&lt;/p&gt;\n\n&lt;p&gt;Under Ubuntu/Windows&lt;/p&gt;\n\n&lt;p&gt;Strix Halo 128GB owner here&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5h7yma/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753641954,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5io58f",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "BandEnvironmental834",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5imgme",
                                "score": 5,
                                "author_fullname": "t2_jrsbr6os",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Quick update: just re-posted it on r/AMDLaptops. Hope more ppl can use it. Thanks for the advice!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5io58f",
                                "is_submitter": true,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Quick update: just re-posted it on &lt;a href=\"/r/AMDLaptops\"&gt;r/AMDLaptops&lt;/a&gt;. Hope more ppl can use it. Thanks for the advice!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5io58f/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753658544,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753658544,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5iqdz2",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5iorac",
                                          "score": 5,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "We believe the key advantage of NPUs is their ability to run LLMs efficiently without consuming GPU or CPU compute resources. This may enable ultra-low-power, always-on AI assistant apps that run locally without impacting system performance. So GPU and CPU can run other tasks (gaming, video, programming, etc.) uninterruptedly.\n\nThat might be an advantage. We do not have a Strix Halo here. Thus, it is hard to benchmark against the great iGPU in it. Hope someone can do it and post it.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5iqdz2",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We believe the key advantage of NPUs is their ability to run LLMs efficiently without consuming GPU or CPU compute resources. This may enable ultra-low-power, always-on AI assistant apps that run locally without impacting system performance. So GPU and CPU can run other tasks (gaming, video, programming, etc.) uninterruptedly.&lt;/p&gt;\n\n&lt;p&gt;That might be an advantage. We do not have a Strix Halo here. Thus, it is hard to benchmark against the great iGPU in it. Hope someone can do it and post it.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5iqdz2/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753659328,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753659328,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 5
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5iorac",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "moko990",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5imgme",
                                "score": 6,
                                "author_fullname": "t2_1kh1rmhlhh",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; We also prefer Linux, however, the majority of the users are on Win\n\nI guess it's because of the laptop shipping with windows by default. I hope the linux version will come out soon! \nDoes this have any benefit for the Ryzen AI Max+ 395 (NPU vs iGPU?), given that it seems the main target is budget Ryzen chips?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5iorac",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;We also prefer Linux, however, the majority of the users are on Win&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I guess it&amp;#39;s because of the laptop shipping with windows by default. I hope the linux version will come out soon! \nDoes this have any benefit for the Ryzen AI Max+ 395 (NPU vs iGPU?), given that it seems the main target is budget Ryzen chips?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5iorac/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753658757,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753658757,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5imgme",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753657960,
                      "send_replies": true,
                      "parent_id": "t1_n5il2vd",
                      "score": 6,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Sorry that FastFlowLM can only work on Win for now. We also prefer Linux, however, the majority of the users are on Win. Maybe we should reach out to a different community as well ... \n\nAMD's team is excellent. I guess we took advantage of the great AMD low-level tooling (Riallto, MLIR-AIE, IRON, and AIR MLIR), and tried differently.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5imgme",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sorry that FastFlowLM can only work on Win for now. We also prefer Linux, however, the majority of the users are on Win. Maybe we should reach out to a different community as well ... &lt;/p&gt;\n\n&lt;p&gt;AMD&amp;#39;s team is excellent. I guess we took advantage of the great AMD low-level tooling (Riallto, MLIR-AIE, IRON, and AIR MLIR), and tried differently.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5imgme/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753657960,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5il2vd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "moko990",
            "can_mod_post": false,
            "created_utc": 1753657482,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 5,
            "author_fullname": "t2_1kh1rmhlhh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Great work, but why only Windows? Linux is the favorite here.\n\nHow did you manage to do better than AMD's team? This goes to show why ROCm still struggling.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5il2vd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great work, but why only Windows? Linux is the favorite here.&lt;/p&gt;\n\n&lt;p&gt;How did you manage to do better than AMD&amp;#39;s team? This goes to show why ROCm still struggling.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5il2vd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753657482,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5l39jh",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5kzsas",
                                          "score": 1,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Great idea! That said, since TPS depends heavily on sequence length due to KV cache usage, it might be a bit confusing to present it. Still, we’ll definitely consider it for the next round of benchmarks.\n\nIn the meantime, you can measure it directly on your Ryzen machine in CLI mode using /status (shows sequence length and speed) and /verbose (toggles detailed per-turn performance metrics). Just run the command again to disable verbose mode.\n\nMore info here: [https://docs.fastflowlm.com/instructions/cli.html](https://docs.fastflowlm.com/instructions/cli.html)\n\nLet us know how you like this function and how it performs on your computer :)",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5l39jh",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great idea! That said, since TPS depends heavily on sequence length due to KV cache usage, it might be a bit confusing to present it. Still, we’ll definitely consider it for the next round of benchmarks.&lt;/p&gt;\n\n&lt;p&gt;In the meantime, you can measure it directly on your Ryzen machine in CLI mode using /status (shows sequence length and speed) and /verbose (toggles detailed per-turn performance metrics). Just run the command again to disable verbose mode.&lt;/p&gt;\n\n&lt;p&gt;More info here: &lt;a href=\"https://docs.fastflowlm.com/instructions/cli.html\"&gt;https://docs.fastflowlm.com/instructions/cli.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let us know how you like this function and how it performs on your computer :)&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l39jh/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753698986,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753698986,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5kzsas",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "kmouratidis",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5g4t6q",
                                "score": 1,
                                "author_fullname": "t2_k6u7rfxb",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Pretty impressive. \n\nAlso, TPS / W might be a good table to add at the bottom.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5kzsas",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Pretty impressive. &lt;/p&gt;\n\n&lt;p&gt;Also, TPS / W might be a good table to add at the bottom.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5kzsas/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753697115,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753697115,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5g4t6q",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753630488,
                      "send_replies": true,
                      "parent_id": "t1_n5g3vw1",
                      "score": 12,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "We only benchmarked it on Kraken. Strix or Strix Halo have a smaller mem BW for NPU. Kraken is about 20% faster (Note that this can vary on different computers, clock speed, mem BW allocation, etc.).\n\nThis was done about a month ago (but we are about 20% faster now on Kracken)\n\n[https://docs.fastflowlm.com/benchmarks/llama3\\_results.html](https://docs.fastflowlm.com/benchmarks/llama3_results.html)",
                      "edited": 1753698480,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5g4t6q",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We only benchmarked it on Kraken. Strix or Strix Halo have a smaller mem BW for NPU. Kraken is about 20% faster (Note that this can vary on different computers, clock speed, mem BW allocation, etc.).&lt;/p&gt;\n\n&lt;p&gt;This was done about a month ago (but we are about 20% faster now on Kracken)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.fastflowlm.com/benchmarks/llama3_results.html\"&gt;https://docs.fastflowlm.com/benchmarks/llama3_results.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g4t6q/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753630488,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 12
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g3vw1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Tenzu9",
            "can_mod_post": false,
            "created_utc": 1753630210,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 7,
            "author_fullname": "t2_10wgss",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So you have benchmarks for Strix Halo inference?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g3vw1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So you have benchmarks for Strix Halo inference?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g3vw1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753630210,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5g34r2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753629984,
                      "send_replies": true,
                      "parent_id": "t1_n5g0cw9",
                      "score": 11,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "We just put together a real-time, head-to-head demo showing NPU-only (FastFlowLM) vs CPU-only (Ollama) and iGPU-only (LM Studio) — check it out here (NPU uses much lower power and lower chip temp): [https://www.youtube.com/watch?v=OZuLQcmFe9A](https://www.youtube.com/watch?v=OZuLQcmFe9A)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5g34r2",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We just put together a real-time, head-to-head demo showing NPU-only (FastFlowLM) vs CPU-only (Ollama) and iGPU-only (LM Studio) — check it out here (NPU uses much lower power and lower chip temp): &lt;a href=\"https://www.youtube.com/watch?v=OZuLQcmFe9A\"&gt;https://www.youtube.com/watch?v=OZuLQcmFe9A&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g34r2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753629984,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 11
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g0cw9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "MaverickPT",
            "can_mod_post": false,
            "created_utc": 1753629137,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 6,
            "author_fullname": "t2_ad0k1",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "~~Newbie here. Any chance this could also take advantage of the iGPU? Wouldn't it be advantageous for the AI 300 chips?~~\n\nEDIT: from the GitHub page: \", faster and over 11x more power efficient than the iGPU or hybrid (iGPU+NPU) solutions.\"",
            "edited": 1753629326,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g0cw9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;del&gt;Newbie here. Any chance this could also take advantage of the iGPU? Wouldn&amp;#39;t it be advantageous for the AI 300 chips?&lt;/del&gt;&lt;/p&gt;\n\n&lt;p&gt;EDIT: from the GitHub page: &amp;quot;, faster and over 11x more power efficient than the iGPU or hybrid (iGPU+NPU) solutions.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g0cw9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753629137,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5kz0vg",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753696696,
                      "send_replies": true,
                      "parent_id": "t1_n5jkfa9",
                      "score": 1,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you for the good words! We really appreciate it. Please give it a try, and let us know if encounter any issues. Thanks again!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5kz0vg",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for the good words! We really appreciate it. Please give it a try, and let us know if encounter any issues. Thanks again!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5kz0vg/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753696696,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5jkfa9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "SkyFeistyLlama8",
            "can_mod_post": false,
            "created_utc": 1753670545,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 3,
            "author_fullname": "t2_1hgbaqgbnq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is really good stuff. I remember how it took months for Microsoft to come up with Deepseek Distill Qwen models from 1.5B to 14B, aimed at the Qualcomm Hexagon NPU. It's a very slow process because each model's weights and activations need to be tweaked for each NPU.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5jkfa9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is really good stuff. I remember how it took months for Microsoft to come up with Deepseek Distill Qwen models from 1.5B to 14B, aimed at the Qualcomm Hexagon NPU. It&amp;#39;s a very slow process because each model&amp;#39;s weights and activations need to be tweaked for each NPU.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5jkfa9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753670545,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5l4xxc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753699827,
                      "send_replies": true,
                      "parent_id": "t1_n5jy5h7",
                      "score": 1,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you for the kind words! That is super encouraging! We will keep building!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5l4xxc",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for the kind words! That is super encouraging! We will keep building!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l4xxc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753699827,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5jy5h7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Dangerous-Initial-88",
            "can_mod_post": false,
            "created_utc": 1753676395,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 3,
            "author_fullname": "t2_8kjb2u5x",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is really impressive. Leveraging the Ryzen AI NPU for LLM inference could open a lot of doors for low-power and efficient local AI.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5jy5h7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is really impressive. Leveraging the Ryzen AI NPU for LLM inference could open a lot of doors for low-power and efficient local AI.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5jy5h7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753676395,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5g7oqa",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753631341,
                      "send_replies": true,
                      "parent_id": "t1_n5g489o",
                      "score": 12,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Great question! For BF16, we’re seeing around 10 TOPS. It’s primarily memory-bound, not compute-bound, so performance is limited by bandwidth allocation.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5g7oqa",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great question! For BF16, we’re seeing around 10 TOPS. It’s primarily memory-bound, not compute-bound, so performance is limited by bandwidth allocation.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g7oqa/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753631341,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 12
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g489o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "bick_nyers",
            "can_mod_post": false,
            "created_utc": 1753630313,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 6,
            "author_fullname": "t2_6nwld4d3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "How many flops do those NPU get?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g489o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How many flops do those NPU get?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g489o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753630313,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5haex8",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5h9l6o",
                                          "score": 6,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "From that perspective, yes — totally agree. FastFlowLM is essentially the same concept, just specifically tailored for AMD NPUs.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5haex8",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;From that perspective, yes — totally agree. FastFlowLM is essentially the same concept, just specifically tailored for AMD NPUs.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5haex8/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753642687,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753642687,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 6
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5h9l6o",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "fallingdowndizzyvr",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5h7bp0",
                                "score": 6,
                                "author_fullname": "t2_o65i6kx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Which is exactly what llama.cpp is. Since the basic engine is GGML and the apps people use to access that engine are things like llama-cli and llama-server. Ollama is yet another wrapper on top of that.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5h9l6o",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Which is exactly what llama.cpp is. Since the basic engine is GGML and the apps people use to access that engine are things like llama-cli and llama-server. Ollama is yet another wrapper on top of that.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5h9l6o/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753642440,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753642440,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5h7bp0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753641760,
                      "send_replies": true,
                      "parent_id": "t1_n5h43wc",
                      "score": 2,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks ... Hmm ... I’d say both — FastFlowLM includes the runtime (code on github, basically a wrapper) as well as model-specific, low-level optimized kernels (huggingface).",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5h7bp0",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks ... Hmm ... I’d say both — FastFlowLM includes the runtime (code on github, basically a wrapper) as well as model-specific, low-level optimized kernels (huggingface).&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5h7bp0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753641760,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5h43wc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "fallingdowndizzyvr",
            "can_mod_post": false,
            "created_utc": 1753640794,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 6,
            "author_fullname": "t2_o65i6kx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt;  Think Ollama, but purpose-built and deeply optimized for AMD NPUs — with both CLI and server mode (REST API).\n\nThen it's not like Ollama. It's like llama.cpp. Ollama is a wrapper around llama.cpp.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5h43wc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Think Ollama, but purpose-built and deeply optimized for AMD NPUs — with both CLI and server mode (REST API).&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Then it&amp;#39;s not like Ollama. It&amp;#39;s like llama.cpp. Ollama is a wrapper around llama.cpp.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5h43wc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753640794,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5gxoww",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5gr5qz",
                                          "score": 5,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "It is hardware limited. We initially tried on NPU1 ... but compute resource is not sufficient to run LLMs (they are good with CNNs) in our opinion. We are excited that NPU2 is powerful to compete with GPUs for local LLM with a small fraction of power consumption. We are hoping that NPU3 and NPU4 can make a huge diff in the near future.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5gxoww",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is hardware limited. We initially tried on NPU1 ... but compute resource is not sufficient to run LLMs (they are good with CNNs) in our opinion. We are excited that NPU2 is powerful to compete with GPUs for local LLM with a small fraction of power consumption. We are hoping that NPU3 and NPU4 can make a huge diff in the near future.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gxoww/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753638897,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753638897,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 5
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5gr5qz",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "AVX_Instructor",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5g7xkz",
                                "score": 2,
                                "author_fullname": "t2_948xhm3j",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Is this a software or hardware limitation? It's about the NPU generation (their manufacturers?).",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5gr5qz",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is this a software or hardware limitation? It&amp;#39;s about the NPU generation (their manufacturers?).&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gr5qz/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753637022,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753637022,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5g7xkz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753631413,
                      "send_replies": true,
                      "parent_id": "t1_n5g5q2o",
                      "score": 9,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "sorry ... it can only run on NPU2 (Strix, Strix Halo, Kracken, etc.)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5g7xkz",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;sorry ... it can only run on NPU2 (Strix, Strix Halo, Kracken, etc.)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g7xkz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753631413,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 9
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g5q2o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "AVX_Instructor",
            "can_mod_post": false,
            "created_utc": 1753630763,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 4,
            "author_fullname": "t2_948xhm3j",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "An extremely promising project. I just got a laptop with an R7 7840HS, and I will definitely test it as soon as I get the chance.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g5q2o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;An extremely promising project. I just got a laptop with an R7 7840HS, and I will definitely test it as soon as I get the chance.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g5q2o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753630763,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5jg05x",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "BenAlexanders",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5hkhdf",
                                "score": 2,
                                "author_fullname": "t2_e93o0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Make sense and I understand the decision... Thanks for at just considering it 😀",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5jg05x",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Make sense and I understand the decision... Thanks for at just considering it 😀&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5jg05x/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753668830,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753668830,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5hkhdf",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753645765,
                      "send_replies": true,
                      "parent_id": "t1_n5hilzg",
                      "score": 3,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Unfortunately, we’ve decided to support NPU2 and newer. We tested Hawk Point, but in our view, it doesn’t provide enough compute to run modern LLMs effectively. That said, it seems well-suited for CNN workloads.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5hkhdf",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Unfortunately, we’ve decided to support NPU2 and newer. We tested Hawk Point, but in our view, it doesn’t provide enough compute to run modern LLMs effectively. That said, it seems well-suited for CNN workloads.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hkhdf/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753645765,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5hilzg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "BenAlexanders",
            "can_mod_post": false,
            "created_utc": 1753645192,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 2,
            "author_fullname": "t2_e93o0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Looks great... any chance of support for hawkpoint (and its whopping 16 TOPS NPU 😀)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hilzg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Looks great... any chance of support for hawkpoint (and its whopping 16 TOPS NPU 😀)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5hilzg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753645192,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gluxh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753635483,
                      "send_replies": true,
                      "parent_id": "t1_n5gji7t",
                      "score": 6,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes, it can use the full memory. However, the memory bandwidth is limited. We are currently focusing on models up to 8B. \n\nNPU is a different type of compute unit. It is originally from Xilinx AI Engine (was on their FPGAs). llama.cpp and vulkan do not support this.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gluxh",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, it can use the full memory. However, the memory bandwidth is limited. We are currently focusing on models up to 8B. &lt;/p&gt;\n\n&lt;p&gt;NPU is a different type of compute unit. It is originally from Xilinx AI Engine (was on their FPGAs). llama.cpp and vulkan do not support this.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gluxh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753635483,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5gji7t",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Zyguard7777777",
            "can_mod_post": false,
            "created_utc": 1753634799,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 2,
            "author_fullname": "t2_zo1h5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Can this use the full memory for the Npu? E.g. For strix halo, ~100gb. I'm planning on running qwen3 235ba22b at q2/q4 using llama.cpp vulkan backend ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gji7t",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can this use the full memory for the Npu? E.g. For strix halo, ~100gb. I&amp;#39;m planning on running qwen3 235ba22b at q2/q4 using llama.cpp vulkan backend &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gji7t/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753634799,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5gb6av",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Rich_Artist_8327",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5g3p42",
                                "score": 1,
                                "author_fullname": "t2_1jk2ep8a52",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Okey, so no commercial use. I will  wait then for the open source version of this.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5gb6av",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Okey, so no commercial use. I will  wait then for the open source version of this.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gb6av/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753632373,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753632373,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5g3p42",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753630152,
                      "send_replies": true,
                      "parent_id": "t1_n5g1yl4",
                      "score": 4,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks! The orchestration code is MIT-licensed (everything on GitHub is open source), while the NPU kernels are proprietary binaries — free to use for non-commercial purposes.\n\nSo far we can only support models up t0 8B; Gemma 3 will arrive soon!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5g3p42",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks! The orchestration code is MIT-licensed (everything on GitHub is open source), while the NPU kernels are proprietary binaries — free to use for non-commercial purposes.&lt;/p&gt;\n\n&lt;p&gt;So far we can only support models up t0 8B; Gemma 3 will arrive soon!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g3p42/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753630152,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g1yl4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Rich_Artist_8327",
            "can_mod_post": false,
            "created_utc": 1753629627,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 1,
            "author_fullname": "t2_1jk2ep8a52",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Nice, would like to know performance of hx 370 ryzen AI NPU with Gemma-3 as big as possible model. So its not open source?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g1yl4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice, would like to know performance of hx 370 ryzen AI NPU with Gemma-3 as big as possible model. So its not open source?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g1yl4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753629627,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5l62or",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753700365,
                      "send_replies": true,
                      "parent_id": "t1_n5kjkal",
                      "score": 1,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you! That’s a bit tricky—we’ve done extensive low-level, model-specific optimizations, so changing the dimensions is challenging. However, if it's just fine-tuned weights of a standard LLM architecture, it can be done relatively quickly.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5l62or",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you! That’s a bit tricky—we’ve done extensive low-level, model-specific optimizations, so changing the dimensions is challenging. However, if it&amp;#39;s just fine-tuned weights of a standard LLM architecture, it can be done relatively quickly.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l62or/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753700365,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5kjkal",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "pcdacks",
            "can_mod_post": false,
            "created_utc": 1753687686,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 1,
            "author_fullname": "t2_6suhydu8g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Great work! I was wondering how to run my own trained model (similar to LLaMA but with modified dimensions) in practice.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kjkal",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great work! I was wondering how to run my own trained model (similar to LLaMA but with modified dimensions) in practice.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5kjkal/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753687686,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ks6aq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "COBECT",
                      "can_mod_post": false,
                      "created_utc": 1753692742,
                      "send_replies": true,
                      "parent_id": "t1_n5kkplu",
                      "score": 2,
                      "author_fullname": "t2_1umam7ln",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "They have video https://youtu.be/OZuLQcmFe9A. Seems GPU is about 2x faster.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ks6aq",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They have video &lt;a href=\"https://youtu.be/OZuLQcmFe9A\"&gt;https://youtu.be/OZuLQcmFe9A&lt;/a&gt;. Seems GPU is about 2x faster.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5ks6aq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753692742,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5l1o2n",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753698142,
                      "send_replies": true,
                      "parent_id": "t1_n5kkplu",
                      "score": 2,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes, we have a benchmark here (Ryzen AI 5 340 chip) across different sequence length. Please note that this data was collected about 1 month ago (pre-release version). The latest release is about 20% faster now after a couple of upgrades. \n\n[https://docs.fastflowlm.com/benchmarks/llama3\\_results.html](https://docs.fastflowlm.com/benchmarks/llama3_results.html)\n\nAs the results show, iGPUs tend to be faster at shorter sequence lengths, but NPUs outperform at longer sequences and offer significantly better power efficiency overall.\n\nAdditionally, decoding speed is memory-bound rather than compute-bound. At the moment, it appears that more memory bandwidth is allocated to the iGPU. We’re hopeful that future chips will allow the NPU to access a larger share of memory bandwidth.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5l1o2n",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, we have a benchmark here (Ryzen AI 5 340 chip) across different sequence length. Please note that this data was collected about 1 month ago (pre-release version). The latest release is about 20% faster now after a couple of upgrades. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.fastflowlm.com/benchmarks/llama3_results.html\"&gt;https://docs.fastflowlm.com/benchmarks/llama3_results.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;As the results show, iGPUs tend to be faster at shorter sequence lengths, but NPUs outperform at longer sequences and offer significantly better power efficiency overall.&lt;/p&gt;\n\n&lt;p&gt;Additionally, decoding speed is memory-bound rather than compute-bound. At the moment, it appears that more memory bandwidth is allocated to the iGPU. We’re hopeful that future chips will allow the NPU to access a larger share of memory bandwidth.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l1o2n/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753698142,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5kkplu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "kkb294",
            "can_mod_post": false,
            "created_utc": 1753688361,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 1,
            "author_fullname": "t2_9u3afpb8q",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Do you have any performance comparison between RoCm runtime in LM Studio Vs your application.?\n\nEdit: Came across this comment thread ( https://www.reddit.com/r/LocalLLaMA/s/TiYjZbv7Xu), will follow the discussion in that thread.",
            "edited": 1753688631,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kkplu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you have any performance comparison between RoCm runtime in LM Studio Vs your application.?&lt;/p&gt;\n\n&lt;p&gt;Edit: Came across this comment thread ( &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/s/TiYjZbv7Xu\"&gt;https://www.reddit.com/r/LocalLLaMA/s/TiYjZbv7Xu&lt;/a&gt;), will follow the discussion in that thread.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5kkplu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753688361,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5l22yp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753698361,
                      "send_replies": true,
                      "parent_id": "t1_n5kmjac",
                      "score": 1,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you for the kind words! Really encouraging! We're a small team with limited resources, and we’ve prioritized Windows since most Ryzen AI users are on WIN. That said, we would like to support Linux once we have more resources.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5l22yp",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for the kind words! Really encouraging! We&amp;#39;re a small team with limited resources, and we’ve prioritized Windows since most Ryzen AI users are on WIN. That said, we would like to support Linux once we have more resources.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l22yp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753698361,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5kmjac",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Craftkorb",
            "can_mod_post": false,
            "created_utc": 1753689418,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 1,
            "author_fullname": "t2_8ubew",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Good job, that's really interesting stuff and almost hilariously efficient compared to GPUs!\n\nHaving a Linux version would be a must for me, and would actually make me buy an AMD CPU with NPU for my next home server (do you hear that, AMD?)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kmjac",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Good job, that&amp;#39;s really interesting stuff and almost hilariously efficient compared to GPUs!&lt;/p&gt;\n\n&lt;p&gt;Having a Linux version would be a must for me, and would actually make me buy an AMD CPU with NPU for my next home server (do you hear that, AMD?)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5kmjac/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753689418,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5lat2c",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5l845t",
                                          "score": 1,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I would say mainly driver and runtime wrapper are WIN-specific at this point.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5lat2c",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would say mainly driver and runtime wrapper are WIN-specific at this point.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5lat2c/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753702540,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753702540,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5l845t",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "spaceman_",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5l676b",
                                "score": 1,
                                "author_fullname": "t2_9neub",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Is any of the code you guys use Windows-specific? Are you guys using a library or how are you interfacing with the XDNA hardware on Windows?\n\nIf it's only a matter of testing &amp; fixing compilation quirks etc, I could definitely have a look at this. I've been wanting to play with the XDNA hardware but have not found a ton of information out there.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5l845t",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is any of the code you guys use Windows-specific? Are you guys using a library or how are you interfacing with the XDNA hardware on Windows?&lt;/p&gt;\n\n&lt;p&gt;If it&amp;#39;s only a matter of testing &amp;amp; fixing compilation quirks etc, I could definitely have a look at this. I&amp;#39;ve been wanting to play with the XDNA hardware but have not found a ton of information out there.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l845t/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753701327,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753701327,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5l676b",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753700424,
                      "send_replies": true,
                      "parent_id": "t1_n5kpo4m",
                      "score": 1,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you! We're a small team with limited resources, and since most Ryzen AI PC users are on Windows, we've focused our efforts there for now. That said, we definitely plan to support Linux as soon as we have the capacity to do so.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5l676b",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you! We&amp;#39;re a small team with limited resources, and since most Ryzen AI PC users are on Windows, we&amp;#39;ve focused our efforts there for now. That said, we definitely plan to support Linux as soon as we have the capacity to do so.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5l676b/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753700424,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5kpo4m",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "spaceman_",
            "can_mod_post": false,
            "created_utc": 1753691265,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 1,
            "author_fullname": "t2_9neub",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I wish this would work on Linux.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kpo4m",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I wish this would work on Linux.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5kpo4m/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753691265,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5gqlbp",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "BandEnvironmental834",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5govq4",
                                                              "score": 2,
                                                              "author_fullname": "t2_jrsbr6os",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "true, just did .. and made it very clear on the repo ... thank you! This is helpful!",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5gqlbp",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;true, just did .. and made it very clear on the repo ... thank you! This is helpful!&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mao95d",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gqlbp/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753636856,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753636856,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5govq4",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "HelicopterBright4480",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5g5ftp",
                                                    "score": 5,
                                                    "author_fullname": "t2_7d9ohsab",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Then remove the MIT label from the Readme. Selling software is fine, but be upfront that this is closed source, and anyone using it will at some point rely on you wanting to sell it to them",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5govq4",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Then remove the MIT label from the Readme. Selling software is fine, but be upfront that this is closed source, and anyone using it will at some point rely on you wanting to sell it to them&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mao95d",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5govq4/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753636362,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753636362,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 5
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5g5ftp",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5g4jjr",
                                          "score": 8,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "We're currently bootstrapping — and at some point, we’ll need to make it sustainable enough to support ourselves :)",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5g5ftp",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re currently bootstrapping — and at some point, we’ll need to make it sustainable enough to support ourselves :)&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g5ftp/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753630677,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753630677,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 8
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5g4jjr",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "a_postgres_situation",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5g224z",
                                "score": 3,
                                "author_fullname": "t2_neruppu",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "    Proprietary binaries (used for low-level NPU acceleration; patent pending) \n\nSome genius mathematics/formulas you came up with and want exclusivity for 20y?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5g4jjr",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;Proprietary binaries (used for low-level NPU acceleration; patent pending) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Some genius mathematics/formulas you came up with and want exclusivity for 20y?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g4jjr/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753630407,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753630407,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 1,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5g224z",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753629657,
                      "send_replies": true,
                      "parent_id": "t1_n5fzi02",
                      "score": 7,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks! It uses MIT-licensed orchestration code (basically all code on github), while the NPU kernels are proprietary binaries—they are free for non-commercial use. ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5g224z",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks! It uses MIT-licensed orchestration code (basically all code on github), while the NPU kernels are proprietary binaries—they are free for non-commercial use. &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g224z/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753629657,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5g1qbm",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "zadiraines",
                      "can_mod_post": false,
                      "created_utc": 1753629557,
                      "send_replies": true,
                      "parent_id": "t1_n5fzi02",
                      "score": 4,
                      "author_fullname": "t2_2sy83",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5g1qbm",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g1qbm/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753629557,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5fzi02",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "a_postgres_situation",
            "can_mod_post": false,
            "created_utc": 1753628871,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": -15,
            "author_fullname": "t2_neruppu",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "    FastFlowLM uses proprietary low-level kernel code optimized for AMD Ryzen™ NPUs.\n    These kernels are not open source, but are included as binaries for seamless integration.\n\nHmm....\n\nEdit: This went from top-upvoted comment to top-downvoted comment in a short period of time - the magic of Reddit at work...",
            "edited": 1753641461,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fzi02",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;FastFlowLM uses proprietary low-level kernel code optimized for AMD Ryzen™ NPUs.\nThese kernels are not open source, but are included as binaries for seamless integration.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Hmm....&lt;/p&gt;\n\n&lt;p&gt;Edit: This went from top-upvoted comment to top-downvoted comment in a short period of time - the magic of Reddit at work...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5fzi02/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753628871,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5grzpu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1753637264,
                      "send_replies": true,
                      "parent_id": "t1_n5gq8yo",
                      "score": 0,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "\\&gt; super interested\n\n\\&gt; contribute from time to time\n\n\\&gt; Top 1% commenter\n\nlmao if you were smarter you'd probably realize why no one wants your \"contributions\".",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5grzpu",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;gt; super interested&lt;/p&gt;\n\n&lt;p&gt;&amp;gt; contribute from time to time&lt;/p&gt;\n\n&lt;p&gt;&amp;gt; Top 1% commenter&lt;/p&gt;\n\n&lt;p&gt;lmao if you were smarter you&amp;#39;d probably realize why no one wants your &amp;quot;contributions&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5grzpu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753637264,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5gq8yo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Double_Cause4609",
            "can_mod_post": false,
            "created_utc": 1753636756,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": 1,
            "author_fullname": "t2_1kubzxt2ww",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "* Windows\n* Kernels private\n\nWelp. I'm super interested in NPU development and like to contribute from time to time but I guess this project is allergic to community support.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gq8yo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;Windows&lt;/li&gt;\n&lt;li&gt;Kernels private&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Welp. I&amp;#39;m super interested in NPU development and like to contribute from time to time but I guess this project is allergic to community support.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5gq8yo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753636756,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5g6buz",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "BandEnvironmental834",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5g58fr",
                                          "score": 5,
                                          "author_fullname": "t2_jrsbr6os",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "understood ... modified the post",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5g6buz",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;understood ... modified the post&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mao95d",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g6buz/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753630944,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753630944,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 5
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5g58fr",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "FullstackSensei",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5g1vry",
                                "score": 11,
                                "author_fullname": "t2_17n3nqtj56",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "There's no license file on the repo. That \"free for non-commercial\" means most of us, myself included, aren't touching your code.\n\nI'm not against limiting use. I'm a software engineer and understand you need to recoup your investment in time and effort, but don't try to pass it as open-source when it really isn't. Just build and sell the app via the windows store. Don't muddy the waters by claiming it's open source when it isn't. It just makes you look dishonest (not saying that you are).",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5g58fr",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s no license file on the repo. That &amp;quot;free for non-commercial&amp;quot; means most of us, myself included, aren&amp;#39;t touching your code.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not against limiting use. I&amp;#39;m a software engineer and understand you need to recoup your investment in time and effort, but don&amp;#39;t try to pass it as open-source when it really isn&amp;#39;t. Just build and sell the app via the windows store. Don&amp;#39;t muddy the waters by claiming it&amp;#39;s open source when it isn&amp;#39;t. It just makes you look dishonest (not saying that you are).&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mao95d",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g58fr/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753630615,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753630615,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 11
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5g1vry",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BandEnvironmental834",
                      "can_mod_post": false,
                      "created_utc": 1753629604,
                      "send_replies": true,
                      "parent_id": "t1_n5g05l1",
                      "score": 2,
                      "author_fullname": "t2_jrsbr6os",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It uses MIT-licensed orchestration code (all code on github), while the NPU kernels are proprietary binaries—free for non-commercial use. Currently, we can only support models up to \\~8B.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5g1vry",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It uses MIT-licensed orchestration code (all code on github), while the NPU kernels are proprietary binaries—free for non-commercial use. Currently, we can only support models up to ~8B.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mao95d",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g1vry/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753629604,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g05l1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "FullstackSensei",
            "can_mod_post": false,
            "created_utc": 1753629074,
            "send_replies": true,
            "parent_id": "t3_1mao95d",
            "score": -28,
            "author_fullname": "t2_17n3nqtj56",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "What's the license here? How does it perform on models like Qwen 3 30b-a3b? Can we take the kernels blob and use it in our own apps?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g05l1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the license here? How does it perform on models like Qwen 3 30b-a3b? Can we take the kernels blob and use it in our own apps?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mao95d/running_llms_exclusively_on_amd_ryzen_ai_npu/n5g05l1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753629074,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mao95d",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -28
          }
        }
      ],
      "before": null
    }
  }
]