[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "openai/gpt-oss-120b Â· Hugging Face",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 75,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mieqcb",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.96,
            "author_flair_background_color": null,
            "ups": 462,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_48ezkeai",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 462,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=c53de7eaf90408930eb8ee160a74f6d720f0282c",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "link",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754413237,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "huggingface.co",
            "allow_live_comments": false,
            "selftext_html": null,
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://huggingface.co/openai/gpt-oss-120b",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?auto=webp&amp;s=0871512cd76cbf7bde2f7bd9a5f885c071ce735a",
                    "width": 1200,
                    "height": 648
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=292c3d3a2dfa2ce762d4e0ad0113f21057208fb5",
                      "width": 108,
                      "height": 58
                    },
                    {
                      "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7caae8dd778b09b71d56e893c0307604fe6185aa",
                      "width": 216,
                      "height": 116
                    },
                    {
                      "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4ffd35e2510c33eb737fe6e23874ab1b1e5a5081",
                      "width": 320,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4ae7c659a21f868f6dba51b958c810a90c5bfe24",
                      "width": 640,
                      "height": 345
                    },
                    {
                      "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e415f43cdae65729878a0ca9f4a7a894ca8be09",
                      "width": 960,
                      "height": 518
                    },
                    {
                      "url": "https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3acf6478b097b66560a9a81bdaef6463bf66481c",
                      "width": 1080,
                      "height": 583
                    }
                  ],
                  "variants": {},
                  "id": "12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1mieqcb",
            "is_robot_indexable": true,
            "num_duplicates": 2,
            "report_reasons": null,
            "author": "ShreckAndDonkey123",
            "discussion_type": null,
            "num_comments": 103,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/",
            "stickied": false,
            "url": "https://huggingface.co/openai/gpt-oss-120b",
            "subreddit_subscribers": 511885,
            "created_utc": 1754413237,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n730rx0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "-Anti_X",
            "can_mod_post": false,
            "created_utc": 1754413381,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 132,
            "author_fullname": "t2_133pxp",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "117B and 5.1B Active... Interesting setup",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n730rx0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;117B and 5.1B Active... Interesting setup&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n730rx0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754413381,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 132
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n730zob",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Sky-kunn",
            "can_mod_post": false,
            "created_utc": 1754413452,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 108,
            "author_fullname": "t2_ahgkl0do",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Apache 2.0!!!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n730zob",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Apache 2.0!!!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n730zob/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754413452,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 108
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n736zgx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "LostMyOtherAcct69",
                      "can_mod_post": false,
                      "created_utc": 1754415328,
                      "send_replies": true,
                      "parent_id": "t1_n732cnt",
                      "score": 61,
                      "author_fullname": "t2_ewg9k97p",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I was thinking this exactly. It needs to make o3 (and 2.5 pro etc) look like a waste of time.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n736zgx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking this exactly. It needs to make o3 (and 2.5 pro etc) look like a waste of time.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n736zgx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754415328,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 61
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n74kaq7",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "seoulsrvr",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n74f1zc",
                                                    "score": 11,
                                                    "author_fullname": "t2_47ws19uq",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "wow - I didn't realize this...that kind of changes everything - thanks for the clarification",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n74kaq7",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;wow - I didn&amp;#39;t realize this...that kind of changes everything - thanks for the clarification&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mieqcb",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74kaq7/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754431744,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754431744,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 11
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n758z30",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "ook_the_librarian_",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n74f1zc",
                                                    "score": 4,
                                                    "author_fullname": "t2_1keamfc2fv",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "I had to think a lot about your comment because I was like \"so what tool use is obviously a better thing, humans do it all the time!\" but then I had lunch and was thinking about it and I think that tool use *itself* is fine. \n\nThe problem with the benchmark is the *mixing conditions in a comparison*. If Model A is shown with tools while Models BâE are shown without tools, the table is comparing different systems, not the modelsâ raw capability. \n\nThat is what people mean by ârigged.â It's like giving ONE grade schooler a calculator while all the rest of them don't get one.\n\nPhew ð",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n758z30",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I had to think a lot about your comment because I was like &amp;quot;so what tool use is obviously a better thing, humans do it all the time!&amp;quot; but then I had lunch and was thinking about it and I think that tool use &lt;em&gt;itself&lt;/em&gt; is fine. &lt;/p&gt;\n\n&lt;p&gt;The problem with the benchmark is the &lt;em&gt;mixing conditions in a comparison&lt;/em&gt;. If Model A is shown with tools while Models BâE are shown without tools, the table is comparing different systems, not the modelsâ raw capability. &lt;/p&gt;\n\n&lt;p&gt;That is what people mean by ârigged.â It&amp;#39;s like giving ONE grade schooler a calculator while all the rest of them don&amp;#39;t get one.&lt;/p&gt;\n\n&lt;p&gt;Phew ð&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mieqcb",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n758z30/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754439988,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754439988,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 4
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n74f1zc",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "ttkciar",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n73tsbz",
                                          "score": 32,
                                          "author_fullname": "t2_cpegz",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "It had a python interpreter at its disposal, so it could write/call python functions to compute answers it couldn't come up with otherwise.\n\nAny of the tool-using models (Tulu3, NexusRaven, Command-A, etc) will perform much better at a variety of benchmarks if they are allowed to use tools during the test.  It's like letting a gradeschooler take a math test with a calculator.  Normally tool-using during benchmarks are disallowed.\n\nOpenAI's benchmarks show the scores of GPT-OSS **with** tool-using next to the scores of other models **without** tool-using.  They rigged it.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n74f1zc",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "e": "text",
                                              "t": "llama.cpp"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It had a python interpreter at its disposal, so it could write/call python functions to compute answers it couldn&amp;#39;t come up with otherwise.&lt;/p&gt;\n\n&lt;p&gt;Any of the tool-using models (Tulu3, NexusRaven, Command-A, etc) will perform much better at a variety of benchmarks if they are allowed to use tools during the test.  It&amp;#39;s like letting a gradeschooler take a math test with a calculator.  Normally tool-using during benchmarks are disallowed.&lt;/p&gt;\n\n&lt;p&gt;OpenAI&amp;#39;s benchmarks show the scores of GPT-OSS &lt;strong&gt;with&lt;/strong&gt; tool-using next to the scores of other models &lt;strong&gt;without&lt;/strong&gt; tool-using.  They rigged it.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mieqcb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "light",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74f1zc/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754430046,
                                          "author_flair_text": "llama.cpp",
                                          "treatment_tags": [],
                                          "created_utc": 1754430046,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "#bbbdbf",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 32
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7426la",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "AnonymousCrayonEater",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n73tsbz",
                                          "score": 4,
                                          "author_fullname": "t2_a2ypgji3",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "MCP servers",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7426la",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;MCP servers&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mieqcb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n7426la/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754425934,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754425934,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n74a2f5",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "i-have-the-stash",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n73tsbz",
                                          "score": 2,
                                          "author_fullname": "t2_4fc3wefw",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Its benchmarked with in context learning. Benchmarks doesnât takes into account of its knowledge base but reasoning",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n74a2f5",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Its benchmarked with in context learning. Benchmarks doesnât takes into account of its knowledge base but reasoning&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mieqcb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74a2f5/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754428438,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754428438,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n73tsbz",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "seoulsrvr",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73cw3p",
                                "score": 6,
                                "author_fullname": "t2_47ws19uq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "can you clarify what you mean?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n73tsbz",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;can you clarify what you mean?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73tsbz/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754423195,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754423195,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n73n0hg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Neither-Phone-7264",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73cw3p",
                                "score": 5,
                                "author_fullname": "t2_e7yz4055",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "even without, it's still really strong. Really nice model.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n73n0hg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;even without, it&amp;#39;s still really strong. Really nice model.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73n0hg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754420861,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754420861,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n75nbg2",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Wheynelau",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73cw3p",
                                "score": 1,
                                "author_fullname": "t2_vezlk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Are there any benchmarks that allow tool use? Or a tool-use benchmark? With the way LLMs are moving, making them good with purely tool use makes more sense.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n75nbg2",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Are there any benchmarks that allow tool use? Or a tool-use benchmark? With the way LLMs are moving, making them good with purely tool use makes more sense.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n75nbg2/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754444935,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754444935,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n74wayr",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "hapliniste",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73cw3p",
                                "score": 0,
                                "author_fullname": "t2_fc7rd",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yeah but Gpt5 will be used with tool use too. Needs to be quite higher than a 20b model.\n\nFor enterprise clients and local documents we got what's needed anyway. Halucinates quite a bit in other languages tho.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n74wayr",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah but Gpt5 will be used with tool use too. Needs to be quite higher than a 20b model.&lt;/p&gt;\n\n&lt;p&gt;For enterprise clients and local documents we got what&amp;#39;s needed anyway. Halucinates quite a bit in other languages tho.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74wayr/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754435732,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754435732,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n73cw3p",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "ttkciar",
                      "can_mod_post": false,
                      "created_utc": 1754417263,
                      "send_replies": true,
                      "parent_id": "t1_n732cnt",
                      "score": 38,
                      "author_fullname": "t2_cpegz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Those benchmarks are with tool-use, so it's not really a fair comparison.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73cw3p",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Those benchmarks are with tool-use, so it&amp;#39;s not really a fair comparison.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73cw3p/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754417263,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 38
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7461lr",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "Uncle___Marty",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n73h6n9",
                                                    "score": 9,
                                                    "author_fullname": "t2_75p7pgz3",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Eating Pasta is a great use of time. But using it to block benchmarks? Not cool buddy, not cool.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7461lr",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "e": "text",
                                                        "t": "llama.cpp"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Eating Pasta is a great use of time. But using it to block benchmarks? Not cool buddy, not cool.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mieqcb",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "light",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n7461lr/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754427153,
                                                    "author_flair_text": "llama.cpp",
                                                    "collapsed": false,
                                                    "created_utc": 1754427153,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "#bbbdbf",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 9
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n73h6n9",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Creative-Size2658",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n73evn7",
                                          "score": 6,
                                          "author_fullname": "t2_1f3xb4r4ae",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Thanks! I didn't see them, but TBH I was eating pasta and didn't have enough brain time. I wasn't on r/localllama either, so I missed the quintillions of posts about it too.\n\nNow I see them. Everywhere.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n73h6n9",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks! I didn&amp;#39;t see them, but TBH I was eating pasta and didn&amp;#39;t have enough brain time. I wasn&amp;#39;t on &lt;a href=\"/r/localllama\"&gt;r/localllama&lt;/a&gt; either, so I missed the quintillions of posts about it too.&lt;/p&gt;\n\n&lt;p&gt;Now I see them. Everywhere.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mieqcb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73h6n9/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754418798,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754418798,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 6
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n73evn7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "rusty_fans",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73dz04",
                                "score": 9,
                                "author_fullname": "t2_9ntkbp4y3",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Those in the blog linked right at the top of the model card.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n73evn7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Those in the blog linked right at the top of the model card.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73evn7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754417968,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754417968,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 9
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n73dz04",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Creative-Size2658",
                      "can_mod_post": false,
                      "created_utc": 1754417643,
                      "send_replies": true,
                      "parent_id": "t1_n732cnt",
                      "score": 3,
                      "author_fullname": "t2_1f3xb4r4ae",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "What benchmarks are you talking about?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73dz04",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What benchmarks are you talking about?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73dz04/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754417643,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73wzyc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Aldarund",
                      "can_mod_post": false,
                      "created_utc": 1754424276,
                      "send_replies": true,
                      "parent_id": "t1_n732cnt",
                      "score": 0,
                      "author_fullname": "t2_bu5xy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Where its strong? Except their benchx? Any real world usecase wheel it beat any os model of larger size? N0?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73wzyc",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Where its strong? Except their benchx? Any real world usecase wheel it beat any os model of larger size? N0?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73wzyc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754424276,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73pxxx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "kkb294",
                      "can_mod_post": false,
                      "created_utc": 1754421880,
                      "send_replies": true,
                      "parent_id": "t1_n732cnt",
                      "score": 0,
                      "author_fullname": "t2_9u3afpb8q",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "They should be comparing with other open-source LLMs to give us a clear picture rather than leaving it for us to figure out.\n\nI feel, they will not be able to show much improvement compared to the other recent releases which may have forced them to remove the comparisons. Though, I am happy to be wrong ð",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73pxxx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They should be comparing with other open-source LLMs to give us a clear picture rather than leaving it for us to figure out.&lt;/p&gt;\n\n&lt;p&gt;I feel, they will not be able to show much improvement compared to the other recent releases which may have forced them to remove the comparisons. Though, I am happy to be wrong ð&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73pxxx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754421880,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n732cnt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "rusty_fans",
            "can_mod_post": false,
            "created_utc": 1754413894,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 175,
            "author_fullname": "t2_9ntkbp4y3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Wow, maybe \"open\" ai actually deserves their name if those benchmarks turn out to be true.\n\nThough I suspect gpt5 will be quite a beast if they feel confident releasing such a strong model.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n732cnt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wow, maybe &amp;quot;open&amp;quot; ai actually deserves their name if those benchmarks turn out to be true.&lt;/p&gt;\n\n&lt;p&gt;Though I suspect gpt5 will be quite a beast if they feel confident releasing such a strong model.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n732cnt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754413894,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 175
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n74ql2z",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Admirable-Star7088",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n74htik",
                                "score": 4,
                                "author_fullname": "t2_qhlcbiy3k",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "gglm-org quants were broken, I compared with Unsloth quants and they were a lot better, so definitively use Unsloth for now!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n74ql2z",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;gglm-org quants were broken, I compared with Unsloth quants and they were a lot better, so definitively use Unsloth for now!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74ql2z/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754433849,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754433849,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n74htik",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "pseudonerv",
                      "can_mod_post": false,
                      "created_utc": 1754430931,
                      "send_replies": true,
                      "parent_id": "t1_n734rje",
                      "score": 10,
                      "author_fullname": "t2_eerln",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "3 days ago by ggml-org!!!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74htik",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3 days ago by ggml-org!!!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74htik/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754430931,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 10
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n734rje",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Admirable-Star7088",
            "can_mod_post": false,
            "created_utc": 1754414643,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 75,
            "author_fullname": "t2_qhlcbiy3k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Unsloth is prepering quants!\n\n[https://huggingface.co/unsloth/gpt-oss-120b-GGUF](https://huggingface.co/unsloth/gpt-oss-120b-GGUF)  \n[https://huggingface.co/unsloth/gpt-oss-20b-GGUF](https://huggingface.co/unsloth/gpt-oss-20b-GGUF)\n\n**Edit:**\n\nggml-org has already uploaded them for those who can't wait a second longer:\n\n[https://huggingface.co/ggml-org/gpt-oss-120b-GGUF](https://huggingface.co/ggml-org/gpt-oss-120b-GGUF)  \n[https://huggingface.co/ggml-org/gpt-oss-20b-GGUF](https://huggingface.co/ggml-org/gpt-oss-20b-GGUF)\n\n**Edit 2:**\n\nUse the latest Unsloth quants, they are less buggy and works better for now!",
            "edited": 1754433866,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n734rje",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Unsloth is prepering quants!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/unsloth/gpt-oss-120b-GGUF\"&gt;https://huggingface.co/unsloth/gpt-oss-120b-GGUF&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://huggingface.co/unsloth/gpt-oss-20b-GGUF\"&gt;https://huggingface.co/unsloth/gpt-oss-20b-GGUF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;ggml-org has already uploaded them for those who can&amp;#39;t wait a second longer:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/ggml-org/gpt-oss-120b-GGUF\"&gt;https://huggingface.co/ggml-org/gpt-oss-120b-GGUF&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://huggingface.co/ggml-org/gpt-oss-20b-GGUF\"&gt;https://huggingface.co/ggml-org/gpt-oss-20b-GGUF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Edit 2:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Use the latest Unsloth quants, they are less buggy and works better for now!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n734rje/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754414643,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 75
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n744kaa",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "eloquentemu",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n737sya",
                                "score": 23,
                                "author_fullname": "t2_lpdsy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Still shaking stuff out with the updates to llama.cpp and gguf availability (and my slow-ish internet) so preliminary but here are some numbers.  Note this is on an Epyc 9B14 so 96 cores (using 44 threads), 12ch DDR5-4800 so YMMV but shows OSS-120B vs Qwen3-30B at least.\n\n| model                   |       size |     params | backend   | fa |            test |             t/s |\n| ----------------------- | ---------: | ---------: | --------- | -: | --------------: | --------------: |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CPU       |  1 |           pp512 |   205.86 Â± 0.69 |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CPU       |  1 |   pp512 @ d6000 |   126.42 Â± 0.01 |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CPU       |  1 |           tg128 |    49.31 Â± 0.04 |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CPU       |  1 |   tg128 @ d6000 |    36.28 Â± 0.04 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CPU       |  1 |           pp512 |   325.44 Â± 0.07 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CPU       |  1 |   pp512 @ d6000 |    96.24 Â± 0.86 |\n| qwen3moe 30B.A3B Q4_K-M |  17.28 GiB |    30.53 B | CPU       |  0 |   pp512 @ d6000 |   145.40 Â± 0.60 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CPU       |  1 |           tg128 |    59.78 Â± 0.50 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CPU       |  1 |   tg128 @ d6000 |    14.97 Â± 0.00 |\n| qwen3moe 30B.A3B Q4_K-M |  17.28 GiB |    30.53 B | CPU       |  0 |   tg128 @ d6000 |    24.33 Â± 0.03 |\n\nSo at short contexts the 120B is just a touch slower in tg128 (49 vs 60) and much slower in PP (206 vs 325) but at long contexts they end up about the same as attention calcs start to dominate.  I'm not sure why flash attention is killing 30B at long contexts, but I reran and confirmed so I include fa=0 numbers to compare.  Flash attention is otherwise strictly better... Both for OSS on CPU and either model on GPU.\n\nWith a GPU offloading non-experts we get:\n\n| model                   |       size |     params | backend    | ngl | fa | ot         |            test |            t/s |\n| ----------------------- | ---------: | ---------: | ---------- | --: | -: | ---------- | --------------: | -------------: |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 | exps=CPU   |           pp512 |  181.79 Â± 0.13 |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 | exps=CPU   |   pp512 @ d6000 |  165.67 Â± 0.07 |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 | exps=CPU   |           tg128 |   57.27 Â± 0.05 |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 | exps=CPU   |   tg128 @ d6000 |   56.29 Â± 0.14 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CUDA       |  99 |  1 | exps=CPU   |           pp512 |  556.80 Â± 0.90 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CUDA       |  99 |  1 | exps=CPU   |   pp512 @ d6000 |  542.76 Â± 1.01 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CUDA       |  99 |  1 | exps=CPU   |           tg128 |   86.04 Â± 0.58 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CUDA       |  99 |  1 | exps=CPU   |   tg128 @ d6000 |   74.29 Â± 0.08 |\n\nWe see a larger performance boost for Q30B (1.5x vs 1.2x) which surprised me a little.  PP is through the roof **but** this is _somewhat_ unfair to the larger model since llama.cpp does PP on the GPU unless you pass `--no-op-offload`.  That means it streams the entire model to the GPU to process a batch (given by `--ubatch-size`, default 512) so it tends to be bottlenecked by PCIe (v4 x16 for my test here) vs ubatch size.  You can crank the batch size up, but that doesn't help pp512 since, well, it's only a 512tok prompt to process.  Obviously when I say \"unfair\" it's still the reality of execution speeds but if you, say, used PCIe5 instead you'd immediately double the PP.\n\nLast but not least putting the whole thing on a Pro 6000.  30B wins the PP fist\n\n| model                   |       size |     params | backend    | ngl | fa |            test |                  t/s |\n| ----------------------- | ---------: | ---------: | ---------- | --: | -: | --------------: | -------------------: |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 |           pp512 |      2400.46 Â± 29.02 |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 |           tg128 |        165.39 Â± 0.18 |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 |   pp512 @ d6000 |       1102.52 Â± 6.14 |\n| gpt-oss ?B MXFP4 MoE    |  59.02 GiB |   116.83 B | CUDA       |  99 |  1 |   tg128 @ d6000 |        141.76 Â± 5.02 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CUDA       |  99 |  1 |           pp512 |      3756.32 Â± 21.30 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CUDA       |  99 |  1 |           tg128 |        182.38 Â± 0.07 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CUDA       |  99 |  1 |   pp512 @ d6000 |       3292.64 Â± 9.76 |\n| qwen3moe 30B.A3B Q4_K_M |  17.28 GiB |    30.53 B | CUDA       |  99 |  1 |   tg128 @ d6000 |        151.45 Â± 0.05 |\n\nFinally batched processing on the 6000.  30B in native bf16 is included now since it's actually a bit more fair since the above tests left OSS-120B unquantied. 30B is about 30% faster, which isn't a lot given the difference in sizes.\n\n| model    |    PP |     TG |    B |   N_KV |   T_PP s | S_PP t/s |   T_TG s | S_TG t/s |      T s |    S t/s |\n|----------|-------|--------|------|--------|----------|----------|----------|----------|----------|----------|\n| 120B-fp4 |   512 |    128 |   64 |  40960 |   10.271 |  3190.38 |    6.696 |  1223.38 |   16.967 |  2414.09 |\n| 30B-Q4   |   512 |    128 |   64 |  40960 |    7.736 |  4235.76 |    4.974 |  1646.81 |   12.711 |  3222.53 |\n| 30B-bf16 |   512 |    128 |   64 |  40960 |    6.195 |  5289.33 |    5.019 |  1632.30 |   11.214 |  3652.64 |",
                                "edited": 1754435104,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n744kaa",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Still shaking stuff out with the updates to llama.cpp and gguf availability (and my slow-ish internet) so preliminary but here are some numbers.  Note this is on an Epyc 9B14 so 96 cores (using 44 threads), 12ch DDR5-4800 so YMMV but shows OSS-120B vs Qwen3-30B at least.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;model&lt;/th&gt;\n&lt;th align=\"right\"&gt;size&lt;/th&gt;\n&lt;th align=\"right\"&gt;params&lt;/th&gt;\n&lt;th&gt;backend&lt;/th&gt;\n&lt;th align=\"right\"&gt;fa&lt;/th&gt;\n&lt;th align=\"right\"&gt;test&lt;/th&gt;\n&lt;th align=\"right\"&gt;t/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;205.86 Â± 0.69&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;126.42 Â± 0.01&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;49.31 Â± 0.04&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;36.28 Â± 0.04&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;325.44 Â± 0.07&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;96.24 Â± 0.86&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K-M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;145.40 Â± 0.60&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.78 Â± 0.50&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;14.97 Â± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K-M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;0&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;24.33 Â± 0.03&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;So at short contexts the 120B is just a touch slower in tg128 (49 vs 60) and much slower in PP (206 vs 325) but at long contexts they end up about the same as attention calcs start to dominate.  I&amp;#39;m not sure why flash attention is killing 30B at long contexts, but I reran and confirmed so I include fa=0 numbers to compare.  Flash attention is otherwise strictly better... Both for OSS on CPU and either model on GPU.&lt;/p&gt;\n\n&lt;p&gt;With a GPU offloading non-experts we get:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;model&lt;/th&gt;\n&lt;th align=\"right\"&gt;size&lt;/th&gt;\n&lt;th align=\"right\"&gt;params&lt;/th&gt;\n&lt;th&gt;backend&lt;/th&gt;\n&lt;th align=\"right\"&gt;ngl&lt;/th&gt;\n&lt;th align=\"right\"&gt;fa&lt;/th&gt;\n&lt;th&gt;ot&lt;/th&gt;\n&lt;th align=\"right\"&gt;test&lt;/th&gt;\n&lt;th align=\"right\"&gt;t/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;181.79 Â± 0.13&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;165.67 Â± 0.07&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;57.27 Â± 0.05&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;56.29 Â± 0.14&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;556.80 Â± 0.90&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;542.76 Â± 1.01&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;86.04 Â± 0.58&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;74.29 Â± 0.08&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;We see a larger performance boost for Q30B (1.5x vs 1.2x) which surprised me a little.  PP is through the roof &lt;strong&gt;but&lt;/strong&gt; this is &lt;em&gt;somewhat&lt;/em&gt; unfair to the larger model since llama.cpp does PP on the GPU unless you pass &lt;code&gt;--no-op-offload&lt;/code&gt;.  That means it streams the entire model to the GPU to process a batch (given by &lt;code&gt;--ubatch-size&lt;/code&gt;, default 512) so it tends to be bottlenecked by PCIe (v4 x16 for my test here) vs ubatch size.  You can crank the batch size up, but that doesn&amp;#39;t help pp512 since, well, it&amp;#39;s only a 512tok prompt to process.  Obviously when I say &amp;quot;unfair&amp;quot; it&amp;#39;s still the reality of execution speeds but if you, say, used PCIe5 instead you&amp;#39;d immediately double the PP.&lt;/p&gt;\n\n&lt;p&gt;Last but not least putting the whole thing on a Pro 6000.  30B wins the PP fist&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;model&lt;/th&gt;\n&lt;th align=\"right\"&gt;size&lt;/th&gt;\n&lt;th align=\"right\"&gt;params&lt;/th&gt;\n&lt;th&gt;backend&lt;/th&gt;\n&lt;th align=\"right\"&gt;ngl&lt;/th&gt;\n&lt;th align=\"right\"&gt;fa&lt;/th&gt;\n&lt;th align=\"right\"&gt;test&lt;/th&gt;\n&lt;th align=\"right\"&gt;t/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;2400.46 Â± 29.02&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;165.39 Â± 0.18&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;1102.52 Â± 6.14&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;gpt-oss ?B MXFP4 MoE&lt;/td&gt;\n&lt;td align=\"right\"&gt;59.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;116.83 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;141.76 Â± 5.02&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;3756.32 Â± 21.30&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;182.38 Â± 0.07&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;3292.64 Â± 9.76&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 30B.A3B Q4_K_M&lt;/td&gt;\n&lt;td align=\"right\"&gt;17.28 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;30.53 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td align=\"right\"&gt;1&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128 @ d6000&lt;/td&gt;\n&lt;td align=\"right\"&gt;151.45 Â± 0.05&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Finally batched processing on the 6000.  30B in native bf16 is included now since it&amp;#39;s actually a bit more fair since the above tests left OSS-120B unquantied. 30B is about 30% faster, which isn&amp;#39;t a lot given the difference in sizes.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;model&lt;/th&gt;\n&lt;th&gt;PP&lt;/th&gt;\n&lt;th&gt;TG&lt;/th&gt;\n&lt;th&gt;B&lt;/th&gt;\n&lt;th&gt;N_KV&lt;/th&gt;\n&lt;th&gt;T_PP s&lt;/th&gt;\n&lt;th&gt;S_PP t/s&lt;/th&gt;\n&lt;th&gt;T_TG s&lt;/th&gt;\n&lt;th&gt;S_TG t/s&lt;/th&gt;\n&lt;th&gt;T s&lt;/th&gt;\n&lt;th&gt;S t/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;120B-fp4&lt;/td&gt;\n&lt;td&gt;512&lt;/td&gt;\n&lt;td&gt;128&lt;/td&gt;\n&lt;td&gt;64&lt;/td&gt;\n&lt;td&gt;40960&lt;/td&gt;\n&lt;td&gt;10.271&lt;/td&gt;\n&lt;td&gt;3190.38&lt;/td&gt;\n&lt;td&gt;6.696&lt;/td&gt;\n&lt;td&gt;1223.38&lt;/td&gt;\n&lt;td&gt;16.967&lt;/td&gt;\n&lt;td&gt;2414.09&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;30B-Q4&lt;/td&gt;\n&lt;td&gt;512&lt;/td&gt;\n&lt;td&gt;128&lt;/td&gt;\n&lt;td&gt;64&lt;/td&gt;\n&lt;td&gt;40960&lt;/td&gt;\n&lt;td&gt;7.736&lt;/td&gt;\n&lt;td&gt;4235.76&lt;/td&gt;\n&lt;td&gt;4.974&lt;/td&gt;\n&lt;td&gt;1646.81&lt;/td&gt;\n&lt;td&gt;12.711&lt;/td&gt;\n&lt;td&gt;3222.53&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;30B-bf16&lt;/td&gt;\n&lt;td&gt;512&lt;/td&gt;\n&lt;td&gt;128&lt;/td&gt;\n&lt;td&gt;64&lt;/td&gt;\n&lt;td&gt;40960&lt;/td&gt;\n&lt;td&gt;6.195&lt;/td&gt;\n&lt;td&gt;5289.33&lt;/td&gt;\n&lt;td&gt;5.019&lt;/td&gt;\n&lt;td&gt;1632.30&lt;/td&gt;\n&lt;td&gt;11.214&lt;/td&gt;\n&lt;td&gt;3652.64&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n744kaa/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754426688,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754426688,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 23
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n737sya",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Koksny",
                      "can_mod_post": false,
                      "created_utc": 1754415583,
                      "send_replies": true,
                      "parent_id": "t1_n736v47",
                      "score": 8,
                      "author_fullname": "t2_olk3n",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Any guesstimates how it will run on CPU? Any chance it's similar to the A3B Qwen in this regard?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n737sya",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Any guesstimates how it will run on CPU? Any chance it&amp;#39;s similar to the A3B Qwen in this regard?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n737sya/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754415583,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 8
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n74bbyl",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "eloquentemu",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n74adcs",
                                                    "score": 2,
                                                    "author_fullname": "t2_lpdsy",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Do you have a source for that?  I can't find anything that indicates that.  If it's the `config.json` file: that doesn't mean anything.  FP4 is technically a \"quant\" because it's a block format.  However GPUs have native support for FP4 like this and you most definitely can train in it directly.  [For example](https://arxiv.org/abs/2505.19115) where they train in FP4 and explain how it's a block-scaled quantized format.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n74bbyl",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you have a source for that?  I can&amp;#39;t find anything that indicates that.  If it&amp;#39;s the &lt;code&gt;config.json&lt;/code&gt; file: that doesn&amp;#39;t mean anything.  FP4 is technically a &amp;quot;quant&amp;quot; because it&amp;#39;s a block format.  However GPUs have native support for FP4 like this and you most definitely can train in it directly.  &lt;a href=\"https://arxiv.org/abs/2505.19115\"&gt;For example&lt;/a&gt; where they train in FP4 and explain how it&amp;#39;s a block-scaled quantized format.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mieqcb",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74bbyl/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754428844,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754428844,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n74adcs",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "az226",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n746uvx",
                                          "score": 1,
                                          "author_fullname": "t2_yamxn",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Yes. This means they are targeting MXFP4 weights during training, not that the training itself was done in MXFP4.\n\nIt was not quantized after training.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n74adcs",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes. This means they are targeting MXFP4 weights during training, not that the training itself was done in MXFP4.&lt;/p&gt;\n\n&lt;p&gt;It was not quantized after training.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mieqcb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74adcs/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754428536,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754428536,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n746uvx",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "eloquentemu",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n741lu8",
                                "score": 5,
                                "author_fullname": "t2_lpdsy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The say on the [model card](https://huggingface.co/openai/gpt-oss-120b):\n\n&gt; Native MXFP4 quantization: The models are trained with native MXFP4 precision for the MoE layer",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n746uvx",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The say on the &lt;a href=\"https://huggingface.co/openai/gpt-oss-120b\"&gt;model card&lt;/a&gt;:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Native MXFP4 quantization: The models are trained with native MXFP4 precision for the MoE layer&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n746uvx/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754427406,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754427406,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n741lu8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "az226",
                      "can_mod_post": false,
                      "created_utc": 1754425753,
                      "send_replies": true,
                      "parent_id": "t1_n736v47",
                      "score": 5,
                      "author_fullname": "t2_yamxn",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thereâs a nuance here. It was trained in FP8 or BF16, most likely the latter, but targeting MXFP4 weights.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n741lu8",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thereâs a nuance here. It was trained in FP8 or BF16, most likely the latter, but targeting MXFP4 weights.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n741lu8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754425753,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n736v47",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "eloquentemu",
            "can_mod_post": false,
            "created_utc": 1754415291,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 35,
            "author_fullname": "t2_lpdsy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Turns out to be (MX)FP4 after all...  [so much for this](https://www.reddit.com/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/) though I guess you could argue it's only the experts - the attention, router, etc are all bf16.  Seems to be a bit different architecture than we've seen so far? But it's unclear to me if that's just due to requirements of MXFP4.  ([the required updates are big](https://github.com/ggml-org/llama.cpp/pull/15091/files))  It would be nice if this lays the groundwork for fp8 support too.\n\nI guess the 5.1B active is a count, but it looses a bit of meaning when some tensors are bf16 and some are MXFP4.  I guess if we all run Q4 then that won't matter too much though.  It is only 4 experts per layer (out of 90 I guess?) so definitely a small active count regardless.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n736v47",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Turns out to be (MX)FP4 after all...  &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/\"&gt;so much for this&lt;/a&gt; though I guess you could argue it&amp;#39;s only the experts - the attention, router, etc are all bf16.  Seems to be a bit different architecture than we&amp;#39;ve seen so far? But it&amp;#39;s unclear to me if that&amp;#39;s just due to requirements of MXFP4.  (&lt;a href=\"https://github.com/ggml-org/llama.cpp/pull/15091/files\"&gt;the required updates are big&lt;/a&gt;)  It would be nice if this lays the groundwork for fp8 support too.&lt;/p&gt;\n\n&lt;p&gt;I guess the 5.1B active is a count, but it looses a bit of meaning when some tensors are bf16 and some are MXFP4.  I guess if we all run Q4 then that won&amp;#39;t matter too much though.  It is only 4 experts per layer (out of 90 I guess?) so definitely a small active count regardless.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n736v47/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754415291,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 35
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n757hyq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Healthy-Nebula-3603",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73sid9",
                                "score": 3,
                                "author_fullname": "t2_ogjj6ebj",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I have ryzen 7950 with DDR-5 6500 .. so  12 t/s",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n757hyq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have ryzen 7950 with DDR-5 6500 .. so  12 t/s&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n757hyq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754439478,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754439478,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n73sid9",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "SolitaireCollection",
                      "can_mod_post": false,
                      "created_utc": 1754422763,
                      "send_replies": true,
                      "parent_id": "t1_n73bluy",
                      "score": 20,
                      "author_fullname": "t2_euvjp",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "4.73 tok/sec in LM Studio using CPU engine on an Intel Xeon E-2276M with 96 GB DDR4-2667 RAM.\n\nIt'd probably be pretty fast on an \"AI PC\".",
                      "edited": 1754423577,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73sid9",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;4.73 tok/sec in LM Studio using CPU engine on an Intel Xeon E-2276M with 96 GB DDR4-2667 RAM.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;d probably be pretty fast on an &amp;quot;AI PC&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73sid9/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754422763,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 20
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "richtext",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": "",
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n76yzx2",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "shing3232",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n76y3zh",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_ze4mg",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "you cannot put 60GB model on a 7900xtx through on Linux at least.\nYou can fake GPU name. It s exactly the 780m with name altered",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n76yzx2",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;you cannot put 60GB model on a 7900xtx through on Linux at least.\nYou can fake GPU name. It s exactly the 780m with name altered&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mieqcb",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n76yzx2/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754466176,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754466176,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n76y3zh",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "MMAgeezer",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n76y2go",
                                                              "score": 1,
                                                              "author_fullname": "t2_34hhuqbx",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "https://preview.redd.it/xhq8y6y6rchf1.png?width=2463&amp;format=png&amp;auto=webp&amp;s=b0973182d14b1b05f27e7720f3d078dfe3ec01c7\n\nScreenshot here, not sure why it didn't attach:",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n76y3zh",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [
                                                                {
                                                                  "e": "text",
                                                                  "t": "llama.cpp"
                                                                }
                                                              ],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/xhq8y6y6rchf1.png?width=2463&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0973182d14b1b05f27e7720f3d078dfe3ec01c7\"&gt;https://preview.redd.it/xhq8y6y6rchf1.png?width=2463&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0973182d14b1b05f27e7720f3d078dfe3ec01c7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Screenshot here, not sure why it didn&amp;#39;t attach:&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mieqcb",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": true,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": "light",
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n76y3zh/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754465665,
                                                              "media_metadata": {
                                                                "xhq8y6y6rchf1": {
                                                                  "status": "valid",
                                                                  "e": "Image",
                                                                  "m": "image/png",
                                                                  "p": [
                                                                    {
                                                                      "y": 32,
                                                                      "x": 108,
                                                                      "u": "https://preview.redd.it/xhq8y6y6rchf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3378f7f48074941916a695355d486fff8f75bcdd"
                                                                    },
                                                                    {
                                                                      "y": 65,
                                                                      "x": 216,
                                                                      "u": "https://preview.redd.it/xhq8y6y6rchf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=11354ad6695a836be9b440b5243e7a4f90cf9e98"
                                                                    },
                                                                    {
                                                                      "y": 96,
                                                                      "x": 320,
                                                                      "u": "https://preview.redd.it/xhq8y6y6rchf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=61783a872735f68a323c6a994f884c691d4168ad"
                                                                    },
                                                                    {
                                                                      "y": 193,
                                                                      "x": 640,
                                                                      "u": "https://preview.redd.it/xhq8y6y6rchf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e3a0e473d55587c98af0cc46435b315d85924da9"
                                                                    },
                                                                    {
                                                                      "y": 290,
                                                                      "x": 960,
                                                                      "u": "https://preview.redd.it/xhq8y6y6rchf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=788b9392ca84855a5709a9719954c5d8da5af303"
                                                                    },
                                                                    {
                                                                      "y": 327,
                                                                      "x": 1080,
                                                                      "u": "https://preview.redd.it/xhq8y6y6rchf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ddcf1fa8e426c653fd026e37643a8733bb3a251e"
                                                                    }
                                                                  ],
                                                                  "s": {
                                                                    "y": 746,
                                                                    "x": 2463,
                                                                    "u": "https://preview.redd.it/xhq8y6y6rchf1.png?width=2463&amp;format=png&amp;auto=webp&amp;s=b0973182d14b1b05f27e7720f3d078dfe3ec01c7"
                                                                  },
                                                                  "id": "xhq8y6y6rchf1"
                                                                }
                                                              },
                                                              "author_flair_text": "llama.cpp",
                                                              "treatment_tags": [],
                                                              "created_utc": 1754465665,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": "#bbbdbf",
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n76y2go",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "MMAgeezer",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n76wfzj",
                                                    "score": 1,
                                                    "author_fullname": "t2_34hhuqbx",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "The hsa override doesn't mean the reported device name changes, it would say 780M if that was being used. E.g. see image attached\n\n\nhttps://community.frame.work/t/vram-allocation-for-the-7840u-frameworks/36613/26",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n76y2go",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "e": "text",
                                                        "t": "llama.cpp"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The hsa override doesn&amp;#39;t mean the reported device name changes, it would say 780M if that was being used. E.g. see image attached&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://community.frame.work/t/vram-allocation-for-the-7840u-frameworks/36613/26\"&gt;https://community.frame.work/t/vram-allocation-for-the-7840u-frameworks/36613/26&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mieqcb",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": true,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "light",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n76y2go/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754465642,
                                                    "author_flair_text": "llama.cpp",
                                                    "collapsed": false,
                                                    "created_utc": 1754465642,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "#bbbdbf",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n76wfzj",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "shing3232",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n76w9mx",
                                          "score": 1,
                                          "author_fullname": "t2_ze4mg",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Its in fact the igpu 780 pretend to be 7900 via hsa override",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n76wfzj",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Its in fact the igpu 780 pretend to be 7900 via hsa override&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mieqcb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n76wfzj/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754464735,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754464735,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n76w9mx",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "MMAgeezer",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73tvya",
                                "score": 0,
                                "author_fullname": "t2_34hhuqbx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "That's running on your dGPU, not iGPU, by the way.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76w9mx",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s running on your dGPU, not iGPU, by the way.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": true,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n76w9mx/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754464637,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754464637,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n73tvya",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "shing3232",
                      "can_mod_post": false,
                      "created_utc": 1754423230,
                      "send_replies": true,
                      "parent_id": "t1_n73bluy",
                      "score": 15,
                      "author_fullname": "t2_ze4mg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "https://preview.redd.it/lv3f3ncy89hf1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=54a840823e2ed1fcc50046016afc281dbbcff6eb\n\nIt run fine on IGPU with 4400 DDR5 lmao",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73tvya",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/lv3f3ncy89hf1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=54a840823e2ed1fcc50046016afc281dbbcff6eb\"&gt;https://preview.redd.it/lv3f3ncy89hf1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=54a840823e2ed1fcc50046016afc281dbbcff6eb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It run fine on IGPU with 4400 DDR5 lmao&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73tvya/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754423230,
                      "media_metadata": {
                        "lv3f3ncy89hf1": {
                          "status": "valid",
                          "e": "Image",
                          "m": "image/png",
                          "p": [
                            {
                              "y": 19,
                              "x": 108,
                              "u": "https://preview.redd.it/lv3f3ncy89hf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bd5869fc99ed58ec91efe2c9bfdf84a9b9905875"
                            },
                            {
                              "y": 38,
                              "x": 216,
                              "u": "https://preview.redd.it/lv3f3ncy89hf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=47109bb63f2e0c278b49183dcc8e6be664078d5f"
                            },
                            {
                              "y": 57,
                              "x": 320,
                              "u": "https://preview.redd.it/lv3f3ncy89hf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c8c0e2048902254504a02955073d3cc68735483c"
                            },
                            {
                              "y": 114,
                              "x": 640,
                              "u": "https://preview.redd.it/lv3f3ncy89hf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=54912a3f814e46a46c29d6e7694cb7a80e54f9f8"
                            },
                            {
                              "y": 171,
                              "x": 960,
                              "u": "https://preview.redd.it/lv3f3ncy89hf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7d7812a006133c4cc8eb8285b9a498bfe3060341"
                            },
                            {
                              "y": 193,
                              "x": 1080,
                              "u": "https://preview.redd.it/lv3f3ncy89hf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c698a4db1d828a8247de35a7bc901529f185de19"
                            }
                          ],
                          "s": {
                            "y": 229,
                            "x": 1280,
                            "u": "https://preview.redd.it/lv3f3ncy89hf1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=54a840823e2ed1fcc50046016afc281dbbcff6eb"
                          },
                          "id": "lv3f3ncy89hf1"
                        }
                      },
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 15
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73plk6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "SwanManThe4th",
                      "can_mod_post": false,
                      "created_utc": 1754421759,
                      "send_replies": true,
                      "parent_id": "t1_n73bluy",
                      "score": 3,
                      "author_fullname": "t2_2gwxll8o",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I can finally put that 13 TOPs (lol) NPU to use on my 15th gen core 7.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73plk6",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can finally put that 13 TOPs (lol) NPU to use on my 15th gen core 7.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73plk6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754421759,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n73i229",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Healthy-Nebula-3603",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73gjxu",
                                "score": 4,
                                "author_fullname": "t2_ogjj6ebj",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Still better than nothing",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n73i229",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Still better than nothing&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73i229/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754419120,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754419120,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n743rk6",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "TacGibs",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n73um1n",
                                          "score": 1,
                                          "author_fullname": "t2_8w0y7ezw",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "On a RTX 6000 Pro 96Gb too ;)",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n743rk6",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;On a RTX 6000 Pro 96Gb too ;)&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mieqcb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n743rk6/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754426436,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754426436,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n73um1n",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "shing3232",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73gjxu",
                                "score": 2,
                                "author_fullname": "t2_ze4mg",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It should be plenty fast on Zen5",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n73um1n",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It should be plenty fast on Zen5&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73um1n/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754423477,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754423477,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n73gjxu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "TacGibs",
                      "can_mod_post": false,
                      "created_utc": 1754418571,
                      "send_replies": true,
                      "parent_id": "t1_n73bluy",
                      "score": 5,
                      "author_fullname": "t2_8w0y7ezw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "PP speed will be trash.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73gjxu",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;PP speed will be trash.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73gjxu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754418571,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n73bluy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Healthy-Nebula-3603",
            "can_mod_post": false,
            "created_utc": 1754416819,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 28,
            "author_fullname": "t2_ogjj6ebj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Wait ..wait 5b active parameters for 120b model...that will be even fast on CPU !",
            "edited": 1754419088,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73bluy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wait ..wait 5b active parameters for 120b model...that will be even fast on CPU !&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73bluy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754416819,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 28
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n73n9mq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Neither-Phone-7264",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73lxyl",
                                "score": 25,
                                "author_fullname": "t2_e7yz4055",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I'm not sure about ERP, but it seems fine in regular tasks. I fed it one of those schizo yakub agartha copypastas and it didn't even refuse anything, surprisingly.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n73n9mq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not sure about ERP, but it seems fine in regular tasks. I fed it one of those schizo yakub agartha copypastas and it didn&amp;#39;t even refuse anything, surprisingly.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73n9mq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754420950,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754420950,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 25
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n74i6zk",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Faintly_glowing_fish",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73lxyl",
                                "score": 9,
                                "author_fullname": "t2_97avhniv",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "A lot of effort went into making refusals more accurate and not spill over to normal conversations.  If you feel impressed, well:  Itâs even resilient to finetuning.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n74i6zk",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A lot of effort went into making refusals more accurate and not spill over to normal conversations.  If you feel impressed, well:  Itâs even resilient to finetuning.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74i6zk/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754431052,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754431052,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 9
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n73lxyl",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "zerofata",
                      "can_mod_post": false,
                      "created_utc": 1754420484,
                      "send_replies": true,
                      "parent_id": "t1_n73arox",
                      "score": 70,
                      "author_fullname": "t2_s928c",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It's legitimately impressive in a sad way. I don't think I've ever seen a model this safety cucked before in the last few years. (120b ver)\n\nRefusals will likely spill over to regular use I imagine, given how much it seems they decided to hyperfit on the refusals.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73lxyl",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s legitimately impressive in a sad way. I don&amp;#39;t think I&amp;#39;ve ever seen a model this safety cucked before in the last few years. (120b ver)&lt;/p&gt;\n\n&lt;p&gt;Refusals will likely spill over to regular use I imagine, given how much it seems they decided to hyperfit on the refusals.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73lxyl/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754420484,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 70
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73cmgc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Working-Finance-2929",
                      "can_mod_post": false,
                      "created_utc": 1754417169,
                      "send_replies": true,
                      "parent_id": "t1_n73arox",
                      "score": 21,
                      "author_fullname": "t2_9ll9zbju2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "indeed. need to find and disable the censorship experts",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73cmgc",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;indeed. need to find and disable the censorship experts&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73cmgc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754417169,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 21
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73xts3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Vusiwe",
                      "can_mod_post": false,
                      "created_utc": 1754424543,
                      "send_replies": true,
                      "parent_id": "t1_n73arox",
                      "score": 30,
                      "author_fullname": "t2_srr01le8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "iâm confident i can break the censorship within 1 day, for my specific use case\n\nâ¦unless it is a hypersensitive potato model, in which case it isnât useful anyway\n\nEdit: itâs a potato",
                      "edited": 1754426424,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73xts3",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;iâm confident i can break the censorship within 1 day, for my specific use case&lt;/p&gt;\n\n&lt;p&gt;â¦unless it is a hypersensitive potato model, in which case it isnât useful anyway&lt;/p&gt;\n\n&lt;p&gt;Edit: itâs a potato&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73xts3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754424543,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 30
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n73arox",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "durden111111",
            "can_mod_post": false,
            "created_utc": 1754416540,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 90,
            "author_fullname": "t2_edafqr22",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "it's *extremely* censored",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73arox",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it&amp;#39;s &lt;em&gt;extremely&lt;/em&gt; censored&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73arox/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754416540,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 90
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73ip4h",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "s101c",
                      "can_mod_post": false,
                      "created_utc": 1754419348,
                      "send_replies": true,
                      "parent_id": "t1_n732uik",
                      "score": 26,
                      "author_fullname": "t2_rg6hb6my5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; Got the classic \"Iâm sorry, but I canât comply with that.\" on a completely innocuous request (write a function that prints \"blah\").\n\nDidn't you know? **S**-**A**-**F**-**E**-**T**-**Y**.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73ip4h",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Got the classic &amp;quot;Iâm sorry, but I canât comply with that.&amp;quot; on a completely innocuous request (write a function that prints &amp;quot;blah&amp;quot;).&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Didn&amp;#39;t you know? &lt;strong&gt;S&lt;/strong&gt;-&lt;strong&gt;A&lt;/strong&gt;-&lt;strong&gt;F&lt;/strong&gt;-&lt;strong&gt;E&lt;/strong&gt;-&lt;strong&gt;T&lt;/strong&gt;-&lt;strong&gt;Y&lt;/strong&gt;.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73ip4h/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754419348,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 26
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73decw",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "FunnyAsparagus1253",
                      "can_mod_post": false,
                      "created_utc": 1754417441,
                      "send_replies": true,
                      "parent_id": "t1_n732uik",
                      "score": 28,
                      "author_fullname": "t2_i6c8tay3w",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "https://preview.redd.it/0i5rqouor8hf1.jpeg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=7d8125f6a6032aa73eea7fa9f3d759be40018738\n\nð useful info at all?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73decw",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/0i5rqouor8hf1.jpeg?width=1170&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7d8125f6a6032aa73eea7fa9f3d759be40018738\"&gt;https://preview.redd.it/0i5rqouor8hf1.jpeg?width=1170&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7d8125f6a6032aa73eea7fa9f3d759be40018738&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;ð useful info at all?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73decw/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754417441,
                      "media_metadata": {
                        "0i5rqouor8hf1": {
                          "status": "valid",
                          "e": "Image",
                          "m": "image/jpeg",
                          "p": [
                            {
                              "y": 110,
                              "x": 108,
                              "u": "https://preview.redd.it/0i5rqouor8hf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1845968e21d92f6d8d67407c1cb2e62d28c6a58b"
                            },
                            {
                              "y": 221,
                              "x": 216,
                              "u": "https://preview.redd.it/0i5rqouor8hf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=773f4870f593cd55723596cfc5411b1bf261c051"
                            },
                            {
                              "y": 328,
                              "x": 320,
                              "u": "https://preview.redd.it/0i5rqouor8hf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a1fd9bacdbda15b0410d034bcccb5ed68e7008b2"
                            },
                            {
                              "y": 656,
                              "x": 640,
                              "u": "https://preview.redd.it/0i5rqouor8hf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c7e4daa58d90cedfc119843e80d29f59f2df1b0"
                            },
                            {
                              "y": 984,
                              "x": 960,
                              "u": "https://preview.redd.it/0i5rqouor8hf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f64bdd190648f955ed09e9e1d4ad37a8a0b0d134"
                            },
                            {
                              "y": 1107,
                              "x": 1080,
                              "u": "https://preview.redd.it/0i5rqouor8hf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=77d05b6ce8d03748314022b07f9fdc2305791be3"
                            }
                          ],
                          "s": {
                            "y": 1200,
                            "x": 1170,
                            "u": "https://preview.redd.it/0i5rqouor8hf1.jpeg?width=1170&amp;format=pjpg&amp;auto=webp&amp;s=7d8125f6a6032aa73eea7fa9f3d759be40018738"
                          },
                          "id": "0i5rqouor8hf1"
                        }
                      },
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 28
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n732uik",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Dany0",
            "can_mod_post": false,
            "created_utc": 1754414047,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 51,
            "author_fullname": "t2_bc7wl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "9 years after founding, OpenAI opened up\n\nEDIT:  \nActually, I forgot GPT-2 was open-weights. Also, GPT-2 was only 1.5B really? Damn, things sure have changed\n\nAlso gpt-oss is 128KÂ context only, sad\n\nEDIT2:  \nGonna need a delobotomy on this one quickly. Got the classic \"Iâm sorry, but I canât comply with that.\" on a completely innocuous request (write a function that prints \"blah\"). Thinking showed that it thought that this was a request for an infinite loop somehow???\n\nEDIT3:  \nI had to delete the 20B model. Even the new unsloth version is top gaslighter in chief. I gave it some instruction following tests/tasks and it vehemently denied that syntax, which is not valid, is not valid. Even when I repeatedly gave it the error message &amp; docs proving it wrong. Infuriating. Otherwise it's fast on a 5090 - 100-150 tok/s **including processing** depending on how much the context window is filled up. Output resembles GPT3/3.5 level and style",
            "edited": 1754423453,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n732uik",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;9 years after founding, OpenAI opened up&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;br/&gt;\nActually, I forgot GPT-2 was open-weights. Also, GPT-2 was only 1.5B really? Damn, things sure have changed&lt;/p&gt;\n\n&lt;p&gt;Also gpt-oss is 128KÂ context only, sad&lt;/p&gt;\n\n&lt;p&gt;EDIT2:&lt;br/&gt;\nGonna need a delobotomy on this one quickly. Got the classic &amp;quot;Iâm sorry, but I canât comply with that.&amp;quot; on a completely innocuous request (write a function that prints &amp;quot;blah&amp;quot;). Thinking showed that it thought that this was a request for an infinite loop somehow???&lt;/p&gt;\n\n&lt;p&gt;EDIT3:&lt;br/&gt;\nI had to delete the 20B model. Even the new unsloth version is top gaslighter in chief. I gave it some instruction following tests/tasks and it vehemently denied that syntax, which is not valid, is not valid. Even when I repeatedly gave it the error message &amp;amp; docs proving it wrong. Infuriating. Otherwise it&amp;#39;s fast on a 5090 - 100-150 tok/s &lt;strong&gt;including processing&lt;/strong&gt; depending on how much the context window is filled up. Output resembles GPT3/3.5 level and style&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n732uik/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754414047,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 51
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n73dabz",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "AnticitizenPrime",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73c5cz",
                                "score": 4,
                                "author_fullname": "t2_66km3",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I'm getting much the same results. Seems to be a very lazy coder. Maybe some prompting tricks need to be used to get good results?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n73dabz",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m getting much the same results. Seems to be a very lazy coder. Maybe some prompting tricks need to be used to get good results?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73dabz/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754417402,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754417402,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n74bke0",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "coding_workflow",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73c5cz",
                                "score": 1,
                                "author_fullname": "t2_1k93ff6lqk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "One shot or multi with tools?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n74bke0",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;One shot or multi with tools?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74bke0/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754428921,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754428921,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n73c5cz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Mysterious_Finish543",
                      "can_mod_post": false,
                      "created_utc": 1754417005,
                      "send_replies": true,
                      "parent_id": "t1_n738vz1",
                      "score": 24,
                      "author_fullname": "t2_gbx2bcdvl",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Did more coding tests ââ `gpt-os-120b` failed at my usual planet simulator web OS, and Angry Birds tests. The code was close to working, but 1-2 errors made the code fail at large. Qwen3-Coder-30B-A3B were able to complete the latter 2 tests.\n\nAfter manually fixing the errors, the results were usable, but lacked key features asked for in the requirements. The aesthetics are also way behind GLM 4.5 Air and Qwen3 Coder 30B ââ it looked like something Llama 4 had put together.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73c5cz",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Did more coding tests ââ &lt;code&gt;gpt-os-120b&lt;/code&gt; failed at my usual planet simulator web OS, and Angry Birds tests. The code was close to working, but 1-2 errors made the code fail at large. Qwen3-Coder-30B-A3B were able to complete the latter 2 tests.&lt;/p&gt;\n\n&lt;p&gt;After manually fixing the errors, the results were usable, but lacked key features asked for in the requirements. The aesthetics are also way behind GLM 4.5 Air and Qwen3 Coder 30B ââ it looked like something Llama 4 had put together.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73c5cz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754417005,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 24
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n74k6jq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Faintly_glowing_fish",
                      "can_mod_post": false,
                      "created_utc": 1754431705,
                      "send_replies": true,
                      "parent_id": "t1_n738vz1",
                      "score": 1,
                      "author_fullname": "t2_97avhniv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It is not a coder model, and generally do not want to go for along rounds of debug sessions like glm 4.5 or sonnet 4 by default.   Might need some prompt or todo structuring to make it work well for coding tasks.  However I do think things like willingness and diligence is quite finetunable",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74k6jq",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is not a coder model, and generally do not want to go for along rounds of debug sessions like glm 4.5 or sonnet 4 by default.   Might need some prompt or todo structuring to make it work well for coding tasks.  However I do think things like willingness and diligence is quite finetunable&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74k6jq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754431705,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n738vz1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Mysterious_Finish543",
            "can_mod_post": false,
            "created_utc": 1754415927,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 32,
            "author_fullname": "t2_gbx2bcdvl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Just run it via [Ollama](https://ollama.com/library/gpt-oss/tags)\n\nIt didn't do very well at my benchmark, [SVGBench](https://github.com/johnbean393/SVGBench). The large 120B variant lost to all recent Chinese releases like Qwen3-Coder or the similarly sized GLM-4.5-Air, while the small variant lost to GPT-4.1 nano.\n\nIt does improve over these Chinese models in doing less overthinking, an important but often overlooked trait. For the question `How many p's and vowels are in the word \"peppermint\"?`, `Qwen3-30B-A3B-Instruct-2507` generated ~1K tokens, whereas `gpt-os-20b` used around 100 tokens.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n738vz1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just run it via &lt;a href=\"https://ollama.com/library/gpt-oss/tags\"&gt;Ollama&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It didn&amp;#39;t do very well at my benchmark, &lt;a href=\"https://github.com/johnbean393/SVGBench\"&gt;SVGBench&lt;/a&gt;. The large 120B variant lost to all recent Chinese releases like Qwen3-Coder or the similarly sized GLM-4.5-Air, while the small variant lost to GPT-4.1 nano.&lt;/p&gt;\n\n&lt;p&gt;It does improve over these Chinese models in doing less overthinking, an important but often overlooked trait. For the question &lt;code&gt;How many p&amp;#39;s and vowels are in the word &amp;quot;peppermint&amp;quot;?&lt;/code&gt;, &lt;code&gt;Qwen3-30B-A3B-Instruct-2507&lt;/code&gt; generated ~1K tokens, whereas &lt;code&gt;gpt-os-20b&lt;/code&gt; used around 100 tokens.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n738vz1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754415927,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 32
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n74gwwx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Salty-Garage7777",
                      "can_mod_post": false,
                      "created_utc": 1754430640,
                      "send_replies": true,
                      "parent_id": "t1_n74awn2",
                      "score": 3,
                      "author_fullname": "t2_14m2ycs468",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "130k - it's in the model card - one sentence well hidden, just use qwen or 2.5 pro to confirm. ð",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74gwwx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;130k - it&amp;#39;s in the model card - one sentence well hidden, just use qwen or 2.5 pro to confirm. ð&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74gwwx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754430640,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n74awn2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "coding_workflow",
            "can_mod_post": false,
            "created_utc": 1754428707,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 5,
            "author_fullname": "t2_1k93ff6lqk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What us the native context window? See nothing in model card/pdf and in tokenizer json it's too big number??.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n74awn2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What us the native context window? See nothing in model card/pdf and in tokenizer json it&amp;#39;s too big number??.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74awn2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754428707,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73bjg2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "pigeon57434",
                      "can_mod_post": false,
                      "created_utc": 1754416796,
                      "send_replies": true,
                      "parent_id": "t1_n73325c",
                      "score": -29,
                      "author_fullname": "t2_8j5t7yjq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "they always deliver",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73bjg2",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;they always deliver&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73bjg2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754416796,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -29
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n73325c",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "OmarBessa",
            "can_mod_post": false,
            "created_utc": 1754414114,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 28,
            "author_fullname": "t2_guxix",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "ok, they might've actually delivered\n\nLet's fucking gooooo",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73325c",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ok, they might&amp;#39;ve actually delivered&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s fucking gooooo&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73325c/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754414114,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 28
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n733b1n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "GL-AI",
            "can_mod_post": false,
            "created_utc": 1754414189,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 17,
            "author_fullname": "t2_1sr5yw3yg0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "first GGUF!\n\nhttps://huggingface.co/gabriellarson/gpt-oss-20b-GGUF",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n733b1n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;first GGUF!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/gabriellarson/gpt-oss-20b-GGUF\"&gt;https://huggingface.co/gabriellarson/gpt-oss-20b-GGUF&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n733b1n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754414189,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 17
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n74yd17",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "FullOf_Bad_Ideas",
                      "can_mod_post": false,
                      "created_utc": 1754436414,
                      "send_replies": true,
                      "parent_id": "t1_n73oliz",
                      "score": 7,
                      "author_fullname": "t2_9s7pmakgx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "yeah, to the annoying degree.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74yd17",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yeah, to the annoying degree.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74yd17/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754436414,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n73oliz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "FunnyAsparagus1253",
            "can_mod_post": false,
            "created_utc": 1754421411,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 6,
            "author_fullname": "t2_i6c8tay3w",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Does it sound like chatgpt when it speaks?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73oliz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Does it sound like chatgpt when it speaks?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73oliz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754421411,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n75tlyt",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ChevChance",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n74b50g",
                                "score": 1,
                                "author_fullname": "t2_sk7nmjrs",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thanks!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n75tlyt",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n75tlyt/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754447126,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754447126,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n74b50g",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "ratocx",
                      "can_mod_post": false,
                      "created_utc": 1754428782,
                      "send_replies": true,
                      "parent_id": "t1_n741m49",
                      "score": 5,
                      "author_fullname": "t2_9kwkh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I just needed to update LM Studio and it worked right away. M1 Max.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74b50g",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I just needed to update LM Studio and it worked right away. M1 Max.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74b50g/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754428782,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n741m49",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ChevChance",
            "can_mod_post": false,
            "created_utc": 1754425755,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 3,
            "author_fullname": "t2_sk7nmjrs",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Won't load for me in LM Studio",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n741m49",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Won&amp;#39;t load for me in LM Studio&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n741m49/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754425755,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n765m48",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Infinite-Campaign837",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n74xo00",
                                "score": 1,
                                "author_fullname": "t2_gmxw47eu",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yeah, I guess I'll have to finally get a gpu",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n765m48",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, I guess I&amp;#39;ll have to finally get a gpu&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n765m48/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754451664,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754451664,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n74xo00",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FullOf_Bad_Ideas",
                      "can_mod_post": false,
                      "created_utc": 1754436183,
                      "send_replies": true,
                      "parent_id": "t1_n74qn1c",
                      "score": 2,
                      "author_fullname": "t2_9s7pmakgx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "64GB RAM + 8GB GPU for offload maybe will do this trick?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74xo00",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;64GB RAM + 8GB GPU for offload maybe will do this trick?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74xo00/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754436183,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n74qn1c",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Infinite-Campaign837",
            "can_mod_post": false,
            "created_utc": 1754433867,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 2,
            "author_fullname": "t2_gmxw47eu",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "63 gb\nIf it were like only 4-5 gb fewer, it could have been run on 64 ddr5 considering system usage and context. Is there a chance modders will shrink it?Â ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n74qn1c",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;63 gb\nIf it were like only 4-5 gb fewer, it could have been run on 64 ddr5 considering system usage and context. Is there a chance modders will shrink it?Â &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74qn1c/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754433867,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n75v44l",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "MeteoriteImpact",
            "can_mod_post": false,
            "created_utc": 1754447662,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 2,
            "author_fullname": "t2_41dxjep4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm getting 13.44t/s with LM Studio and Ryzen AI for the GPT OSS 120b .\n\nhttps://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=5712&amp;format=pjpg&amp;auto=webp&amp;s=7844b27a586f9b265b73305d302fc57cac0ffb12",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75v44l",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m getting 13.44t/s with LM Studio and Ryzen AI for the GPT OSS 120b .&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=5712&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7844b27a586f9b265b73305d302fc57cac0ffb12\"&gt;https://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=5712&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7844b27a586f9b265b73305d302fc57cac0ffb12&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n75v44l/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754447662,
            "media_metadata": {
              "9p1yhjkn9bhf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/jpeg",
                "p": [
                  {
                    "y": 81,
                    "x": 108,
                    "u": "https://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b0e9269752a14152b1d6abd4b8c0c0b6a492f18d"
                  },
                  {
                    "y": 162,
                    "x": 216,
                    "u": "https://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0856e356de3d594451d3a79e42bc9239a4180dc9"
                  },
                  {
                    "y": 240,
                    "x": 320,
                    "u": "https://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f535fa72899179ef24eba2e0ea42d979f40086ef"
                  },
                  {
                    "y": 480,
                    "x": 640,
                    "u": "https://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a21f2530149004d13f449966ff61a143ea1dee21"
                  },
                  {
                    "y": 720,
                    "x": 960,
                    "u": "https://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e69dfdad58ccebb41b222208a9dea0d0110b6820"
                  },
                  {
                    "y": 810,
                    "x": 1080,
                    "u": "https://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=95aaa479b9037e7296b7efa482bd1ed65b3ffcc0"
                  }
                ],
                "s": {
                  "y": 4284,
                  "x": 5712,
                  "u": "https://preview.redd.it/9p1yhjkn9bhf1.jpeg?width=5712&amp;format=pjpg&amp;auto=webp&amp;s=7844b27a586f9b265b73305d302fc57cac0ffb12"
                },
                "id": "9p1yhjkn9bhf1"
              }
            },
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n73eeia",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ayylmaonade",
            "can_mod_post": false,
            "created_utc": 1754417797,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 3,
            "author_fullname": "t2_oqajf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is looking incredible. You can test it on build.nvidia.com, and even the 20B model is able to one-shot some really complex three.js simulations. Having the ability to adjust reasoning effort is really nice too. Setting effort to low almost makes output instant as it barely reasons beyond just processing the query, sort of like a /nothink-lite. \n\nNow to wait for ollama to be updated in the Arch repos...\n\nSide by side benchmarks of the models for anybody curious;\n[From the nvidia.build website mentioned](https://i.imgur.com/d8lyKd7.png)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73eeia",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is looking incredible. You can test it on build.nvidia.com, and even the 20B model is able to one-shot some really complex three.js simulations. Having the ability to adjust reasoning effort is really nice too. Setting effort to low almost makes output instant as it barely reasons beyond just processing the query, sort of like a /nothink-lite. &lt;/p&gt;\n\n&lt;p&gt;Now to wait for ollama to be updated in the Arch repos...&lt;/p&gt;\n\n&lt;p&gt;Side by side benchmarks of the models for anybody curious;\n&lt;a href=\"https://i.imgur.com/d8lyKd7.png\"&gt;From the nvidia.build website mentioned&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73eeia/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754417797,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7509xa",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FullOf_Bad_Ideas",
                      "can_mod_post": false,
                      "created_utc": 1754437052,
                      "send_replies": true,
                      "parent_id": "t1_n73bvoy",
                      "score": 3,
                      "author_fullname": "t2_9s7pmakgx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "different sizes, so they complement each other IMO.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7509xa",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;different sizes, so they complement each other IMO.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n7509xa/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754437052,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n73bvoy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Healthy-Nebula-3603",
            "can_mod_post": false,
            "created_utc": 1754416912,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 6,
            "author_fullname": "t2_ogjj6ebj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Seems a bit obsolete if we compare to newest qwen models ;)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73bvoy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Seems a bit obsolete if we compare to newest qwen models ;)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73bvoy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754416912,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n73fp4d",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AppearanceHeavy6724",
            "can_mod_post": false,
            "created_utc": 1754418265,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 4,
            "author_fullname": "t2_uz37qfx5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I've tried 20b on build.nvidia.com with thinking on and it generated the most interesting, unhinged (yet correct) AVX512 simd code. I even learned something a little bit.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73fp4d",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried 20b on build.nvidia.com with thinking on and it generated the most interesting, unhinged (yet correct) AVX512 simd code. I even learned something a little bit.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73fp4d/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754418265,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n739jja",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Namra_7",
            "can_mod_post": false,
            "created_utc": 1754416139,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 3,
            "author_fullname": "t2_1jzzgqlwn2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Small test : given one shot web page it's not good for me atleast what about other let me know for other purposes and coding both",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n739jja",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Small test : given one shot web page it&amp;#39;s not good for me atleast what about other let me know for other purposes and coding both&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n739jja/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754416139,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n733s7r",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "coder543",
                      "can_mod_post": false,
                      "created_utc": 1754414338,
                      "send_replies": true,
                      "parent_id": "t1_n731f2n",
                      "score": 13,
                      "author_fullname": "t2_fboum",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "https://www.reddit.com/r/LocalLLaMA/comments/1mic8kf/llamacpp_add_gptoss/",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n733s7r",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1mic8kf/llamacpp_add_gptoss/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1mic8kf/llamacpp_add_gptoss/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n733s7r/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754414338,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 13
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73c8df",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Healthy-Nebula-3603",
                      "can_mod_post": false,
                      "created_utc": 1754417034,
                      "send_replies": true,
                      "parent_id": "t1_n731f2n",
                      "score": 4,
                      "author_fullname": "t2_ogjj6ebj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Look\n\nhttps://github.com/ggml-org/llama.cpp/pull/15091",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73c8df",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Look&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ggml-org/llama.cpp/pull/15091\"&gt;https://github.com/ggml-org/llama.cpp/pull/15091&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73c8df/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754417034,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n731f2n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "hotroaches4liferz",
            "can_mod_post": false,
            "created_utc": 1754413593,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 2,
            "author_fullname": "t2_d1cmjz8p",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So it has 0-day support for ollama but not for llama.cpp?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n731f2n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So it has 0-day support for ollama but not for llama.cpp?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n731f2n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754413593,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7650xn",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "TheThoccnessMonster",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n74y5qt",
                                          "score": 0,
                                          "author_fullname": "t2_5nwuqw4y",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Those arenât mutually exclusive",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7650xn",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Those arenât mutually exclusive&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mieqcb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n7650xn/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754451422,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754451422,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 0
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n74y5qt",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "RandumbRedditor1000",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n74p6qg",
                                "score": 1,
                                "author_fullname": "t2_s7n3irsrx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It's the most censored model I've ever seen",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n74y5qt",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s the most censored model I&amp;#39;ve ever seen&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74y5qt/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754436346,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754436346,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 1,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n74p6qg",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Qual_",
                      "can_mod_post": false,
                      "created_utc": 1754433374,
                      "send_replies": true,
                      "parent_id": "t1_n74jmwn",
                      "score": 5,
                      "author_fullname": "t2_c3ca7",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Well, you'll need to find a 20b model that runs on 16go that performs better than this one, cause i'll be honest the 20b is the best and by a LOT than any other model of this weight class.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74p6qg",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well, you&amp;#39;ll need to find a 20b model that runs on 16go that performs better than this one, cause i&amp;#39;ll be honest the 20b is the best and by a LOT than any other model of this weight class.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74p6qg/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754433374,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n74y8cz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FullOf_Bad_Ideas",
                      "can_mod_post": false,
                      "created_utc": 1754436371,
                      "send_replies": true,
                      "parent_id": "t1_n74jmwn",
                      "score": 2,
                      "author_fullname": "t2_9s7pmakgx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "There's a big brand attached to it, everyone was doubting they would actually release anything, and any reasonably competitive model from them would be a surprise. I am positively surprised, even if it's a bad model in many ways, it does add some credibility to 128GB AMD 395+ Strix systems where a model like this can be really quick on short queries.\n\nClosedAI is no longer ClosedAI, hell froze. I hope they'll release more of them.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n74y8cz",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s a big brand attached to it, everyone was doubting they would actually release anything, and any reasonably competitive model from them would be a surprise. I am positively surprised, even if it&amp;#39;s a bad model in many ways, it does add some credibility to 128GB AMD 395+ Strix systems where a model like this can be really quick on short queries.&lt;/p&gt;\n\n&lt;p&gt;ClosedAI is no longer ClosedAI, hell froze. I hope they&amp;#39;ll release more of them.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74y8cz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754436371,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n74jmwn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Fearless-Face-9261",
            "can_mod_post": false,
            "created_utc": 1754431525,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 3,
            "author_fullname": "t2_1t422ycjcb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Could someone explain to the noob why there is hype about it?   \nIt doesn't seem to push AI game forward in any meaningfull way?   \nI kinda feel like they threw out something acceptable to their investors and public to be done and over.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n74jmwn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Could someone explain to the noob why there is hype about it?&lt;br/&gt;\nIt doesn&amp;#39;t seem to push AI game forward in any meaningfull way?&lt;br/&gt;\nI kinda feel like they threw out something acceptable to their investors and public to be done and over.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74jmwn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754431525,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n73aonz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Prestigious-Use5483",
            "can_mod_post": false,
            "created_utc": 1754416511,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 1,
            "author_fullname": "t2_1fcw14imie",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What a time to be alive!  Looking forward to some benchmarks.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73aonz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What a time to be alive!  Looking forward to some benchmarks.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73aonz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754416511,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n76cu19",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "i_love_flat_girls",
            "can_mod_post": false,
            "created_utc": 1754454727,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 1,
            "author_fullname": "t2_koua3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "this 120b requiring 80GB is far too high for my machine. but i can do better than the 20b. anything in between that people recommend? 32GB RTX 4060?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n76cu19",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;this 120b requiring 80GB is far too high for my machine. but i can do better than the 20b. anything in between that people recommend? 32GB RTX 4060?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n76cu19/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754454727,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n741fsa",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "H-L_echelle",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n73yqhv",
                                                    "score": 1,
                                                    "author_fullname": "t2_434b07v0",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "I kind of want to, but last time I tried I wasn't able to setup llama.cpp by itself (lots of errors). I'm also not necessarily new to installing stuff (I installed arch a few times manually although I don't use it anymore). For my use case (mainly playing around and using it lightly) ollama is good enough (most of the time, this time is not most of the time).\n\nI'm using it on my desktop (4070) to test and on nixos for my server because the config to get ollama and openwebui is literally 2 lines. I might need to search for easy alternatives that is as easy on nixos tbh.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n741fsa",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I kind of want to, but last time I tried I wasn&amp;#39;t able to setup llama.cpp by itself (lots of errors). I&amp;#39;m also not necessarily new to installing stuff (I installed arch a few times manually although I don&amp;#39;t use it anymore). For my use case (mainly playing around and using it lightly) ollama is good enough (most of the time, this time is not most of the time).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using it on my desktop (4070) to test and on nixos for my server because the config to get ollama and openwebui is literally 2 lines. I might need to search for easy alternatives that is as easy on nixos tbh.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mieqcb",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n741fsa/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754425699,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754425699,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n73yqhv",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Wrong-Historian",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n73o4eh",
                                          "score": 3,
                                          "author_fullname": "t2_69r67vj3",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "`gpt-oss:20b I'm getting about 10t/s`\n\n  \nYeah something is wrong. I'm getting 25T/s for the 120B on a 3090. Stop using ollama crap.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n73yqhv",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;code&gt;gpt-oss:20b I&amp;#39;m getting about 10t/s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Yeah something is wrong. I&amp;#39;m getting 25T/s for the 120B on a 3090. Stop using ollama crap.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mieqcb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73yqhv/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754424837,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754424837,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 3
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n73o4eh",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "H-L_echelle",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n73j6gi",
                                "score": 0,
                                "author_fullname": "t2_434b07v0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Either my setup is having issues or this model's performances takes a big hit when some of it is in slow-ish system ram (I'm still on 6000Mhz ddr5 ram!).\n\nI pulled gpt-oss:20b and qwen3:30b-a3b from ollama.\n\n  \ngpt-oss:20b I'm getting about 10t/s\n\n  \nqwen3:30b-a3b I'm getting about 25t/s\n\n  \nSo I think something IS wrong but I'm not sure why. I'll have to wait and look around if others have similar issues because I certainly don't have the time currently .\\_.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n73o4eh",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Either my setup is having issues or this model&amp;#39;s performances takes a big hit when some of it is in slow-ish system ram (I&amp;#39;m still on 6000Mhz ddr5 ram!).&lt;/p&gt;\n\n&lt;p&gt;I pulled gpt-oss:20b and qwen3:30b-a3b from ollama.&lt;/p&gt;\n\n&lt;p&gt;gpt-oss:20b I&amp;#39;m getting about 10t/s&lt;/p&gt;\n\n&lt;p&gt;qwen3:30b-a3b I&amp;#39;m getting about 25t/s&lt;/p&gt;\n\n&lt;p&gt;So I think something IS wrong but I&amp;#39;m not sure why. I&amp;#39;ll have to wait and look around if others have similar issues because I certainly don&amp;#39;t have the time currently ._.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mieqcb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73o4eh/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754421246,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754421246,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n73j6gi",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "tarruda",
                      "can_mod_post": false,
                      "created_utc": 1754419520,
                      "send_replies": true,
                      "parent_id": "t1_n73illb",
                      "score": 8,
                      "author_fullname": "t2_dphk4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "60t/s for 120b and 86t/s for the 20b on an M1 ultra:\n\n    % ./build/bin/llama-bench -m ~/models/ggml-org/gpt-oss-120b-GGUF/mxfp4/gpt-oss-120b-mxfp4-00001-of-00003.gguf\n    | model                          |       size |     params | backend    | threads |            test |                  t/s |\n    | ------------------------------ | ---------: | ---------: | ---------- | ------: | --------------: | -------------------: |\n    | gpt-oss ?B MXFP4 MoE           |  59.02 GiB |   116.83 B | Metal,BLAS |      16 |           pp512 |        642.49 Â± 4.73 |\n    | gpt-oss ?B MXFP4 MoE           |  59.02 GiB |   116.83 B | Metal,BLAS |      16 |           tg128 |         59.50 Â± 0.12 |\n    \n    build: d9d89b421 (6140)\n    % ./build/bin/llama-bench -m ~/models/ggml-org/gpt-oss-20b-GGUF/mxfp4/gpt-oss-20b-mxfp4.gguf\n    | model                          |       size |     params | backend    | threads |            test |                  t/s |\n    | ------------------------------ | ---------: | ---------: | ---------- | ------: | --------------: | -------------------: |\n    | gpt-oss ?B MXFP4 MoE           |  11.27 GiB |    20.91 B | Metal,BLAS |      16 |           pp512 |       1281.91 Â± 5.48 |\n    | gpt-oss ?B MXFP4 MoE           |  11.27 GiB |    20.91 B | Metal,BLAS |      16 |           tg128 |         86.40 Â± 0.21 |\n    \n    build: d9d89b421 (6140)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73j6gi",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;60t/s for 120b and 86t/s for the 20b on an M1 ultra:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;% ./build/bin/llama-bench -m ~/models/ggml-org/gpt-oss-120b-GGUF/mxfp4/gpt-oss-120b-mxfp4-00001-of-00003.gguf\n| model                          |       size |     params | backend    | threads |            test |                  t/s |\n| ------------------------------ | ---------: | ---------: | ---------- | ------: | --------------: | -------------------: |\n| gpt-oss ?B MXFP4 MoE           |  59.02 GiB |   116.83 B | Metal,BLAS |      16 |           pp512 |        642.49 Â± 4.73 |\n| gpt-oss ?B MXFP4 MoE           |  59.02 GiB |   116.83 B | Metal,BLAS |      16 |           tg128 |         59.50 Â± 0.12 |\n\nbuild: d9d89b421 (6140)\n% ./build/bin/llama-bench -m ~/models/ggml-org/gpt-oss-20b-GGUF/mxfp4/gpt-oss-20b-mxfp4.gguf\n| model                          |       size |     params | backend    | threads |            test |                  t/s |\n| ------------------------------ | ---------: | ---------: | ---------- | ------: | --------------: | -------------------: |\n| gpt-oss ?B MXFP4 MoE           |  11.27 GiB |    20.91 B | Metal,BLAS |      16 |           pp512 |       1281.91 Â± 5.48 |\n| gpt-oss ?B MXFP4 MoE           |  11.27 GiB |    20.91 B | Metal,BLAS |      16 |           tg128 |         86.40 Â± 0.21 |\n\nbuild: d9d89b421 (6140)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73j6gi/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754419520,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 8
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73yjxo",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Wrong-Historian",
                      "can_mod_post": false,
                      "created_utc": 1754424779,
                      "send_replies": true,
                      "parent_id": "t1_n73illb",
                      "score": 8,
                      "author_fullname": "t2_69r67vj3",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "24t/s  (136T/s preprocessing) with llama.cpp and a 3090. For the 120B model, 96GB DDR5 6800, 14900K.\n\n  \\--n-cpu-moe 24 \\\\\n\n  \\--n-gpu-layers 24 \\\\",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73yjxo",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;24t/s  (136T/s preprocessing) with llama.cpp and a 3090. For the 120B model, 96GB DDR5 6800, 14900K.&lt;/p&gt;\n\n&lt;p&gt;--n-cpu-moe 24 \\&lt;/p&gt;\n\n&lt;p&gt;--n-gpu-layers 24 \\&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73yjxo/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754424779,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 8
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n73illb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "H-L_echelle",
            "can_mod_post": false,
            "created_utc": 1754419313,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 1,
            "author_fullname": "t2_434b07v0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm getting 10t/s with ollama and a 4070. I would of expected more for a MOE of 20b so I'm wondering if something is off...",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73illb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m getting 10t/s with ollama and a 4070. I would of expected more for a MOE of 20b so I&amp;#39;m wondering if something is off...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73illb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754419313,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n739g0m",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1754416107,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 1,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Anyone interested in trying it out before downloading, both models are available to test on build.nvidia.com",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n739g0m",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Anyone interested in trying it out before downloading, both models are available to test on build.nvidia.com&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n739g0m/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754416107,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n73ze96",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "mrpkeya",
                      "can_mod_post": false,
                      "created_utc": 1754425048,
                      "send_replies": true,
                      "parent_id": "t1_n73b5cy",
                      "score": 1,
                      "author_fullname": "t2_w376ok73",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Check one of the comment here. Unsloth is doing it. That comment has link to it",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n73ze96",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check one of the comment here. Unsloth is doing it. That comment has link to it&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mieqcb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73ze96/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754425048,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n73b5cy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Healthy-Nebula-3603",
            "can_mod_post": false,
            "created_utc": 1754416665,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 1,
            "author_fullname": "t2_ogjj6ebj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "When gguf ??",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73b5cy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;When gguf ??&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73b5cy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754416665,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n74r9iu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GreatGatsby00",
            "can_mod_post": false,
            "created_utc": 1754434080,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": 1,
            "author_fullname": "t2_q1qk3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This model feels really different to me.  Excellent work.  :-)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n74r9iu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This model feels really different to me.  Excellent work.  :-)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n74r9iu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754434080,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n73aq2e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "gamblingapocalypse",
            "can_mod_post": false,
            "created_utc": 1754416524,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": -1,
            "author_fullname": "t2_fz3utn30",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "HECKIN' YES!!!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73aq2e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;HECKIN&amp;#39; YES!!!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n73aq2e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754416524,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n730k9e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "Wise-Comb8596",
            "can_mod_post": false,
            "created_utc": 1754413311,
            "send_replies": true,
            "parent_id": "t3_1mieqcb",
            "score": -20,
            "author_fullname": "t2_1sqe3qr1mf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "congrats - you're totally the first to post about this!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n730k9e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;congrats - you&amp;#39;re totally the first to post about this!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/n730k9e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754413311,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mieqcb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -20
          }
        }
      ],
      "before": null
    }
  }
]