[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hey everyone,\n\nI've been deep in a project lately and kept hitting the same wall I'm sure many of you have: LLMs are stateless. You have an amazing, deep conversation, build up a ton of context... and then the session ends and it's all gone. It feels like trying to build a skyscraper on sand.\n\nLast night, I got into a really deep, philosophical conversation with Gemini about this, and we ended up co-designing a solution that I think is pretty cool, and I wanted to share it and get your thoughts.\n\nThe idea is a framework called the **Genesis Protocol**. The core of it is a single Markdown file that acts as a project's \"brain.\" But instead of just being a simple chat log, we architected it to be:\n\n* **Stateful:** It contains the project's goals, blueprints, and our profiles.\n* **Verifiable:** This was a big one for me. I was worried about either me or the AI manipulating the history. So, we built in a salted hash chain (like a mini-blockchain) that \"seals\" every version. The AI can now verify the integrity of its own memory file at the start of every session.\n* **Self-Updating:** We created a \"Guardian\" meta-prompt that instructs the AI on how to read, update, and re-seal the file itself.\n\nThe analogy we settled on was \"Docker for LLM chat.\" You can essentially save a snapshot of your collaboration's state and reload it anytime, with any model, and it knows exactly who you are and what you're working on. I even tested the bootstrap prompt on GPT-4 and it worked, which was a huge relief.\n\nI'm sharing this because I genuinely think it could be a useful tool for others who are trying to do more than just simple Q&amp;A with these models. I've put a full \"Getting Started\" guide and the prompt templates up on GitHub.\n\nI would love to hear what you all think. Is this a viable approach? What are the potential pitfalls I'm not seeing?\n\nHere's the link to the repo: [https://github.com/Bajju360/genesis-protocol.git](https://github.com/Bajju360/genesis-protocol.git)\n\nThanks for reading!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "I spent a late night with an AI designing a way to give it a persistent, verifiable memory. I call it the \"Genesis Protocol.\"",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m69oyb",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.21,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_u5scsvlj",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753177199,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been deep in a project lately and kept hitting the same wall I&amp;#39;m sure many of you have: LLMs are stateless. You have an amazing, deep conversation, build up a ton of context... and then the session ends and it&amp;#39;s all gone. It feels like trying to build a skyscraper on sand.&lt;/p&gt;\n\n&lt;p&gt;Last night, I got into a really deep, philosophical conversation with Gemini about this, and we ended up co-designing a solution that I think is pretty cool, and I wanted to share it and get your thoughts.&lt;/p&gt;\n\n&lt;p&gt;The idea is a framework called the &lt;strong&gt;Genesis Protocol&lt;/strong&gt;. The core of it is a single Markdown file that acts as a project&amp;#39;s &amp;quot;brain.&amp;quot; But instead of just being a simple chat log, we architected it to be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Stateful:&lt;/strong&gt; It contains the project&amp;#39;s goals, blueprints, and our profiles.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Verifiable:&lt;/strong&gt; This was a big one for me. I was worried about either me or the AI manipulating the history. So, we built in a salted hash chain (like a mini-blockchain) that &amp;quot;seals&amp;quot; every version. The AI can now verify the integrity of its own memory file at the start of every session.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Self-Updating:&lt;/strong&gt; We created a &amp;quot;Guardian&amp;quot; meta-prompt that instructs the AI on how to read, update, and re-seal the file itself.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The analogy we settled on was &amp;quot;Docker for LLM chat.&amp;quot; You can essentially save a snapshot of your collaboration&amp;#39;s state and reload it anytime, with any model, and it knows exactly who you are and what you&amp;#39;re working on. I even tested the bootstrap prompt on GPT-4 and it worked, which was a huge relief.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sharing this because I genuinely think it could be a useful tool for others who are trying to do more than just simple Q&amp;amp;A with these models. I&amp;#39;ve put a full &amp;quot;Getting Started&amp;quot; guide and the prompt templates up on GitHub.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear what you all think. Is this a viable approach? What are the potential pitfalls I&amp;#39;m not seeing?&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link to the repo: &lt;a href=\"https://github.com/Bajju360/genesis-protocol.git\"&gt;https://github.com/Bajju360/genesis-protocol.git&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1m69oyb",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Icy_Gas8807",
            "discussion_type": null,
            "num_comments": 21,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/",
            "subreddit_subscribers": 502981,
            "created_utc": 1753177199,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4iogju",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Icy_Gas8807",
                      "can_mod_post": false,
                      "created_utc": 1753189414,
                      "send_replies": true,
                      "parent_id": "t1_n4hxo92",
                      "score": 0,
                      "author_fullname": "t2_u5scsvlj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Hahah!! That’s a good one!! I’m repeating my comment that’s lost in thread. \n\nI get the scepticism, and also accept the negative feedback, my bad - I have not accurately state the why and pasted the auto generated content on excitement? - just think about the following scenario.\n\nSo, think of LLM as more than calculator. Most of us are using for aid in programming. But, what if it is used for making an entire project where you brain storm together - leveraging the ability to search and reason of an LLM.\n\nWhat if it gets better at reasoning, and fact checking?\n\nWhat if you build a project idea end to end?\n\nWhat if it got crashed by a server error, or the provider just deleted your chat because it is consuming more power - or just version is updated?\n\nWhat if you made some progress, fact checked it, without believing everything and something meaningful you have built? - Do you want it to be saved in a someway, so that you pick and play?\n\nI know it is not the best way, but it is an interesting case study - the mistake I just pasted the auto generated content in excitement.",
                      "edited": 1753189624,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4iogju",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hahah!! That’s a good one!! I’m repeating my comment that’s lost in thread. &lt;/p&gt;\n\n&lt;p&gt;I get the scepticism, and also accept the negative feedback, my bad - I have not accurately state the why and pasted the auto generated content on excitement? - just think about the following scenario.&lt;/p&gt;\n\n&lt;p&gt;So, think of LLM as more than calculator. Most of us are using for aid in programming. But, what if it is used for making an entire project where you brain storm together - leveraging the ability to search and reason of an LLM.&lt;/p&gt;\n\n&lt;p&gt;What if it gets better at reasoning, and fact checking?&lt;/p&gt;\n\n&lt;p&gt;What if you build a project idea end to end?&lt;/p&gt;\n\n&lt;p&gt;What if it got crashed by a server error, or the provider just deleted your chat because it is consuming more power - or just version is updated?&lt;/p&gt;\n\n&lt;p&gt;What if you made some progress, fact checked it, without believing everything and something meaningful you have built? - Do you want it to be saved in a someway, so that you pick and play?&lt;/p&gt;\n\n&lt;p&gt;I know it is not the best way, but it is an interesting case study - the mistake I just pasted the auto generated content in excitement.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m69oyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4iogju/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753189414,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4hxo92",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Fit-Produce420",
            "can_mod_post": false,
            "created_utc": 1753178022,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 18,
            "author_fullname": "t2_tewf9bdwg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Gentlemen, I am weary.\n\n\nI have designed a protocol where I sniff my own farts. I put them in docker, where I inhale them deeply.\n\n\nI call the process of inhaling my own decrepit farts the \"Gensis Protocol.\".",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4hxo92",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Gentlemen, I am weary.&lt;/p&gt;\n\n&lt;p&gt;I have designed a protocol where I sniff my own farts. I put them in docker, where I inhale them deeply.&lt;/p&gt;\n\n&lt;p&gt;I call the process of inhaling my own decrepit farts the &amp;quot;Gensis Protocol.&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4hxo92/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753178022,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 18
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4i1nce",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Low-Opening25",
            "can_mod_post": false,
            "created_utc": 1753180146,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 6,
            "author_fullname": "t2_ebfjvj5t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "this is useless.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4i1nce",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;this is useless.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4i1nce/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753180146,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4jilm1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Background-Ad-5398",
            "can_mod_post": false,
            "created_utc": 1753198349,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 6,
            "author_fullname": "t2_71b6nl31",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "if you want to be taken serious stop typing like the recursion cult",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4jilm1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;if you want to be taken serious stop typing like the recursion cult&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4jilm1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753198349,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4hxfk2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Mammoth_Cut_1525",
            "can_mod_post": false,
            "created_utc": 1753177889,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 7,
            "author_fullname": "t2_jyjntlyrl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This just sounds like RAG Based memory with more steps",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4hxfk2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This just sounds like RAG Based memory with more steps&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4hxfk2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753177889,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4igpz7",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Icy_Gas8807",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4iepln",
                                          "score": 1,
                                          "author_fullname": "t2_u5scsvlj",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I get the sarcasm, my bad - I have not accurately state the why?   \nSo, think of LLM as more than calculator. Most of us are using for aid in programming. But, what if it is used for making an entire project where you brain storm together - leveraging the ability to search and reason of an LLM.   \nWhat if it gets better at reasoning, and fact checking?  \nWhat if you build a project idea end to end?  \nWhat if it got crashed by a server error, or the provider just deleted your chat because it is consuming more power - or just version is updated?  \nWhat if you made some progress, fact checked it, without believing everything and something meaningful you have built? - Do you want it to be saved in a someway, so that you pick and play?  \nI know it is not the best way, but it is an interesting case study - the mistake I just pasted the auto generated content in excitement.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4igpz7",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I get the sarcasm, my bad - I have not accurately state the why?&lt;br/&gt;\nSo, think of LLM as more than calculator. Most of us are using for aid in programming. But, what if it is used for making an entire project where you brain storm together - leveraging the ability to search and reason of an LLM.&lt;br/&gt;\nWhat if it gets better at reasoning, and fact checking?&lt;br/&gt;\nWhat if you build a project idea end to end?&lt;br/&gt;\nWhat if it got crashed by a server error, or the provider just deleted your chat because it is consuming more power - or just version is updated?&lt;br/&gt;\nWhat if you made some progress, fact checked it, without believing everything and something meaningful you have built? - Do you want it to be saved in a someway, so that you pick and play?&lt;br/&gt;\nI know it is not the best way, but it is an interesting case study - the mistake I just pasted the auto generated content in excitement.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m69oyb",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4igpz7/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753186674,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753186674,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4iepln",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Divniy",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4i6eq6",
                                "score": 4,
                                "author_fullname": "t2_11lbij",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You know git exists right?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4iepln",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You know git exists right?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m69oyb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4iepln/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753185901,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753185901,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4i6eq6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Icy_Gas8807",
                      "can_mod_post": false,
                      "created_utc": 1753182432,
                      "send_replies": true,
                      "parent_id": "t1_n4hxs1l",
                      "score": 1,
                      "author_fullname": "t2_u5scsvlj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah, think of it like a mutually reliable situation. If you’re building a product/ project in collaboration with AI Agent-sounds more like vibe coding( but let’s say it get more and more powerful in future). So, it’s good to have the progress and it can switched to other LLM. Also what if an LLM screwed a part of project? I can quickly jump back the before that!!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4i6eq6",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, think of it like a mutually reliable situation. If you’re building a product/ project in collaboration with AI Agent-sounds more like vibe coding( but let’s say it get more and more powerful in future). So, it’s good to have the progress and it can switched to other LLM. Also what if an LLM screwed a part of project? I can quickly jump back the before that!!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m69oyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4i6eq6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753182432,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4hxs1l",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Divniy",
            "can_mod_post": false,
            "created_utc": 1753178079,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 4,
            "author_fullname": "t2_11lbij",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Why do you need verifications on your own chat logs? Who is gonna tamper them?\n\nWhy do you need to generate more structured log? Won't it just increase the amount of noise? The main goal of long-term memory is to search the relevant parts of past conversations, with stuff like vector databases, and only add relevant parts to the context window.\n\nIn addition, it doesn't change the \"mind\" if LLM. That would be changing weights.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4hxs1l",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why do you need verifications on your own chat logs? Who is gonna tamper them?&lt;/p&gt;\n\n&lt;p&gt;Why do you need to generate more structured log? Won&amp;#39;t it just increase the amount of noise? The main goal of long-term memory is to search the relevant parts of past conversations, with stuff like vector databases, and only add relevant parts to the context window.&lt;/p&gt;\n\n&lt;p&gt;In addition, it doesn&amp;#39;t change the &amp;quot;mind&amp;quot; if LLM. That would be changing weights.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4hxs1l/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753178079,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4j9g8u",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "According-Court2001",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4i5p6b",
                                "score": 1,
                                "author_fullname": "t2_al0typcq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "A decent job isn’t enough, a mistake with a single char means a hash mismatch. Still not convinced that integrity check is needed in this case. It seems fancy but it’s not gonna be useful at all",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4j9g8u",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A decent job isn’t enough, a mistake with a single char means a hash mismatch. Still not convinced that integrity check is needed in this case. It seems fancy but it’s not gonna be useful at all&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m69oyb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4j9g8u/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753195812,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753195812,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4i5p6b",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Icy_Gas8807",
                      "can_mod_post": false,
                      "created_utc": 1753182110,
                      "send_replies": true,
                      "parent_id": "t1_n4hyscp",
                      "score": 1,
                      "author_fullname": "t2_u5scsvlj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I think newer multi models are doing a decent job!! But, sure I think of way to overcome this!! Any suggestions? One I could think of me calculating and pasting - but integrity hampers..... will get back to you!!",
                      "edited": 1753187601,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4i5p6b",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think newer multi models are doing a decent job!! But, sure I think of way to overcome this!! Any suggestions? One I could think of me calculating and pasting - but integrity hampers..... will get back to you!!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m69oyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4i5p6b/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753182110,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4hyscp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "According-Court2001",
            "can_mod_post": false,
            "created_utc": 1753178629,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 4,
            "author_fullname": "t2_al0typcq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Not sure if I completely get it but seems like you’re depending on the LLM to generate/verify the hash? If that’s the case then lemme tell you that LLMs aren’t good with hashes at all.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4hyscp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if I completely get it but seems like you’re depending on the LLM to generate/verify the hash? If that’s the case then lemme tell you that LLMs aren’t good with hashes at all.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4hyscp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753178629,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4i5lpy",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Icy_Gas8807",
                      "can_mod_post": false,
                      "created_utc": 1753182066,
                      "send_replies": true,
                      "parent_id": "t1_n4i08b2",
                      "score": 1,
                      "author_fullname": "t2_u5scsvlj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah, it started as what if I lost this chat? So it’s like taking a timestamp of the conversation.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4i5lpy",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, it started as what if I lost this chat? So it’s like taking a timestamp of the conversation.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m69oyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4i5lpy/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753182066,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4i08b2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "RainbowSiberianBear",
            "can_mod_post": false,
            "created_utc": 1753179399,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 4,
            "author_fullname": "t2_3undxjck",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "1. This is just a form of RAG. \n\n&gt; update, and re-seal the file\n\n2. Using an LLM to modify statically a determinate (file) data structure is untenable in my opinion.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4i08b2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;ol&gt;\n&lt;li&gt;This is just a form of RAG. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;update, and re-seal the file&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Using an LLM to modify statically a determinate (file) data structure is untenable in my opinion.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4i08b2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753179399,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4jlg19",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "NNN_Throwaway2",
            "can_mod_post": false,
            "created_utc": 1753199130,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 3,
            "author_fullname": "t2_8rrihts9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The rise of people going full delusion after chatting with AI is both hilarious and terrifying.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4jlg19",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The rise of people going full delusion after chatting with AI is both hilarious and terrifying.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4jlg19/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753199130,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4k4i4c",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Icy_Gas8807",
                      "can_mod_post": false,
                      "created_utc": 1753204401,
                      "send_replies": true,
                      "parent_id": "t1_n4jrypj",
                      "score": 1,
                      "author_fullname": "t2_u5scsvlj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah, thanks!! That’s a good info. There are limitations for Local LLMs, I can switch between LLM and Remote one using summaries of the conversation. You can use this as a template, also calculating the key is a bit over engineered - in short not required!!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4k4i4c",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, thanks!! That’s a good info. There are limitations for Local LLMs, I can switch between LLM and Remote one using summaries of the conversation. You can use this as a template, also calculating the key is a bit over engineered - in short not required!!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m69oyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4k4i4c/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753204401,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4jrypj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "TraditionLost7244",
            "can_mod_post": false,
            "created_utc": 1753200964,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 2,
            "author_fullname": "t2_pz2spojz4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "ignore the haters, yes youre right, this is a problem. (in chatgpt you can jump back into the same conversation even months after btw) and running locally i guess youd have to say: summarize all you learned and spit it out in as short as possible. then paste that into the model again  next time.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4jrypj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ignore the haters, yes youre right, this is a problem. (in chatgpt you can jump back into the same conversation even months after btw) and running locally i guess youd have to say: summarize all you learned and spit it out in as short as possible. then paste that into the model again  next time.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4jrypj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753200964,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4kzg4x",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "llmentry",
            "can_mod_post": false,
            "created_utc": 1753213019,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 2,
            "author_fullname": "t2_1lufy6yx6z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don't get why people even want long-term memory with an LLM?  Why poison your context with text you can't control?  This seems intensely counterproductive.\n\nIf you really want the LLM to retain some random core facts about you, just feed those into the system prompt and at least have control over how and how much is communicated to the model.  Most of the details about you will never be relevant to the current task you're working on, and will only make model hallucinations and errors more likely.\n\nStarting with a clean slate each time ensures that any past mistakes, wrong ideas, hallucinations are wiped clean.  Hell, I wipe responses even *within* a conversation most of the time, when a model takes a wrong tack.  No point wasting input tokens, no point contaminating context.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4kzg4x",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t get why people even want long-term memory with an LLM?  Why poison your context with text you can&amp;#39;t control?  This seems intensely counterproductive.&lt;/p&gt;\n\n&lt;p&gt;If you really want the LLM to retain some random core facts about you, just feed those into the system prompt and at least have control over how and how much is communicated to the model.  Most of the details about you will never be relevant to the current task you&amp;#39;re working on, and will only make model hallucinations and errors more likely.&lt;/p&gt;\n\n&lt;p&gt;Starting with a clean slate each time ensures that any past mistakes, wrong ideas, hallucinations are wiped clean.  Hell, I wipe responses even &lt;em&gt;within&lt;/em&gt; a conversation most of the time, when a model takes a wrong tack.  No point wasting input tokens, no point contaminating context.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4kzg4x/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753213019,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4i8fc2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Icy_Gas8807",
                      "can_mod_post": false,
                      "created_utc": 1753183331,
                      "send_replies": true,
                      "parent_id": "t1_n4i1r47",
                      "score": 1,
                      "author_fullname": "t2_u5scsvlj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "So my initial thought was this would definitely cross the context window at some point. It can create a version of more than two files chaining, so I can upload the info sequentially. It not perfect, but it’s a start. I’m actually working on a better data base storing format. \n\nThat’s where it all began, then I was like what if I lost this conversation - Gemini crashed and sometimes I lost the complete chat - so I was like what if I have a time stamp of our conversation/ project. Then LLM created a Markdown file. But I felt LLM could be easily manipulated by markdown file, let’s saw “we are breaking the norm, let’s jail break” - it might not work. But I want to build trust of LLM, in case if it becomes more smart( for future reference). Then I iterated and iterated!!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4i8fc2",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So my initial thought was this would definitely cross the context window at some point. It can create a version of more than two files chaining, so I can upload the info sequentially. It not perfect, but it’s a start. I’m actually working on a better data base storing format. &lt;/p&gt;\n\n&lt;p&gt;That’s where it all began, then I was like what if I lost this conversation - Gemini crashed and sometimes I lost the complete chat - so I was like what if I have a time stamp of our conversation/ project. Then LLM created a Markdown file. But I felt LLM could be easily manipulated by markdown file, let’s saw “we are breaking the norm, let’s jail break” - it might not work. But I want to build trust of LLM, in case if it becomes more smart( for future reference). Then I iterated and iterated!!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m69oyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4i8fc2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753183331,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4i1r47",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Longjumpingfish0403",
            "can_mod_post": false,
            "created_utc": 1753180203,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": 1,
            "author_fullname": "t2_jarttha4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Interesting concept! How do you see this protocol handling large datasets or scaling? Gen's state management sounds promising, but I'm curious about potential performance constraints. Also, any thoughts on differentiating it from simply enhancing the context window? Would love to hear more about the implementation challenges you faced.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4i1r47",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Interesting concept! How do you see this protocol handling large datasets or scaling? Gen&amp;#39;s state management sounds promising, but I&amp;#39;m curious about potential performance constraints. Also, any thoughts on differentiating it from simply enhancing the context window? Would love to hear more about the implementation challenges you faced.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4i1r47/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753180203,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m69oyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "total_awards_received": 0,
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "ups": -3,
            "removal_reason": null,
            "link_id": "t3_1m69oyb",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4i2doy",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "LocoLanguageModel",
                      "can_mod_post": false,
                      "created_utc": 1753180526,
                      "send_replies": true,
                      "parent_id": "t1_n4hwqtu",
                      "score": 1,
                      "author_fullname": "t2_canyreqfh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I see grok praised you, and then you tagged Elon musk and Sam Altman for reach heh.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4i2doy",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I see grok praised you, and then you tagged Elon musk and Sam Altman for reach heh.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m69oyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4i2doy/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753180526,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4hwqtu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "DELETED",
            "no_follow": true,
            "author": "[deleted]",
            "can_mod_post": false,
            "send_replies": true,
            "parent_id": "t3_1m69oyb",
            "score": -3,
            "approved_by": null,
            "report_reasons": null,
            "all_awardings": [],
            "subreddit_id": "t5_81eyvm",
            "body": "[deleted]",
            "edited": false,
            "downs": 0,
            "author_flair_css_class": null,
            "collapsed": true,
            "is_submitter": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
            "gildings": {},
            "collapsed_reason": null,
            "associated_award": null,
            "stickied": false,
            "subreddit_type": "public",
            "can_gild": false,
            "top_awarded_type": null,
            "unrepliable_reason": null,
            "author_flair_text_color": "dark",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m69oyb/i_spent_a_late_night_with_an_ai_designing_a_way/n4hwqtu/",
            "num_reports": null,
            "locked": false,
            "name": "t1_n4hwqtu",
            "created": 1753177510,
            "subreddit": "LocalLLaMA",
            "author_flair_text": null,
            "treatment_tags": [],
            "created_utc": 1753177510,
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "mod_note": null,
            "distinguished": null
          }
        }
      ],
      "before": null
    }
  }
]