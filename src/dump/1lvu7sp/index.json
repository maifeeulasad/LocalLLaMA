[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Ever since the release of o1, I've been noticing more and more that a lot of the efforts OpenAI is making is not necessarily on the quality of their LLMs themselves but in how they are stitched/orchestrated together. To take a simple example, you might have noticed that ChatGPT generally performs way better than the GPT APIs alone, which are just the output of raw LLMs, whereas ChatGPT is more of a black box and has several layers around the GPT models that process the answers before they reach us. Same with o1 which seems to wrap a reasoning algorithm around raw GPT as far as we know. So it's not the actual LLMs underlying closed source products that are changing the most but the way the output of raw LLMs is passed around and processed until it reaches us. Seems GPT-5 will be continuing down that path by offering a \"unified model\" with less user \"model switching\". This seems to me like this will mean more black-box model glue (i.e. switching) behind the scenes. This will mean even more vendor lock-in because different model APIs will no longer be easily interchangeable due to some outputs being way more processed than others (in the same way that ChatGPT's output is way more processed than a raw LLM's output). \n\nThe bottom line is the products being offered are no longer just LLMs but something approaching what could be called proto-agents in the sense that they have memory, use tools and reason to some degree (but they don't act on external systems yet hence \"proto\").\n\nSo I've been wondering, what does this mean for open-source? Will it mimic closed-source and pursue proto-agentic solutions or should/will it continue down the path of improving the actual LLMs, leaving the orchestration and agentic part to the developer or to open-source agentic frameworks like CrewAI/PydanticAI?\n\nI think a lot of the answer depends on whether the art of \"stitching\" together LLMs can be undertaken by any software engineer or if highly specialized researchers are needed for that. If the former, this will be great for open-source because we won't need all the resources OpenAI has and their extremely well-paid researchers. If the latter, then the future might be tougher for open-source. I personally am cautiously optimistic as I don't see orchestration requiring the same amount of resources or specialized knowledge as training an LLM but then again I don't actually know what happens behind the scenes of o3 or ChatGPT.\n\n**TLDR:** Most changes in the past year seem to have been LLM-adjacent (namely, reasoning and proto-agentic features in general). Wondering if this is an opportunity or a risk for open-source.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Musings on recent trends in closed-source and the way forward for open-source",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1lvu7sp",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.84,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 8,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_8802a9mc",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 8,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1752094869,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ever since the release of o1, I&amp;#39;ve been noticing more and more that a lot of the efforts OpenAI is making is not necessarily on the quality of their LLMs themselves but in how they are stitched/orchestrated together. To take a simple example, you might have noticed that ChatGPT generally performs way better than the GPT APIs alone, which are just the output of raw LLMs, whereas ChatGPT is more of a black box and has several layers around the GPT models that process the answers before they reach us. Same with o1 which seems to wrap a reasoning algorithm around raw GPT as far as we know. So it&amp;#39;s not the actual LLMs underlying closed source products that are changing the most but the way the output of raw LLMs is passed around and processed until it reaches us. Seems GPT-5 will be continuing down that path by offering a &amp;quot;unified model&amp;quot; with less user &amp;quot;model switching&amp;quot;. This seems to me like this will mean more black-box model glue (i.e. switching) behind the scenes. This will mean even more vendor lock-in because different model APIs will no longer be easily interchangeable due to some outputs being way more processed than others (in the same way that ChatGPT&amp;#39;s output is way more processed than a raw LLM&amp;#39;s output). &lt;/p&gt;\n\n&lt;p&gt;The bottom line is the products being offered are no longer just LLMs but something approaching what could be called proto-agents in the sense that they have memory, use tools and reason to some degree (but they don&amp;#39;t act on external systems yet hence &amp;quot;proto&amp;quot;).&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve been wondering, what does this mean for open-source? Will it mimic closed-source and pursue proto-agentic solutions or should/will it continue down the path of improving the actual LLMs, leaving the orchestration and agentic part to the developer or to open-source agentic frameworks like CrewAI/PydanticAI?&lt;/p&gt;\n\n&lt;p&gt;I think a lot of the answer depends on whether the art of &amp;quot;stitching&amp;quot; together LLMs can be undertaken by any software engineer or if highly specialized researchers are needed for that. If the former, this will be great for open-source because we won&amp;#39;t need all the resources OpenAI has and their extremely well-paid researchers. If the latter, then the future might be tougher for open-source. I personally am cautiously optimistic as I don&amp;#39;t see orchestration requiring the same amount of resources or specialized knowledge as training an LLM but then again I don&amp;#39;t actually know what happens behind the scenes of o3 or ChatGPT.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR:&lt;/strong&gt; Most changes in the past year seem to have been LLM-adjacent (namely, reasoning and proto-agentic features in general). Wondering if this is an opportunity or a risk for open-source.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1lvu7sp",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "AgreeableCaptain1372",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lvu7sp/musings_on_recent_trends_in_closedsource_and_the/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lvu7sp/musings_on_recent_trends_in_closedsource_and_the/",
            "subreddit_subscribers": 497023,
            "created_utc": 1752094869,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n29e9yh",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ttkciar",
            "can_mod_post": false,
            "created_utc": 1752099861,
            "send_replies": true,
            "parent_id": "t3_1lvu7sp",
            "score": 5,
            "author_fullname": "t2_cpegz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt; Will [open source] mimic closed-source and pursue proto-agentic solutions or should/will it continue down the path of improving the actual LLMs, leaving the orchestration and agentic part to the developer or to open-source agentic frameworks like CrewAI/PydanticAI?\n\nIt's not an either/or situation.  The open source community is intrinsically pretty fragmented, with some people focusing on making LLM training better, others making LLM inference better, and others focusing on the scaffolding which does things like orchestration.\n\nI expect that to continue.\n\nIt's also worth noting that often innovations in this scaffolding appear in academia first, are then implemented in open source projects, and are later picked up by commercial services when they are recognized as beneficial.\n\nGuided Generation is a key example of that.  Researchers demonstrated GG with regular expressions, and then open source projects implemented GG with either regular expressions or (in llama.cpp's case) formal grammars.\n\nllama.cpp had its grammar feature for almost a year before OpenAI rolled out its equivalent \"schemas\" GG implementation.\n\n&gt; I think a lot of the answer depends on whether the art of \"stitching\" together LLMs can be undertaken by any software engineer or if highly specialized researchers are needed for that.\n\nI wouldn't say \"any\" software engineer, but it's definitely within the capabilities of a competent software engineer who is familiar with the space.  Implementation does not require the attention of specialized researchers, except inasmuch that researchers publish new theory about it and engineers read what they publish and base implementations on it.\n\nMy impressions might be stale, but from what I have seen the kinds of scaffolding you are talking about are fairly fragmented in the open source world.  There are projects for orchestration, and projects for self-critique, and projects for RAG, etc, and it's up to other developers to glue them together to make applications which integrate these features.\n\nWe'll get there.  It's just more chaotic.  Corporations have managers who set and prioritize their developers' tasks, and the open source world only has anything like that (or more frequently *nothing* like it) on a project-by-project basis.  Github issues help, but are frequently not prioritized in a structured way.\n\nIn some ways that's an asset.  A manager is not always the person most qualified to tell developers what should be developed, and developers are often more up to date on the latest technologies.\n\nAlso, I have yet to meet a manager who reads published theory to decide what engineers should try to implement.  That's almost entirely the bailiwick of engineers, who might or might not be empowered to make suggestions along those lines to their managers, depending on the corporate culture.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n29e9yh",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Will [open source] mimic closed-source and pursue proto-agentic solutions or should/will it continue down the path of improving the actual LLMs, leaving the orchestration and agentic part to the developer or to open-source agentic frameworks like CrewAI/PydanticAI?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s not an either/or situation.  The open source community is intrinsically pretty fragmented, with some people focusing on making LLM training better, others making LLM inference better, and others focusing on the scaffolding which does things like orchestration.&lt;/p&gt;\n\n&lt;p&gt;I expect that to continue.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s also worth noting that often innovations in this scaffolding appear in academia first, are then implemented in open source projects, and are later picked up by commercial services when they are recognized as beneficial.&lt;/p&gt;\n\n&lt;p&gt;Guided Generation is a key example of that.  Researchers demonstrated GG with regular expressions, and then open source projects implemented GG with either regular expressions or (in llama.cpp&amp;#39;s case) formal grammars.&lt;/p&gt;\n\n&lt;p&gt;llama.cpp had its grammar feature for almost a year before OpenAI rolled out its equivalent &amp;quot;schemas&amp;quot; GG implementation.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I think a lot of the answer depends on whether the art of &amp;quot;stitching&amp;quot; together LLMs can be undertaken by any software engineer or if highly specialized researchers are needed for that.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I wouldn&amp;#39;t say &amp;quot;any&amp;quot; software engineer, but it&amp;#39;s definitely within the capabilities of a competent software engineer who is familiar with the space.  Implementation does not require the attention of specialized researchers, except inasmuch that researchers publish new theory about it and engineers read what they publish and base implementations on it.&lt;/p&gt;\n\n&lt;p&gt;My impressions might be stale, but from what I have seen the kinds of scaffolding you are talking about are fairly fragmented in the open source world.  There are projects for orchestration, and projects for self-critique, and projects for RAG, etc, and it&amp;#39;s up to other developers to glue them together to make applications which integrate these features.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ll get there.  It&amp;#39;s just more chaotic.  Corporations have managers who set and prioritize their developers&amp;#39; tasks, and the open source world only has anything like that (or more frequently &lt;em&gt;nothing&lt;/em&gt; like it) on a project-by-project basis.  Github issues help, but are frequently not prioritized in a structured way.&lt;/p&gt;\n\n&lt;p&gt;In some ways that&amp;#39;s an asset.  A manager is not always the person most qualified to tell developers what should be developed, and developers are often more up to date on the latest technologies.&lt;/p&gt;\n\n&lt;p&gt;Also, I have yet to meet a manager who reads published theory to decide what engineers should try to implement.  That&amp;#39;s almost entirely the bailiwick of engineers, who might or might not be empowered to make suggestions along those lines to their managers, depending on the corporate culture.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lvu7sp/musings_on_recent_trends_in_closedsource_and_the/n29e9yh/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752099861,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1lvu7sp",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2912ma",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "datbackup",
            "can_mod_post": false,
            "created_utc": 1752095891,
            "send_replies": true,
            "parent_id": "t3_1lvu7sp",
            "score": 1,
            "author_fullname": "t2_ielo6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Good observations, I think we’ll see some innovation in open source to implement the proto-agent approach you describe.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2912ma",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Good observations, I think we’ll see some innovation in open source to implement the proto-agent approach you describe.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lvu7sp/musings_on_recent_trends_in_closedsource_and_the/n2912ma/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752095891,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lvu7sp",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n29hipa",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "SlimyResearcher",
            "can_mod_post": false,
            "created_utc": 1752100910,
            "send_replies": true,
            "parent_id": "t3_1lvu7sp",
            "score": 1,
            "author_fullname": "t2_ch7ib0zs",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think the answer is to use the closed source models like Gemini/GPT to implement the scaffolding that’s needed.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n29hipa",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the answer is to use the closed source models like Gemini/GPT to implement the scaffolding that’s needed.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lvu7sp/musings_on_recent_trends_in_closedsource_and_the/n29hipa/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752100910,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lvu7sp",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2ad9z1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Dr_Me_123",
            "can_mod_post": false,
            "created_utc": 1752111624,
            "send_replies": true,
            "parent_id": "t3_1lvu7sp",
            "score": 1,
            "author_fullname": "t2_59yau29b",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "A better orchestration needs to be automated, and this requires the cooperation of the model. Therefore, this matter is naturally linked to the compatibility work with specific models and targeted model training. In the  ‘closed-source’ field, this is quite natural. However, in the open-source field, perhaps this kind of specific, unified collaboration between upstream and downstream doesn't usually happen so spontaneously.",
            "edited": 1752113248,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2ad9z1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A better orchestration needs to be automated, and this requires the cooperation of the model. Therefore, this matter is naturally linked to the compatibility work with specific models and targeted model training. In the  ‘closed-source’ field, this is quite natural. However, in the open-source field, perhaps this kind of specific, unified collaboration between upstream and downstream doesn&amp;#39;t usually happen so spontaneously.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lvu7sp/musings_on_recent_trends_in_closedsource_and_the/n2ad9z1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752111624,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lvu7sp",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]