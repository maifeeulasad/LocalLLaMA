[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "  \nHow about running a local agent on a smartphone? Here's how I did it.  \n  \nI stitched together onnxruntime implemented KV Cache in DelitePy(Python) and added FP16 activations support in cpp with (via `uint16_t`), works for all binary ops in DeliteAI. Result Local Qwen 3 1.7B on mobile! \n\n# Tool Calling Features\n\n* **Multi-step conversation support** with automatic tool execution\n* **JSON-based tool calling** with `&lt;tool_call&gt;` XML tags\n* **test tools**: weather, math calculator, time, location\n\n# Used [tokenizer-cpp](https://github.com/mlc-ai/tokenizers-cpp) from MLC \n\nwhich binds rust [huggingface/tokenizers](https://github.com/huggingface/tokenizers) giving full support for android/iOS.\n\n    // - dist/tokenizer.json\n    void HuggingFaceTokenizerExample() {\n      auto blob = LoadBytesFromFile(\"dist/tokenizer.json\");  \n      auto tok = Tokenizer::FromBlobJSON(blob);\n      std::string prompt = \"What is the capital of Canada?\";\n      std::vector&lt;int&gt; ids = tok-&gt;Encode(prompt);\n      std::string decoded_prompt = tok-&gt;Decode(ids);\n    }\n\n# Push LLM streams into Kotlin Flows\n\n        suspend fun feedInput(input: String, isVoiceInitiated: Boolean, callback: (String?)-&gt;Unit) : String? {\n            val res = NimbleNet.runMethod(\n                \"prompt_for_tool_calling\",\n                inputs = hashMapOf(\n                    \"prompt\" to NimbleNetTensor(input, DATATYPE.STRING, null),\n                    \"output_stream_callback\" to  createNimbleNetTensorFromForeignFunction(callback)\n                ),\n            )\n            assert(res.status) { \"NimbleNet.runMethod('prompt_for_tool_calling') failed with status: ${res.status}\" }\n            return res.payload?.get(\"results\")?.data as String?\n        }\n\n  \nCheck the code soon merging in Delite AI (https://github.com/NimbleEdge/deliteAI/pull/165)  \nOr try in the assistant app (https://github.com/NimbleEdge/assistant)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Qwen 1.7B tool calling across Android on Pixel 9 and S22",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 74,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mcl15k",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.91,
            "author_flair_background_color": null,
            "ups": 48,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_74zl16jw",
            "secure_media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/3wcxuotf7vff1/DASH_1080.mp4?source=fallback",
                "has_audio": false,
                "height": 1028,
                "width": 1920,
                "scrubber_media_url": "https://v.redd.it/3wcxuotf7vff1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/3wcxuotf7vff1/DASHPlaylist.mpd?a=1756470748%2CNGRjMjNhNzEwYzFkMWRhMWI3MTNkYmQ4Yjc4MTQyMjJiYjdjNDU0MTFlZmI1ODMwODJkYzYwNDA2NWQ0ZGIxMw%3D%3D&amp;v=1&amp;f=sd",
                "duration": 96,
                "hls_url": "https://v.redd.it/3wcxuotf7vff1/HLSPlaylist.m3u8?a=1756470748%2CZWZmNTQ3ZjM3YzFkNmY2MGFhNTMyNDFjZDVlOTIzYTkyNzIwNzNhZGRhODFjZjQ2NTAzYzliYjEwOTFhYzc4Ng%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 48,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/OGE0eDhmMWo3dmZmMahIsQ78FFRykDtTsz9hlKfWwrVXaeuOW0fcBOh_-QBa.png?width=140&amp;height=74&amp;crop=140:74,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=0cc796d906797d3e01c0e1b59e9c7394c449065a",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "hosted:video",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753817426,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "v.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How about running a local agent on a smartphone? Here&amp;#39;s how I did it.  &lt;/p&gt;\n\n&lt;p&gt;I stitched together onnxruntime implemented KV Cache in DelitePy(Python) and added FP16 activations support in cpp with (via &lt;code&gt;uint16_t&lt;/code&gt;), works for all binary ops in DeliteAI. Result Local Qwen 3 1.7B on mobile! &lt;/p&gt;\n\n&lt;h1&gt;Tool Calling Features&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Multi-step conversation support&lt;/strong&gt; with automatic tool execution&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;JSON-based tool calling&lt;/strong&gt; with &lt;code&gt;&amp;lt;tool_call&amp;gt;&lt;/code&gt; XML tags&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;test tools&lt;/strong&gt;: weather, math calculator, time, location&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Used &lt;a href=\"https://github.com/mlc-ai/tokenizers-cpp\"&gt;tokenizer-cpp&lt;/a&gt; from MLC&lt;/h1&gt;\n\n&lt;p&gt;which binds rust &lt;a href=\"https://github.com/huggingface/tokenizers\"&gt;huggingface/tokenizers&lt;/a&gt; giving full support for android/iOS.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;// - dist/tokenizer.json\nvoid HuggingFaceTokenizerExample() {\n  auto blob = LoadBytesFromFile(&amp;quot;dist/tokenizer.json&amp;quot;);  \n  auto tok = Tokenizer::FromBlobJSON(blob);\n  std::string prompt = &amp;quot;What is the capital of Canada?&amp;quot;;\n  std::vector&amp;lt;int&amp;gt; ids = tok-&amp;gt;Encode(prompt);\n  std::string decoded_prompt = tok-&amp;gt;Decode(ids);\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;Push LLM streams into Kotlin Flows&lt;/h1&gt;\n\n&lt;pre&gt;&lt;code&gt;    suspend fun feedInput(input: String, isVoiceInitiated: Boolean, callback: (String?)-&amp;gt;Unit) : String? {\n        val res = NimbleNet.runMethod(\n            &amp;quot;prompt_for_tool_calling&amp;quot;,\n            inputs = hashMapOf(\n                &amp;quot;prompt&amp;quot; to NimbleNetTensor(input, DATATYPE.STRING, null),\n                &amp;quot;output_stream_callback&amp;quot; to  createNimbleNetTensorFromForeignFunction(callback)\n            ),\n        )\n        assert(res.status) { &amp;quot;NimbleNet.runMethod(&amp;#39;prompt_for_tool_calling&amp;#39;) failed with status: ${res.status}&amp;quot; }\n        return res.payload?.get(&amp;quot;results&amp;quot;)?.data as String?\n    }\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Check the code soon merging in Delite AI (&lt;a href=\"https://github.com/NimbleEdge/deliteAI/pull/165\"&gt;https://github.com/NimbleEdge/deliteAI/pull/165&lt;/a&gt;)&lt;br/&gt;\nOr try in the assistant app (&lt;a href=\"https://github.com/NimbleEdge/assistant\"&gt;https://github.com/NimbleEdge/assistant&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://v.redd.it/3wcxuotf7vff1",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/OGE0eDhmMWo3dmZmMahIsQ78FFRykDtTsz9hlKfWwrVXaeuOW0fcBOh_-QBa.png?format=pjpg&amp;auto=webp&amp;s=165be791b8080463b2ab6d14b9b9776e0a4a8e2c",
                    "width": 2506,
                    "height": 1342
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/OGE0eDhmMWo3dmZmMahIsQ78FFRykDtTsz9hlKfWwrVXaeuOW0fcBOh_-QBa.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6fe43a7642d9c73f60904aa7697e5f67367fe209",
                      "width": 108,
                      "height": 57
                    },
                    {
                      "url": "https://external-preview.redd.it/OGE0eDhmMWo3dmZmMahIsQ78FFRykDtTsz9hlKfWwrVXaeuOW0fcBOh_-QBa.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=71dece6bba55a954e2ccff12a4d99077d7266799",
                      "width": 216,
                      "height": 115
                    },
                    {
                      "url": "https://external-preview.redd.it/OGE0eDhmMWo3dmZmMahIsQ78FFRykDtTsz9hlKfWwrVXaeuOW0fcBOh_-QBa.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=3debc156667479551d71bb1d9aeeef63ebbe0152",
                      "width": 320,
                      "height": 171
                    },
                    {
                      "url": "https://external-preview.redd.it/OGE0eDhmMWo3dmZmMahIsQ78FFRykDtTsz9hlKfWwrVXaeuOW0fcBOh_-QBa.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=80d701462462fdc5caf3f289d125f5645db09a52",
                      "width": 640,
                      "height": 342
                    },
                    {
                      "url": "https://external-preview.redd.it/OGE0eDhmMWo3dmZmMahIsQ78FFRykDtTsz9hlKfWwrVXaeuOW0fcBOh_-QBa.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=28bf0f71381faf47ee92aa7f472fd7dcb66cdfb7",
                      "width": 960,
                      "height": 514
                    },
                    {
                      "url": "https://external-preview.redd.it/OGE0eDhmMWo3dmZmMahIsQ78FFRykDtTsz9hlKfWwrVXaeuOW0fcBOh_-QBa.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2f7355860cb6fa6f63f5a696b008dbd0e23f562f",
                      "width": 1080,
                      "height": 578
                    }
                  ],
                  "variants": {},
                  "id": "OGE0eDhmMWo3dmZmMahIsQ78FFRykDtTsz9hlKfWwrVXaeuOW0fcBOh_-QBa"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1mcl15k",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Economy-Mud-6626",
            "discussion_type": null,
            "num_comments": 6,
            "send_replies": true,
            "media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/3wcxuotf7vff1/DASH_1080.mp4?source=fallback",
                "has_audio": false,
                "height": 1028,
                "width": 1920,
                "scrubber_media_url": "https://v.redd.it/3wcxuotf7vff1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/3wcxuotf7vff1/DASHPlaylist.mpd?a=1756470748%2CNGRjMjNhNzEwYzFkMWRhMWI3MTNkYmQ4Yjc4MTQyMjJiYjdjNDU0MTFlZmI1ODMwODJkYzYwNDA2NWQ0ZGIxMw%3D%3D&amp;v=1&amp;f=sd",
                "duration": 96,
                "hls_url": "https://v.redd.it/3wcxuotf7vff1/HLSPlaylist.m3u8?a=1756470748%2CZWZmNTQ3ZjM3YzFkNmY2MGFhNTMyNDFjZDVlOTIzYTkyNzIwNzNhZGRhODFjZjQ2NTAzYzliYjEwOTFhYzc4Ng%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mcl15k/qwen_17b_tool_calling_across_android_on_pixel_9/",
            "stickied": false,
            "url": "https://v.redd.it/3wcxuotf7vff1",
            "subreddit_subscribers": 506973,
            "created_utc": 1753817426,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": true
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5xf3km",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "sherlockAI",
                      "can_mod_post": false,
                      "created_utc": 1753852253,
                      "send_replies": true,
                      "parent_id": "t1_n5vnokd",
                      "score": 2,
                      "author_fullname": "t2_am0mu96a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "There are newer techniques coming which enables flash storage to be used to conserve ram while llm inference",
                      "edited": 1753859241,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5xf3km",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There are newer techniques coming which enables flash storage to be used to conserve ram while llm inference&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcl15k",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcl15k/qwen_17b_tool_calling_across_android_on_pixel_9/n5xf3km/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753852253,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5vnokd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "moko990",
            "can_mod_post": false,
            "created_utc": 1753828838,
            "send_replies": true,
            "parent_id": "t3_1mcl15k",
            "score": 5,
            "author_fullname": "t2_1kh1rmhlhh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is great! If only more android phone come with higher rams. I think it's becoming inevitable.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vnokd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is great! If only more android phone come with higher rams. I think it&amp;#39;s becoming inevitable.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcl15k/qwen_17b_tool_calling_across_android_on_pixel_9/n5vnokd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753828838,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcl15k",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ulegy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Sad_Hall_2216",
            "can_mod_post": false,
            "created_utc": 1753817617,
            "send_replies": true,
            "parent_id": "t3_1mcl15k",
            "score": 1,
            "author_fullname": "t2_1d7v8fhjpt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is very cool!!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ulegy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is very cool!!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcl15k/qwen_17b_tool_calling_across_android_on_pixel_9/n5ulegy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753817617,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcl15k",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5umrvy",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Economy-Mud-6626",
                      "can_mod_post": false,
                      "created_utc": 1753818013,
                      "send_replies": true,
                      "parent_id": "t1_n5um6ha",
                      "score": 5,
                      "author_fullname": "t2_74zl16jw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It has been quite tedious to export Qwen 3 to onnxruntime-gen ai with manual graph building only supporting a few models. I used optimum exported models from huggingface which were more reliable and gave stronger control over maintaining incremental kv cache. Here's the model I used [https://huggingface.co/onnx-community/Qwen3-1.7B-ONNX](https://huggingface.co/onnx-community/Qwen3-1.7B-ONNX)",
                      "edited": 1753820362,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5umrvy",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It has been quite tedious to export Qwen 3 to onnxruntime-gen ai with manual graph building only supporting a few models. I used optimum exported models from huggingface which were more reliable and gave stronger control over maintaining incremental kv cache. Here&amp;#39;s the model I used &lt;a href=\"https://huggingface.co/onnx-community/Qwen3-1.7B-ONNX\"&gt;https://huggingface.co/onnx-community/Qwen3-1.7B-ONNX&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcl15k",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcl15k/qwen_17b_tool_calling_across_android_on_pixel_9/n5umrvy/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753818013,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5um6ha",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Sad_Hall_2216",
            "can_mod_post": false,
            "created_utc": 1753817842,
            "send_replies": true,
            "parent_id": "t3_1mcl15k",
            "score": 1,
            "author_fullname": "t2_1d7v8fhjpt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Why are you not using ONNX GenAI runtime for this?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5um6ha",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why are you not using ONNX GenAI runtime for this?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcl15k/qwen_17b_tool_calling_across_android_on_pixel_9/n5um6ha/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753817842,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcl15k",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5um8xj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GPTrack_ai",
            "can_mod_post": false,
            "created_utc": 1753817861,
            "send_replies": true,
            "parent_id": "t3_1mcl15k",
            "score": -4,
            "author_fullname": "t2_1tpuoj72sa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Only people who do not know what the electrolyte of a lithium-ion battery is use smartphones.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5um8xj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Only people who do not know what the electrolyte of a lithium-ion battery is use smartphones.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcl15k/qwen_17b_tool_calling_across_android_on_pixel_9/n5um8xj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753817861,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcl15k",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -4
          }
        }
      ],
      "before": null
    }
  }
]