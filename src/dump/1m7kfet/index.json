[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I'm new to LLMs and I'm trying to understand a few things.\n\nIsn't RAG similar to a search engine? looks at keywords typed by user then feeds it to LLM to \"understand\" it an generate a nice response back? \n\nLet's say instead of RAG I'm using something like ElasticSearch/Meillsearch - would the results be that different? Does RAG handle synonyms as well? \n\nIdeally each chunk added into ChromaDb should be a full \"logic unit\" meaning it should make sense by itself (not a cutoff sentence with no start and end. Ex: Steven is ...). No?\n\nWhat about text with references to other pages, articles etc. How to handle them? ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Gemma3/other, Langchain, ChromaDb, RAG - a few questions",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m7kfet",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 1,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_7bnnpzic",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753302872,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to LLMs and I&amp;#39;m trying to understand a few things.&lt;/p&gt;\n\n&lt;p&gt;Isn&amp;#39;t RAG similar to a search engine? looks at keywords typed by user then feeds it to LLM to &amp;quot;understand&amp;quot; it an generate a nice response back? &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say instead of RAG I&amp;#39;m using something like ElasticSearch/Meillsearch - would the results be that different? Does RAG handle synonyms as well? &lt;/p&gt;\n\n&lt;p&gt;Ideally each chunk added into ChromaDb should be a full &amp;quot;logic unit&amp;quot; meaning it should make sense by itself (not a cutoff sentence with no start and end. Ex: Steven is ...). No?&lt;/p&gt;\n\n&lt;p&gt;What about text with references to other pages, articles etc. How to handle them? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m7kfet",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "viitorfermier",
            "discussion_type": null,
            "num_comments": 8,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/",
            "subreddit_subscribers": 503758,
            "created_utc": 1753302872,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4updcb",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "viitorfermier",
                      "can_mod_post": false,
                      "created_utc": 1753336718,
                      "send_replies": true,
                      "parent_id": "t1_n4s5djj",
                      "score": 1,
                      "author_fullname": "t2_7bnnpzic",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Nice üòÅ great work at Chroma - from my searches is the most mentioned vector search db. \n\nGood to know that we can \"add links in chunks\" to group units of text.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4updcb",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice üòÅ great work at Chroma - from my searches is the most mentioned vector search db. &lt;/p&gt;\n\n&lt;p&gt;Good to know that we can &amp;quot;add links in chunks&amp;quot; to group units of text.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7kfet",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/n4updcb/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753336718,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4s5djj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "jeffreyhuber",
            "can_mod_post": false,
            "created_utc": 1753303476,
            "send_replies": true,
            "parent_id": "t3_1m7kfet",
            "score": 3,
            "author_fullname": "t2_aua9g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yes - RAG is basically a search engine. \n\nMost \"vector databases\" support full-text search, vector search, metadata filtering - not all traditional search tools do that or do that well. \n\nIn terms of chunks - it kinda depends on your use case. It would be ok for example if a paragraph is cut in half so long as a query that needs both chunks gets both chunks. \n\nFor text with references, you can put that into the metadata and then \"follow the metadata\" - so for example if a paragraph references page 5, you can add {page:5} to your metadata and then once you get the first chunk - you can \"follow\" it to other chunks through metadata search. \n\n(I work at Chroma, hi! )",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4s5djj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes - RAG is basically a search engine. &lt;/p&gt;\n\n&lt;p&gt;Most &amp;quot;vector databases&amp;quot; support full-text search, vector search, metadata filtering - not all traditional search tools do that or do that well. &lt;/p&gt;\n\n&lt;p&gt;In terms of chunks - it kinda depends on your use case. It would be ok for example if a paragraph is cut in half so long as a query that needs both chunks gets both chunks. &lt;/p&gt;\n\n&lt;p&gt;For text with references, you can put that into the metadata and then &amp;quot;follow the metadata&amp;quot; - so for example if a paragraph references page 5, you can add {page:5} to your metadata and then once you get the first chunk - you can &amp;quot;follow&amp;quot; it to other chunks through metadata search. &lt;/p&gt;\n\n&lt;p&gt;(I work at Chroma, hi! )&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/n4s5djj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753303476,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7kfet",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4uszfn",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "viitorfermier",
                      "can_mod_post": false,
                      "created_utc": 1753338624,
                      "send_replies": true,
                      "parent_id": "t1_n4s4va1",
                      "score": 1,
                      "author_fullname": "t2_7bnnpzic",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "RAG is the way. Thank you.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4uszfn",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;RAG is the way. Thank you.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7kfet",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/n4uszfn/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753338624,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4s4va1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Efficiency_1144",
            "can_mod_post": false,
            "created_utc": 1753303333,
            "send_replies": true,
            "parent_id": "t3_1m7kfet",
            "score": 2,
            "author_fullname": "t2_1nkj9l14b0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What you are calling RAG can out perform traditional text search. A lot of systems do a hybrid search though.\n\n\nI haven‚Äôt really kept up with traditional RAG because I almost never need more than 64k context and at that size you can just put everything in context.\n\n\nNow that we have multi-agents things will likely change again.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4s4va1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What you are calling RAG can out perform traditional text search. A lot of systems do a hybrid search though.&lt;/p&gt;\n\n&lt;p&gt;I haven‚Äôt really kept up with traditional RAG because I almost never need more than 64k context and at that size you can just put everything in context.&lt;/p&gt;\n\n&lt;p&gt;Now that we have multi-agents things will likely change again.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/n4s4va1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753303333,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7kfet",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4uu4a4",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "sneakpeekbot",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4uu3d2",
                                "score": 1,
                                "author_fullname": "t2_140r4p",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Here's a sneak peek of /r/Rag using the [top posts](https://np.reddit.com/r/Rag/top/?sort=top&amp;t=year) of the year!\n\n\\#1: [üåü My RAG_Techniques repo is now the 5th result on Google when searching \"RAG GitHub\"! üåü](https://github.com/NirDiamant/RAG_Techniques) | [20 comments](https://np.reddit.com/r/Rag/comments/1gbba5d/my_rag_techniques_repo_is_now_the_5th_result_on/)  \n\\#2: [Tough feedback, VCs are pissed and I might get fired. Roast us!](https://np.reddit.com/r/Rag/comments/1hc7dda/tough_feedback_vcs_are_pissed_and_i_might_get/)  \n\\#3: [How I finally got agentic RAG to work right](https://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/) | [4 comments](https://np.reddit.com/r/Rag/comments/1ft0fpn/how_i_finally_got_agentic_rag_to_work_right/)\n\n----\n^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| ^^[Contact](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| ^^[Info](https://np.reddit.com/r/sneakpeekbot/) ^^| ^^[Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/o8wk1r/blacklist_ix/) ^^| ^^[GitHub](https://github.com/ghnr/sneakpeekbot)",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4uu4a4",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s a sneak peek of &lt;a href=\"/r/Rag\"&gt;/r/Rag&lt;/a&gt; using the &lt;a href=\"https://np.reddit.com/r/Rag/top/?sort=top&amp;amp;t=year\"&gt;top posts&lt;/a&gt; of the year!&lt;/p&gt;\n\n&lt;p&gt;#1: &lt;a href=\"https://github.com/NirDiamant/RAG_Techniques\"&gt;üåü My RAG_Techniques repo is now the 5th result on Google when searching &amp;quot;RAG GitHub&amp;quot;! üåü&lt;/a&gt; | &lt;a href=\"https://np.reddit.com/r/Rag/comments/1gbba5d/my_rag_techniques_repo_is_now_the_5th_result_on/\"&gt;20 comments&lt;/a&gt;&lt;br/&gt;\n#2: &lt;a href=\"https://np.reddit.com/r/Rag/comments/1hc7dda/tough_feedback_vcs_are_pissed_and_i_might_get/\"&gt;Tough feedback, VCs are pissed and I might get fired. Roast us!&lt;/a&gt;&lt;br/&gt;\n#3: &lt;a href=\"https://vectorize.io/how-i-finally-got-agentic-rag-to-work-right/\"&gt;How I finally got agentic RAG to work right&lt;/a&gt; | &lt;a href=\"https://np.reddit.com/r/Rag/comments/1ft0fpn/how_i_finally_got_agentic_rag_to_work_right/\"&gt;4 comments&lt;/a&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;sup&gt;&lt;sup&gt;I&amp;#39;m&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;bot,&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;beep&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;boop&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;|&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;Downvote&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;to&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;remove&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;|&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;&lt;a href=\"https://www.reddit.com/message/compose/?to=sneakpeekbot\"&gt;Contact&lt;/a&gt;&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;|&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;&lt;a href=\"https://np.reddit.com/r/sneakpeekbot/\"&gt;Info&lt;/a&gt;&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;|&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;&lt;a href=\"https://np.reddit.com/r/sneakpeekbot/comments/o8wk1r/blacklist_ix/\"&gt;Opt-out&lt;/a&gt;&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;|&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;&lt;a href=\"https://github.com/ghnr/sneakpeekbot\"&gt;GitHub&lt;/a&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7kfet",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/n4uu4a4/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753339237,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753339237,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4uu3d2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "viitorfermier",
                      "can_mod_post": false,
                      "created_utc": 1753339223,
                      "send_replies": true,
                      "parent_id": "t1_n4tcspb",
                      "score": 1,
                      "author_fullname": "t2_7bnnpzic",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Interesting. Looks like the search part needs to work very well in order for the LLM to do it's job. Just joined r/RAG I'll explore more there. Thank you!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4uu3d2",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Interesting. Looks like the search part needs to work very well in order for the LLM to do it&amp;#39;s job. Just joined &lt;a href=\"/r/RAG\"&gt;r/RAG&lt;/a&gt; I&amp;#39;ll explore more there. Thank you!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7kfet",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/n4uu3d2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753339223,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4tcspb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ttkciar",
            "can_mod_post": false,
            "created_utc": 1753317188,
            "send_replies": true,
            "parent_id": "t3_1m7kfet",
            "score": 2,
            "author_fullname": "t2_cpegz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "RAG uses a search engine or database (which are different things, but can have extensive overlap).  It is searching for content relevant to a prompt, with which to ground LLM inference in truth (ideally) or at least help it infer more competently.\n\nRAG with ElasticSearch is still RAG.  RAG doesn't have to use a vector database, though that's currently the popular practice.\n\nI have been using Lucy (a pure-C implementation \"inspired by\" Lucene) to implement RAG for years now, and it does a pretty good job.  I've been meaning to switch to hybrid search (Lucy + vector DB, not sure which vector DB yet) because stemming isn't always sufficient to find relevant content.\n\nIf your data is sufficiently well-organized, you could even use a relational database.  Some relational databases have vector extensions, too (like Postgres' `pgvector` extension), so these aren't mutually exclusive.\n\nThe underlying mechanism matters less than the general principle:  RAG looks up stored data with which to populate context for augmented inference.  Changing the technology you use to look things up doesn't make it not-RAG.\n\nYour questions about chunking and dependencies/references across chunks are quite apt.  You can probably find answers in r/RAG, which is all about that sort of thing.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4tcspb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;RAG uses a search engine or database (which are different things, but can have extensive overlap).  It is searching for content relevant to a prompt, with which to ground LLM inference in truth (ideally) or at least help it infer more competently.&lt;/p&gt;\n\n&lt;p&gt;RAG with ElasticSearch is still RAG.  RAG doesn&amp;#39;t have to use a vector database, though that&amp;#39;s currently the popular practice.&lt;/p&gt;\n\n&lt;p&gt;I have been using Lucy (a pure-C implementation &amp;quot;inspired by&amp;quot; Lucene) to implement RAG for years now, and it does a pretty good job.  I&amp;#39;ve been meaning to switch to hybrid search (Lucy + vector DB, not sure which vector DB yet) because stemming isn&amp;#39;t always sufficient to find relevant content.&lt;/p&gt;\n\n&lt;p&gt;If your data is sufficiently well-organized, you could even use a relational database.  Some relational databases have vector extensions, too (like Postgres&amp;#39; &lt;code&gt;pgvector&lt;/code&gt; extension), so these aren&amp;#39;t mutually exclusive.&lt;/p&gt;\n\n&lt;p&gt;The underlying mechanism matters less than the general principle:  RAG looks up stored data with which to populate context for augmented inference.  Changing the technology you use to look things up doesn&amp;#39;t make it not-RAG.&lt;/p&gt;\n\n&lt;p&gt;Your questions about chunking and dependencies/references across chunks are quite apt.  You can probably find answers in &lt;a href=\"/r/RAG\"&gt;r/RAG&lt;/a&gt;, which is all about that sort of thing.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/n4tcspb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753317188,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m7kfet",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4v4sno",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "wfgy_engine",
            "can_mod_post": false,
            "created_utc": 1753345200,
            "send_replies": true,
            "parent_id": "t3_1m7kfet",
            "score": 1,
            "author_fullname": "t2_1tgp8l87vk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "RAG isn‚Äôt just a search engine with delusions of grandeur ‚Äî it‚Äôs more like an improv actor who reads your cues and then free-associates a monologue from memory. \n\nElasticSearch/Meilisearch? Sure, they‚Äôll fetch your keywords like obedient dogs. But RAG tries to *understand what you meant to say at 2AM while emotionally compromised*. It‚Äôs all about context weaving.\n\n**Synonyms?** That‚Äôs where embeddings step in. If your chunks are indexed with semantic models (like `text-embedding-ada`), then ‚ÄúCEO‚Äù and ‚Äúfounder‚Äù can live in the same semantic neighborhood and still wave hi to each other. With classical keyword search, they‚Äôd live on opposite sides of town and never meet.\n\n**Your instinct about chunk logic is spot on.** Think of it like: you‚Äôre not feeding the LLM a torn-up note ‚Äî you‚Äôre feeding it one clean, meaningful thought per bite. Ending mid-sentence is like tossing someone a book and ripping out the last page. Not polite.\n\n**Handling references?** Either inline (bake the reference into the chunk itself with context), or via metadata routing, depending on how fancy your pipeline is. But no magic ‚Äî LLMs don‚Äôt ‚Äúclick links,‚Äù they hallucinate connections, so give them breadcrumbs.\n\nBottom line: if you‚Äôre building a RAG that doesn‚Äôt sound drunk at a dinner party, your chunking logic and retrieval must carry most of the weight.\n\nLet me know if you want chunking recipes ‚Äî I've spilled enough ink and tears on this one to fill a Medium blog no one reads.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v4sno",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;RAG isn‚Äôt just a search engine with delusions of grandeur ‚Äî it‚Äôs more like an improv actor who reads your cues and then free-associates a monologue from memory. &lt;/p&gt;\n\n&lt;p&gt;ElasticSearch/Meilisearch? Sure, they‚Äôll fetch your keywords like obedient dogs. But RAG tries to &lt;em&gt;understand what you meant to say at 2AM while emotionally compromised&lt;/em&gt;. It‚Äôs all about context weaving.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Synonyms?&lt;/strong&gt; That‚Äôs where embeddings step in. If your chunks are indexed with semantic models (like &lt;code&gt;text-embedding-ada&lt;/code&gt;), then ‚ÄúCEO‚Äù and ‚Äúfounder‚Äù can live in the same semantic neighborhood and still wave hi to each other. With classical keyword search, they‚Äôd live on opposite sides of town and never meet.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Your instinct about chunk logic is spot on.&lt;/strong&gt; Think of it like: you‚Äôre not feeding the LLM a torn-up note ‚Äî you‚Äôre feeding it one clean, meaningful thought per bite. Ending mid-sentence is like tossing someone a book and ripping out the last page. Not polite.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Handling references?&lt;/strong&gt; Either inline (bake the reference into the chunk itself with context), or via metadata routing, depending on how fancy your pipeline is. But no magic ‚Äî LLMs don‚Äôt ‚Äúclick links,‚Äù they hallucinate connections, so give them breadcrumbs.&lt;/p&gt;\n\n&lt;p&gt;Bottom line: if you‚Äôre building a RAG that doesn‚Äôt sound drunk at a dinner party, your chunking logic and retrieval must carry most of the weight.&lt;/p&gt;\n\n&lt;p&gt;Let me know if you want chunking recipes ‚Äî I&amp;#39;ve spilled enough ink and tears on this one to fill a Medium blog no one reads.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7kfet/gemma3other_langchain_chromadb_rag_a_few_questions/n4v4sno/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753345200,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7kfet",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]