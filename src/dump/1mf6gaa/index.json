[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Just wanted to share my results running Llama-4-Scout-17B-16E-Instruct-GGUF:Q4\\_K\\_S on my Ryzen AI Max + 395 using llama.cpp with Vulkan backend and the Lemonade server. I’m getting a solid 20 tokens/second with 60 GB of GPU memory in use. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Llama-4-Scout-17B-16E-Instruct-GGUF:Q4_K_S running at 20 tk/s on Ryzen AI Max + 395 with llama.cpp Vulkan + Lemonade server (60GB GPU memory)",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 78,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mf6gaa",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.73,
            "author_flair_background_color": null,
            "ups": 15,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1rpxg2806v",
            "secure_media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/zf13w9taqggf1/DASH_1080.mp4?source=fallback",
                "has_audio": true,
                "height": 1080,
                "width": 1920,
                "scrubber_media_url": "https://v.redd.it/zf13w9taqggf1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/zf13w9taqggf1/DASHPlaylist.mpd?a=1756776238%2CZmI3N2E5ODAwMzQxMzNhZGM0NTM4Y2ZjYTViZTI4M2FlMzMzOWYyZWE0MmQyNTA1ZjdkMDQxOTAzNzZkYzIyMw%3D%3D&amp;v=1&amp;f=sd",
                "duration": 33,
                "hls_url": "https://v.redd.it/zf13w9taqggf1/HLSPlaylist.m3u8?a=1756776238%2CNmQwMTVhNGNiY2I3NTgzNmUxYmY2YzJhNWNjYWRkZWY2MjYyOWFhM2RkM2Q4OTNkM2ZlYzgxM2Q2YzQ2YmNjYQ%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 15,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/anl1eG84dGFxZ2dmMUED0vbVDpHB_6J3h9pq2feZQo01Xw2lEninALLqCef8.png?width=140&amp;height=78&amp;crop=140:78,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=4ad7991508d2b549531e751e830361ac79a4409b",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "hosted:video",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754077979,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "v.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wanted to share my results running Llama-4-Scout-17B-16E-Instruct-GGUF:Q4_K_S on my Ryzen AI Max + 395 using llama.cpp with Vulkan backend and the Lemonade server. I’m getting a solid 20 tokens/second with 60 GB of GPU memory in use. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://v.redd.it/zf13w9taqggf1",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/anl1eG84dGFxZ2dmMUED0vbVDpHB_6J3h9pq2feZQo01Xw2lEninALLqCef8.png?format=pjpg&amp;auto=webp&amp;s=de129663feb9bbf95e122a859d728b746c9defbf",
                    "width": 1920,
                    "height": 1080
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/anl1eG84dGFxZ2dmMUED0vbVDpHB_6J3h9pq2feZQo01Xw2lEninALLqCef8.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=e9150f6d4ace971cda6add553081a915ea75aff7",
                      "width": 108,
                      "height": 60
                    },
                    {
                      "url": "https://external-preview.redd.it/anl1eG84dGFxZ2dmMUED0vbVDpHB_6J3h9pq2feZQo01Xw2lEninALLqCef8.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=0815afd00caf616bfa60e82c3f16ddc27fce172e",
                      "width": 216,
                      "height": 121
                    },
                    {
                      "url": "https://external-preview.redd.it/anl1eG84dGFxZ2dmMUED0vbVDpHB_6J3h9pq2feZQo01Xw2lEninALLqCef8.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=dc775410ecfa429f782ad107df358093728a3ee5",
                      "width": 320,
                      "height": 180
                    },
                    {
                      "url": "https://external-preview.redd.it/anl1eG84dGFxZ2dmMUED0vbVDpHB_6J3h9pq2feZQo01Xw2lEninALLqCef8.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=2de42a5c72bba5762d5890300e1ca483a478e69b",
                      "width": 640,
                      "height": 360
                    },
                    {
                      "url": "https://external-preview.redd.it/anl1eG84dGFxZ2dmMUED0vbVDpHB_6J3h9pq2feZQo01Xw2lEninALLqCef8.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8985c8a18d1e7b326211843c594c2ffef6d43740",
                      "width": 960,
                      "height": 540
                    },
                    {
                      "url": "https://external-preview.redd.it/anl1eG84dGFxZ2dmMUED0vbVDpHB_6J3h9pq2feZQo01Xw2lEninALLqCef8.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=06a9c35365c0dc196bcf55cc7cc2519c5f5e8e01",
                      "width": 1080,
                      "height": 607
                    }
                  ],
                  "variants": {},
                  "id": "anl1eG84dGFxZ2dmMUED0vbVDpHB_6J3h9pq2feZQo01Xw2lEninALLqCef8"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1mf6gaa",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "ShamanFlamingoFR",
            "discussion_type": null,
            "num_comments": 12,
            "send_replies": true,
            "media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/zf13w9taqggf1/DASH_1080.mp4?source=fallback",
                "has_audio": true,
                "height": 1080,
                "width": 1920,
                "scrubber_media_url": "https://v.redd.it/zf13w9taqggf1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/zf13w9taqggf1/DASHPlaylist.mpd?a=1756776238%2CZmI3N2E5ODAwMzQxMzNhZGM0NTM4Y2ZjYTViZTI4M2FlMzMzOWYyZWE0MmQyNTA1ZjdkMDQxOTAzNzZkYzIyMw%3D%3D&amp;v=1&amp;f=sd",
                "duration": 33,
                "hls_url": "https://v.redd.it/zf13w9taqggf1/HLSPlaylist.m3u8?a=1756776238%2CNmQwMTVhNGNiY2I3NTgzNmUxYmY2YzJhNWNjYWRkZWY2MjYyOWFhM2RkM2Q4OTNkM2ZlYzgxM2Q2YzQ2YmNjYQ%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/",
            "stickied": false,
            "url": "https://v.redd.it/zf13w9taqggf1",
            "subreddit_subscribers": 509055,
            "created_utc": 1754077979,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": true
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6f02sn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Entubulated",
            "can_mod_post": false,
            "created_utc": 1754081175,
            "send_replies": true,
            "parent_id": "t3_1mf6gaa",
            "score": 9,
            "author_fullname": "t2_1opxde6hyq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you regularly use llama-4-scout, you might want to look at [Cogito v2 preview](https://huggingface.co/collections/deepcogito/cogito-v2-preview-6886b5450b897ea2a2389a6b) models, which includes a [further trained version of scout](https://huggingface.co/models?search=cogito-v2%20109b).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6f02sn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you regularly use llama-4-scout, you might want to look at &lt;a href=\"https://huggingface.co/collections/deepcogito/cogito-v2-preview-6886b5450b897ea2a2389a6b\"&gt;Cogito v2 preview&lt;/a&gt; models, which includes a &lt;a href=\"https://huggingface.co/models?search=cogito-v2%20109b\"&gt;further trained version of scout&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6f02sn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754081175,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf6gaa",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6hzf0u",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "uti24",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6hopil",
                                "score": 1,
                                "author_fullname": "t2_13hbro",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "So with context 2,000–3,000 tokens speed falls to half? But how it's possible?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6hzf0u",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So with context 2,000–3,000 tokens speed falls to half? But how it&amp;#39;s possible?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf6gaa",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6hzf0u/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754126034,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754126034,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6hopil",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ShamanFlamingoFR",
                      "can_mod_post": false,
                      "created_utc": 1754119593,
                      "send_replies": true,
                      "parent_id": "t1_n6eqw4n",
                      "score": 1,
                      "author_fullname": "t2_1rpxg2806v",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The model requires significant memory:\n\n* Model weights: \\~64.51 GB.\n* Context (KV cache): Varies by context length (e.g., 114.29 GB for 409,470 tokens, 8.67 GB for 30,950 tokens, etc.).\n\nAccording to benchmarks, with 4 A4 pages of context (approximately 2,000–3,000 tokens, assuming \\~500–750 tokens per page), the model achieves a processing speed of 10 tokens per second (tk/s).",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6hopil",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The model requires significant memory:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Model weights: ~64.51 GB.&lt;/li&gt;\n&lt;li&gt;Context (KV cache): Varies by context length (e.g., 114.29 GB for 409,470 tokens, 8.67 GB for 30,950 tokens, etc.).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;According to benchmarks, with 4 A4 pages of context (approximately 2,000–3,000 tokens, assuming ~500–750 tokens per page), the model achieves a processing speed of 10 tokens per second (tk/s).&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf6gaa",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6hopil/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754119593,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6eqw4n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "uti24",
            "can_mod_post": false,
            "created_utc": 1754078440,
            "send_replies": true,
            "parent_id": "t3_1mf6gaa",
            "score": 2,
            "author_fullname": "t2_13hbro",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "How fast does RAM usage increase with context size? \n\nWhat context size will cause the speed to drop to 10 tokens per second?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6eqw4n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How fast does RAM usage increase with context size? &lt;/p&gt;\n\n&lt;p&gt;What context size will cause the speed to drop to 10 tokens per second?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6eqw4n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754078440,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf6gaa",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6f9sqk",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Theio666",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6f8wwh",
                                                              "score": 1,
                                                              "author_fullname": "t2_ikhuo",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "I just checked, there's merged fixes for GLM, but these didn't make into 0.10, probably next release will have them. But the model is good, ngl, I'd use 4.5 air locally if I had the hardware, but 16vram+64ram is clearly not enough for good quant.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6f9sqk",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I just checked, there&amp;#39;s merged fixes for GLM, but these didn&amp;#39;t make into 0.10, probably next release will have them. But the model is good, ngl, I&amp;#39;d use 4.5 air locally if I had the hardware, but 16vram+64ram is clearly not enough for good quant.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mf6gaa",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6f9sqk/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754084161,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754084161,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6f8wwh",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "Entubulated",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6f7lzp",
                                                    "score": 1,
                                                    "author_fullname": "t2_1opxde6hyq",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": ":'-(\n\nConsidering the issues being chased in the llama.cpp PR and that the GLM 4.5 [demo](https://huggingface.co/spaces/zai-org/GLM-4.5-Space) page on HF was showing some [issues](https://www.reddit.com/r/LocalLLaMA/comments/1mbf3dz/comment/n5n2yu1/?context=3) at last I looked, not much of a surprise.  Hopefully it all gets ironed out before long.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6f8wwh",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;:&amp;#39;-(&lt;/p&gt;\n\n&lt;p&gt;Considering the issues being chased in the llama.cpp PR and that the GLM 4.5 &lt;a href=\"https://huggingface.co/spaces/zai-org/GLM-4.5-Space\"&gt;demo&lt;/a&gt; page on HF was showing some &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1mbf3dz/comment/n5n2yu1/?context=3\"&gt;issues&lt;/a&gt; at last I looked, not much of a surprise.  Hopefully it all gets ironed out before long.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mf6gaa",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6f8wwh/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754083876,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754083876,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6f7lzp",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Theio666",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6f6hr7",
                                          "score": 1,
                                          "author_fullname": "t2_ikhuo",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "vLLM had tool calling issues last time I tried, some days it's reasoning problem, some days that with building from source the bug is fixed, not sure myself",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6f7lzp",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;vLLM had tool calling issues last time I tried, some days it&amp;#39;s reasoning problem, some days that with building from source the bug is fixed, not sure myself&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf6gaa",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6f7lzp/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754083467,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754083467,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6f6hr7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Entubulated",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6ez7va",
                                "score": 2,
                                "author_fullname": "t2_1opxde6hyq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "vllm and mlx both have GLM 4.5 MoE support now. Not checked anything else.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6f6hr7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;vllm and mlx both have GLM 4.5 MoE support now. Not checked anything else.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf6gaa",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6f6hr7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754083118,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754083118,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ez7va",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "TaroOk7112",
                      "can_mod_post": false,
                      "created_utc": 1754080920,
                      "send_replies": true,
                      "parent_id": "t1_n6ero3v",
                      "score": 6,
                      "author_fullname": "t2_tsjh0dua",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "We have no support for GLM 4.5 in llama.cpp. The pull request still is in Draft, being worked on:\n\n[https://github.com/ggml-org/llama.cpp/pull/14939](https://github.com/ggml-org/llama.cpp/pull/14939)\n\nDoes the other implementation support it yet? [ONNX Runtime GenAI (OGA)](https://github.com/microsoft/onnxruntime-genai)",
                      "edited": 1754081216,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ez7va",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We have no support for GLM 4.5 in llama.cpp. The pull request still is in Draft, being worked on:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ggml-org/llama.cpp/pull/14939\"&gt;https://github.com/ggml-org/llama.cpp/pull/14939&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Does the other implementation support it yet? &lt;a href=\"https://github.com/microsoft/onnxruntime-genai\"&gt;ONNX Runtime GenAI (OGA)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf6gaa",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6ez7va/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754080920,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6ero3v",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "jamaalwakamaal",
            "can_mod_post": false,
            "created_utc": 1754078672,
            "send_replies": true,
            "parent_id": "t3_1mf6gaa",
            "score": 2,
            "author_fullname": "t2_alyeos2m",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Awesome. Do one for GLM 4.5 Air? With prompt processing numbers.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ero3v",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Awesome. Do one for GLM 4.5 Air? With prompt processing numbers.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6ero3v/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754078672,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf6gaa",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6kn8n1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "randomqhacker",
            "can_mod_post": false,
            "created_utc": 1754162112,
            "send_replies": true,
            "parent_id": "t3_1mf6gaa",
            "score": 1,
            "author_fullname": "t2_4nw3v",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What's the prompt processing speed like?  Really need that for coding.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6kn8n1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the prompt processing speed like?  Really need that for coding.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf6gaa/llama4scout17b16einstructggufq4_k_s_running_at_20/n6kn8n1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754162112,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf6gaa",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]