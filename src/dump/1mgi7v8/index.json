[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Any interesting questions from your experience that you asked a Reasoning LLM and it failed to answer",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "What is an interesting question that an LLM failed to answer, in your experience?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mgi7v8",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.73,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 5,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_xvwcc",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 5,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754224711,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any interesting questions from your experience that you asked a Reasoning LLM and it failed to answer&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mgi7v8",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "VR-Person",
            "discussion_type": null,
            "num_comments": 10,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/",
            "subreddit_subscribers": 509918,
            "created_utc": 1754224711,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6oq0sv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Hamza9575",
            "can_mod_post": false,
            "created_utc": 1754225293,
            "send_replies": true,
            "parent_id": "t3_1mgi7v8",
            "score": 7,
            "author_fullname": "t2_2z5hm75",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Ask coding ai to break denuvo drm of modern pc games.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6oq0sv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ask coding ai to break denuvo drm of modern pc games.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/n6oq0sv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754225293,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgi7v8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6q1xu3",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "InfiniteTrans69",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6pudxc",
                                "score": 3,
                                "author_fullname": "t2_1j5dv6mrfz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The Jindosh Riddle\n\nAt the dinner party were Lady Winslow, Doctor Marcolla, Countess Contee, Madam Natsiou, and Baroness Finch.\n\nThe women sat in a row. They all wore different colors and Madam Natsiou wore a jaunty red hat. Baroness Finch was at the far left, next to the guest wearing a purple jacket. The lady in white sat left of someone in blue. I remember that white outfit because the woman spilled her wine all over it. The traveler from Dabokva was dressed entirely in green. When one of the dinner guests bragged about her Ring, the woman next to her said they were finer in Dabokva, where she lived.\n\nSo Lady Winslow showed off a prized Diamond, at which the lady from Karnaca scoffed, saying it was no match for her Snuff Tin. Someone else carried a valuable War Medal and when she saw it, the visitor from Dunwall next to her almost spilled her neighbor's whiskey. Countess Contee raised her beer in toast. The lady from Fraeport, full of absinthe, jumped up onto the table, falling onto the guest in the center seat, spilling the poor woman's rum. Then Doctor Marcolla captivated them all with a story about her wild youth in Baleton.\n\nIn the morning, there were four heirlooms under the table: the Ring, Bird Pendant, the Snuff Tin, and the War Medal.\n\nBut who owned each?\n\nhttps://preview.redd.it/0zcp3gaa6ugf1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=c9d1cbd10de6cbbfd009e587aad282981ae60657",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6q1xu3",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The Jindosh Riddle&lt;/p&gt;\n\n&lt;p&gt;At the dinner party were Lady Winslow, Doctor Marcolla, Countess Contee, Madam Natsiou, and Baroness Finch.&lt;/p&gt;\n\n&lt;p&gt;The women sat in a row. They all wore different colors and Madam Natsiou wore a jaunty red hat. Baroness Finch was at the far left, next to the guest wearing a purple jacket. The lady in white sat left of someone in blue. I remember that white outfit because the woman spilled her wine all over it. The traveler from Dabokva was dressed entirely in green. When one of the dinner guests bragged about her Ring, the woman next to her said they were finer in Dabokva, where she lived.&lt;/p&gt;\n\n&lt;p&gt;So Lady Winslow showed off a prized Diamond, at which the lady from Karnaca scoffed, saying it was no match for her Snuff Tin. Someone else carried a valuable War Medal and when she saw it, the visitor from Dunwall next to her almost spilled her neighbor&amp;#39;s whiskey. Countess Contee raised her beer in toast. The lady from Fraeport, full of absinthe, jumped up onto the table, falling onto the guest in the center seat, spilling the poor woman&amp;#39;s rum. Then Doctor Marcolla captivated them all with a story about her wild youth in Baleton.&lt;/p&gt;\n\n&lt;p&gt;In the morning, there were four heirlooms under the table: the Ring, Bird Pendant, the Snuff Tin, and the War Medal.&lt;/p&gt;\n\n&lt;p&gt;But who owned each?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0zcp3gaa6ugf1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c9d1cbd10de6cbbfd009e587aad282981ae60657\"&gt;https://preview.redd.it/0zcp3gaa6ugf1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c9d1cbd10de6cbbfd009e587aad282981ae60657&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgi7v8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/n6q1xu3/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754240664,
                                "media_metadata": {
                                  "0zcp3gaa6ugf1": {
                                    "status": "valid",
                                    "e": "Image",
                                    "m": "image/png",
                                    "p": [
                                      {
                                        "y": 60,
                                        "x": 108,
                                        "u": "https://preview.redd.it/0zcp3gaa6ugf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c8e3f252374ef96942045f5ff5069bb6f0ee7a32"
                                      },
                                      {
                                        "y": 121,
                                        "x": 216,
                                        "u": "https://preview.redd.it/0zcp3gaa6ugf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=dc8201f1cf6c5603205969b265142060cb8e772e"
                                      },
                                      {
                                        "y": 180,
                                        "x": 320,
                                        "u": "https://preview.redd.it/0zcp3gaa6ugf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3143108a5ae61c3d6cded0d87baf321de18a88d0"
                                      },
                                      {
                                        "y": 360,
                                        "x": 640,
                                        "u": "https://preview.redd.it/0zcp3gaa6ugf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=554364b122b63b3d929ffd581719b89977f92557"
                                      },
                                      {
                                        "y": 540,
                                        "x": 960,
                                        "u": "https://preview.redd.it/0zcp3gaa6ugf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=75733312ed68926b6f858110adf7cfeed6dfd5ca"
                                      },
                                      {
                                        "y": 607,
                                        "x": 1080,
                                        "u": "https://preview.redd.it/0zcp3gaa6ugf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ab066d48ba167dd60dfa3682d38f15b04419b659"
                                      }
                                    ],
                                    "s": {
                                      "y": 1080,
                                      "x": 1920,
                                      "u": "https://preview.redd.it/0zcp3gaa6ugf1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=c9d1cbd10de6cbbfd009e587aad282981ae60657"
                                    },
                                    "id": "0zcp3gaa6ugf1"
                                  }
                                },
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754240664,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6pudxc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "nomorebuttsplz",
                      "can_mod_post": false,
                      "created_utc": 1754238364,
                      "send_replies": true,
                      "parent_id": "t1_n6ouwab",
                      "score": 2,
                      "author_fullname": "t2_syq52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Do you have it together in one place? I would love to try it on some if you have the text prompt.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6pudxc",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you have it together in one place? I would love to try it on some if you have the text prompt.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgi7v8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/n6pudxc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754238364,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6ouwab",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "InfiniteTrans69",
            "can_mod_post": false,
            "created_utc": 1754227131,
            "send_replies": true,
            "parent_id": "t3_1mgi7v8",
            "score": 2,
            "author_fullname": "t2_1j5dv6mrfz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "My benchmark is still the Puzzle of Kirin Jindosch in Dishonored 2. No LLM so far as cracked it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ouwab",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My benchmark is still the Puzzle of Kirin Jindosch in Dishonored 2. No LLM so far as cracked it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/n6ouwab/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754227131,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgi7v8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6q1mvs",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Fheredin",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6pyg41",
                                "score": 2,
                                "author_fullname": "t2_y4p3e",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Typically I just ask the LLM to describe the rules and sometimes give it a correction or two if it made an error which could affect performance. Small models may need to be spoon fed the rules, but larger ones can typically remember the rules just fine.\n\nApplying those rules in practice is a different matter.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6q1mvs",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Typically I just ask the LLM to describe the rules and sometimes give it a correction or two if it made an error which could affect performance. Small models may need to be spoon fed the rules, but larger ones can typically remember the rules just fine.&lt;/p&gt;\n\n&lt;p&gt;Applying those rules in practice is a different matter.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgi7v8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/n6q1mvs/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754240573,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754240573,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6pyg41",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "nomorebuttsplz",
                      "can_mod_post": false,
                      "created_utc": 1754239617,
                      "send_replies": true,
                      "parent_id": "t1_n6osud1",
                      "score": 1,
                      "author_fullname": "t2_syq52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "is there where you provide the rules for reference in the prompt?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6pyg41",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;is there where you provide the rules for reference in the prompt?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgi7v8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/n6pyg41/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754239617,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6s5sos",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "DorphinPack",
                      "can_mod_post": false,
                      "created_utc": 1754264660,
                      "send_replies": true,
                      "parent_id": "t1_n6osud1",
                      "score": 1,
                      "author_fullname": "t2_zebuyjw9s",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That’s a neat problem for an LLM!\n\nThe thinking iterations issue is fascinatingly structural instead of technical. I bet an LLM could get there if it actually put an example of each iteration in the context then predicted. Have you tried one-shotting it? Predicting the right chain of thought gets a lot easier with an example.\n\nI think what you’re seeing is that it’s trained to only predict “hmmm… but” or “okay, so then…” a limited number of times. With the right prompting there’s no reason it can’t put all the iterations in one “stanza” then ponder about the resulting context before answering.\n\nAlternatively, it seems like an opportunity to show where the chat metaphor can be a hindrance. If the iterations are complex enough to risk tripping up prediction and triggering a “no, scratch that…” you may want to do small context, small max token batches. One per iteration and then a final run with the full context.\n\nIf you didn’t know there are 13 iterations (you wanted to generalize to other problems that have an attainable threshold for exhaustiveness) I bet you could one-shot a similar loop to the ones used for developing code. Show it what exhaustive analysis looks like and let it run, self evaluate, repeat. Other than maximum repeats and other guardrails it would also probably be good to implement some kind of memory management (not the RAM kind) for analysis that overflows context.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6s5sos",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That’s a neat problem for an LLM!&lt;/p&gt;\n\n&lt;p&gt;The thinking iterations issue is fascinatingly structural instead of technical. I bet an LLM could get there if it actually put an example of each iteration in the context then predicted. Have you tried one-shotting it? Predicting the right chain of thought gets a lot easier with an example.&lt;/p&gt;\n\n&lt;p&gt;I think what you’re seeing is that it’s trained to only predict “hmmm… but” or “okay, so then…” a limited number of times. With the right prompting there’s no reason it can’t put all the iterations in one “stanza” then ponder about the resulting context before answering.&lt;/p&gt;\n\n&lt;p&gt;Alternatively, it seems like an opportunity to show where the chat metaphor can be a hindrance. If the iterations are complex enough to risk tripping up prediction and triggering a “no, scratch that…” you may want to do small context, small max token batches. One per iteration and then a final run with the full context.&lt;/p&gt;\n\n&lt;p&gt;If you didn’t know there are 13 iterations (you wanted to generalize to other problems that have an attainable threshold for exhaustiveness) I bet you could one-shot a similar loop to the ones used for developing code. Show it what exhaustive analysis looks like and let it run, self evaluate, repeat. Other than maximum repeats and other guardrails it would also probably be good to implement some kind of memory management (not the RAM kind) for analysis that overflows context.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgi7v8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/n6s5sos/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754264660,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6osud1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Fheredin",
            "can_mod_post": false,
            "created_utc": 1754226378,
            "send_replies": true,
            "parent_id": "t3_1mgi7v8",
            "score": 1,
            "author_fullname": "t2_y4p3e",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have never seen an LLM do a passable job of splitting a cribbage hand. Many of them will get the majority of the rules correct when asked, but they tend to miss points when asked to assess a hand's point totals, and very rarely assess how starter cards change the hand properly, even when specifically asked. \n\nThe problem is that most thinking LLMs I have tested on tend to go through only 3 logical step iterations, but properly assessing a cribbage hand's starter card potentials requires assessing **13 iterations,** which is a much deeper analysis than these things are typically programmed to follow.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6osud1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have never seen an LLM do a passable job of splitting a cribbage hand. Many of them will get the majority of the rules correct when asked, but they tend to miss points when asked to assess a hand&amp;#39;s point totals, and very rarely assess how starter cards change the hand properly, even when specifically asked. &lt;/p&gt;\n\n&lt;p&gt;The problem is that most thinking LLMs I have tested on tend to go through only 3 logical step iterations, but properly assessing a cribbage hand&amp;#39;s starter card potentials requires assessing &lt;strong&gt;13 iterations,&lt;/strong&gt; which is a much deeper analysis than these things are typically programmed to follow.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/n6osud1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754226378,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgi7v8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6p8mf3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Patentsmatter",
            "can_mod_post": false,
            "created_utc": 1754231713,
            "send_replies": true,
            "parent_id": "t3_1mgi7v8",
            "score": 1,
            "author_fullname": "t2_cocl8roo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Reconstructing tables from an OCR scan:\n\n      [298]   Træk i krav 1 i EP                 Stridsprodukterne MPU 1000/2000/3000                                                  Træk\n      [299]   4238202                                                                                                                  tilsted\n      [300]   A       mobile          hybrid       Reference 1% og 3% viser et hybridgeneratorsystem trukket af en bil.                Ja\n      [301]   generator         system     for     Reference 2* nævner at MPU 1000 er \"Super Mobil, løftepunkter til\n      [302]                                        kran, gaffel kanaler, gaffel kanaler, eller trailer træk med B kørekod'.\n      [303]   providing         gridlike   AC Dermed er hybridgeneratorsystem tydeligvis mobil.\n      [304]   power output to a load\n      [305]   at off-grid locations,               Reference 2 nævner \"24 kVA AC \n    out\" hvilket er et netlignende\n      [306]                                        vekselstrømsoutput.\n      [307]                                        Et netværkslignende vekseistrømsoutput er teknisk nødvendigt for at\n      [308]                                        hybridgeneratorsystemet skal kunne drive alle almindelige elektriske\n      [309]                                        enheder,     da   elektriske    enheder     er     designede     til   specifikke\n      [310]                                        vekselstrømsoutput.\n      [311]   the     hybrid       generator       Reference 2 henviser til at \"designet følger MPU 2000/3000 familien\".               Ja\n      [312]   system        comprising       a     Reference 4* viser i tabellen første række, at hver MPU har en trailer og\n      [313]   housing                              et hus jf. billede og angivelser af \"Unit size\".\n      [314]   accommodating:\n      [315]   a                 rechargeable       Reference 2 nævner et 24 kWh LTO-batteri.                                           Ja\n      [316]   electrical              energy LTO batterier er specifikt nævnt flere gange i EP4238202, se [0026),\n      [317]   storage unit, such as a [0031), [0049) samt krav 6 (lithium-titanate battery unit).].\n      [318]   battery,      configured      to\n      [319]   provide       a    DC   power\n      [320]   output,\n\nUnfortunately the Unified Patent Court does not publish all decisions in a machine-readable format, so sometimes it is \"OCR time\". And then you're lost making sense of tables included in the decisions.",
            "edited": 1754231915,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6p8mf3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Reconstructing tables from an OCR scan:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  [298]   Træk i krav 1 i EP                 Stridsprodukterne MPU 1000/2000/3000                                                  Træk\n  [299]   4238202                                                                                                                  tilsted\n  [300]   A       mobile          hybrid       Reference 1% og 3% viser et hybridgeneratorsystem trukket af en bil.                Ja\n  [301]   generator         system     for     Reference 2* nævner at MPU 1000 er &amp;quot;Super Mobil, løftepunkter til\n  [302]                                        kran, gaffel kanaler, gaffel kanaler, eller trailer træk med B kørekod&amp;#39;.\n  [303]   providing         gridlike   AC Dermed er hybridgeneratorsystem tydeligvis mobil.\n  [304]   power output to a load\n  [305]   at off-grid locations,               Reference 2 nævner &amp;quot;24 kVA AC \nout&amp;quot; hvilket er et netlignende\n  [306]                                        vekselstrømsoutput.\n  [307]                                        Et netværkslignende vekseistrømsoutput er teknisk nødvendigt for at\n  [308]                                        hybridgeneratorsystemet skal kunne drive alle almindelige elektriske\n  [309]                                        enheder,     da   elektriske    enheder     er     designede     til   specifikke\n  [310]                                        vekselstrømsoutput.\n  [311]   the     hybrid       generator       Reference 2 henviser til at &amp;quot;designet følger MPU 2000/3000 familien&amp;quot;.               Ja\n  [312]   system        comprising       a     Reference 4* viser i tabellen første række, at hver MPU har en trailer og\n  [313]   housing                              et hus jf. billede og angivelser af &amp;quot;Unit size&amp;quot;.\n  [314]   accommodating:\n  [315]   a                 rechargeable       Reference 2 nævner et 24 kWh LTO-batteri.                                           Ja\n  [316]   electrical              energy LTO batterier er specifikt nævnt flere gange i EP4238202, se [0026),\n  [317]   storage unit, such as a [0031), [0049) samt krav 6 (lithium-titanate battery unit).].\n  [318]   battery,      configured      to\n  [319]   provide       a    DC   power\n  [320]   output,\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Unfortunately the Unified Patent Court does not publish all decisions in a machine-readable format, so sometimes it is &amp;quot;OCR time&amp;quot;. And then you&amp;#39;re lost making sense of tables included in the decisions.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgi7v8/what_is_an_interesting_question_that_an_llm/n6p8mf3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754231713,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgi7v8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]