[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Edit: Added excellent suggestions from u/Everlier:\n\n* Harbor: [https://github.com/av/harbor](https://github.com/av/harbor)\n* Parllama: [https://github.com/paulrobello/parllama](https://github.com/paulrobello/parllama)\n* Oterm (ollama centric): [https://github.com/ggozad/oterm](https://github.com/ggozad/oterm)\n* aichat: [https://github.com/sigoden/aichat](https://github.com/sigoden/aichat)\n* gptme: [https://github.com/gptme/gptme](https://github.com/gptme/gptme)\n* Open Interpreter: [https://github.com/OpenInterpreter/open-interpreter](https://github.com/OpenInterpreter/open-interpreter)\n* Crush: [https://github.com/charmbracelet/crush](https://github.com/charmbracelet/crush)\n* OpenHands: [https://github.com/All-Hands-AI/OpenHands](https://github.com/All-Hands-AI/OpenHands)\n\nAdded by u/ekaj:\n\n* TLDW Chatbook: [https://github.com/rmusser01/tldw\\_chatbook](https://github.com/rmusser01/tldw_chatbook) \n\nI have only used Python to interact with a model on vLLM so far. What are some good terminal UIs (not GUIs like OpenWebUI)? Here are the ones I found so far:\n\n* Elia: [https://github.com/darrenburns/elia](https://github.com/darrenburns/elia)\n* Yappus: [https://github.com/MostlyKIGuess/Yappus-Term](https://github.com/MostlyKIGuess/Yappus-Term)\n* Aider (CLI but not TUI): [https://github.com/Aider-AI/aider](https://github.com/Aider-AI/aider)\n\nI use [Codex CLI](https://github.com/openai/codex), but it's designed for coding in a git repository and not general chat. I basically want a Codex CLI but for chat.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "What are some terminal UIs for chatting with a vLLM-hosted model?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjyuv5",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.54,
            "author_flair_background_color": "transparent",
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
            "is_original_content": false,
            "author_fullname": "t2_1a48h7vf",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1754603914,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "a": ":X:",
                "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                "e": "emoji"
              }
            ],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754570060,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Edit: Added excellent suggestions from &lt;a href=\"/u/Everlier\"&gt;u/Everlier&lt;/a&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Harbor: &lt;a href=\"https://github.com/av/harbor\"&gt;https://github.com/av/harbor&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Parllama: &lt;a href=\"https://github.com/paulrobello/parllama\"&gt;https://github.com/paulrobello/parllama&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Oterm (ollama centric): &lt;a href=\"https://github.com/ggozad/oterm\"&gt;https://github.com/ggozad/oterm&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;aichat: &lt;a href=\"https://github.com/sigoden/aichat\"&gt;https://github.com/sigoden/aichat&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;gptme: &lt;a href=\"https://github.com/gptme/gptme\"&gt;https://github.com/gptme/gptme&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Open Interpreter: &lt;a href=\"https://github.com/OpenInterpreter/open-interpreter\"&gt;https://github.com/OpenInterpreter/open-interpreter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Crush: &lt;a href=\"https://github.com/charmbracelet/crush\"&gt;https://github.com/charmbracelet/crush&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;OpenHands: &lt;a href=\"https://github.com/All-Hands-AI/OpenHands\"&gt;https://github.com/All-Hands-AI/OpenHands&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Added by &lt;a href=\"/u/ekaj\"&gt;u/ekaj&lt;/a&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;TLDW Chatbook: &lt;a href=\"https://github.com/rmusser01/tldw_chatbook\"&gt;https://github.com/rmusser01/tldw_chatbook&lt;/a&gt; &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I have only used Python to interact with a model on vLLM so far. What are some good terminal UIs (not GUIs like OpenWebUI)? Here are the ones I found so far:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Elia: &lt;a href=\"https://github.com/darrenburns/elia\"&gt;https://github.com/darrenburns/elia&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Yappus: &lt;a href=\"https://github.com/MostlyKIGuess/Yappus-Term\"&gt;https://github.com/MostlyKIGuess/Yappus-Term&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Aider (CLI but not TUI): &lt;a href=\"https://github.com/Aider-AI/aider\"&gt;https://github.com/Aider-AI/aider&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I use &lt;a href=\"https://github.com/openai/codex\"&gt;Codex CLI&lt;/a&gt;, but it&amp;#39;s designed for coding in a git repository and not general chat. I basically want a Codex CLI but for chat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/ZgkHUBpCI-mo-R7TKIoMYlxSnS7RxUAKXJWeDlhzeZ4.png?auto=webp&amp;s=fed100b482ca08e68bfe1320d6f04cdcc9bfc332",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/ZgkHUBpCI-mo-R7TKIoMYlxSnS7RxUAKXJWeDlhzeZ4.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=07558ff258ec7cde0629188daba7d8644e255c11",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/ZgkHUBpCI-mo-R7TKIoMYlxSnS7RxUAKXJWeDlhzeZ4.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1e60aeca776f3c0f146e13300be0a6fed92151ae",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/ZgkHUBpCI-mo-R7TKIoMYlxSnS7RxUAKXJWeDlhzeZ4.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e42bcb07cbd718f4f4434071d4fa4661c614ff4b",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/ZgkHUBpCI-mo-R7TKIoMYlxSnS7RxUAKXJWeDlhzeZ4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=45aec152595485a7fbadd33bdc89e3fed5931f49",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/ZgkHUBpCI-mo-R7TKIoMYlxSnS7RxUAKXJWeDlhzeZ4.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee7e489c5bbe5a35e90aaadc6a73e885a2d25609",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/ZgkHUBpCI-mo-R7TKIoMYlxSnS7RxUAKXJWeDlhzeZ4.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a8a6848d01f6cc72dba6303152ab33402380ac12",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "ZgkHUBpCI-mo-R7TKIoMYlxSnS7RxUAKXJWeDlhzeZ4"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": ":X:",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mjyuv5",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "entsnack",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "dark",
            "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/",
            "subreddit_subscribers": 513417,
            "created_utc": 1754570060,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7fjsi1",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "MoneyPowerNexis",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7eqdfs",
                                "score": 3,
                                "author_fullname": "t2_635g2",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Here is a very basic vibe coded streaming chat loop in python:\n \n    #!/usr/bin/env python3\n    import time\n    import json\n    import requests\n    \n    # ----------------------------------------------------------------------\n    # 1️⃣  Payload – a tiny helper that stores the chat history\n    # ----------------------------------------------------------------------\n    class Payload:\n        \"\"\"\n        Holds the list of messages and the request‑level parameters.\n        \"\"\"\n        def __init__(self):\n            # Default request parameters (feel free to change)\n            self.payload = {\n                \"model\": \"\",   # &lt;-- LEAVE BLANK WORKS BEST\n                \"temperature\": 0.6,\n                \"stream\": True,\n                \"messages\": []              # ← conversation history\n            }\n    \n        # ------------------------------------------------------------------\n        # Helper methods\n        # ------------------------------------------------------------------\n        def add(self, role: str, content: str) -&gt; None:\n            \"\"\"Append a new message (role = 'user' | 'assistant' | 'system').\"\"\"\n            self.payload[\"messages\"].append({\"role\": role, \"content\": content})\n    \n        def copy_with_focus(self, focus: str) -&gt; dict:\n            \"\"\"\n            Return a **new** payload dict that contains the whole history plus a\n            temporary system message (`focus`).  The original `self.payload` stays\n            unchanged.\n            \"\"\"\n            copy = {\n                **self.payload,\n                \"messages\": self.payload[\"messages\"][:]   # shallow copy of list\n            }\n            # Insert the focus message just before the last user message\n            if copy[\"messages\"]:\n                copy[\"messages\"].insert(-1, {\"role\": \"system\", \"content\": focus})\n            else:\n                copy[\"messages\"].append({\"role\": \"system\", \"content\": focus})\n            return copy\n    \n        def get(self) -&gt; dict:\n            \"\"\"Return the raw dict that will be JSON‑encoded for the request.\"\"\"\n            return self.payload\n    \n    \n    # ----------------------------------------------------------------------\n    # 2️⃣  LLMStream – does the HTTP call and streams the answer\n    # ----------------------------------------------------------------------\n    class LLMStream:\n        \"\"\"\n        Sends a request to `url` and yields the assistant’s answer token‑by‑token.\n        \"\"\"\n        def __init__(self, url: str):\n            self.url = url\n            self.tps = 0.0          # tokens (characters) per second – for info only\n    \n        def fetch(self, payload: dict, stream: bool = True) -&gt; str:\n            \"\"\"\n            Sends the JSON payload to the server.\n            If `stream` is True, prints each chunk as it arrives.\n            Returns the complete assistant response as a string.\n            \"\"\"\n            start = time.time()\n            response = requests.post(self.url, json=payload, stream=True)\n    \n            collected = []          # pieces of the answer\n            total_chars = 0\n    \n            for line in response.iter_lines():\n                if not line:\n                    continue\n                txt = line.decode(\"utf-8\")\n                if not txt.startswith(\"data:\"):\n                    continue\n    \n                data = txt[5:].strip()\n                if data == \"[DONE]\":\n                    break\n    \n                try:\n                    chunk = json.loads(data)\n                    # The streamed format follows OpenAI’s spec:\n                    #   {\"choices\":[{\"delta\":{\"content\":\"Hello\"}}]}\n                    delta = chunk.get(\"choices\", [{}])[0].get(\"delta\", {})\n                    content = delta.get(\"content\")\n                    if content:\n                        collected.append(content)\n                        total_chars += len(content)\n                        if stream:\n                            print(content, end=\"\", flush=True)\n                except json.JSONDecodeError:\n                    # If the server sends something unexpected, just ignore it.\n                    continue\n    \n            # Compute a very rough \"tokens per second\" (here we use characters)\n            elapsed = time.time() - start\n            self.tps = total_chars / elapsed if elapsed &gt; 0 else 0.0\n    \n            if stream:\n                print()   # newline after the streamed answer\n    \n            return \"\".join(collected)\n    \n    \n    # ----------------------------------------------------------------------\n    # 3️⃣  Main chat loop\n    # ----------------------------------------------------------------------\n    def main():\n        # 👉 Change this to the address of your own LLM server.\n        API_URL = \"http://127.0.0.1:8080/v1/chat/completions\"\n    \n        llm = LLMStream(API_URL)\n        chat = Payload()                     # holds the whole conversation\n    \n        # Optional: give the model a system prompt once at the start\n        chat.add(\"system\", \"You are a helpful assistant.\")   # you can delete this line\n    \n        print(\"Simple chat – type ‘exit’ to quit, ‘tps’ to see tokens‑per‑second.\\n\")\n    \n        while True:\n            user_msg = input(\"&gt; \").strip()\n            if not user_msg:\n                continue\n    \n            if user_msg.lower() == \"exit\":\n                break\n            if user_msg.lower() == \"tps\":\n                print(f\"Tokens per second: {llm.tps:.2f}\")\n                continue\n    \n            # 1️⃣  Add the user message to the history\n            chat.add(\"user\", user_msg)\n    \n            # 2️⃣  Build a copy that contains a short “focus” system message.\n            #     This lets us ask the model to stay on‑topic without losing\n            #     the original history.\n            focus_payload = chat.copy_with_focus(\"Please answer only the last question.\")\n    \n            # 3️⃣  Send to the LLM and stream the answer\n            answer = llm.fetch(focus_payload)\n    \n            # 4️⃣  Store the assistant’s reply so the next round knows the full context\n            chat.add(\"assistant\", answer)\n    \n    \n    if __name__ == \"__main__\":\n        main()\n\nthis is from an old project I just used an llm to strip out some project specific stuff and comment it. I was working with older models that had more trouble keeping in context so had a system prompt at the head of the chat history to tell it to stay on topic. that could probably be remove now",
                                "edited": 1754580592,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7fjsi1",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here is a very basic vibe coded streaming chat loop in python:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;#!/usr/bin/env python3\nimport time\nimport json\nimport requests\n\n# ----------------------------------------------------------------------\n# 1️⃣  Payload – a tiny helper that stores the chat history\n# ----------------------------------------------------------------------\nclass Payload:\n    &amp;quot;&amp;quot;&amp;quot;\n    Holds the list of messages and the request‑level parameters.\n    &amp;quot;&amp;quot;&amp;quot;\n    def __init__(self):\n        # Default request parameters (feel free to change)\n        self.payload = {\n            &amp;quot;model&amp;quot;: &amp;quot;&amp;quot;,   # &amp;lt;-- LEAVE BLANK WORKS BEST\n            &amp;quot;temperature&amp;quot;: 0.6,\n            &amp;quot;stream&amp;quot;: True,\n            &amp;quot;messages&amp;quot;: []              # ← conversation history\n        }\n\n    # ------------------------------------------------------------------\n    # Helper methods\n    # ------------------------------------------------------------------\n    def add(self, role: str, content: str) -&amp;gt; None:\n        &amp;quot;&amp;quot;&amp;quot;Append a new message (role = &amp;#39;user&amp;#39; | &amp;#39;assistant&amp;#39; | &amp;#39;system&amp;#39;).&amp;quot;&amp;quot;&amp;quot;\n        self.payload[&amp;quot;messages&amp;quot;].append({&amp;quot;role&amp;quot;: role, &amp;quot;content&amp;quot;: content})\n\n    def copy_with_focus(self, focus: str) -&amp;gt; dict:\n        &amp;quot;&amp;quot;&amp;quot;\n        Return a **new** payload dict that contains the whole history plus a\n        temporary system message (`focus`).  The original `self.payload` stays\n        unchanged.\n        &amp;quot;&amp;quot;&amp;quot;\n        copy = {\n            **self.payload,\n            &amp;quot;messages&amp;quot;: self.payload[&amp;quot;messages&amp;quot;][:]   # shallow copy of list\n        }\n        # Insert the focus message just before the last user message\n        if copy[&amp;quot;messages&amp;quot;]:\n            copy[&amp;quot;messages&amp;quot;].insert(-1, {&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: focus})\n        else:\n            copy[&amp;quot;messages&amp;quot;].append({&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: focus})\n        return copy\n\n    def get(self) -&amp;gt; dict:\n        &amp;quot;&amp;quot;&amp;quot;Return the raw dict that will be JSON‑encoded for the request.&amp;quot;&amp;quot;&amp;quot;\n        return self.payload\n\n\n# ----------------------------------------------------------------------\n# 2️⃣  LLMStream – does the HTTP call and streams the answer\n# ----------------------------------------------------------------------\nclass LLMStream:\n    &amp;quot;&amp;quot;&amp;quot;\n    Sends a request to `url` and yields the assistant’s answer token‑by‑token.\n    &amp;quot;&amp;quot;&amp;quot;\n    def __init__(self, url: str):\n        self.url = url\n        self.tps = 0.0          # tokens (characters) per second – for info only\n\n    def fetch(self, payload: dict, stream: bool = True) -&amp;gt; str:\n        &amp;quot;&amp;quot;&amp;quot;\n        Sends the JSON payload to the server.\n        If `stream` is True, prints each chunk as it arrives.\n        Returns the complete assistant response as a string.\n        &amp;quot;&amp;quot;&amp;quot;\n        start = time.time()\n        response = requests.post(self.url, json=payload, stream=True)\n\n        collected = []          # pieces of the answer\n        total_chars = 0\n\n        for line in response.iter_lines():\n            if not line:\n                continue\n            txt = line.decode(&amp;quot;utf-8&amp;quot;)\n            if not txt.startswith(&amp;quot;data:&amp;quot;):\n                continue\n\n            data = txt[5:].strip()\n            if data == &amp;quot;[DONE]&amp;quot;:\n                break\n\n            try:\n                chunk = json.loads(data)\n                # The streamed format follows OpenAI’s spec:\n                #   {&amp;quot;choices&amp;quot;:[{&amp;quot;delta&amp;quot;:{&amp;quot;content&amp;quot;:&amp;quot;Hello&amp;quot;}}]}\n                delta = chunk.get(&amp;quot;choices&amp;quot;, [{}])[0].get(&amp;quot;delta&amp;quot;, {})\n                content = delta.get(&amp;quot;content&amp;quot;)\n                if content:\n                    collected.append(content)\n                    total_chars += len(content)\n                    if stream:\n                        print(content, end=&amp;quot;&amp;quot;, flush=True)\n            except json.JSONDecodeError:\n                # If the server sends something unexpected, just ignore it.\n                continue\n\n        # Compute a very rough &amp;quot;tokens per second&amp;quot; (here we use characters)\n        elapsed = time.time() - start\n        self.tps = total_chars / elapsed if elapsed &amp;gt; 0 else 0.0\n\n        if stream:\n            print()   # newline after the streamed answer\n\n        return &amp;quot;&amp;quot;.join(collected)\n\n\n# ----------------------------------------------------------------------\n# 3️⃣  Main chat loop\n# ----------------------------------------------------------------------\ndef main():\n    # 👉 Change this to the address of your own LLM server.\n    API_URL = &amp;quot;http://127.0.0.1:8080/v1/chat/completions&amp;quot;\n\n    llm = LLMStream(API_URL)\n    chat = Payload()                     # holds the whole conversation\n\n    # Optional: give the model a system prompt once at the start\n    chat.add(&amp;quot;system&amp;quot;, &amp;quot;You are a helpful assistant.&amp;quot;)   # you can delete this line\n\n    print(&amp;quot;Simple chat – type ‘exit’ to quit, ‘tps’ to see tokens‑per‑second.\\n&amp;quot;)\n\n    while True:\n        user_msg = input(&amp;quot;&amp;gt; &amp;quot;).strip()\n        if not user_msg:\n            continue\n\n        if user_msg.lower() == &amp;quot;exit&amp;quot;:\n            break\n        if user_msg.lower() == &amp;quot;tps&amp;quot;:\n            print(f&amp;quot;Tokens per second: {llm.tps:.2f}&amp;quot;)\n            continue\n\n        # 1️⃣  Add the user message to the history\n        chat.add(&amp;quot;user&amp;quot;, user_msg)\n\n        # 2️⃣  Build a copy that contains a short “focus” system message.\n        #     This lets us ask the model to stay on‑topic without losing\n        #     the original history.\n        focus_payload = chat.copy_with_focus(&amp;quot;Please answer only the last question.&amp;quot;)\n\n        # 3️⃣  Send to the LLM and stream the answer\n        answer = llm.fetch(focus_payload)\n\n        # 4️⃣  Store the assistant’s reply so the next round knows the full context\n        chat.add(&amp;quot;assistant&amp;quot;, answer)\n\n\nif __name__ == &amp;quot;__main__&amp;quot;:\n    main()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;this is from an old project I just used an llm to strip out some project specific stuff and comment it. I was working with older models that had more trouble keeping in context so had a system prompt at the head of the chat history to tell it to stay on topic. that could probably be remove now&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjyuv5",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7fjsi1/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754579688,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754579688,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7esxpl",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "No_Efficiency_1144",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7eqdfs",
                                "score": 2,
                                "author_fullname": "t2_1nkj9l14b0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You need a store for the conversation history. You need a loop to take user input and add it to the history and then send it to the LLM. When the LLM response returns you need a loop to take the LLM output, take only the latest response and add it to the conversation history.\n\n\nThese two loops close the overall meta loop as information is passed to and from the LLM and the conversation history is updated over time.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7esxpl",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You need a store for the conversation history. You need a loop to take user input and add it to the history and then send it to the LLM. When the LLM response returns you need a loop to take the LLM output, take only the latest response and add it to the conversation history.&lt;/p&gt;\n\n&lt;p&gt;These two loops close the overall meta loop as information is passed to and from the LLM and the conversation history is updated over time.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjyuv5",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7esxpl/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754571455,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754571455,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7eqdfs",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754570586,
                      "send_replies": true,
                      "parent_id": "t1_n7epc7o",
                      "score": 2,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "But how do you maintain the conversation state? You have to keep adding it to the context after each response. It's tedious.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7eqdfs",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But how do you maintain the conversation state? You have to keep adding it to the context after each response. It&amp;#39;s tedious.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjyuv5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7eqdfs/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754570586,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7epc7o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "No_Efficiency_1144",
            "can_mod_post": false,
            "created_utc": 1754570217,
            "send_replies": true,
            "parent_id": "t3_1mjyuv5",
            "score": 3,
            "author_fullname": "t2_1nkj9l14b0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Just some bash is ok",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7epc7o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just some bash is ok&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7epc7o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754570217,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjyuv5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "d2642412-d9ce-11ed-ae30-32b11309f5bd",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "d2642412-d9ce-11ed-ae30-32b11309f5bd",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "d2642412-d9ce-11ed-ae30-32b11309f5bd",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "richtext",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n7fgtyz",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "entsnack",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n7f7w5y",
                                                              "score": 1,
                                                              "author_fullname": "t2_1a48h7vf",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "haha even better to spend my weekend on!",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n7fgtyz",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [
                                                                {
                                                                  "a": ":X:",
                                                                  "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                                                  "e": "emoji"
                                                                }
                                                              ],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;haha even better to spend my weekend on!&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mjyuv5",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": "dark",
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7fgtyz/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754578840,
                                                              "author_flair_text": ":X:",
                                                              "treatment_tags": [],
                                                              "created_utc": 1754578840,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": "transparent",
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7f7w5y",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "Everlier",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n7exmng",
                                                    "score": 2,
                                                    "author_fullname": "t2_o7p5m",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Happy weekend! Just don't read about the controversy behind it",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7f7w5y",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "e": "text",
                                                        "t": "Alpaca"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Happy weekend! Just don&amp;#39;t read about the controversy behind it&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mjyuv5",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "light",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7f7w5y/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754576264,
                                                    "author_flair_text": "Alpaca",
                                                    "collapsed": false,
                                                    "created_utc": 1754576264,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "#bd9e9e",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7exmng",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "entsnack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7eul44",
                                          "score": 2,
                                          "author_fullname": "t2_1a48h7vf",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "OK you've literally made my weekend, I'm an absolute slut for beautiful TUIs and never knew about Crush.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7exmng",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "a": ":X:",
                                              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                              "e": "emoji"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OK you&amp;#39;ve literally made my weekend, I&amp;#39;m an absolute slut for beautiful TUIs and never knew about Crush.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjyuv5",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "dark",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7exmng/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754573030,
                                          "author_flair_text": ":X:",
                                          "treatment_tags": [],
                                          "created_utc": 1754573030,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "transparent",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7ewh3m",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "entsnack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7eul44",
                                          "score": 1,
                                          "author_fullname": "t2_1a48h7vf",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "liked and subscribed",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7ewh3m",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "a": ":X:",
                                              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                              "e": "emoji"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;liked and subscribed&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjyuv5",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "dark",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7ewh3m/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754572653,
                                          "author_flair_text": ":X:",
                                          "treatment_tags": [],
                                          "created_utc": 1754572653,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "transparent",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7eul44",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Everlier",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7es9no",
                                "score": 2,
                                "author_fullname": "t2_o7p5m",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I've seen your posts about Codex CLI. \n\nYou might find Aider interesting too, the OG TUI dev agent. There's also OpenHands, OpenCode and a Crush from the Charm corp",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7eul44",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "Alpaca"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen your posts about Codex CLI. &lt;/p&gt;\n\n&lt;p&gt;You might find Aider interesting too, the OG TUI dev agent. There&amp;#39;s also OpenHands, OpenCode and a Crush from the Charm corp&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjyuv5",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7eul44/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754572020,
                                "author_flair_text": "Alpaca",
                                "treatment_tags": [],
                                "created_utc": 1754572020,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bd9e9e",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7es9no",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754571231,
                      "send_replies": true,
                      "parent_id": "t1_n7eqdnd",
                      "score": 3,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I like the plug! Added all to my post.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7es9no",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I like the plug! Added all to my post.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjyuv5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7es9no/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754571231,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7eqdnd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Everlier",
            "can_mod_post": false,
            "created_utc": 1754570588,
            "send_replies": true,
            "parent_id": "t3_1mjyuv5",
            "score": 2,
            "author_fullname": "t2_o7p5m",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The ones I used:\n\n* [Parllama](https://github.com/paulrobello/parllama) \\- was mainly for Ollama in the past, now generic\n* [Oterm](https://github.com/ggozad/oterm) \\- still Ollama-centric\n* [aichat](https://github.com/sigoden/aichat) \\- simple straightforward response/reply + lightweight agentic coding\n* [gptme](https://github.com/gptme/gptme) \\- light shell automation \n* [Open Interpreter](https://github.com/OpenInterpreter/open-interpreter) \\- aims to solve more, but also works as a simple TUI for LLM conversations\n\nShameless plug: if you're ok with Docker, [Harbor](https://github.com/av/harbor) allows running all of the above in one command",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7eqdnd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Alpaca"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The ones I used:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/paulrobello/parllama\"&gt;Parllama&lt;/a&gt; - was mainly for Ollama in the past, now generic&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/ggozad/oterm\"&gt;Oterm&lt;/a&gt; - still Ollama-centric&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/sigoden/aichat\"&gt;aichat&lt;/a&gt; - simple straightforward response/reply + lightweight agentic coding&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/gptme/gptme\"&gt;gptme&lt;/a&gt; - light shell automation &lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/OpenInterpreter/open-interpreter\"&gt;Open Interpreter&lt;/a&gt; - aims to solve more, but also works as a simple TUI for LLM conversations&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Shameless plug: if you&amp;#39;re ok with Docker, &lt;a href=\"https://github.com/av/harbor\"&gt;Harbor&lt;/a&gt; allows running all of the above in one command&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7eqdnd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754570588,
            "author_flair_text": "Alpaca",
            "treatment_tags": [],
            "link_id": "t3_1mjyuv5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bd9e9e",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7hvk7y",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754603887,
                      "send_replies": true,
                      "parent_id": "t1_n7ht1ti",
                      "score": 2,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This is cracked! Thanks for building and sharing.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7hvk7y",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is cracked! Thanks for building and sharing.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjyuv5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7hvk7y/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754603887,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7ht1ti",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ekaj",
            "can_mod_post": false,
            "created_utc": 1754603087,
            "send_replies": true,
            "parent_id": "t3_1mjyuv5",
            "score": 2,
            "author_fullname": "t2_3cajs",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'll throw in my own: [https://github.com/rmusser01/tldw\\_chatbook](https://github.com/rmusser01/tldw_chatbook) (Textual/Python-based)  \nIts a WIP, but is supposed to be a standalone front-end to my tldw\\_server project.\n\n\\- 18(?) APIs supported, Llama.cpp/Kobold/Ooba/vllm/custom(placeholders for custom providers using OpenAI API spec) / TabbyAPI/Aphrodite/OpenAI/Anthropic/Cohere/Groq/Google/HuggingFace/Mistral/MoonShot/OpenRouter/Zai\n\n\\- File &amp; Image attach in chat - can upload/parse files on upload for in-context chatting, or attach an image into the chat message,\n\n\\- Conversation Search/Storage/Export\n\n\\- Character cards Import/Export/Creation/Editing (Lore/World books + Chat Dictionaries)\n\n\\- Prompt Storage/keywords/etc\n\n\\- Allows for file ingestion -&gt; markdown/text (Video/audio/pdf/documents/plaintext/webscraper/etc)\n\n\\- RAG (Contextual chunking, hybrid BM25+Vector search, lots of tuning options + OCR backend support)\n\n\\- In-App Notes with local file sync,\n\n\\- TTS/STT via Higgs, Elevenlabs, openai, Kokoro, chatterbox\n\n\\- File download/creation, ask the LLM to generate a file for you and the chat UI can identify that and offer it to you as a download.\n\n\\- Wrapper for ollama/llama.cpp/llamafile/vllm/mlx-lm - Supports running them and hosting them as local servers, and in the chat UI, can select 'local-X' to be able to chat with the local server.\n\n\\- Evals (Custom evals + existing ones; UI is broken, but backend code is there)\n\n\\- Chatbooks - a means of collecting various notes/conversations/media items into a bundled zip/sqlite/JSON file for sharing with others. One of the goals of the project and the prior PoC was as a research multi-tool, and making it easy for individuals to share their notes/research.\n\nPlanning to make a post about it once I'm happier with the UI/less bugs.",
            "edited": 1754603752,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7ht1ti",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll throw in my own: &lt;a href=\"https://github.com/rmusser01/tldw_chatbook\"&gt;https://github.com/rmusser01/tldw_chatbook&lt;/a&gt; (Textual/Python-based)&lt;br/&gt;\nIts a WIP, but is supposed to be a standalone front-end to my tldw_server project.&lt;/p&gt;\n\n&lt;p&gt;- 18(?) APIs supported, Llama.cpp/Kobold/Ooba/vllm/custom(placeholders for custom providers using OpenAI API spec) / TabbyAPI/Aphrodite/OpenAI/Anthropic/Cohere/Groq/Google/HuggingFace/Mistral/MoonShot/OpenRouter/Zai&lt;/p&gt;\n\n&lt;p&gt;- File &amp;amp; Image attach in chat - can upload/parse files on upload for in-context chatting, or attach an image into the chat message,&lt;/p&gt;\n\n&lt;p&gt;- Conversation Search/Storage/Export&lt;/p&gt;\n\n&lt;p&gt;- Character cards Import/Export/Creation/Editing (Lore/World books + Chat Dictionaries)&lt;/p&gt;\n\n&lt;p&gt;- Prompt Storage/keywords/etc&lt;/p&gt;\n\n&lt;p&gt;- Allows for file ingestion -&amp;gt; markdown/text (Video/audio/pdf/documents/plaintext/webscraper/etc)&lt;/p&gt;\n\n&lt;p&gt;- RAG (Contextual chunking, hybrid BM25+Vector search, lots of tuning options + OCR backend support)&lt;/p&gt;\n\n&lt;p&gt;- In-App Notes with local file sync,&lt;/p&gt;\n\n&lt;p&gt;- TTS/STT via Higgs, Elevenlabs, openai, Kokoro, chatterbox&lt;/p&gt;\n\n&lt;p&gt;- File download/creation, ask the LLM to generate a file for you and the chat UI can identify that and offer it to you as a download.&lt;/p&gt;\n\n&lt;p&gt;- Wrapper for ollama/llama.cpp/llamafile/vllm/mlx-lm - Supports running them and hosting them as local servers, and in the chat UI, can select &amp;#39;local-X&amp;#39; to be able to chat with the local server.&lt;/p&gt;\n\n&lt;p&gt;- Evals (Custom evals + existing ones; UI is broken, but backend code is there)&lt;/p&gt;\n\n&lt;p&gt;- Chatbooks - a means of collecting various notes/conversations/media items into a bundled zip/sqlite/JSON file for sharing with others. One of the goals of the project and the prior PoC was as a research multi-tool, and making it easy for individuals to share their notes/research.&lt;/p&gt;\n\n&lt;p&gt;Planning to make a post about it once I&amp;#39;m happier with the UI/less bugs.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjyuv5/what_are_some_terminal_uis_for_chatting_with_a/n7ht1ti/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754603087,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mjyuv5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]