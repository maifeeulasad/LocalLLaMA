[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Ive been looking at buying a few mi50 32gb cards for my local training setup because they are absurdly affordable for the VRAM they have. I'm not too concerned with FLOP/s performance, as long as they have compatibility with a relatively modern pytorch and its dependencies.\n\nI've seen people on here talking about this card for inference but not training. Would this be a good idea?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Mi50 array for training LLMs",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m96wrc",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.75,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 4,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1jemkvy49e",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 4,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753468011,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Ive been looking at buying a few mi50 32gb cards for my local training setup because they are absurdly affordable for the VRAM they have. I&amp;#39;m not too concerned with FLOP/s performance, as long as they have compatibility with a relatively modern pytorch and its dependencies.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen people on here talking about this card for inference but not training. Would this be a good idea?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m96wrc",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Used_Algae_1077",
            "discussion_type": null,
            "num_comments": 9,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/",
            "subreddit_subscribers": 504692,
            "created_utc": 1753468011,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n55cduu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FullstackSensei",
                      "can_mod_post": false,
                      "created_utc": 1753474246,
                      "send_replies": true,
                      "parent_id": "t1_n54v6mv",
                      "score": 3,
                      "author_fullname": "t2_17n3nqtj56",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The latest stable Pytorch wheels are built against ROCm 6.3. ROCm 6.3.3 still supports the Mi50. It's marked as deprecated, but AMD explicitly states \"Existing features and capabilities are maintained, but no new features or optimizations will be added.\"\n\nDepending on OP's budget and available options, it could very well be their only viable option.",
                      "edited": 1753475670,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n55cduu",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The latest stable Pytorch wheels are built against ROCm 6.3. ROCm 6.3.3 still supports the Mi50. It&amp;#39;s marked as deprecated, but AMD explicitly states &amp;quot;Existing features and capabilities are maintained, but no new features or optimizations will be added.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Depending on OP&amp;#39;s budget and available options, it could very well be their only viable option.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m96wrc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/n55cduu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753474246,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n54v6mv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ForsookComparison",
            "can_mod_post": false,
            "created_utc": 1753469165,
            "send_replies": true,
            "parent_id": "t3_1m96wrc",
            "score": 8,
            "author_fullname": "t2_on5es7pe3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "These cards are incredible for inference but I'd be hesitant in getting them for training.\n\nTraining is still sort of bleeding edge with AMD, so you'll really want to be on the train for updates.\n\nAs of ROCm 6.4 [it looks like the mi50 has phased out](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html) - so it may work for future versions, but AMD will not be making full efforts to test/ensure compatibility.\n\n**TLDR** - I would not suggest it for training",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n54v6mv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;These cards are incredible for inference but I&amp;#39;d be hesitant in getting them for training.&lt;/p&gt;\n\n&lt;p&gt;Training is still sort of bleeding edge with AMD, so you&amp;#39;ll really want to be on the train for updates.&lt;/p&gt;\n\n&lt;p&gt;As of ROCm 6.4 &lt;a href=\"https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html\"&gt;it looks like the mi50 has phased out&lt;/a&gt; - so it may work for future versions, but AMD will not be making full efforts to test/ensure compatibility.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TLDR&lt;/strong&gt; - I would not suggest it for training&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/n54v6mv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753469165,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m96wrc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n55x5e8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "FullstackSensei",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n55mr2r",
                                "score": 1,
                                "author_fullname": "t2_17n3nqtj56",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "vLLM's build documentation refers to ROCm 6.2, which supports the Mi50, so it should work. I don't know how's the experience because I don't have the cards yet.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n55x5e8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;vLLM&amp;#39;s build documentation refers to ROCm 6.2, which supports the Mi50, so it should work. I don&amp;#39;t know how&amp;#39;s the experience because I don&amp;#39;t have the cards yet.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m96wrc",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/n55x5e8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753480471,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753480471,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n56io5e",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "coolestmage",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n55mr2r",
                                "score": 1,
                                "author_fullname": "t2_6dtdz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I've had success with this vllm fork: https://github.com/nlzy/vllm-gfx906",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n56io5e",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve had success with this vllm fork: &lt;a href=\"https://github.com/nlzy/vllm-gfx906\"&gt;https://github.com/nlzy/vllm-gfx906&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m96wrc",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/n56io5e/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753487674,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753487674,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n55mr2r",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Theio666",
                      "can_mod_post": false,
                      "created_utc": 1753477261,
                      "send_replies": true,
                      "parent_id": "t1_n55h5uo",
                      "score": 1,
                      "author_fullname": "t2_ikhuo",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "By any chance, do you know if mi50 works with vLLM? Probably not with fp8, but in general, how's the experience?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n55mr2r",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;By any chance, do you know if mi50 works with vLLM? Probably not with fp8, but in general, how&amp;#39;s the experience?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m96wrc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/n55mr2r/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753477261,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n56q2pm",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "FullstackSensei",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n568bmm",
                                "score": 2,
                                "author_fullname": "t2_17n3nqtj56",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "alibaba.com. Installed the app, created account, searched Mi50, messaged seller with the most sales with the questions I had, got a reply, a bit of forth and back to figure all the details, got a quote, agreed to it, seller generated payment request via alibaba, paid via paypal, now waiting for shipping.\n\nIf I had messaged the seller sooner, to account for time difference, it would have been less than 2hrs from first contact to payment. The seller I bought from had excellent English.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n56q2pm",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;alibaba.com. Installed the app, created account, searched Mi50, messaged seller with the most sales with the questions I had, got a reply, a bit of forth and back to figure all the details, got a quote, agreed to it, seller generated payment request via alibaba, paid via paypal, now waiting for shipping.&lt;/p&gt;\n\n&lt;p&gt;If I had messaged the seller sooner, to account for time difference, it would have been less than 2hrs from first contact to payment. The seller I bought from had excellent English.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m96wrc",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/n56q2pm/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753490322,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753490322,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n568bmm",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MachineZer0",
                      "can_mod_post": false,
                      "created_utc": 1753484171,
                      "send_replies": true,
                      "parent_id": "t1_n55h5uo",
                      "score": 1,
                      "author_fullname": "t2_55kl2a90",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Can you detail how/where you ordered from China. Last time I tried on TaoBao. I never got my items and after a protracted amount of time I got most of my money back minus fees. I don’t see a shipping option anymore. So hard to figure out freight consolidation with broken English or no English",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n568bmm",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you detail how/where you ordered from China. Last time I tried on TaoBao. I never got my items and after a protracted amount of time I got most of my money back minus fees. I don’t see a shipping option anymore. So hard to figure out freight consolidation with broken English or no English&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m96wrc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/n568bmm/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753484171,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n55h5uo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "FullstackSensei",
            "can_mod_post": false,
            "created_utc": 1753475637,
            "send_replies": true,
            "parent_id": "t3_1m96wrc",
            "score": 1,
            "author_fullname": "t2_17n3nqtj56",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I ordered five Mi50s from China yesterday. Four Mi50s cost the same as one RTX 3090 on ebay. I had recently bought a fourth 3090 locally but haven't had the time to install it yet (my rig is water cooled). I figured I can flip the 3090 on ebay to recoup the cost of four cards. \n\nI just checked the official Pytorch wheels, and the latest stable release (2.7.1) is built against ROCm 6.3. Funny enough, 2.7.1 is also available for CUDA 11.8, which was EoL almost 3 years ago. I'm bringing this up because every time someone mentions the P40/P100/V100,which were marked as deprecated in CUDA 12.9, the community's reaction is as if those cards will become paperweights the very day CUDA 13 is released sometime later this year. Seems the people at Meta have yet to get that memo.\n\nI'd say go for it. The cards have 32GB each and 1TB memory bandwidth (more than the 3090/3090Ti, and about the same as the 4090). Sure they don't have tensor cores, but ~27 TFLOPS at FP16 is not bad at all. The Chinese sellers will include a blower fan for $9 extra if you want.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n55h5uo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I ordered five Mi50s from China yesterday. Four Mi50s cost the same as one RTX 3090 on ebay. I had recently bought a fourth 3090 locally but haven&amp;#39;t had the time to install it yet (my rig is water cooled). I figured I can flip the 3090 on ebay to recoup the cost of four cards. &lt;/p&gt;\n\n&lt;p&gt;I just checked the official Pytorch wheels, and the latest stable release (2.7.1) is built against ROCm 6.3. Funny enough, 2.7.1 is also available for CUDA 11.8, which was EoL almost 3 years ago. I&amp;#39;m bringing this up because every time someone mentions the P40/P100/V100,which were marked as deprecated in CUDA 12.9, the community&amp;#39;s reaction is as if those cards will become paperweights the very day CUDA 13 is released sometime later this year. Seems the people at Meta have yet to get that memo.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d say go for it. The cards have 32GB each and 1TB memory bandwidth (more than the 3090/3090Ti, and about the same as the 4090). Sure they don&amp;#39;t have tensor cores, but ~27 TFLOPS at FP16 is not bad at all. The Chinese sellers will include a blower fan for $9 extra if you want.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/n55h5uo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753475637,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m96wrc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n58odst",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GPTrack_ai",
            "can_mod_post": false,
            "created_utc": 1753523997,
            "send_replies": true,
            "parent_id": "t3_1m96wrc",
            "score": 1,
            "author_fullname": "t2_1tpuoj72sa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It is like buidling a supercomputer with pentium 60s.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n58odst",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is like buidling a supercomputer with pentium 60s.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m96wrc/mi50_array_for_training_llms/n58odst/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753523997,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m96wrc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]