[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hey folks,\n\nI’m putting together a PC mainly for running large language models like Qwen, LLaMA3, DeepSeek, etc. It’ll mostly be used for **code generation tasks**, and I want it to run **24/7**, quietly, in my home office.\n\nHere’s what I’ve picked so far:\n\n* **Case**: Lian Li O11D EVO XL\n* **CPU**: AMD Ryzen 9 7950X3D\n* **GPU**: MSI RTX 4090 Suprim Liquid X\n* **Motherboard**: ASUS ProArt X670E-Creator\n* **RAM**: 64GB DDR5 G.Skill Trident Z5\n* **AIO Coolers**: 360mm for CPU, 240mm for GPU (built-in)\n* **SSD**: Samsung 990 Pro 2TB\n* **PSU**: Corsair AX1600i Titanium (probably overkill, but wanted room to grow)\n\n**What I’m wondering:**\n\n1. Anyone running something similar — how **quiet** is it under load? Any tips to make it even quieter?\n2. Can this handle models like **Qwen2.5-32B** comfortably in 4-bit? Or am I dreaming?\n3. I’m also thinking of renting the GPU out on [**Vast.ai**](http://Vast.ai) **/ RunPod** when I’m not using it. Anyone making decent side income doing that?\n4. Any parts you’d swap out or downscale without losing performance?\n\nGoal is to have something powerful but also quiet enough to keep on 24/7 — and if it can earn a bit while idle, even better.\n\nAppreciate any thoughts!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Building a quiet LLM machine for 24/7 use, is this setup overkill or smart?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1malflg",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.86,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 15,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_px0vov1",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 15,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753620460,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I’m putting together a PC mainly for running large language models like Qwen, LLaMA3, DeepSeek, etc. It’ll mostly be used for &lt;strong&gt;code generation tasks&lt;/strong&gt;, and I want it to run &lt;strong&gt;24/7&lt;/strong&gt;, quietly, in my home office.&lt;/p&gt;\n\n&lt;p&gt;Here’s what I’ve picked so far:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Case&lt;/strong&gt;: Lian Li O11D EVO XL&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: AMD Ryzen 9 7950X3D&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;GPU&lt;/strong&gt;: MSI RTX 4090 Suprim Liquid X&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Motherboard&lt;/strong&gt;: ASUS ProArt X670E-Creator&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;RAM&lt;/strong&gt;: 64GB DDR5 G.Skill Trident Z5&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;AIO Coolers&lt;/strong&gt;: 360mm for CPU, 240mm for GPU (built-in)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;SSD&lt;/strong&gt;: Samsung 990 Pro 2TB&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;PSU&lt;/strong&gt;: Corsair AX1600i Titanium (probably overkill, but wanted room to grow)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;What I’m wondering:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Anyone running something similar — how &lt;strong&gt;quiet&lt;/strong&gt; is it under load? Any tips to make it even quieter?&lt;/li&gt;\n&lt;li&gt;Can this handle models like &lt;strong&gt;Qwen2.5-32B&lt;/strong&gt; comfortably in 4-bit? Or am I dreaming?&lt;/li&gt;\n&lt;li&gt;I’m also thinking of renting the GPU out on &lt;a href=\"http://Vast.ai\"&gt;&lt;strong&gt;Vast.ai&lt;/strong&gt;&lt;/a&gt; &lt;strong&gt;/ RunPod&lt;/strong&gt; when I’m not using it. Anyone making decent side income doing that?&lt;/li&gt;\n&lt;li&gt;Any parts you’d swap out or downscale without losing performance?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Goal is to have something powerful but also quiet enough to keep on 24/7 — and if it can earn a bit while idle, even better.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/MV8WQnKGiSSypEI5QKJe4g08BAeccM6KobeueLMOJdY.png?auto=webp&amp;s=c5b1db2b11bd21a955cbe1e863cde94ef57607f4",
                    "width": 4000,
                    "height": 2250
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/MV8WQnKGiSSypEI5QKJe4g08BAeccM6KobeueLMOJdY.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a08158a2ec290c8157b492f314bfb148408be1fc",
                      "width": 108,
                      "height": 60
                    },
                    {
                      "url": "https://external-preview.redd.it/MV8WQnKGiSSypEI5QKJe4g08BAeccM6KobeueLMOJdY.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5d4693d9fc011431e9348152136fa7a13c95504b",
                      "width": 216,
                      "height": 121
                    },
                    {
                      "url": "https://external-preview.redd.it/MV8WQnKGiSSypEI5QKJe4g08BAeccM6KobeueLMOJdY.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=93ef867725a538dad3a6209e5062d3d1de60aeaa",
                      "width": 320,
                      "height": 180
                    },
                    {
                      "url": "https://external-preview.redd.it/MV8WQnKGiSSypEI5QKJe4g08BAeccM6KobeueLMOJdY.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc186b216811c20876ecdaf0e913cc0b59498d7a",
                      "width": 640,
                      "height": 360
                    },
                    {
                      "url": "https://external-preview.redd.it/MV8WQnKGiSSypEI5QKJe4g08BAeccM6KobeueLMOJdY.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=67812638cc7d2b930cd8bebf733409c3b2d92397",
                      "width": 960,
                      "height": 540
                    },
                    {
                      "url": "https://external-preview.redd.it/MV8WQnKGiSSypEI5QKJe4g08BAeccM6KobeueLMOJdY.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bc092f31a95e3a3df682dc8f7222b0fb1363a5df",
                      "width": 1080,
                      "height": 607
                    }
                  ],
                  "variants": {},
                  "id": "MV8WQnKGiSSypEI5QKJe4g08BAeccM6KobeueLMOJdY"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1malflg",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "bardanaadam",
            "discussion_type": null,
            "num_comments": 37,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/",
            "subreddit_subscribers": 505616,
            "created_utc": 1753620460,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "body": "For question 2:\n\nA 24GB GPU will definitely comfortably run 32B models at 4-bit quantization, but the context size will likely be limited to under ~16K, which might not be enough for extensive coding sessions with a lot of back and forth.\n\nThat being said, if you're doing coding, you can look into Devstral-Small (An official coding fine tune of the 24B parameter Mistral Small), which will free up much for VRAM for context.",
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5fhsd0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Mysterious_Finish543",
            "can_mod_post": false,
            "created_utc": 1753623098,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 15,
            "author_fullname": "t2_gbx2bcdvl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "author_cakeday": true,
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fhsd0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For question 2:&lt;/p&gt;\n\n&lt;p&gt;A 24GB GPU will definitely comfortably run 32B models at 4-bit quantization, but the context size will likely be limited to under ~16K, which might not be enough for extensive coding sessions with a lot of back and forth.&lt;/p&gt;\n\n&lt;p&gt;That being said, if you&amp;#39;re doing coding, you can look into Devstral-Small (An official coding fine tune of the 24B parameter Mistral Small), which will free up much for VRAM for context.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5fhsd0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753623098,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5g2d03",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "zipperlein",
                      "can_mod_post": false,
                      "created_utc": 1753629749,
                      "send_replies": true,
                      "parent_id": "t1_n5fgk37",
                      "score": 3,
                      "author_fullname": "t2_x3duw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "More RAM hurts if u go above 2 sticks of memory on AM5 because u need to drop frequency like crazy for it to work most of the time.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5g2d03",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;More RAM hurts if u go above 2 sticks of memory on AM5 because u need to drop frequency like crazy for it to work most of the time.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1malflg",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5g2d03/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753629749,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gu0ny",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "eloquentemu",
                      "can_mod_post": false,
                      "created_utc": 1753637845,
                      "send_replies": true,
                      "parent_id": "t1_n5fgk37",
                      "score": 3,
                      "author_fullname": "t2_lpdsy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "While you are absolutely correct, in the context of OP's question it's worth pointing out that the 4090 uses a smaller process node and is more efficient (though the RAM isn't) with lower idle power consumption.  I don't think it's worth the cost premium, but it's something.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gu0ny",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;While you are absolutely correct, in the context of OP&amp;#39;s question it&amp;#39;s worth pointing out that the 4090 uses a smaller process node and is more efficient (though the RAM isn&amp;#39;t) with lower idle power consumption.  I don&amp;#39;t think it&amp;#39;s worth the cost premium, but it&amp;#39;s something.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1malflg",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5gu0ny/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753637845,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5glcys",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "fizzy1242",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5gkv32",
                                "score": 1,
                                "author_fullname": "t2_16zcsx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "well, normally you want to have a big dense model fully on VRAM decent speeds.\n\nwith MoE models, you can have parts of the model reside on normal RAM, and still get solid speeds, because only a fraction of it's parameters are active per token.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5glcys",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;well, normally you want to have a big dense model fully on VRAM decent speeds.&lt;/p&gt;\n\n&lt;p&gt;with MoE models, you can have parts of the model reside on normal RAM, and still get solid speeds, because only a fraction of it&amp;#39;s parameters are active per token.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1malflg",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5glcys/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753635337,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753635337,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gkv32",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "bardanaadam",
                      "can_mod_post": false,
                      "created_utc": 1753635192,
                      "send_replies": true,
                      "parent_id": "t1_n5fgk37",
                      "score": 1,
                      "author_fullname": "t2_px0vov1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Im not sure im asking right question but what difference will MoE make ?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gkv32",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Im not sure im asking right question but what difference will MoE make ?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1malflg",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5gkv32/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753635192,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5fgk37",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "fizzy1242",
            "can_mod_post": false,
            "created_utc": 1753622661,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 15,
            "author_fullname": "t2_16zcsx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "i'd get a 3090 to save some money, as 4090 won't really give you ***that*** much more value/capacity for LLMs.\n\nMore RAM probably wont hurt either with more MoE models coming out recently.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fgk37",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;i&amp;#39;d get a 3090 to save some money, as 4090 won&amp;#39;t really give you &lt;strong&gt;&lt;em&gt;that&lt;/em&gt;&lt;/strong&gt; much more value/capacity for LLMs.&lt;/p&gt;\n\n&lt;p&gt;More RAM probably wont hurt either with more MoE models coming out recently.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5fgk37/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753622661,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5fexm0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "AMillionMonkeys",
            "can_mod_post": false,
            "created_utc": 1753622076,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 7,
            "author_fullname": "t2_4qvpc",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Get the biggest radiator you can fit in there. Watercooling doesn't make a build quieter, it just moves heat around (if anything it adds pump noise). A large radiator will dissipate the heat with less air flow / fan noise.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fexm0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Get the biggest radiator you can fit in there. Watercooling doesn&amp;#39;t make a build quieter, it just moves heat around (if anything it adds pump noise). A large radiator will dissipate the heat with less air flow / fan noise.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5fexm0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753622076,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5hxsgf",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "perelmanych",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5hqefs",
                                "score": 2,
                                "author_fullname": "t2_63q8kong",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The speed should be higher, 5600\\*2\\*8=89.6Gb/s And at Q4 active experts would take around 12-14Gb So the theoretical maximum speed becomes around 6.5t/s. More, practical speed should be around 3.5t/s and it is without offloading anything to GPU. Your number is closer to my DDR4@3000 rig speed with GPU offloading.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5hxsgf",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The speed should be higher, 5600*2*8=89.6Gb/s And at Q4 active experts would take around 12-14Gb So the theoretical maximum speed becomes around 6.5t/s. More, practical speed should be around 3.5t/s and it is without offloading anything to GPU. Your number is closer to my DDR4@3000 rig speed with GPU offloading.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1malflg",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5hxsgf/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753649829,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753649829,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5hqefs",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "pulse77",
                      "can_mod_post": false,
                      "created_utc": 1753647584,
                      "send_replies": true,
                      "parent_id": "t1_n5fcwbp",
                      "score": 3,
                      "author_fullname": "t2_5zyo90",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "On similar configuration but with 128GB DDR5 RAM the Qwen3-235B will run at 2.8 t/s (4 bit quant). I don't know if that counts as \"fairly decent speed\" ...",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5hqefs",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;On similar configuration but with 128GB DDR5 RAM the Qwen3-235B will run at 2.8 t/s (4 bit quant). I don&amp;#39;t know if that counts as &amp;quot;fairly decent speed&amp;quot; ...&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1malflg",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5hqefs/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753647584,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5fcwbp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "dugavo",
            "can_mod_post": false,
            "created_utc": 1753621339,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 3,
            "author_fullname": "t2_1nge67um4h",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you get 128 *(or, better, 192GB*) of RAM you'll be able to run Qwen3-235B at a fairly decent speed",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fcwbp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you get 128 &lt;em&gt;(or, better, 192GB&lt;/em&gt;) of RAM you&amp;#39;ll be able to run Qwen3-235B at a fairly decent speed&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5fcwbp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753621339,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5fm86e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "TacGibs",
            "can_mod_post": false,
            "created_utc": 1753624626,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 3,
            "author_fullname": "t2_8w0y7ezw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Got a Thermaltake CTE C750 case with plenty of 140mm Arctic fans, a 280 Arctic AIO, 2 x RTX 3090 MSI Suprim X, a Ryzen 9 5950X and a Corsair AX1500i.\n\nBoth cards are limited to 260W each.\n\nIt's in my main room and it's pretty quiet, even under heavy load (spend a few hours thinking the airflow and tuning the fan control).\n\nGet 2 3090, a 4090 is only worth it for video and image generation not for LLM.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fm86e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Got a Thermaltake CTE C750 case with plenty of 140mm Arctic fans, a 280 Arctic AIO, 2 x RTX 3090 MSI Suprim X, a Ryzen 9 5950X and a Corsair AX1500i.&lt;/p&gt;\n\n&lt;p&gt;Both cards are limited to 260W each.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s in my main room and it&amp;#39;s pretty quiet, even under heavy load (spend a few hours thinking the airflow and tuning the fan control).&lt;/p&gt;\n\n&lt;p&gt;Get 2 3090, a 4090 is only worth it for video and image generation not for LLM.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5fm86e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753624626,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5h39io",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Eden63",
            "can_mod_post": false,
            "created_utc": 1753640543,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 3,
            "author_fullname": "t2_mhb0rkd4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Pretty odd config for LLM. CPU/Memory nice, but wont change the situation for you. Memory Bandwidth problem as usual\n\nOnly VRAM counts..",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5h39io",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Pretty odd config for LLM. CPU/Memory nice, but wont change the situation for you. Memory Bandwidth problem as usual&lt;/p&gt;\n\n&lt;p&gt;Only VRAM counts..&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5h39io/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753640543,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5h5tpz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Marksta",
            "can_mod_post": false,
            "created_utc": 1753641308,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 4,
            "author_fullname": "t2_559a1",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt;Building a quiet LLM machine\n\n&gt;&gt;Look insides, it's a gaming rig.\n\nIs this a multi-use computer on Windows with everything in mind including gaming, or meant to be an LLM server on a Linux OS? For an LLM server purposes, there is not a single part here in your list worth purchasing. We need more info on OS you'll be using, budget, and if it's a headless LLM focused server goal or a multi-use personal computer.\n\nCheck out these previous threads that are relevant to you too:\n\n[About consumer platform DDR5 bandwidth](https://www.reddit.com/r/LocalLLaMA/comments/1ld3ivo/mixed_ramvram_strategies_for_large_moe_models_is/my71d6m/)\n\n[High budget everything PC + Gaming + LLMs](https://www.reddit.com/r/LocalLLaMA/comments/1lxs0s0/new_local_ai_system_planning_stage_need_advice/n2oqukf/)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5h5tpz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Building a quiet LLM machine&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Look insides, it&amp;#39;s a gaming rig.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Is this a multi-use computer on Windows with everything in mind including gaming, or meant to be an LLM server on a Linux OS? For an LLM server purposes, there is not a single part here in your list worth purchasing. We need more info on OS you&amp;#39;ll be using, budget, and if it&amp;#39;s a headless LLM focused server goal or a multi-use personal computer.&lt;/p&gt;\n\n&lt;p&gt;Check out these previous threads that are relevant to you too:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1ld3ivo/mixed_ramvram_strategies_for_large_moe_models_is/my71d6m/\"&gt;About consumer platform DDR5 bandwidth&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1lxs0s0/new_local_ai_system_planning_stage_need_advice/n2oqukf/\"&gt;High budget everything PC + Gaming + LLMs&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5h5tpz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753641308,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5hdvv8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "penmoid",
                      "can_mod_post": false,
                      "created_utc": 1753643743,
                      "send_replies": true,
                      "parent_id": "t1_n5fgzkn",
                      "score": 1,
                      "author_fullname": "t2_3dw2i",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Coil whine is a strong possibility.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5hdvv8",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Coil whine is a strong possibility.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": true,
                      "can_gild": false,
                      "link_id": "t3_1malflg",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5hdvv8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753643743,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5fgzkn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Secure_Reflection409",
            "can_mod_post": false,
            "created_utc": 1753622814,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 2,
            "author_fullname": "t2_by77ogdhr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have the same case (it's awesome) and similar setup with the same goal.\n\n\nIt is not completely silent.\n\n\n\n\nSomething in there is creating a low volume whine. It's not loud but it's slightly annoying. I have a terrible feeling it's the tiny fan on my AIO that they added for VRM cooling. Not something I can remove without binning the whole thing.\n\n\nDefault fan profile on the motherboard is also kinda annoying. Would constantly spin up and down at a certain temp, had to create a custom profile.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fgzkn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have the same case (it&amp;#39;s awesome) and similar setup with the same goal.&lt;/p&gt;\n\n&lt;p&gt;It is not completely silent.&lt;/p&gt;\n\n&lt;p&gt;Something in there is creating a low volume whine. It&amp;#39;s not loud but it&amp;#39;s slightly annoying. I have a terrible feeling it&amp;#39;s the tiny fan on my AIO that they added for VRM cooling. Not something I can remove without binning the whole thing.&lt;/p&gt;\n\n&lt;p&gt;Default fan profile on the motherboard is also kinda annoying. Would constantly spin up and down at a certain temp, had to create a custom profile.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5fgzkn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753622814,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5ixlpu",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "TableSurface",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5iri9p",
                                          "score": 1,
                                          "author_fullname": "t2_r5ot7",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Thanks. Kind of hard to find consistent numbers on EPYC or Threadripper power consumption.\n\n170W - (~20-30 for switch+router) is pretty manageable.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5ixlpu",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks. Kind of hard to find consistent numbers on EPYC or Threadripper power consumption.&lt;/p&gt;\n\n&lt;p&gt;170W - (~20-30 for switch+router) is pretty manageable.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1malflg",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5ixlpu/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753661925,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753661925,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5iri9p",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "createthiscom",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5ioq5a",
                                "score": 1,
                                "author_fullname": "t2_ozxxf",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "170ish watts. It’s on a double conversion UPS and I think that includes the switch and router too. It spikes as high as 960 watts under full load. I think it’s capable of quite a bit more, but LLMs don’t flog the system quite as hard as they could.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5iri9p",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;170ish watts. It’s on a double conversion UPS and I think that includes the switch and router too. It spikes as high as 960 watts under full load. I think it’s capable of quite a bit more, but LLMs don’t flog the system quite as hard as they could.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1malflg",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5iri9p/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753659719,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753659719,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ioq5a",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "TableSurface",
                      "can_mod_post": false,
                      "created_utc": 1753658746,
                      "send_replies": true,
                      "parent_id": "t1_n5g22oi",
                      "score": 1,
                      "author_fullname": "t2_r5ot7",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "What's idle power consumption like at the wall?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ioq5a",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s idle power consumption like at the wall?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1malflg",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5ioq5a/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753658746,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g22oi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "createthiscom",
            "can_mod_post": false,
            "created_utc": 1753629662,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 2,
            "author_fullname": "t2_ozxxf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "my dual epyc 9355 machine with 24 channels of 32gb 5600 MT/s rdimms and a blackwell 6000 pro is quiet enough to keep in my livingroom. I never turn it off.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g22oi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;my dual epyc 9355 machine with 24 channels of 32gb 5600 MT/s rdimms and a blackwell 6000 pro is quiet enough to keep in my livingroom. I never turn it off.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5g22oi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753629662,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ha0d5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "kpodkanowicz",
            "can_mod_post": false,
            "created_utc": 1753642566,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 2,
            "author_fullname": "t2_1jxjvqre",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "like others said only Mac can be very quiet (like 15db) Im close to 25 db with epyc board, very big cooler from noctua, dual gigabyte 3090 (which below 55C are passive and in general only nocuta fans. Dark Power 13 1000W as PSU. GPUs are underpowered as mucb as possible.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ha0d5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;like others said only Mac can be very quiet (like 15db) Im close to 25 db with epyc board, very big cooler from noctua, dual gigabyte 3090 (which below 55C are passive and in general only nocuta fans. Dark Power 13 1000W as PSU. GPUs are underpowered as mucb as possible.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5ha0d5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753642566,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5hcbmf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Crazyfucker73",
            "can_mod_post": false,
            "created_utc": 1753643268,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 3,
            "author_fullname": "t2_1tlmy88y5t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yep go with a Mac Studio. My M4 Studio with 64gb Ram and 40 GPU cores smashes  models up to 70b - not sure exactly what the cost of your rig is there but my M4 Studio cost me £2523 with the education discount..",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hcbmf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yep go with a Mac Studio. My M4 Studio with 64gb Ram and 40 GPU cores smashes  models up to 70b - not sure exactly what the cost of your rig is there but my M4 Studio cost me £2523 with the education discount..&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5hcbmf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753643268,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5gp3bq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "henfiber",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5giaot",
                                "score": 2,
                                "author_fullname": "t2_lw9me25",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Maybe they are not comfortable with used hardware. \n\nAlso, OP specifically mentioned: \"24/7, quietly, in my home office\", so that's more difficult to achieve with a 280W server CPU and 8x memory channels.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5gp3bq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe they are not comfortable with used hardware. &lt;/p&gt;\n\n&lt;p&gt;Also, OP specifically mentioned: &amp;quot;24/7, quietly, in my home office&amp;quot;, so that&amp;#39;s more difficult to achieve with a 280W server CPU and 8x memory channels.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1malflg",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5gp3bq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753636423,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753636423,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5gy1xg",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "eloquentemu",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5giaot",
                                "score": 1,
                                "author_fullname": "t2_lpdsy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "If the plan is (as it sounds like OP's is) to rely on GPU then the 7950X (well, Zen 4 desktop in general) does offer some real benefits: boosts to 5.7GHz while Milan maxes out at 4.0GHz and Zen 4 is ~10% faster clock-per-clock vs Zen 3.  Desktop CPUs are also a lot better about idle power than server ones and 8ch RAM used non-trivial power too.\n\nBut if someone is planning on using the CPU (and IMO with the current model landscape one should) then they definitely should only be looking at server / HEDT CPUs instead of expensive desktop setups.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5gy1xg",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If the plan is (as it sounds like OP&amp;#39;s is) to rely on GPU then the 7950X (well, Zen 4 desktop in general) does offer some real benefits: boosts to 5.7GHz while Milan maxes out at 4.0GHz and Zen 4 is ~10% faster clock-per-clock vs Zen 3.  Desktop CPUs are also a lot better about idle power than server ones and 8ch RAM used non-trivial power too.&lt;/p&gt;\n\n&lt;p&gt;But if someone is planning on using the CPU (and IMO with the current model landscape one should) then they definitely should only be looking at server / HEDT CPUs instead of expensive desktop setups.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1malflg",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5gy1xg/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753638999,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753638999,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5giaot",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FullstackSensei",
                      "can_mod_post": false,
                      "created_utc": 1753634447,
                      "send_replies": true,
                      "parent_id": "t1_n5fn1pd",
                      "score": 2,
                      "author_fullname": "t2_17n3nqtj56",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I also don't get why they go for DDR5 desktop platforms when for the same money you can get a DDR4 epyc with 3x the cores, 8x the RAM and more than 2x the memory bandwidth.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5giaot",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I also don&amp;#39;t get why they go for DDR5 desktop platforms when for the same money you can get a DDR4 epyc with 3x the cores, 8x the RAM and more than 2x the memory bandwidth.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1malflg",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5giaot/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753634447,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gh4f3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "bardanaadam",
                      "can_mod_post": false,
                      "created_utc": 1753634108,
                      "send_replies": true,
                      "parent_id": "t1_n5fn1pd",
                      "score": 1,
                      "author_fullname": "t2_px0vov1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I’m not really into hardware myself. I usually do my own research and try to figure things out on my own. But if you have any recommendations, I’d love to hear them!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gh4f3",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’m not really into hardware myself. I usually do my own research and try to figure things out on my own. But if you have any recommendations, I’d love to hear them!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1malflg",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5gh4f3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753634108,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5fn1pd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "jacek2023",
            "can_mod_post": false,
            "created_utc": 1753624898,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 4,
            "author_fullname": "t2_vqgbql9w",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I still don't get why people on Reddit buy expensive mobos/CPUs and a single 4090/5090 instead of multiple 3090s",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fn1pd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I still don&amp;#39;t get why people on Reddit buy expensive mobos/CPUs and a single 4090/5090 instead of multiple 3090s&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5fn1pd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753624898,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5h75zv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "waescher",
            "can_mod_post": false,
            "created_utc": 1753641712,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 2,
            "author_fullname": "t2_1gpif4cz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you want it quiet and 24/7 I would recommend getting an Mac Studio because it‘s available with plenty of VRAM, silent and uses A LOT less power than any x64 machine. And Mac’s handle 24/7 way better than Windows machines.\nMacs have their weaknesses (like slower prompt processing) but they perform really well with LLMs. 32b is a joke for a M4 Max or an M3 Ultra.\nMy M4 Max is idling at 2-8W and using max 90-100W peak at inferencing. My prior Windows machine had like 5x of that for less compute power.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5h75zv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you want it quiet and 24/7 I would recommend getting an Mac Studio because it‘s available with plenty of VRAM, silent and uses A LOT less power than any x64 machine. And Mac’s handle 24/7 way better than Windows machines.\nMacs have their weaknesses (like slower prompt processing) but they perform really well with LLMs. 32b is a joke for a M4 Max or an M3 Ultra.\nMy M4 Max is idling at 2-8W and using max 90-100W peak at inferencing. My prior Windows machine had like 5x of that for less compute power.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5h75zv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753641712,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5hs0zm",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Fun_Librarian_7699",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5gkz6x",
                                "score": 1,
                                "author_fullname": "t2_qi9hc5s1",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "If you want speed use VRAM (more expensive) and if you want something cheaper use RAM (really slow)",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5hs0zm",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you want speed use VRAM (more expensive) and if you want something cheaper use RAM (really slow)&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1malflg",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5hs0zm/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753648073,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753648073,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gkz6x",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "bardanaadam",
                      "can_mod_post": false,
                      "created_utc": 1753635225,
                      "send_replies": true,
                      "parent_id": "t1_n5fck5n",
                      "score": 1,
                      "author_fullname": "t2_px0vov1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Which one would you recommend?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gkz6x",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Which one would you recommend?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1malflg",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5gkz6x/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753635225,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5fck5n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Fun_Librarian_7699",
            "can_mod_post": false,
            "created_utc": 1753621213,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 1,
            "author_fullname": "t2_qi9hc5s1",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Do you want to run your models on VRAM or RAM? \n\nIf you want to know how silent your setup will be, I would watch or read reports about the radiators.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fck5n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you want to run your models on VRAM or RAM? &lt;/p&gt;\n\n&lt;p&gt;If you want to know how silent your setup will be, I would watch or read reports about the radiators.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5fck5n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753621213,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5fz36l",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "swagonflyyyy",
            "can_mod_post": false,
            "created_utc": 1753628743,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 1,
            "author_fullname": "t2_iev1qh7k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "No such thing as overkill.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fz36l",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No such thing as overkill.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5fz36l/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753628743,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5g1lh7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "zipperlein",
            "can_mod_post": false,
            "created_utc": 1753629516,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 1,
            "author_fullname": "t2_x3duw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If u want to run bigger MOE-models I'd highly recommend getting 2 really fast RAM sticks, don't stop at 6000. Also, AM5 doesn't like 4 sticks. Noise will be determined by your setup. Idle GPUs aren't loud. If u want silent fans I'd recommend Noctua. If not and u want to stick to dense models, 2x3090 will be probabbly way more comfortable, because of context size.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g1lh7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If u want to run bigger MOE-models I&amp;#39;d highly recommend getting 2 really fast RAM sticks, don&amp;#39;t stop at 6000. Also, AM5 doesn&amp;#39;t like 4 sticks. Noise will be determined by your setup. Idle GPUs aren&amp;#39;t loud. If u want silent fans I&amp;#39;d recommend Noctua. If not and u want to stick to dense models, 2x3090 will be probabbly way more comfortable, because of context size.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5g1lh7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753629516,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ghvaz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "FullstackSensei",
            "can_mod_post": false,
            "created_utc": 1753634323,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 1,
            "author_fullname": "t2_17n3nqtj56",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "AIOs aren't the best option, nor the quietest, especially for the 4090.\n\nAs others commented, you'll be better off with two 3090s for the same price. Waterblocks for those are also much cheaper, especially in the 2nd hand market.\n\nQuiet is very subjective. [I have a triple 3090 build in an O11D XL](https://www.reddit.com/r/watercooling/comments/1k8il8m/smolboi_watercooled_3x_rtx_3090_fe_epyc_7642_in/) and I don't consider it loud when running models on GPU only. Where things get a bit loud is when offloading layers to RAM. I find airflow over RAM to be far from ideal in the O11D despite having 9 fans there. Now looking to get some small RAM mounted fans/cooler to help with that.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ghvaz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;AIOs aren&amp;#39;t the best option, nor the quietest, especially for the 4090.&lt;/p&gt;\n\n&lt;p&gt;As others commented, you&amp;#39;ll be better off with two 3090s for the same price. Waterblocks for those are also much cheaper, especially in the 2nd hand market.&lt;/p&gt;\n\n&lt;p&gt;Quiet is very subjective. &lt;a href=\"https://www.reddit.com/r/watercooling/comments/1k8il8m/smolboi_watercooled_3x_rtx_3090_fe_epyc_7642_in/\"&gt;I have a triple 3090 build in an O11D XL&lt;/a&gt; and I don&amp;#39;t consider it loud when running models on GPU only. Where things get a bit loud is when offloading layers to RAM. I find airflow over RAM to be far from ideal in the O11D despite having 9 fans there. Now looking to get some small RAM mounted fans/cooler to help with that.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5ghvaz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753634323,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5hn845",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "tarruda",
            "can_mod_post": false,
            "created_utc": 1753646612,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 2,
            "author_fullname": "t2_dphk4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Here are some stats from my Mac Studio M1 Ultra with 128GB during inference of Qwen 3 235B IQ4_XS:\n\n- ~65w power (CPU + GPU + ANE, according to asitop)\n- 100% silent\n- Approx 18 tokens per second (can load up to 40k context).\n\nI'm not a fan of Apple and this Mac Studio was the first Apple product I ever purchased, simply because there's no competition for LLM inference when you weight performance and power consumption. Those new 128GB Ryzen AI chips (which came years after the first apple silicon) have about 1/3 of the memory bandwidth and cannot compete.\n\nCan you build a machine with higher inference speed? Sure, just spend a small fortune in a bunch of RTX 3090 and server hardware that can handle it using no less than 1kW.\n\nI paid $3k on my used mac studio, purchased from eBay. Nowadays you can probably get a similar config for $2.5k or lower. If you can, try to get a used 192GB M2 ultra, and you will be able to load even bigger models/contexts.\n\nI don't think 512GB mac studio is worth it at current prices. Even if you can run deepseek or Kimi, it will have very low inference speed since those models have significantly more active parameters.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hn845",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here are some stats from my Mac Studio M1 Ultra with 128GB during inference of Qwen 3 235B IQ4_XS:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;~65w power (CPU + GPU + ANE, according to asitop)&lt;/li&gt;\n&lt;li&gt;100% silent&lt;/li&gt;\n&lt;li&gt;Approx 18 tokens per second (can load up to 40k context).&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m not a fan of Apple and this Mac Studio was the first Apple product I ever purchased, simply because there&amp;#39;s no competition for LLM inference when you weight performance and power consumption. Those new 128GB Ryzen AI chips (which came years after the first apple silicon) have about 1/3 of the memory bandwidth and cannot compete.&lt;/p&gt;\n\n&lt;p&gt;Can you build a machine with higher inference speed? Sure, just spend a small fortune in a bunch of RTX 3090 and server hardware that can handle it using no less than 1kW.&lt;/p&gt;\n\n&lt;p&gt;I paid $3k on my used mac studio, purchased from eBay. Nowadays you can probably get a similar config for $2.5k or lower. If you can, try to get a used 192GB M2 ultra, and you will be able to load even bigger models/contexts.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think 512GB mac studio is worth it at current prices. Even if you can run deepseek or Kimi, it will have very low inference speed since those models have significantly more active parameters.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5hn845/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753646612,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ih79v",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "johnkapolos",
            "can_mod_post": false,
            "created_utc": 1753656128,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 1,
            "author_fullname": "t2_te4dl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hey there,\n\nI have the same case but with a 9950X and a 5090 (hydro cooling for the CPU) and 360mm fans (except for the back).\n\nIt's not quiet when the GPU kicks in hard. It's more quiet than my previous builds but expect noise. If you are fine with the noise when playing an AAA game, this is what you should expect.\n\nTip: Put it in another room, use a high quality long cable for your screen and a usb hub connected with a long usb cable for the rest of the peripherals.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ih79v",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I have the same case but with a 9950X and a 5090 (hydro cooling for the CPU) and 360mm fans (except for the back).&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not quiet when the GPU kicks in hard. It&amp;#39;s more quiet than my previous builds but expect noise. If you are fine with the noise when playing an AAA game, this is what you should expect.&lt;/p&gt;\n\n&lt;p&gt;Tip: Put it in another room, use a high quality long cable for your screen and a usb hub connected with a long usb cable for the rest of the peripherals.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5ih79v/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753656128,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ivo95",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Roland_Bodel_the_2nd",
            "can_mod_post": false,
            "created_utc": 1753661211,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": 1,
            "author_fullname": "t2_i80v0xfb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have the \"MSI RTX 4090 Suprim Liquid X\" and I ended up mounting the radiator in a way that ended up pointing at my feet and while it's not \"loud\" it's definitely a little space heater.  You'll have \\~500W of heat blowing out heating your home office.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ivo95",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have the &amp;quot;MSI RTX 4090 Suprim Liquid X&amp;quot; and I ended up mounting the radiator in a way that ended up pointing at my feet and while it&amp;#39;s not &amp;quot;loud&amp;quot; it&amp;#39;s definitely a little space heater.  You&amp;#39;ll have ~500W of heat blowing out heating your home office.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5ivo95/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753661211,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5gnbkd",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AI-On-A-Dime",
            "can_mod_post": false,
            "created_utc": 1753635910,
            "send_replies": true,
            "parent_id": "t3_1malflg",
            "score": -2,
            "author_fullname": "t2_1ttp8mwcgv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I just want to say the responses in this thread are golden! I have nothing more to add other than make sure to bookkeep this thread!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gnbkd",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I just want to say the responses in this thread are golden! I have nothing more to add other than make sure to bookkeep this thread!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1malflg/building_a_quiet_llm_machine_for_247_use_is_this/n5gnbkd/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753635910,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1malflg",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -2
          }
        }
      ],
      "before": null
    }
  }
]