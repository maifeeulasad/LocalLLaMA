[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "From the Readme: “We are excited to introduce Ling-lite-1.5-2506, the updated version of our highly capable Ling-lite-1.5 model.\n\nLing-lite-1.5-2506 boasts 16.8 billion parameters with 2.75 billion activated parameters, building upon its predecessor with significant advancements across the board, featuring the following key improvements:\n\n- Reasoning and Knowledge: Significant gains in general intelligence, logical reasoning, and complex problem-solving abilities. For instance, in GPQA Diamond, Ling-lite-1.5-2506 achieves 53.79%, a substantial lead over Ling-lite-1.5's 36.55%.\n- Coding Capabilities: A notable enhancement in coding and debugging prowess. For instance,in LiveCodeBench 2408-2501, a critical and highly popular programming benchmark, Ling-lite-1.5-2506 demonstrates improved performance with 26.97% compared to Ling-lite-1.5's 22.22%.”\n\nPaper: https://huggingface.co/papers/2503.05139\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "inclusionAI/Ling-lite-1.5-2506 (16.8B total, 2.75B active, MIT license)",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 75,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m9y506",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.98,
            "author_flair_background_color": null,
            "ups": 106,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_14okit",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 106,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/e7ctnhD9fGClQAWGTRPiUR684S9oQO734fubNQzMy7w.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=df4ee3da0ac24982d7470071054e9ddfcaedb3d7",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "link",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753548535,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "huggingface.co",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;From the Readme: “We are excited to introduce Ling-lite-1.5-2506, the updated version of our highly capable Ling-lite-1.5 model.&lt;/p&gt;\n\n&lt;p&gt;Ling-lite-1.5-2506 boasts 16.8 billion parameters with 2.75 billion activated parameters, building upon its predecessor with significant advancements across the board, featuring the following key improvements:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Reasoning and Knowledge: Significant gains in general intelligence, logical reasoning, and complex problem-solving abilities. For instance, in GPQA Diamond, Ling-lite-1.5-2506 achieves 53.79%, a substantial lead over Ling-lite-1.5&amp;#39;s 36.55%.&lt;/li&gt;\n&lt;li&gt;Coding Capabilities: A notable enhancement in coding and debugging prowess. For instance,in LiveCodeBench 2408-2501, a critical and highly popular programming benchmark, Ling-lite-1.5-2506 demonstrates improved performance with 26.97% compared to Ling-lite-1.5&amp;#39;s 22.22%.”&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Paper: &lt;a href=\"https://huggingface.co/papers/2503.05139\"&gt;https://huggingface.co/papers/2503.05139&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://huggingface.co/inclusionAI/Ling-lite-1.5-2506",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/e7ctnhD9fGClQAWGTRPiUR684S9oQO734fubNQzMy7w.png?auto=webp&amp;s=f64afba829e86afae636cfa89d8b629473344cde",
                    "width": 1200,
                    "height": 648
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/e7ctnhD9fGClQAWGTRPiUR684S9oQO734fubNQzMy7w.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8296a7257d0017a5ea7dbf418ca4a2ddfb9e318d",
                      "width": 108,
                      "height": 58
                    },
                    {
                      "url": "https://external-preview.redd.it/e7ctnhD9fGClQAWGTRPiUR684S9oQO734fubNQzMy7w.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d40ddd1252be4a590b3d25bd63db318622713834",
                      "width": 216,
                      "height": 116
                    },
                    {
                      "url": "https://external-preview.redd.it/e7ctnhD9fGClQAWGTRPiUR684S9oQO734fubNQzMy7w.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9915108fff5b8cee702fecab2863aaf0517d62c5",
                      "width": 320,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/e7ctnhD9fGClQAWGTRPiUR684S9oQO734fubNQzMy7w.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=404f4d1a954e64355fe9daae161dfd9814fe8b80",
                      "width": 640,
                      "height": 345
                    },
                    {
                      "url": "https://external-preview.redd.it/e7ctnhD9fGClQAWGTRPiUR684S9oQO734fubNQzMy7w.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e54c747b540171e887944a6012c6c474369fa20f",
                      "width": 960,
                      "height": 518
                    },
                    {
                      "url": "https://external-preview.redd.it/e7ctnhD9fGClQAWGTRPiUR684S9oQO734fubNQzMy7w.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bd92d7e54cef9052509e5ce3003f2f70ef267830",
                      "width": 1080,
                      "height": 583
                    }
                  ],
                  "variants": {},
                  "id": "e7ctnhD9fGClQAWGTRPiUR684S9oQO734fubNQzMy7w"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1m9y506",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Balance-",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/",
            "stickied": false,
            "url": "https://huggingface.co/inclusionAI/Ling-lite-1.5-2506",
            "subreddit_subscribers": 505881,
            "created_utc": 1753548535,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5akztp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Independent_Tear2863",
            "can_mod_post": false,
            "created_utc": 1753549728,
            "send_replies": true,
            "parent_id": "t3_1m9y506",
            "score": 21,
            "author_fullname": "t2_169bseyc6k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Nice my favourite LLM lang lite I can store it in my mini PC and use it for rag and summary",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5akztp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice my favourite LLM lang lite I can store it in my mini PC and use it for rag and summary&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5akztp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753549728,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9y506",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 21
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5cefjw",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "silenceimpaired",
                      "can_mod_post": false,
                      "created_utc": 1753571298,
                      "send_replies": true,
                      "parent_id": "t1_n5c8jql",
                      "score": 3,
                      "author_fullname": "t2_dissgzyl",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That's amazing.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5cefjw",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s amazing.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9y506",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5cefjw/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753571298,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5c8jql",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "disillusioned_okapi",
            "can_mod_post": false,
            "created_utc": 1753569166,
            "send_replies": true,
            "parent_id": "t3_1m9y506",
            "score": 9,
            "author_fullname": "t2_wy3w8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Will try the model over the next days, but this bit from the paper is the key highlight for me. \n\n\n&gt; Ultimately, our experimental findings demonstrate that a 300B MoE LLM can be effectively trained on lower-performance devices while achieving comparable performance to models of a similar scale, including dense and MoE models.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5c8jql",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Will try the model over the next days, but this bit from the paper is the key highlight for me. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Ultimately, our experimental findings demonstrate that a 300B MoE LLM can be effectively trained on lower-performance devices while achieving comparable performance to models of a similar scale, including dense and MoE models.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5c8jql/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753569166,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9y506",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ce3mt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "silenceimpaired",
            "can_mod_post": false,
            "created_utc": 1753571177,
            "send_replies": true,
            "parent_id": "t3_1m9y506",
            "score": 8,
            "author_fullname": "t2_dissgzyl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "MIT license gets an upvote from me.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ce3mt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;MIT license gets an upvote from me.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5ce3mt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753571177,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9y506",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5dhcid",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "handsoapdispenser",
            "can_mod_post": false,
            "created_utc": 1753586462,
            "send_replies": true,
            "parent_id": "t3_1m9y506",
            "score": 8,
            "author_fullname": "t2_1akx4946qy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I looked up the creator and it's a division of Ant Group that also owns Alibaba, makers of Qwen.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5dhcid",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I looked up the creator and it&amp;#39;s a division of Ant Group that also owns Alibaba, makers of Qwen.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5dhcid/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753586462,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9y506",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5e169a",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "altoidsjedi",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5dz3yu",
                                                    "score": 6,
                                                    "author_fullname": "t2_6f7v3",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Thanks. Was wondering what the origin was. The more I think about it, the more it makes sense **as a rule of thumb**, in terms of being something like the geometric mean between size and compute, and as something that can be used to make a  lower bound estimation of how intelligent the model should be. \n\n---\n\nFor anyone else reading this, what I mean is this: \n\nIf you have a regular old 7B dense model, you can say \"it has 7B worth of knowledge capacity and 7B worth of compute capacity per each forward pass.\" \n\nSo size x compute = 7 x 7 = 49. The square root of which is 7 of course. Meeting the obvious assumption that a 7B dense model will perform like a 7B dense model. \n\nIn that sense we could say an MoE model like Qwen3 30B 3AB has a theoretical knowledge capacity of 30B parameters, and a compute capacity of 3B active parameters per forward pass. \n\nSo that would mean 30 x 3 = 90, and square root of 90 is 9.48.\n\nSo by this rule of thumb, we would expect Qwen3 30B-3AB to be within range of the geometric mean of size and compute of a dense 9.48B parameter model. \n\nGiven that the general view is that its intelligence/knowledge is somewhere in the range between Qwen3 14B and Qwen3 32b, I think we can at the very least say that it's a successful training run.\n\nAnd probably can also say that the sqrt(size x compute) is a rather conservative estimate, and we might need  a refined estimation heuristic that accounts for other static aspects of an MoE architectures, such as the number of transformer blocks or number of attention heads, etc.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5e169a",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks. Was wondering what the origin was. The more I think about it, the more it makes sense &lt;strong&gt;as a rule of thumb&lt;/strong&gt;, in terms of being something like the geometric mean between size and compute, and as something that can be used to make a  lower bound estimation of how intelligent the model should be. &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;For anyone else reading this, what I mean is this: &lt;/p&gt;\n\n&lt;p&gt;If you have a regular old 7B dense model, you can say &amp;quot;it has 7B worth of knowledge capacity and 7B worth of compute capacity per each forward pass.&amp;quot; &lt;/p&gt;\n\n&lt;p&gt;So size x compute = 7 x 7 = 49. The square root of which is 7 of course. Meeting the obvious assumption that a 7B dense model will perform like a 7B dense model. &lt;/p&gt;\n\n&lt;p&gt;In that sense we could say an MoE model like Qwen3 30B 3AB has a theoretical knowledge capacity of 30B parameters, and a compute capacity of 3B active parameters per forward pass. &lt;/p&gt;\n\n&lt;p&gt;So that would mean 30 x 3 = 90, and square root of 90 is 9.48.&lt;/p&gt;\n\n&lt;p&gt;So by this rule of thumb, we would expect Qwen3 30B-3AB to be within range of the geometric mean of size and compute of a dense 9.48B parameter model. &lt;/p&gt;\n\n&lt;p&gt;Given that the general view is that its intelligence/knowledge is somewhere in the range between Qwen3 14B and Qwen3 32b, I think we can at the very least say that it&amp;#39;s a successful training run.&lt;/p&gt;\n\n&lt;p&gt;And probably can also say that the sqrt(size x compute) is a rather conservative estimate, and we might need  a refined estimation heuristic that accounts for other static aspects of an MoE architectures, such as the number of transformer blocks or number of attention heads, etc.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m9y506",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5e169a/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753595980,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753595980,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 6
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5dz3yu",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "ResidentPositive4122",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5dm9ma",
                                          "score": 4,
                                          "author_fullname": "t2_10nxrjjgay",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "&gt; Help me understand where the sqrt(params x active params) formula is coming from?\n\nIt's an old \"rule of thumb\" proposed by someone at mistral, IIRC. It's not a studied &amp; proved formula, more of an approximation.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5dz3yu",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Help me understand where the sqrt(params x active params) formula is coming from?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s an old &amp;quot;rule of thumb&amp;quot; proposed by someone at mistral, IIRC. It&amp;#39;s not a studied &amp;amp; proved formula, more of an approximation.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m9y506",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5dz3yu/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753594876,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753594876,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5dm9ma",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "altoidsjedi",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5b7kt0",
                                "score": 4,
                                "author_fullname": "t2_6f7v3",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Help me understand where the sqrt(params x active params) formula is coming from? \n\nWhat's the logic behind using this formula to identify the ideal dense model size for comparison?\n\nIs this essentially a measure of geometric mean?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5dm9ma",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Help me understand where the sqrt(params x active params) formula is coming from? &lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the logic behind using this formula to identify the ideal dense model size for comparison?&lt;/p&gt;\n\n&lt;p&gt;Is this essentially a measure of geometric mean?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9y506",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5dm9ma/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753588631,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753588631,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5b7kt0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Mysterious_Finish543",
                      "can_mod_post": false,
                      "created_utc": 1753556801,
                      "send_replies": true,
                      "parent_id": "t1_n5anccc",
                      "score": 14,
                      "author_fullname": "t2_gbx2bcdvl",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "`sqrt(16.8*2.75)=6.79`\n\nThis MoE should be equivalent to a 6.79B dense model, so perhaps a comparison with both Qwen3-4B and 8B would be appropriate.\n\nThe README does feature comparisons with Qwen3-8B in non-thinking mode, so I thinks it's a decent comparison.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5b7kt0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;code&gt;sqrt(16.8*2.75)=6.79&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;This MoE should be equivalent to a 6.79B dense model, so perhaps a comparison with both Qwen3-4B and 8B would be appropriate.&lt;/p&gt;\n\n&lt;p&gt;The README does feature comparisons with Qwen3-8B in non-thinking mode, so I thinks it&amp;#39;s a decent comparison.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9y506",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5b7kt0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753556801,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 14
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5anccc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "GreenTreeAndBlueSky",
            "can_mod_post": false,
            "created_utc": 1753550435,
            "send_replies": true,
            "parent_id": "t3_1m9y506",
            "score": 9,
            "author_fullname": "t2_1p50pl73j2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "A bit disapointing results though, the size is perfect but then it cmpares itself to qwen3-4b?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5anccc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A bit disapointing results though, the size is perfect but then it cmpares itself to qwen3-4b?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5anccc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753550435,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9y506",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "50c36eba-fdca-11ee-9735-92a88d7e3b87",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "50c36eba-fdca-11ee-9735-92a88d7e3b87",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ekybf",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "-finnegannn-",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5ekm8s",
                                "score": 1,
                                "author_fullname": "t2_15923syckr",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "HAHAHAHHA yeah there’s probably (definitely) a lot of that….",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ekybf",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "Ollama"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;HAHAHAHHA yeah there’s probably (definitely) a lot of that….&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9y506",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5ekybf/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753607387,
                                "author_flair_text": "Ollama",
                                "treatment_tags": [],
                                "created_utc": 1753607387,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ekm8s",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Cultured_Alien",
                      "can_mod_post": false,
                      "created_utc": 1753607182,
                      "send_replies": true,
                      "parent_id": "t1_n5e8dla",
                      "score": 3,
                      "author_fullname": "t2_83kh7oz2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I know it's a bit better than 8B, but I can't help but think of this due to your comment.\nhttps://imgur.com/a/3BmIHn0",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ekm8s",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I know it&amp;#39;s a bit better than 8B, but I can&amp;#39;t help but think of this due to your comment.\n&lt;a href=\"https://imgur.com/a/3BmIHn0\"&gt;https://imgur.com/a/3BmIHn0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9y506",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5ekm8s/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753607182,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5e8dla",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "-finnegannn-",
            "can_mod_post": false,
            "created_utc": 1753599990,
            "send_replies": true,
            "parent_id": "t3_1m9y506",
            "score": 1,
            "author_fullname": "t2_15923syckr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I’ve played with this one a little bit today, seems pretty good (in my limited testing), but below qwen3-14b imo, but it runs a lot faster on my P40 system, I’m getting around 40-45 tok/s at Q6_K… so that alone makes it very enticing!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5e8dla",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Ollama"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’ve played with this one a little bit today, seems pretty good (in my limited testing), but below qwen3-14b imo, but it runs a lot faster on my P40 system, I’m getting around 40-45 tok/s at Q6_K… so that alone makes it very enticing!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9y506/inclusionailinglite152506_168b_total_275b_active/n5e8dla/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753599990,
            "author_flair_text": "Ollama",
            "treatment_tags": [],
            "link_id": "t3_1m9y506",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]