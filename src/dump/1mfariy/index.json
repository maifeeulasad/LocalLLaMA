[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I've been having a lot of fun playing around with the new Qwen coder as a 100% local agentic coding. A lot of going on with in the demo above: \n\n- Roo Code with [Unsloth Qwen3 Coder 30B Q8](https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF)\n- [llama-swap](https://github.com/mostlygeek/llama-swap) with new Activity page with real time updates. \n- [VibeCities MCP server](https://github.com/mostlygeek/vibecities) for hosting the pages\n- Dual 3090s with Q8 gives about 50 tok/sec to 55 tok/sec. The UD Q4_K_XL quant was not able to one shot the spinning pentagon. \n\nHere's my llama-swap config: \n\n```\nmacros:\n  \"qwen3-coder-server\": |\n    /path/to/llama-server/llama-server-latest\n    --host 127.0.0.1 --port ${PORT}\n    --flash-attn -ngl 999 -ngld 999\n    --no-mmap\n    --cache-type-k q8_0 --cache-type-v q8_0\n    --temp 0.7 --top-k 20 --top-p 0.8 --repeat_penalty 1.05\n    --jinja\n    --swa-full\n\nmodels:\n  \"Q3-30B-CODER-3090\":\n    env:\n      - \"CUDA_VISIBLE_DEVICES=GPU-6f0,GPU-f10\"\n    name: \"Qwen3 30B Coder Dual 3090 (Q3-30B-CODER-3090)\"\n    description: \"Q8_K_XL, 180K context, 2x3090\"\n    filters:\n      # enforce recommended params for model\n      strip_params: \"temperature, top_k, top_p, repeat_penalty\"\n    cmd: |\n      ${qwen3-coder-server}\n      --model /path/to/models/Qwen3-Coder-30B-A3B-Instruct-UD-Q8_K_XL.gguf\n      --ctx-size 184320\n      # rebalance layers/context a bit better across dual GPUs\n      --tensor-split 46,54\n```\n\nRoo code MCP settings: \n\n```\n{\n  \"mcpServers\": {\n    \"vibecities\": {\n      \"type\": \"streamable-http\",\n      \"url\": \"http://10.0.1.173:8888/mcp\",\n      \"headers\": {\n        \"X-API-Key\": \"your-secure-api-key\"\n      },\n      \"alwaysAllow\": [\n        \"page_list\",\n        \"page_set\",\n        \"page_get\"\n      ],\n      \"disabled\": false\n    }\n  }\n}\n```\n\n\n\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "All local Roo Code and qwen3 coder 30B Q8",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 87,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mfariy",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 1,
            "author_flair_background_color": "#bbbdbf",
            "ups": 16,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "is_original_content": false,
            "author_fullname": "t2_11gh93nhos",
            "secure_media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/g5aj1csfjhgf1/DASH_1080.mp4?source=fallback",
                "has_audio": false,
                "height": 1080,
                "width": 1920,
                "scrubber_media_url": "https://v.redd.it/g5aj1csfjhgf1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/g5aj1csfjhgf1/DASHPlaylist.mpd?a=1756688995%2CZDlhM2Y4YjlhNjdiODQ2ZjFiYzRkYWE0OTY5ODJjZGViMjllMTI5ZTMyY2E5YzUzM2IzZGEzZDI3ZjBlMmU5OA%3D%3D&amp;v=1&amp;f=sd",
                "duration": 158,
                "hls_url": "https://v.redd.it/g5aj1csfjhgf1/HLSPlaylist.m3u8?a=1756688995%2CMzNjYWM3OGQ4MmFkMjg1Njc4YzMxOWM1OTE4NGFkNzg3MmI3YzY1ZjU4OGI0OWUwZmVjMWRhYjhiOWYzYmQ3MA%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 16,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/OWxnaXVhc2ZqaGdmMfGWh3MmEBu_PyLbr6sXIOAmucdihxn6n5oQbX60BtAw.png?width=140&amp;height=87&amp;crop=140:87,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=96e2057bb1f1ef1e9f3beb1d9a28a9ccd4dcaa6b",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "gildings": {},
            "post_hint": "hosted:video",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754088672,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "v.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been having a lot of fun playing around with the new Qwen coder as a 100% local agentic coding. A lot of going on with in the demo above: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Roo Code with &lt;a href=\"https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF\"&gt;Unsloth Qwen3 Coder 30B Q8&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/mostlygeek/llama-swap\"&gt;llama-swap&lt;/a&gt; with new Activity page with real time updates. &lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/mostlygeek/vibecities\"&gt;VibeCities MCP server&lt;/a&gt; for hosting the pages&lt;/li&gt;\n&lt;li&gt;Dual 3090s with Q8 gives about 50 tok/sec to 55 tok/sec. The UD Q4_K_XL quant was not able to one shot the spinning pentagon. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here&amp;#39;s my llama-swap config: &lt;/p&gt;\n\n&lt;p&gt;```\nmacros:\n  &amp;quot;qwen3-coder-server&amp;quot;: |\n    /path/to/llama-server/llama-server-latest\n    --host 127.0.0.1 --port ${PORT}\n    --flash-attn -ngl 999 -ngld 999\n    --no-mmap\n    --cache-type-k q8_0 --cache-type-v q8_0\n    --temp 0.7 --top-k 20 --top-p 0.8 --repeat_penalty 1.05\n    --jinja\n    --swa-full&lt;/p&gt;\n\n&lt;p&gt;models:\n  &amp;quot;Q3-30B-CODER-3090&amp;quot;:\n    env:\n      - &amp;quot;CUDA_VISIBLE_DEVICES=GPU-6f0,GPU-f10&amp;quot;\n    name: &amp;quot;Qwen3 30B Coder Dual 3090 (Q3-30B-CODER-3090)&amp;quot;\n    description: &amp;quot;Q8_K_XL, 180K context, 2x3090&amp;quot;\n    filters:\n      # enforce recommended params for model\n      strip_params: &amp;quot;temperature, top_k, top_p, repeat_penalty&amp;quot;\n    cmd: |\n      ${qwen3-coder-server}\n      --model /path/to/models/Qwen3-Coder-30B-A3B-Instruct-UD-Q8_K_XL.gguf\n      --ctx-size 184320\n      # rebalance layers/context a bit better across dual GPUs\n      --tensor-split 46,54\n```&lt;/p&gt;\n\n&lt;p&gt;Roo code MCP settings: &lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;\n{\n  &amp;quot;mcpServers&amp;quot;: {\n    &amp;quot;vibecities&amp;quot;: {\n      &amp;quot;type&amp;quot;: &amp;quot;streamable-http&amp;quot;,\n      &amp;quot;url&amp;quot;: &amp;quot;http://10.0.1.173:8888/mcp&amp;quot;,\n      &amp;quot;headers&amp;quot;: {\n        &amp;quot;X-API-Key&amp;quot;: &amp;quot;your-secure-api-key&amp;quot;\n      },\n      &amp;quot;alwaysAllow&amp;quot;: [\n        &amp;quot;page_list&amp;quot;,\n        &amp;quot;page_set&amp;quot;,\n        &amp;quot;page_get&amp;quot;\n      ],\n      &amp;quot;disabled&amp;quot;: false\n    }\n  }\n}\n&lt;/code&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://v.redd.it/g5aj1csfjhgf1",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/OWxnaXVhc2ZqaGdmMfGWh3MmEBu_PyLbr6sXIOAmucdihxn6n5oQbX60BtAw.png?format=pjpg&amp;auto=webp&amp;s=a799694f3cd2a8d09be3eac7cc9981be88d234a1",
                    "width": 1920,
                    "height": 1197
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/OWxnaXVhc2ZqaGdmMfGWh3MmEBu_PyLbr6sXIOAmucdihxn6n5oQbX60BtAw.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7b56a58c7f6f027ee7357cad95a460ff999afeea",
                      "width": 108,
                      "height": 67
                    },
                    {
                      "url": "https://external-preview.redd.it/OWxnaXVhc2ZqaGdmMfGWh3MmEBu_PyLbr6sXIOAmucdihxn6n5oQbX60BtAw.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5adfd5aba83e12c59bf4648d145f4ab40fd5648e",
                      "width": 216,
                      "height": 134
                    },
                    {
                      "url": "https://external-preview.redd.it/OWxnaXVhc2ZqaGdmMfGWh3MmEBu_PyLbr6sXIOAmucdihxn6n5oQbX60BtAw.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=4be2e0e3ac56fa7c11be8c2c58c9a02a90039429",
                      "width": 320,
                      "height": 199
                    },
                    {
                      "url": "https://external-preview.redd.it/OWxnaXVhc2ZqaGdmMfGWh3MmEBu_PyLbr6sXIOAmucdihxn6n5oQbX60BtAw.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c11415fad487d232adecf2767cc5b4b8ac2ab42f",
                      "width": 640,
                      "height": 399
                    },
                    {
                      "url": "https://external-preview.redd.it/OWxnaXVhc2ZqaGdmMfGWh3MmEBu_PyLbr6sXIOAmucdihxn6n5oQbX60BtAw.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=fd1f305092aa1774fdb5bb8d64c33f4d4acc5781",
                      "width": 960,
                      "height": 598
                    },
                    {
                      "url": "https://external-preview.redd.it/OWxnaXVhc2ZqaGdmMfGWh3MmEBu_PyLbr6sXIOAmucdihxn6n5oQbX60BtAw.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=a0c4665784dbdfe56aa44706a6b06cd7fb427df9",
                      "width": 1080,
                      "height": 673
                    }
                  ],
                  "variants": {},
                  "id": "OWxnaXVhc2ZqaGdmMfGWh3MmEBu_PyLbr6sXIOAmucdihxn6n5oQbX60BtAw"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1mfariy",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "No-Statement-0001",
            "discussion_type": null,
            "num_comments": 6,
            "send_replies": true,
            "media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/g5aj1csfjhgf1/DASH_1080.mp4?source=fallback",
                "has_audio": false,
                "height": 1080,
                "width": 1920,
                "scrubber_media_url": "https://v.redd.it/g5aj1csfjhgf1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/g5aj1csfjhgf1/DASHPlaylist.mpd?a=1756688995%2CZDlhM2Y4YjlhNjdiODQ2ZjFiYzRkYWE0OTY5ODJjZGViMjllMTI5ZTMyY2E5YzUzM2IzZGEzZDI3ZjBlMmU5OA%3D%3D&amp;v=1&amp;f=sd",
                "duration": 158,
                "hls_url": "https://v.redd.it/g5aj1csfjhgf1/HLSPlaylist.m3u8?a=1756688995%2CMzNjYWM3OGQ4MmFkMjg1Njc4YzMxOWM1OTE4NGFkNzg3MmI3YzY1ZjU4OGI0OWUwZmVjMWRhYjhiOWYzYmQ3MA%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "light",
            "permalink": "/r/LocalLLaMA/comments/1mfariy/all_local_roo_code_and_qwen3_coder_30b_q8/",
            "stickied": false,
            "url": "https://v.redd.it/g5aj1csfjhgf1",
            "subreddit_subscribers": 508541,
            "created_utc": 1754088672,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": true
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6fnyqe",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No-Statement-0001",
            "can_mod_post": false,
            "created_utc": 1754088867,
            "send_replies": true,
            "parent_id": "t3_1mfariy",
            "score": 1,
            "author_fullname": "t2_11gh93nhos",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Here's the prompt: \n\n```\nCreate a 2D physics demo with multiple balls bouncing around inside a rotating pentagon.\n- put a set of buttons to set rotation speed of the pentagon and ball speed\n- Put the new page under /bouncy_30B in VibeCities.\n\nJust work with the VibeCities MCP server. Do not look at the code in this current repo.\n```",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6fnyqe",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s the prompt: &lt;/p&gt;\n\n&lt;p&gt;```\nCreate a 2D physics demo with multiple balls bouncing around inside a rotating pentagon.\n- put a set of buttons to set rotation speed of the pentagon and ball speed\n- Put the new page under /bouncy_30B in VibeCities.&lt;/p&gt;\n\n&lt;p&gt;Just work with the VibeCities MCP server. Do not look at the code in this current repo.\n```&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfariy/all_local_roo_code_and_qwen3_coder_30b_q8/n6fnyqe/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754088867,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mfariy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6fpnuw",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No-Statement-0001",
                      "can_mod_post": false,
                      "created_utc": 1754089446,
                      "send_replies": true,
                      "parent_id": "t1_n6for7j",
                      "score": 1,
                      "author_fullname": "t2_11gh93nhos",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yup, it's super inefficient to set a page.  I think in order to make it do an upload I would have to make a local stdio mcp server.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6fpnuw",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yup, it&amp;#39;s super inefficient to set a page.  I think in order to make it do an upload I would have to make a local stdio mcp server.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfariy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfariy/all_local_roo_code_and_qwen3_coder_30b_q8/n6fpnuw/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754089446,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6for7j",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "this-just_in",
            "can_mod_post": false,
            "created_utc": 1754089136,
            "send_replies": true,
            "parent_id": "t3_1mfariy",
            "score": 1,
            "author_fullname": "t2_kdmu4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "VibeCities looks neat.  It doesn’t make sense that it writes a file and then has to rewrite the same file in the MCP tool call; a file ref would be a lot faster.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6for7j",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;VibeCities looks neat.  It doesn’t make sense that it writes a file and then has to rewrite the same file in the MCP tool call; a file ref would be a lot faster.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfariy/all_local_roo_code_and_qwen3_coder_30b_q8/n6for7j/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754089136,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfariy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6g33lv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Eugr",
            "can_mod_post": false,
            "created_utc": 1754094162,
            "send_replies": true,
            "parent_id": "t3_1mfariy",
            "score": 1,
            "author_fullname": "t2_f3l6q",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Are you using diff edits with Roo code? I tried it on my machine, and it works well until it needs to make a change in the code, and then it often fails with error related to diff edit tool invocation. I'm also running llama.cpp, Unsloth dynamic quants, but since I'm running on single 4090, I set my context to 40K tokens.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6g33lv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Are you using diff edits with Roo code? I tried it on my machine, and it works well until it needs to make a change in the code, and then it often fails with error related to diff edit tool invocation. I&amp;#39;m also running llama.cpp, Unsloth dynamic quants, but since I&amp;#39;m running on single 4090, I set my context to 40K tokens.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfariy/all_local_roo_code_and_qwen3_coder_30b_q8/n6g33lv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754094162,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfariy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6g4njr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Eden63",
            "can_mod_post": false,
            "created_utc": 1754094738,
            "send_replies": true,
            "parent_id": "t3_1mfariy",
            "score": 1,
            "author_fullname": "t2_mhb0rkd4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Can you help me out with information, as I am basically going to opt for the same configuration (Dual 3090). \n\nHow much token per second you reach with a 100k context?\n\nAnd how much GB VRAM does it really need with that context size?\n\nThank you.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6g4njr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you help me out with information, as I am basically going to opt for the same configuration (Dual 3090). &lt;/p&gt;\n\n&lt;p&gt;How much token per second you reach with a 100k context?&lt;/p&gt;\n\n&lt;p&gt;And how much GB VRAM does it really need with that context size?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfariy/all_local_roo_code_and_qwen3_coder_30b_q8/n6g4njr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754094738,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfariy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6g7gp8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "sleepy_roger",
            "can_mod_post": false,
            "created_utc": 1754095781,
            "send_replies": true,
            "parent_id": "t3_1mfariy",
            "score": 1,
            "author_fullname": "t2_usojvms",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The model probably has this example trained into it, you have to think of some better more unique problems nowadays.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6g7gp8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The model probably has this example trained into it, you have to think of some better more unique problems nowadays.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfariy/all_local_roo_code_and_qwen3_coder_30b_q8/n6g7gp8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754095781,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfariy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]