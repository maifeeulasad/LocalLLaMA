[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I was reading the Databricks article on function calling ([https://docs.databricks.com/aws/en/machine-learning/model-serving/function-calling#limitations](https://docs.databricks.com/aws/en/machine-learning/model-serving/function-calling#limitations)) and noticed two main limitations:\n\n* Multi-turn function calling is “supported during the preview, but is under development.”\n* Parallel function calling is **not** supported.\n\nFor multi-turn, isn’t it just about keeping the conversation history in an array/list, like in this example?  \n[https://docs.empower.dev/inference/tool-use/multi-turn](https://docs.empower.dev/inference/tool-use/multi-turn)\n\nWhy is this still a “work in progress” on Databricks?  \nAnd for parallel calls, what’s stopping them technically? What changes are actually needed under the hood to support both multi-turn and parallel function calling?\n\nWould appreciate any insights or links if someone has a deeper technical explanation!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Databricks",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m9yaku",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.25,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_nrllu7at",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753548918,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was reading the Databricks article on function calling (&lt;a href=\"https://docs.databricks.com/aws/en/machine-learning/model-serving/function-calling#limitations\"&gt;https://docs.databricks.com/aws/en/machine-learning/model-serving/function-calling#limitations&lt;/a&gt;) and noticed two main limitations:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Multi-turn function calling is “supported during the preview, but is under development.”&lt;/li&gt;\n&lt;li&gt;Parallel function calling is &lt;strong&gt;not&lt;/strong&gt; supported.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;For multi-turn, isn’t it just about keeping the conversation history in an array/list, like in this example?&lt;br/&gt;\n&lt;a href=\"https://docs.empower.dev/inference/tool-use/multi-turn\"&gt;https://docs.empower.dev/inference/tool-use/multi-turn&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Why is this still a “work in progress” on Databricks?&lt;br/&gt;\nAnd for parallel calls, what’s stopping them technically? What changes are actually needed under the hood to support both multi-turn and parallel function calling?&lt;/p&gt;\n\n&lt;p&gt;Would appreciate any insights or links if someone has a deeper technical explanation!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/o43qrM26RouAumS7K9OJYHQ1dEcdi9Zde9EzVhtRJew.png?auto=webp&amp;s=5a38df929ca7966c66437f05338c46f601afbec9",
                    "width": 1200,
                    "height": 630
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/o43qrM26RouAumS7K9OJYHQ1dEcdi9Zde9EzVhtRJew.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8d49de4c7f610703ab1e3a00e5257abfa9646201",
                      "width": 108,
                      "height": 56
                    },
                    {
                      "url": "https://external-preview.redd.it/o43qrM26RouAumS7K9OJYHQ1dEcdi9Zde9EzVhtRJew.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f187a3cfae15a10f7fa4a653aff56740eb89492e",
                      "width": 216,
                      "height": 113
                    },
                    {
                      "url": "https://external-preview.redd.it/o43qrM26RouAumS7K9OJYHQ1dEcdi9Zde9EzVhtRJew.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff52547d2d9438f42ba6ebfd6a7e10d1bbc5f252",
                      "width": 320,
                      "height": 168
                    },
                    {
                      "url": "https://external-preview.redd.it/o43qrM26RouAumS7K9OJYHQ1dEcdi9Zde9EzVhtRJew.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=12837190ead47a910c9059e2ff34af6df9a5263a",
                      "width": 640,
                      "height": 336
                    },
                    {
                      "url": "https://external-preview.redd.it/o43qrM26RouAumS7K9OJYHQ1dEcdi9Zde9EzVhtRJew.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=83109376f25cfe6fa667f8cdff30c30342dae06c",
                      "width": 960,
                      "height": 504
                    },
                    {
                      "url": "https://external-preview.redd.it/o43qrM26RouAumS7K9OJYHQ1dEcdi9Zde9EzVhtRJew.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e39db0253817a35352abcd06ba12a20b187ddf74",
                      "width": 1080,
                      "height": 567
                    }
                  ],
                  "variants": {},
                  "id": "o43qrM26RouAumS7K9OJYHQ1dEcdi9Zde9EzVhtRJew"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m9yaku",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Grand_Internet7254",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m9yaku/databricks/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m9yaku/databricks/",
            "subreddit_subscribers": 505251,
            "created_utc": 1753548918,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5bx9hp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Grand_Internet7254",
                      "can_mod_post": false,
                      "created_utc": 1753565247,
                      "send_replies": true,
                      "parent_id": "t1_n5b7mav",
                      "score": 1,
                      "author_fullname": "t2_nrllu7at",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for pointing me to smolagents! It sounds promising, but I’m still unclear on how it specifically handles multi-turn and parallel function calling compared to Databricks. Could you share a quick example of how smolagents manages these, or how other models like OpenAI, Mistral, or LLaMA handle these limitations? Appreciate any further insights!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5bx9hp",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for pointing me to smolagents! It sounds promising, but I’m still unclear on how it specifically handles multi-turn and parallel function calling compared to Databricks. Could you share a quick example of how smolagents manages these, or how other models like OpenAI, Mistral, or LLaMA handle these limitations? Appreciate any further insights!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9yaku",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9yaku/databricks/n5bx9hp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753565247,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5b7mav",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "____vladrad",
            "can_mod_post": false,
            "created_utc": 1753556815,
            "send_replies": true,
            "parent_id": "t3_1m9yaku",
            "score": 2,
            "author_fullname": "t2_u6i8a0ay",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Check out https://github.com/huggingface/smolagents \n\nIt turns function calling into code which it can thread and optimize. Makes it easy to say for every row in the database call this function. Or for every row call this function which queues it and processes x at a time.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5b7mav",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check out &lt;a href=\"https://github.com/huggingface/smolagents\"&gt;https://github.com/huggingface/smolagents&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;It turns function calling into code which it can thread and optimize. Makes it easy to say for every row in the database call this function. Or for every row call this function which queues it and processes x at a time.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9yaku/databricks/n5b7mav/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753556815,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9yaku",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]