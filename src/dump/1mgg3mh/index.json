[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hey, poor GPU guys\n\nA few days ago, I purchased the 32GB version of MI50 from Alibaba, and it arrived at my doorstep via UPS in just a few days, accompanied by a rather loud blower.\n\nSome married guys might understand, but I’ve been using an m-ATX case I bought about 15 years ago, and there’s no room for the MI50 since the 4070ti is already in there. I went ahead and used a PCIe riser cable to mount it on the side of my desk, and then I finally got down to “real” work.\n\nhttps://preview.redd.it/oe4uyadb4sgf1.jpg?width=960&amp;format=pjpg&amp;auto=webp&amp;s=9e8c9de636b034bd89f57dddca7291dcce101a80\n\nOne of the reasons the MI50 was rejected is that AMD only developed drivers for Linux and has since discontinued support, as most people are aware. That's why the “32GB” model ended up in my hands.\n\nOf course, some experts claim they can force-install the Radeon Pro VII BIOS, but that seemed too challenging for me, and after reading many posts stating that the “Original MI50” cannot be BIOS-re-flashed, I had given up.\n\nFirst, take a look at the results: the MI50 is running with  GTX 4070ti or alone on Windows.\n\nhttps://preview.redd.it/pvictbhu4sgf1.png?width=1707&amp;format=png&amp;auto=webp&amp;s=49102c07c665ed9635a4c99e9a3aed46da15c6a9\n\n[4070+MI50 \\(22GB only\\)](https://preview.redd.it/3cabctch4sgf1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=4ed2201e24962d94990ea9bc149d8ec389982b96)\n\n[MI50 works alone upto 30GB](https://preview.redd.it/lrtre5656sgf1.png?width=1883&amp;format=png&amp;auto=webp&amp;s=f14e51095d28e301c62418f12f52586a62861ee2)\n\nGuys, hold your horses. I'm aware there are a few issues here.\n\n1. It's recognized as a Radeon Pro VII\n2. It runs on LM STUDIO, which some people really dislike\n3. Even if it's recognized as Vulkan, you can't use the combined VRAM of  hetero cards—only twice the VRAM of the first graphics card (On my PC, it's 12+12GB instead of 12+32GB\n\n\\-&gt; However, I haven't tested it yet, but if you get a 32GB 5090 or V100, it might work with 32+32, and being able to steal GTX's prompt processing ability is an extra bonus.\n\n4. **Surely, you could use whole 32GB if you turn off other GPU and MI50 only!!!**  \n\n\n**Anyway, there are only three things you need to do.**\n\n1. Disable Secure Boot in the CMOS BIOS.\n2. Run PowerShell in administrator mode and enter the following command:\n\nbcdedit.exe -set TESTSIGNING on\n\n3. Download and install the Polaris-Vega-Navi driver created by the real pros.\n\n[R.ID - AMD 3rd Party Drivers](https://rdn-id.com/)\n\nAll risks are on you, but I think it's better than getting divorced by your wife over buying an RTX 6000,\n\nThe blower fan sent by the Ali seller is very effective, but it's incredibly loud. The GPU also gets quite hot, so you might want to find a way to adjust the fan speed.\n\nP.S. Could you please share a link to a guide on how to install ROCM to support MI50 on Ubuntu 24.04 LTS? I tried version 6.3.3, but it doesn't recognize it at all. Do I really have to rebuild PyTorch from scratch?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Successfully running INSTINCT MI50 on Win11",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 140,
            "top_awarded_type": null,
            "hide_score": false,
            "media_metadata": {
              "3cabctch4sgf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 50,
                    "x": 108,
                    "u": "https://preview.redd.it/3cabctch4sgf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ca1ba2f5dc37ce486326b1c5d7f492e6257e417"
                  },
                  {
                    "y": 100,
                    "x": 216,
                    "u": "https://preview.redd.it/3cabctch4sgf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b47948a9375686a348f3135013fad572be0e5bb9"
                  },
                  {
                    "y": 149,
                    "x": 320,
                    "u": "https://preview.redd.it/3cabctch4sgf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c54a61000b055f717d4c99392991a3016a75c607"
                  },
                  {
                    "y": 299,
                    "x": 640,
                    "u": "https://preview.redd.it/3cabctch4sgf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e82c15d58578bccb18253e91c4a9d5a4a136e4bf"
                  },
                  {
                    "y": 448,
                    "x": 960,
                    "u": "https://preview.redd.it/3cabctch4sgf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0908df44a99335aef9b4daf3dd4796f130b6f492"
                  },
                  {
                    "y": 504,
                    "x": 1080,
                    "u": "https://preview.redd.it/3cabctch4sgf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=098996b1e02247a51bd56e72b50def71975ccc73"
                  }
                ],
                "s": {
                  "y": 897,
                  "x": 1920,
                  "u": "https://preview.redd.it/3cabctch4sgf1.png?width=1920&amp;format=png&amp;auto=webp&amp;s=4ed2201e24962d94990ea9bc149d8ec389982b96"
                },
                "id": "3cabctch4sgf1"
              },
              "pvictbhu4sgf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 64,
                    "x": 108,
                    "u": "https://preview.redd.it/pvictbhu4sgf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a2e7b199737b649bf0dc517eeb27f38372ace77a"
                  },
                  {
                    "y": 128,
                    "x": 216,
                    "u": "https://preview.redd.it/pvictbhu4sgf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=296d5c0e017c541acde4c0789322db6a0ee8ee9f"
                  },
                  {
                    "y": 190,
                    "x": 320,
                    "u": "https://preview.redd.it/pvictbhu4sgf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8871508585c0b72a963270b0a8f2d645d8162a54"
                  },
                  {
                    "y": 380,
                    "x": 640,
                    "u": "https://preview.redd.it/pvictbhu4sgf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f925d22a93079c9ac16e8bacc366d444a121475"
                  },
                  {
                    "y": 570,
                    "x": 960,
                    "u": "https://preview.redd.it/pvictbhu4sgf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3e4bce81c738e2313acab5f1b611fcbcd1bec79c"
                  },
                  {
                    "y": 642,
                    "x": 1080,
                    "u": "https://preview.redd.it/pvictbhu4sgf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a90fa210d1e30a035719e4bdeba9f8afa3eb2e24"
                  }
                ],
                "s": {
                  "y": 1015,
                  "x": 1707,
                  "u": "https://preview.redd.it/pvictbhu4sgf1.png?width=1707&amp;format=png&amp;auto=webp&amp;s=49102c07c665ed9635a4c99e9a3aed46da15c6a9"
                },
                "id": "pvictbhu4sgf1"
              },
              "lrtre5656sgf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 59,
                    "x": 108,
                    "u": "https://preview.redd.it/lrtre5656sgf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=445e311f264b6b0ba67f8c1a6fc639d332a2e5f8"
                  },
                  {
                    "y": 118,
                    "x": 216,
                    "u": "https://preview.redd.it/lrtre5656sgf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f8becb210c0a1f400e0e6189f5b9ea272c0c7364"
                  },
                  {
                    "y": 175,
                    "x": 320,
                    "u": "https://preview.redd.it/lrtre5656sgf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2b05acc3dcc8e5ab71a4080b7d0fb7e7f2dd9536"
                  },
                  {
                    "y": 350,
                    "x": 640,
                    "u": "https://preview.redd.it/lrtre5656sgf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce822ce9b7ef000d574cada4c7c415bfe2d44912"
                  },
                  {
                    "y": 526,
                    "x": 960,
                    "u": "https://preview.redd.it/lrtre5656sgf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc5d5e9ad324bd8954b842c0285c298a6f3a5ba1"
                  },
                  {
                    "y": 591,
                    "x": 1080,
                    "u": "https://preview.redd.it/lrtre5656sgf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=18c465dd09dbecdf9cec8ef723dc48df07a9ff22"
                  }
                ],
                "s": {
                  "y": 1032,
                  "x": 1883,
                  "u": "https://preview.redd.it/lrtre5656sgf1.png?width=1883&amp;format=png&amp;auto=webp&amp;s=f14e51095d28e301c62418f12f52586a62861ee2"
                },
                "id": "lrtre5656sgf1"
              },
              "oe4uyadb4sgf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/jpg",
                "p": [
                  {
                    "y": 144,
                    "x": 108,
                    "u": "https://preview.redd.it/oe4uyadb4sgf1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2ac61e80aae254bda55f9b7cd6addf90d29a446b"
                  },
                  {
                    "y": 288,
                    "x": 216,
                    "u": "https://preview.redd.it/oe4uyadb4sgf1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9fae70f72d90191dd274df1040d6d75cbbbd6475"
                  },
                  {
                    "y": 426,
                    "x": 320,
                    "u": "https://preview.redd.it/oe4uyadb4sgf1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0c28cb00db6a2547f8fead9579aa8b2fd3c53086"
                  },
                  {
                    "y": 853,
                    "x": 640,
                    "u": "https://preview.redd.it/oe4uyadb4sgf1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9bdeb09d493de51c07e4fcc97ec462f8aac3b551"
                  },
                  {
                    "y": 1280,
                    "x": 960,
                    "u": "https://preview.redd.it/oe4uyadb4sgf1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e51eb15dd64da3685f668083f579b2705a4c55e"
                  }
                ],
                "s": {
                  "y": 1280,
                  "x": 960,
                  "u": "https://preview.redd.it/oe4uyadb4sgf1.jpg?width=960&amp;format=pjpg&amp;auto=webp&amp;s=9e8c9de636b034bd89f57dddca7291dcce101a80"
                },
                "id": "oe4uyadb4sgf1"
              }
            },
            "name": "t3_1mgg3mh",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.88,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 19,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1dhesoqqtu",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 19,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/ac8XNi9a_cAzytIhKD5Gg-Gwa0GLMmvvfiuUz9ia33E.jpg",
            "edited": 1754227118,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754217510,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, poor GPU guys&lt;/p&gt;\n\n&lt;p&gt;A few days ago, I purchased the 32GB version of MI50 from Alibaba, and it arrived at my doorstep via UPS in just a few days, accompanied by a rather loud blower.&lt;/p&gt;\n\n&lt;p&gt;Some married guys might understand, but I’ve been using an m-ATX case I bought about 15 years ago, and there’s no room for the MI50 since the 4070ti is already in there. I went ahead and used a PCIe riser cable to mount it on the side of my desk, and then I finally got down to “real” work.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oe4uyadb4sgf1.jpg?width=960&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9e8c9de636b034bd89f57dddca7291dcce101a80\"&gt;https://preview.redd.it/oe4uyadb4sgf1.jpg?width=960&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9e8c9de636b034bd89f57dddca7291dcce101a80&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;One of the reasons the MI50 was rejected is that AMD only developed drivers for Linux and has since discontinued support, as most people are aware. That&amp;#39;s why the “32GB” model ended up in my hands.&lt;/p&gt;\n\n&lt;p&gt;Of course, some experts claim they can force-install the Radeon Pro VII BIOS, but that seemed too challenging for me, and after reading many posts stating that the “Original MI50” cannot be BIOS-re-flashed, I had given up.&lt;/p&gt;\n\n&lt;p&gt;First, take a look at the results: the MI50 is running with  GTX 4070ti or alone on Windows.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/pvictbhu4sgf1.png?width=1707&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=49102c07c665ed9635a4c99e9a3aed46da15c6a9\"&gt;https://preview.redd.it/pvictbhu4sgf1.png?width=1707&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=49102c07c665ed9635a4c99e9a3aed46da15c6a9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/3cabctch4sgf1.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4ed2201e24962d94990ea9bc149d8ec389982b96\"&gt;4070+MI50 (22GB only)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lrtre5656sgf1.png?width=1883&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f14e51095d28e301c62418f12f52586a62861ee2\"&gt;MI50 works alone upto 30GB&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Guys, hold your horses. I&amp;#39;m aware there are a few issues here.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;It&amp;#39;s recognized as a Radeon Pro VII&lt;/li&gt;\n&lt;li&gt;It runs on LM STUDIO, which some people really dislike&lt;/li&gt;\n&lt;li&gt;Even if it&amp;#39;s recognized as Vulkan, you can&amp;#39;t use the combined VRAM of  hetero cards—only twice the VRAM of the first graphics card (On my PC, it&amp;#39;s 12+12GB instead of 12+32GB&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;-&amp;gt; However, I haven&amp;#39;t tested it yet, but if you get a 32GB 5090 or V100, it might work with 32+32, and being able to steal GTX&amp;#39;s prompt processing ability is an extra bonus.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Surely, you could use whole 32GB if you turn off other GPU and MI50 only!!!&lt;/strong&gt;&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Anyway, there are only three things you need to do.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Disable Secure Boot in the CMOS BIOS.&lt;/li&gt;\n&lt;li&gt;Run PowerShell in administrator mode and enter the following command:&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;bcdedit.exe -set TESTSIGNING on&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Download and install the Polaris-Vega-Navi driver created by the real pros.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;a href=\"https://rdn-id.com/\"&gt;R.ID - AMD 3rd Party Drivers&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;All risks are on you, but I think it&amp;#39;s better than getting divorced by your wife over buying an RTX 6000,&lt;/p&gt;\n\n&lt;p&gt;The blower fan sent by the Ali seller is very effective, but it&amp;#39;s incredibly loud. The GPU also gets quite hot, so you might want to find a way to adjust the fan speed.&lt;/p&gt;\n\n&lt;p&gt;P.S. Could you please share a link to a guide on how to install ROCM to support MI50 on Ubuntu 24.04 LTS? I tried version 6.3.3, but it doesn&amp;#39;t recognize it at all. Do I really have to rebuild PyTorch from scratch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1mgg3mh",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Desperate-Sir-5088",
            "discussion_type": null,
            "num_comments": 16,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/",
            "subreddit_subscribers": 509626,
            "created_utc": 1754217510,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ojcak",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FullstackSensei",
                      "can_mod_post": false,
                      "created_utc": 1754222500,
                      "send_replies": true,
                      "parent_id": "t1_n6oawuw",
                      "score": 3,
                      "author_fullname": "t2_17n3nqtj56",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I suspect the card is being held back by both Windows and LM studio. Should be quite a bit faster under Linux + ROCm + vLLM or recent llama.cpp",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ojcak",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I suspect the card is being held back by both Windows and LM studio. Should be quite a bit faster under Linux + ROCm + vLLM or recent llama.cpp&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgg3mh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6ojcak/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754222500,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6oawuw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Toooooool",
            "can_mod_post": false,
            "created_utc": 1754218389,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 3,
            "author_fullname": "t2_8llornh4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "6.5T/s on a 49B LLM for $150 is honestly really impressive. every time i hear about the MI50 i get tempted to get one too.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6oawuw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;6.5T/s on a 49B LLM for $150 is honestly really impressive. every time i hear about the MI50 i get tempted to get one too.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6oawuw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754218389,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6oqi63",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "FullstackSensei",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6opr6n",
                                "score": 3,
                                "author_fullname": "t2_17n3nqtj56",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Ditch thsoe wrappers and use llama.cpp directly. It doesn't take more than an hour or two to learn about all the important flags you need to set. Works much better than lm studio or ollama, and you don't need to mess with a gazillion environment variables to set options.\n\nMixing Nvidia with AMD will not work on the same instance (AFAIK), but you can use RPC to run two instances. No pipeline parallelism across brands and you'll lose a lot of optimizations that exist in either backend.\n\nMixing card brands is still highly experimental and flakey at best. But IMO, one card with 32BG is better than 12+12....\n\nEDIT: maybe try llama.cpp with the Vulkan backend. That might be able to use both cards under Ubuntu. I read somewhere that the Mi50 works with Vulkan out of the box on Ubuntu, without ROCm, but it's a bit slower in prompt processing.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6oqi63",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ditch thsoe wrappers and use llama.cpp directly. It doesn&amp;#39;t take more than an hour or two to learn about all the important flags you need to set. Works much better than lm studio or ollama, and you don&amp;#39;t need to mess with a gazillion environment variables to set options.&lt;/p&gt;\n\n&lt;p&gt;Mixing Nvidia with AMD will not work on the same instance (AFAIK), but you can use RPC to run two instances. No pipeline parallelism across brands and you&amp;#39;ll lose a lot of optimizations that exist in either backend.&lt;/p&gt;\n\n&lt;p&gt;Mixing card brands is still highly experimental and flakey at best. But IMO, one card with 32BG is better than 12+12....&lt;/p&gt;\n\n&lt;p&gt;EDIT: maybe try llama.cpp with the Vulkan backend. That might be able to use both cards under Ubuntu. I read somewhere that the Mi50 works with Vulkan out of the box on Ubuntu, without ROCm, but it&amp;#39;s a bit slower in prompt processing.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgg3mh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6oqi63/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754225486,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754225486,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6opr6n",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Desperate-Sir-5088",
                      "can_mod_post": false,
                      "created_utc": 1754225187,
                      "send_replies": true,
                      "parent_id": "t1_n6oiitz",
                      "score": 2,
                      "author_fullname": "t2_1dhesoqqtu",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for comment, I'll try installing ROCm 6.3.4 again.\n\nIt think 12+12GB Issue may be caused by LM Studio - it only experimentally support Pipeline Parallelism for CUDA. Anyway I confirmed that it could steal Nvidia's prompt processing ability on Win11 Environment.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6opr6n",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for comment, I&amp;#39;ll try installing ROCm 6.3.4 again.&lt;/p&gt;\n\n&lt;p&gt;It think 12+12GB Issue may be caused by LM Studio - it only experimentally support Pipeline Parallelism for CUDA. Anyway I confirmed that it could steal Nvidia&amp;#39;s prompt processing ability on Win11 Environment.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgg3mh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6opr6n/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754225187,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6oiitz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "FullstackSensei",
            "can_mod_post": false,
            "created_utc": 1754222128,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 5,
            "author_fullname": "t2_17n3nqtj56",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The 12+12GB is weird and doesn't make sense. Windows doesn't need cadds to hVe matched VRAM size.\n\nHave you tried installing ROCm 6.3.4? I recall reading somewhere 6.3.3 had some issues with the Mi50. FYI, software support for the Mi50 is not discontinued yet, it's been marked as deprecated. ROCm 7 will not support the Mi50, but 6.x still supports it. Even when 6.x is EoL, that doesn't mean the cards will stop working or ROCm will magically stop working.\n\nTo give an example, CUDA 11 has been EoL since 2022, but Pytorch and so many other projects still support it. llama.cpp provides binaries against CUDA 11 for all their CI builds.\n\nYou'll still be able to use the Mi50 for at least another 2-3 years without issue, and very probably it will still work with a lot of current software at the end of the decade.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6oiitz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The 12+12GB is weird and doesn&amp;#39;t make sense. Windows doesn&amp;#39;t need cadds to hVe matched VRAM size.&lt;/p&gt;\n\n&lt;p&gt;Have you tried installing ROCm 6.3.4? I recall reading somewhere 6.3.3 had some issues with the Mi50. FYI, software support for the Mi50 is not discontinued yet, it&amp;#39;s been marked as deprecated. ROCm 7 will not support the Mi50, but 6.x still supports it. Even when 6.x is EoL, that doesn&amp;#39;t mean the cards will stop working or ROCm will magically stop working.&lt;/p&gt;\n\n&lt;p&gt;To give an example, CUDA 11 has been EoL since 2022, but Pytorch and so many other projects still support it. llama.cpp provides binaries against CUDA 11 for all their CI builds.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;ll still be able to use the Mi50 for at least another 2-3 years without issue, and very probably it will still work with a lot of current software at the end of the decade.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6oiitz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754222128,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6puzfu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Desperate-Sir-5088",
                      "can_mod_post": false,
                      "created_utc": 1754238549,
                      "send_replies": true,
                      "parent_id": "t1_n6poypk",
                      "score": 2,
                      "author_fullname": "t2_1dhesoqqtu",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "You are my savior! I've been try to finding missing one",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6puzfu",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You are my savior! I&amp;#39;ve been try to finding missing one&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgg3mh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6puzfu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754238549,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6poypk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "tyoyvr-2222",
            "can_mod_post": false,
            "created_utc": 1754236696,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 5,
            "author_fullname": "t2_v7l3ekwd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Running MI50-32GB in Ubuntu 24.04 LTS with ROCM 6.4.1 smoothly  \n\n\n1. follow the [official guide to install driver](https://rocm.docs.amd.com/projects/install-on-linux/en/docs-6.4.1/install/install-methods/amdgpu-installer/amdgpu-installer-ubuntu.html)\n2. download missing gfx906 TensileLibrary files from Arch Linux  [`https://github.com/ROCm/ROCm/issues/4625#issuecomment-2934325443`](https://github.com/ROCm/ROCm/issues/4625#issuecomment-2934325443)  \n3. [`https://archlinux.org/packages/extra/x86_64/rocblas/`](https://archlinux.org/packages/extra/x86_64/rocblas/)\n\n&amp;#8203;\n\n    root@aiserver:/ai# update-alternatives --display rocm\n    rocm - auto mode\n      link best version is /opt/rocm-6.4.1\n      link currently points to /opt/rocm-6.4.1\n      link rocm is /opt/rocm\n    /opt/rocm-6.4.1 - priority 647542159\n    \n    root@aiserver:/ai# llama-server --list-devices\n    ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n    ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n    ggml_cuda_init: found 1 ROCm devices:\n      Device 0: AMD Radeon Graphics, gfx906:sramecc+:xnack- (0x906), VMM: no, Wave Size: 64\n    load_backend: loaded ROCm backend from /ai/github/llama.cpp/build/bin/libggml-hip.so\n    load_backend: loaded RPC backend from /ai/github/llama.cpp/build/bin/libggml-rpc.so\n    load_backend: loaded CPU backend from /ai/github/llama.cpp/build/bin/libggml-cpu-alderlake.so\n    Available devices:\n      ROCm0: AMD Radeon Graphics (32752 MiB, 32732 MiB free)\n    \n    root@aiserver:/ai# uname -a\n    Linux aiserver 6.8.0-71-generic #71-Ubuntu SMP PREEMPT_DYNAMIC Tue Jul 22 16:52:38 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6poypk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Running MI50-32GB in Ubuntu 24.04 LTS with ROCM 6.4.1 smoothly  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;follow the &lt;a href=\"https://rocm.docs.amd.com/projects/install-on-linux/en/docs-6.4.1/install/install-methods/amdgpu-installer/amdgpu-installer-ubuntu.html\"&gt;official guide to install driver&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;download missing gfx906 TensileLibrary files from Arch Linux  &lt;a href=\"https://github.com/ROCm/ROCm/issues/4625#issuecomment-2934325443\"&gt;&lt;code&gt;https://github.com/ROCm/ROCm/issues/4625#issuecomment-2934325443&lt;/code&gt;&lt;/a&gt;&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://archlinux.org/packages/extra/x86_64/rocblas/\"&gt;&lt;code&gt;https://archlinux.org/packages/extra/x86_64/rocblas/&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#8203;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;root@aiserver:/ai# update-alternatives --display rocm\nrocm - auto mode\n  link best version is /opt/rocm-6.4.1\n  link currently points to /opt/rocm-6.4.1\n  link rocm is /opt/rocm\n/opt/rocm-6.4.1 - priority 647542159\n\nroot@aiserver:/ai# llama-server --list-devices\nggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\nggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\nggml_cuda_init: found 1 ROCm devices:\n  Device 0: AMD Radeon Graphics, gfx906:sramecc+:xnack- (0x906), VMM: no, Wave Size: 64\nload_backend: loaded ROCm backend from /ai/github/llama.cpp/build/bin/libggml-hip.so\nload_backend: loaded RPC backend from /ai/github/llama.cpp/build/bin/libggml-rpc.so\nload_backend: loaded CPU backend from /ai/github/llama.cpp/build/bin/libggml-cpu-alderlake.so\nAvailable devices:\n  ROCm0: AMD Radeon Graphics (32752 MiB, 32732 MiB free)\n\nroot@aiserver:/ai# uname -a\nLinux aiserver 6.8.0-71-generic #71-Ubuntu SMP PREEMPT_DYNAMIC Tue Jul 22 16:52:38 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6poypk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754236696,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6pue1c",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Desperate-Sir-5088",
                      "can_mod_post": false,
                      "created_utc": 1754238365,
                      "send_replies": true,
                      "parent_id": "t1_n6ol4is",
                      "score": 1,
                      "author_fullname": "t2_1dhesoqqtu",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Alibaba Seller sent a blower type cooler with \"custom fit\" shroud. Only problem is you can't put the card into ATX cass",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6pue1c",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Alibaba Seller sent a blower type cooler with &amp;quot;custom fit&amp;quot; shroud. Only problem is you can&amp;#39;t put the card into ATX cass&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgg3mh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6pue1c/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754238365,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6ol4is",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "woahdudee2a",
            "can_mod_post": false,
            "created_utc": 1754223273,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 1,
            "author_fullname": "t2_o6qm5t0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "off topic but what cooler are you using there? I thought you needed a plastic shroud to keep it attached",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ol4is",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;off topic but what cooler are you using there? I thought you needed a plastic shroud to keep it attached&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6ol4is/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754223273,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6ou8vy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Desperate-Sir-5088",
            "can_mod_post": false,
            "created_utc": 1754226896,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 1,
            "author_fullname": "t2_1dhesoqqtu",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Here is 'on-job' benchmark test about 20K tokens M&amp;A documents analysis and summerizing\n\n1. Dense-thinking model(Mi50 only)\n\nModel : nvidia\\_Llama-3\\_3-Nemotron-Super-49B-v1\\_5  \nQuant : IQ4\\_NL (28.38GB)  \nCTX : 20,000 tokens  \n4.81 tok/sec 2728 tokens 1460.30s to first token // 121s thinking time\n\n2. Mid-size MOE Model\n\nModel : Qwen3-30B-A3B-Instruct-2507  \nQuant : UD-Q5\\_K\\_XL.gguf(unsloth Dynamic-Quant 21.74GB)  \nCTX    : 20,000 tokens\n\na) 4070ti + MI50\n\n29.17 tok/sec / 3712 tokens / 54.04s to first token (No-thinking)\n\nb) MI50 only\n\n30.13 tok/sec/ 3642 tokens / 90.85s to first token\n\nPrompt Processing is hopeless, but forget MI50's HBM2 is quite faster (1TB/s) than even brand-new AI-PRO 9700(640GB/s and same 32GB memory)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ou8vy",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here is &amp;#39;on-job&amp;#39; benchmark test about 20K tokens M&amp;amp;A documents analysis and summerizing&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Dense-thinking model(Mi50 only)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Model : nvidia_Llama-3_3-Nemotron-Super-49B-v1_5&lt;br/&gt;\nQuant : IQ4_NL (28.38GB)&lt;br/&gt;\nCTX : 20,000 tokens&lt;br/&gt;\n4.81 tok/sec 2728 tokens 1460.30s to first token // 121s thinking time&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Mid-size MOE Model&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Model : Qwen3-30B-A3B-Instruct-2507&lt;br/&gt;\nQuant : UD-Q5_K_XL.gguf(unsloth Dynamic-Quant 21.74GB)&lt;br/&gt;\nCTX    : 20,000 tokens&lt;/p&gt;\n\n&lt;p&gt;a) 4070ti + MI50&lt;/p&gt;\n\n&lt;p&gt;29.17 tok/sec / 3712 tokens / 54.04s to first token (No-thinking)&lt;/p&gt;\n\n&lt;p&gt;b) MI50 only&lt;/p&gt;\n\n&lt;p&gt;30.13 tok/sec/ 3642 tokens / 90.85s to first token&lt;/p&gt;\n\n&lt;p&gt;Prompt Processing is hopeless, but forget MI50&amp;#39;s HBM2 is quite faster (1TB/s) than even brand-new AI-PRO 9700(640GB/s and same 32GB memory)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6ou8vy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754226896,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6p2ozt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "jetaudio",
            "can_mod_post": false,
            "created_utc": 1754229825,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 1,
            "author_fullname": "t2_5plbh7ia",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Setting up those MI50s on Ubuntu 24.02 is just like setting up an NVIDIA card—no hassle at all. Just install the latest ROCm and PyTorch, enable 4G decoding in the BIOS, disable Secure Boot, and voilà—you’ve got dirt-cheap 32GB VRAM with 1 TB/s bandwidth at your service.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6p2ozt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Setting up those MI50s on Ubuntu 24.02 is just like setting up an NVIDIA card—no hassle at all. Just install the latest ROCm and PyTorch, enable 4G decoding in the BIOS, disable Secure Boot, and voilà—you’ve got dirt-cheap 32GB VRAM with 1 TB/s bandwidth at your service.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6p2ozt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754229825,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6p6ede",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "fp4guru",
            "can_mod_post": false,
            "created_utc": 1754231017,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 1,
            "author_fullname": "t2_1tp8zldw5g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What is the model number of that fan , brother ? Thanks.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6p6ede",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What is the model number of that fan , brother ? Thanks.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6p6ede/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754231017,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6pi0h9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ShinyAnkleBalls",
            "can_mod_post": false,
            "created_utc": 1754234572,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 1,
            "author_fullname": "t2_2m3au2xb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Interesting. How is multi GPU support? If someone was to get multiple of these?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6pi0h9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Interesting. How is multi GPU support? If someone was to get multiple of these?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6pi0h9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754234572,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6q40i9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "dc740",
            "can_mod_post": false,
            "created_utc": 1754241279,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 3,
            "author_fullname": "t2_dkwhd0p",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have three of these cards. Flashing the bios gave me worse performance than the original. Yes, it kind of fixes Vulkan so it can see the full 32gb instead of 16, but it's slower and the Vulkan implementation still has big issues preventing you from using the memory anyway. So, IMHO, you are not missing anything by avoiding the bios flash process",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6q40i9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have three of these cards. Flashing the bios gave me worse performance than the original. Yes, it kind of fixes Vulkan so it can see the full 32gb instead of 16, but it&amp;#39;s slower and the Vulkan implementation still has big issues preventing you from using the memory anyway. So, IMHO, you are not missing anything by avoiding the bios flash process&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6q40i9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754241279,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6oz9sz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Marksta",
                      "can_mod_post": false,
                      "created_utc": 1754228672,
                      "send_replies": true,
                      "parent_id": "t1_n6oucmb",
                      "score": 6,
                      "author_fullname": "t2_559a1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It's closed source",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6oz9sz",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s closed source&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgg3mh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6oz9sz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754228672,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6oucmb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "SanDiegoDude",
            "can_mod_post": false,
            "created_utc": 1754226933,
            "send_replies": true,
            "parent_id": "t3_1mgg3mh",
            "score": 0,
            "author_fullname": "t2_3h3gm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hardcore man, you're braver than I am. \n\nWhy do you say some people don't like LM Studio? Not a badass unless you're grinding your teeth on pure CLI on a headless distro and only using Dvorak keyboard layout?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6oucmb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hardcore man, you&amp;#39;re braver than I am. &lt;/p&gt;\n\n&lt;p&gt;Why do you say some people don&amp;#39;t like LM Studio? Not a badass unless you&amp;#39;re grinding your teeth on pure CLI on a headless distro and only using Dvorak keyboard layout?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgg3mh/successfully_running_instinct_mi50_on_win11/n6oucmb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754226933,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgg3mh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]