[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I'm working on a new model that allows for attribution of trained on data to be identified at the time of inference. One of my hypothesis being that if the the data being used at inference can be attributed then the next round of fine tuning can,  \n  \n1. Trim data that wasn't used at inference  \n2. More data could be added that is contextual to the outcome  \n  \nI'd love to get some initial feedback on this thinking, would it be helpful when fine tuning your own models?  ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Fine Tuning; Attribution at Inference Time",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mbako7",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.8,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_6cyd8",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753690842,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a new model that allows for attribution of trained on data to be identified at the time of inference. One of my hypothesis being that if the the data being used at inference can be attributed then the next round of fine tuning can,  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Trim data that wasn&amp;#39;t used at inference&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;More data could be added that is contextual to the outcome&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;d love to get some initial feedback on this thinking, would it be helpful when fine tuning your own models?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mbako7",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Iam_Alastair",
            "discussion_type": null,
            "num_comments": 5,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mbako7/fine_tuning_attribution_at_inference_time/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mbako7/fine_tuning_attribution_at_inference_time/",
            "subreddit_subscribers": 506191,
            "created_utc": 1753690842,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5kqk40",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Efficiency_1144",
            "can_mod_post": false,
            "created_utc": 1753691794,
            "send_replies": true,
            "parent_id": "t3_1mbako7",
            "score": 2,
            "author_fullname": "t2_1nkj9l14b0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Models only memorise a very small amount of their data- their capacity for this is extremely tiny relative to their size. The rest of the data is actually made using synthesis. This means the vast majority of outputs won’t have an actual training data point to be matched with.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kqk40",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Models only memorise a very small amount of their data- their capacity for this is extremely tiny relative to their size. The rest of the data is actually made using synthesis. This means the vast majority of outputs won’t have an actual training data point to be matched with.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbako7/fine_tuning_attribution_at_inference_time/n5kqk40/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753691794,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbako7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5l8nhx",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Awwtifishal",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5l7214",
                                "score": 1,
                                "author_fullname": "t2_1d96a8k10t",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The problem is the same. Each individual piece of training data only influences the model a tiny bit, an incredibly small amount, so if you could calculate what's the most influential, the highest percentages you could find would still be extremely small, and many of them. There's a lot of unattributed references everywhere, and LLMs are trained with all of them. Unless you can add attribution to the references of all training data, I think that's impossible to do.\n\nMuch more plausible is to vectorize all stuff you want to attribute in the training data in a database, and look it up with a generated piece of text. Basically doing the back end of a RAG pipeline that can handle the amount of data you want to feed it.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5l8nhx",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The problem is the same. Each individual piece of training data only influences the model a tiny bit, an incredibly small amount, so if you could calculate what&amp;#39;s the most influential, the highest percentages you could find would still be extremely small, and many of them. There&amp;#39;s a lot of unattributed references everywhere, and LLMs are trained with all of them. Unless you can add attribution to the references of all training data, I think that&amp;#39;s impossible to do.&lt;/p&gt;\n\n&lt;p&gt;Much more plausible is to vectorize all stuff you want to attribute in the training data in a database, and look it up with a generated piece of text. Basically doing the back end of a RAG pipeline that can handle the amount of data you want to feed it.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mbako7",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mbako7/fine_tuning_attribution_at_inference_time/n5l8nhx/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753701572,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753701572,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5lsz98",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "No_Efficiency_1144",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5l7214",
                                "score": 1,
                                "author_fullname": "t2_1nkj9l14b0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "This is different from what I thought you meant. This does seem more viable and there are existing projects in Explainable AI that try to estimate this (often for CNNs.) I am not sure how well it would scale.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5lsz98",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is different from what I thought you meant. This does seem more viable and there are existing projects in Explainable AI that try to estimate this (often for CNNs.) I am not sure how well it would scale.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mbako7",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mbako7/fine_tuning_attribution_at_inference_time/n5lsz98/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753709352,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753709352,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5l7214",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Iam_Alastair",
                      "can_mod_post": false,
                      "created_utc": 1753700833,
                      "send_replies": true,
                      "parent_id": "t1_n5kqwti",
                      "score": 1,
                      "author_fullname": "t2_6cyd8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "When doing attribution, we are not expecting to find quoted text in an inference that points to some specific piece of content in the training set. We are expecting to find the pieces of data that were most influential in generating the inference response.\n\nSo it's not so much attribution but influence at inference.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5l7214",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;When doing attribution, we are not expecting to find quoted text in an inference that points to some specific piece of content in the training set. We are expecting to find the pieces of data that were most influential in generating the inference response.&lt;/p&gt;\n\n&lt;p&gt;So it&amp;#39;s not so much attribution but influence at inference.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbako7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbako7/fine_tuning_attribution_at_inference_time/n5l7214/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753700833,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5kqwti",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Awwtifishal",
            "can_mod_post": false,
            "created_utc": 1753692005,
            "send_replies": true,
            "parent_id": "t3_1mbako7",
            "score": 0,
            "author_fullname": "t2_1d96a8k10t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don't see how could that work, since almost all training data influences pretty much all of the model even if it's just a little bit. The way data is stored in LLMs is actually not well understood. Otherwise it would probably be much easier to given them memory than it is now.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kqwti",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t see how could that work, since almost all training data influences pretty much all of the model even if it&amp;#39;s just a little bit. The way data is stored in LLMs is actually not well understood. Otherwise it would probably be much easier to given them memory than it is now.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbako7/fine_tuning_attribution_at_inference_time/n5kqwti/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753692005,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbako7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]