[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "At least for models built on the Qwen 3 architecture, I noticed that the speed difference between the MoE models and roughly equivalent dense models is minimal, particularly as context sizes get larger.\n\nFor instance, on my M4 Max MacBook Pro, with llama.cpp, unsloth Q4\\_K\\_XL quants, flash attention, and q8\\_0 KV cache quantization, here are the performance results I got:\n\n|Model|Context Size (tokens, approx)|Prompt Processing (tok/s)|Token Generation (tok/s)|\n|:-|:-|:-|:-|\n|Qwen 3 8B|500|730|70|\n|Qwen 3 8B|53000|103|22|\n|Qwen 3 30B-A3B|500|849|88|\n|Qwen 3 30B-A3B|53000|73|22|\n|Qwen 3 14B|500|402|43|\n|Qwen 3 14B|53000|66|12|\n\nNote: the prompt processing and token generation speeds are for processing additional inputs or generating additional output tokens, after the indicated number of tokens have already been processed in context\n\nIn terms of intelligence and knowledge, the original 30B-A3B model was somewhere in between the 8B and 14B in my experiments. At large context sizes, the 30B-A3B has prompt processing size in between 8B and 14B, and token generation speeds roughly the same as the 8B.\n\nI've read that MoEs are more efficient (cheaper) to train, but for end users, under the Qwen 3 architecture at least, the inference speed benefit of MoE seems limited, and the large memory footprint is problematic for those who don't have huge amounts of RAM.\n\nI'm curious how the IBM Granite 4 architecture will fare, particularly with large contexts, given its context memory efficient Mamba-Transformer hybrid design.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "MoE models not as fast as active parameter counts suggest",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mfh4ee",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.5,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_702zh1r2",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754107542,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At least for models built on the Qwen 3 architecture, I noticed that the speed difference between the MoE models and roughly equivalent dense models is minimal, particularly as context sizes get larger.&lt;/p&gt;\n\n&lt;p&gt;For instance, on my M4 Max MacBook Pro, with llama.cpp, unsloth Q4_K_XL quants, flash attention, and q8_0 KV cache quantization, here are the performance results I got:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;Context Size (tokens, approx)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Prompt Processing (tok/s)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Token Generation (tok/s)&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 3 8B&lt;/td&gt;\n&lt;td align=\"left\"&gt;500&lt;/td&gt;\n&lt;td align=\"left\"&gt;730&lt;/td&gt;\n&lt;td align=\"left\"&gt;70&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 3 8B&lt;/td&gt;\n&lt;td align=\"left\"&gt;53000&lt;/td&gt;\n&lt;td align=\"left\"&gt;103&lt;/td&gt;\n&lt;td align=\"left\"&gt;22&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 3 30B-A3B&lt;/td&gt;\n&lt;td align=\"left\"&gt;500&lt;/td&gt;\n&lt;td align=\"left\"&gt;849&lt;/td&gt;\n&lt;td align=\"left\"&gt;88&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 3 30B-A3B&lt;/td&gt;\n&lt;td align=\"left\"&gt;53000&lt;/td&gt;\n&lt;td align=\"left\"&gt;73&lt;/td&gt;\n&lt;td align=\"left\"&gt;22&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 3 14B&lt;/td&gt;\n&lt;td align=\"left\"&gt;500&lt;/td&gt;\n&lt;td align=\"left\"&gt;402&lt;/td&gt;\n&lt;td align=\"left\"&gt;43&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 3 14B&lt;/td&gt;\n&lt;td align=\"left\"&gt;53000&lt;/td&gt;\n&lt;td align=\"left\"&gt;66&lt;/td&gt;\n&lt;td align=\"left\"&gt;12&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Note: the prompt processing and token generation speeds are for processing additional inputs or generating additional output tokens, after the indicated number of tokens have already been processed in context&lt;/p&gt;\n\n&lt;p&gt;In terms of intelligence and knowledge, the original 30B-A3B model was somewhere in between the 8B and 14B in my experiments. At large context sizes, the 30B-A3B has prompt processing size in between 8B and 14B, and token generation speeds roughly the same as the 8B.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve read that MoEs are more efficient (cheaper) to train, but for end users, under the Qwen 3 architecture at least, the inference speed benefit of MoE seems limited, and the large memory footprint is problematic for those who don&amp;#39;t have huge amounts of RAM.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious how the IBM Granite 4 architecture will fare, particularly with large contexts, given its context memory efficient Mamba-Transformer hybrid design.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mfh4ee",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Federal-Effective879",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/",
            "subreddit_subscribers": 509293,
            "created_utc": 1754107542,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "text",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": null,
                                                                                            "likes": null,
                                                                                            "replies": "",
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n6l969x",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": true,
                                                                                            "author": "a_beautiful_rhind",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1754169387,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n6l447m",
                                                                                            "score": 1,
                                                                                            "author_fullname": "t2_h5utwre7",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "2 procs so 12 in total. \n\n    ALL Reads        :\t220192.3\n    Stream-triad like:\t179996.1\n\nstill only makes:\n\n\n|    PP |     TG |   N_KV |   T_PP s | S_PP t/s |   T_TG s | S_TG t/s |\n|-------|--------|--------|----------|----------|----------|----------|\n|  2048 |    512 |      0 |   42.593 |    48.08 |   53.335 |     9.60 |\n|  2048 |    512 |   2048 |   41.731 |    49.08 |   48.897 |    10.47 |\n|  2048 |    512 |   4096 |   42.419 |    48.28 |   55.966 |     9.15 |\n\nOn IQ2_XXS deepseek v3 with 4x3090. For something like 4KM, you'll get 4t/s.",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n6l969x",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;2 procs so 12 in total. &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;ALL Reads        :  220192.3\nStream-triad like:  179996.1\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;still only makes:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;PP&lt;/th&gt;\n&lt;th&gt;TG&lt;/th&gt;\n&lt;th&gt;N_KV&lt;/th&gt;\n&lt;th&gt;T_PP s&lt;/th&gt;\n&lt;th&gt;S_PP t/s&lt;/th&gt;\n&lt;th&gt;T_TG s&lt;/th&gt;\n&lt;th&gt;S_TG t/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;2048&lt;/td&gt;\n&lt;td&gt;512&lt;/td&gt;\n&lt;td&gt;0&lt;/td&gt;\n&lt;td&gt;42.593&lt;/td&gt;\n&lt;td&gt;48.08&lt;/td&gt;\n&lt;td&gt;53.335&lt;/td&gt;\n&lt;td&gt;9.60&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2048&lt;/td&gt;\n&lt;td&gt;512&lt;/td&gt;\n&lt;td&gt;2048&lt;/td&gt;\n&lt;td&gt;41.731&lt;/td&gt;\n&lt;td&gt;49.08&lt;/td&gt;\n&lt;td&gt;48.897&lt;/td&gt;\n&lt;td&gt;10.47&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;2048&lt;/td&gt;\n&lt;td&gt;512&lt;/td&gt;\n&lt;td&gt;4096&lt;/td&gt;\n&lt;td&gt;42.419&lt;/td&gt;\n&lt;td&gt;48.28&lt;/td&gt;\n&lt;td&gt;55.966&lt;/td&gt;\n&lt;td&gt;9.15&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;On IQ2_XXS deepseek v3 with 4x3090. For something like 4KM, you&amp;#39;ll get 4t/s.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": null,
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6l969x/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1754169387,
                                                                                            "author_flair_text": null,
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1mfh4ee",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": null,
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 1
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n6l447m",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": true,
                                                                                  "author": "AppearanceHeavy6724",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754167745,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n6l2kyc",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_uz37qfx5",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "&gt; I have old ass DDR4\n\nhow many channels?",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n6l447m",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I have old ass DDR4&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;how many channels?&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mfh4ee",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6l447m/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754167745,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n6l2kyc",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "a_beautiful_rhind",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n6kmzdj",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_h5utwre7",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "I have old ass DDR4 and I'm telling you the speeds aren't that great. Especially if you want reasoning or coding. I'm not complaining about it as some theoretical. \n\nThe really low parameter MoE like hunyan, dots, etc kinda suck which is why they compare them with 30b models. So you have to run the big GLM4.5, deepseek, etc and then it's slow again. Still have to put tensors on GPU to make it tolerable and there goes your extra context. \n\nThose rigs that make 20t/s with one GPU and 4-bit quants are not cheap in the same way vram isn't cheap. In a year they might be, but not yet.",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n6l2kyc",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have old ass DDR4 and I&amp;#39;m telling you the speeds aren&amp;#39;t that great. Especially if you want reasoning or coding. I&amp;#39;m not complaining about it as some theoretical. &lt;/p&gt;\n\n&lt;p&gt;The really low parameter MoE like hunyan, dots, etc kinda suck which is why they compare them with 30b models. So you have to run the big GLM4.5, deepseek, etc and then it&amp;#39;s slow again. Still have to put tensors on GPU to make it tolerable and there goes your extra context. &lt;/p&gt;\n\n&lt;p&gt;Those rigs that make 20t/s with one GPU and 4-bit quants are not cheap in the same way vram isn&amp;#39;t cheap. In a year they might be, but not yet.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mfh4ee",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6l2kyc/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754167257,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754167257,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6kmzdj",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "AppearanceHeavy6724",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6km6tp",
                                                              "score": 1,
                                                              "author_fullname": "t2_uz37qfx5",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "some old ass ddr4 xeon cost peanuts. whole builds $1000. You do not super high compute per se you need memory channels.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6kmzdj",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;some old ass ddr4 xeon cost peanuts. whole builds $1000. You do not super high compute per se you need memory channels.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mfh4ee",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6kmzdj/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754162026,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754162026,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6km6tp",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "a_beautiful_rhind",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6jxcef",
                                                    "score": 1,
                                                    "author_fullname": "t2_h5utwre7",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "What would that be? There's xeon, epyc and macs. High bandwidth stuff costs.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6km6tp",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What would that be? There&amp;#39;s xeon, epyc and macs. High bandwidth stuff costs.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mfh4ee",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6km6tp/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754161764,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754161764,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6jxcef",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "AppearanceHeavy6724",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6jwnbq",
                                          "score": 2,
                                          "author_fullname": "t2_uz37qfx5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "&gt;  you're buying $2k worth of ram and processor.\n\nNo, xeons are poweful but trash tier priced, altogether $1000 with ram, and eats less power too, like 1/6 joules per token of comparable amount GPUs and a dense model.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6jxcef",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;you&amp;#39;re buying $2k worth of ram and processor.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No, xeons are poweful but trash tier priced, altogether $1000 with ram, and eats less power too, like 1/6 joules per token of comparable amount GPUs and a dense model.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mfh4ee",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6jxcef/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754153782,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754153782,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6jwnbq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "a_beautiful_rhind",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6jrxoh",
                                "score": 2,
                                "author_fullname": "t2_h5utwre7",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yea but \"you can run\" has a big gulf with \"run well\". The good CPU costs a lot too. Instead of 2 more 3090s, you're buying $2k worth of ram and processor.\n\nI saw people posting how everyone with GPUs is supposed to be salty now. It \"runs\" so well and they wasted their money. They must have never actually done it to see the realities. Nobody's GPUs are going to waste, it's *hybrid* inference and both are going full tilt to keep it from chugging.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6jwnbq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yea but &amp;quot;you can run&amp;quot; has a big gulf with &amp;quot;run well&amp;quot;. The good CPU costs a lot too. Instead of 2 more 3090s, you&amp;#39;re buying $2k worth of ram and processor.&lt;/p&gt;\n\n&lt;p&gt;I saw people posting how everyone with GPUs is supposed to be salty now. It &amp;quot;runs&amp;quot; so well and they wasted their money. They must have never actually done it to see the realities. Nobody&amp;#39;s GPUs are going to waste, it&amp;#39;s &lt;em&gt;hybrid&lt;/em&gt; inference and both are going full tilt to keep it from chugging.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfh4ee",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6jwnbq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754153551,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754153551,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6jrxoh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AppearanceHeavy6724",
                      "can_mod_post": false,
                      "created_utc": 1754152040,
                      "send_replies": true,
                      "parent_id": "t1_n6jr2mf",
                      "score": 2,
                      "author_fullname": "t2_uz37qfx5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "\"MoE\" biggest cheerleaders cannot afford GPU's that can load large models; with proper software and good cpu you can run even deepseek on 2x3090.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6jrxoh",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;MoE&amp;quot; biggest cheerleaders cannot afford GPU&amp;#39;s that can load large models; with proper software and good cpu you can run even deepseek on 2x3090.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfh4ee",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6jrxoh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754152040,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6jr2mf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "a_beautiful_rhind",
            "can_mod_post": false,
            "created_utc": 1754151763,
            "send_replies": true,
            "parent_id": "t3_1mfh4ee",
            "score": 2,
            "author_fullname": "t2_h5utwre7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think MoE's biggest cheerleaders don't regularly use the models in general. That or they were stuck with much smaller dense before.\n\nIt does mostly come out as a wash. My mistral-large/command-a/qwen-235b speeds end up pretty close in practice. \n\nSpeed advantage gets eaten by offloading, or in your case lack of compute.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6jr2mf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think MoE&amp;#39;s biggest cheerleaders don&amp;#39;t regularly use the models in general. That or they were stuck with much smaller dense before.&lt;/p&gt;\n\n&lt;p&gt;It does mostly come out as a wash. My mistral-large/command-a/qwen-235b speeds end up pretty close in practice. &lt;/p&gt;\n\n&lt;p&gt;Speed advantage gets eaten by offloading, or in your case lack of compute.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6jr2mf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754151763,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfh4ee",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6jrapa",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Federal-Effective879",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6jq7ll",
                                          "score": 1,
                                          "author_fullname": "t2_702zh1r2",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Agreed; MoE is a major speedup on CPU with small context. I'm curious how prompt processing speed would fare on say an Nvidia 5090 running the same models and context sizes.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6jrapa",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Agreed; MoE is a major speedup on CPU with small context. I&amp;#39;m curious how prompt processing speed would fare on say an Nvidia 5090 running the same models and context sizes.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mfh4ee",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6jrapa/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754151836,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754151836,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6jq7ll",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "AppearanceHeavy6724",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6jnmt8",
                                "score": 1,
                                "author_fullname": "t2_uz37qfx5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "your point is neither right nor wrong, as the result is highly dependent on the hardware. If all you have is cpu and you need only for small to moderate &lt; 8k context than MoE provides massive improvement.Or if you have very large model impossible or uneconomical to run on on a single big gpu. Hostings love moe as you can split it on many pieces easily and increase utilization. \n\nDeepseek uses very economical attention mechanism, so attention demands scale slower than on good old group query attention.\n\nUltimately yes, at some point attention becomes dominant, but when it happens depends on hardware.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6jq7ll",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;your point is neither right nor wrong, as the result is highly dependent on the hardware. If all you have is cpu and you need only for small to moderate &amp;lt; 8k context than MoE provides massive improvement.Or if you have very large model impossible or uneconomical to run on on a single big gpu. Hostings love moe as you can split it on many pieces easily and increase utilization. &lt;/p&gt;\n\n&lt;p&gt;Deepseek uses very economical attention mechanism, so attention demands scale slower than on good old group query attention.&lt;/p&gt;\n\n&lt;p&gt;Ultimately yes, at some point attention becomes dominant, but when it happens depends on hardware.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfh4ee",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6jq7ll/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754151488,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754151488,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6jnmt8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Federal-Effective879",
                      "can_mod_post": false,
                      "created_utc": 1754150660,
                      "send_replies": true,
                      "parent_id": "t1_n6jjfbq",
                      "score": 1,
                      "author_fullname": "t2_702zh1r2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "In general, the Qwen 3 30B-A3B feels roughly equivalent to a 10-11B dense Qwen 3 model in my experiments, so yes with enough RAM (like on my Mac) it does give better knowledge than 8B with equivalent or slightly faster token generation and proportionate to intelligence prompt processing speed.\n\nMy point was mainly that at larger context sizes, the performance benefits of MoE is pretty minimal compared to an equivalent dense model - i.e. no prompt processing speed benefit, and only a slight token generation speed benefit nowhere near the active parameter count ratio.",
                      "edited": 1754150900,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6jnmt8",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In general, the Qwen 3 30B-A3B feels roughly equivalent to a 10-11B dense Qwen 3 model in my experiments, so yes with enough RAM (like on my Mac) it does give better knowledge than 8B with equivalent or slightly faster token generation and proportionate to intelligence prompt processing speed.&lt;/p&gt;\n\n&lt;p&gt;My point was mainly that at larger context sizes, the performance benefits of MoE is pretty minimal compared to an equivalent dense model - i.e. no prompt processing speed benefit, and only a slight token generation speed benefit nowhere near the active parameter count ratio.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfh4ee",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6jnmt8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754150660,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6jjfbq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AppearanceHeavy6724",
            "can_mod_post": false,
            "created_utc": 1754149323,
            "send_replies": true,
            "parent_id": "t3_1mfh4ee",
            "score": 0,
            "author_fullname": "t2_uz37qfx5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is because attention computation is expensive and scales with total number of weights, not active. Mac being weak on computation side would degrade  faster with context growth than a GPU. \n\n30B A3B still is a bargain though - it has more knowledge than qwen 3 8b and faster. at reasoble (&lt; 16k) contexts.\n\nTry falcon-H1, similar to granite arch, but already supported in llama.cpp.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6jjfbq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is because attention computation is expensive and scales with total number of weights, not active. Mac being weak on computation side would degrade  faster with context growth than a GPU. &lt;/p&gt;\n\n&lt;p&gt;30B A3B still is a bargain though - it has more knowledge than qwen 3 8b and faster. at reasoble (&amp;lt; 16k) contexts.&lt;/p&gt;\n\n&lt;p&gt;Try falcon-H1, similar to granite arch, but already supported in llama.cpp.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfh4ee/moe_models_not_as_fast_as_active_parameter_counts/n6jjfbq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754149323,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfh4ee",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]