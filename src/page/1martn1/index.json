[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I have a chance to travel to China the end of this year. I'm thinking about buying the 48 GB dual B60 GPU, if I could find one (not really the goal of my travel there). Can you guys give me some insights on the Intel's previous GPUs compatibility with Nvidia kit? I've read that AMD's Rocm is a bit of a pain. That's why I'm interested with intel Arc. I'm currently using 3060 TI (8gb), just to mess around with comfyui on Windows 10. But I want to upgrade. I don't mind the speed, more interested in capability (training, generation, etc). Thanks.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "General Intel Arc compatibility with Nvidia",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1martn1",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.83,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 4,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_7uclp",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 4,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753636465,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a chance to travel to China the end of this year. I&amp;#39;m thinking about buying the 48 GB dual B60 GPU, if I could find one (not really the goal of my travel there). Can you guys give me some insights on the Intel&amp;#39;s previous GPUs compatibility with Nvidia kit? I&amp;#39;ve read that AMD&amp;#39;s Rocm is a bit of a pain. That&amp;#39;s why I&amp;#39;m interested with intel Arc. I&amp;#39;m currently using 3060 TI (8gb), just to mess around with comfyui on Windows 10. But I want to upgrade. I don&amp;#39;t mind the speed, more interested in capability (training, generation, etc). Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1martn1",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "SwingNinja",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": false,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1martn1/general_intel_arc_compatibility_with_nvidia/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1martn1/general_intel_arc_compatibility_with_nvidia/",
            "subreddit_subscribers": 505879,
            "created_utc": 1753636465,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5gumcp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Tyme4Trouble",
            "can_mod_post": false,
            "created_utc": 1753638017,
            "send_replies": true,
            "parent_id": "t3_1martn1",
            "score": 2,
            "author_fullname": "t2_973amyap",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Mixing GPU drivers in Windows is known to cause headaches with any GPU combination. ML on any GPU is kind of a pain in windows in general. Linux is usually much easier to work with.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gumcp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mixing GPU drivers in Windows is known to cause headaches with any GPU combination. ML on any GPU is kind of a pain in windows in general. Linux is usually much easier to work with.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1martn1/general_intel_arc_compatibility_with_nvidia/n5gumcp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753638017,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1martn1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5hp2ym",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ravage382",
            "can_mod_post": false,
            "created_utc": 1753647182,
            "send_replies": true,
            "parent_id": "t3_1martn1",
            "score": 1,
            "author_fullname": "t2_9sf41",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think you are tied to one back end if you are using llama.cpp. So, you would have to use vulkan or the llama.cpp rpc server as a work around. Performance on the Arc 770 is pretty low from my experience, but has improved quite a bit with the newest linux kernels.  I would expect it to continue to get better over time.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hp2ym",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think you are tied to one back end if you are using llama.cpp. So, you would have to use vulkan or the llama.cpp rpc server as a work around. Performance on the Arc 770 is pretty low from my experience, but has improved quite a bit with the newest linux kernels.  I would expect it to continue to get better over time.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1martn1/general_intel_arc_compatibility_with_nvidia/n5hp2ym/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753647182,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1martn1",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]