[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hopefully soemthign thats somewhat easy to digest for someone who doesnt really know all the terminology and the technical aspects in this subject area and can gradually build their undertsanding. Im still a bit overwhlemed at the amount of tweaking a user can do to the model at runtime, have been using ollama for several weeks and just the other day moved over to ik\\_llama.cpp.\n\nCurrently Im running models that comfortably fit entirely into an RTX 4090 but the system has 128GB RAM and I dont really know how to get the best out of it. \n\nI undertand the scope of my request is vague at best as I havent specified what tasks or my objectives. Thats half the problem, I dont really know what I want to do with all this, but seeign as I've just gone and installed VS Codium for the first time in my life, it woudl be fair to say very likely some kind of developing and building of tools and applications that would be of benefit to me is on the cards.\n\nI have only the last month or so started dabbling with LLMs (mainly due to hardware upgrades for other reasons) and find it very interesting.  Just pulled [Qwen3-Coder-30B-A3B](https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF):Q5KM from hf and setup up continue in VS Codium. I'm seeing people using all kinds of confusing regex stuff in their run parameters and calculating how many or which layers are offloaded to GPU vs CPU. I'd hate to be leaving any low hanging performance/capability fruit still on the table (if that mishmash of expressions makes any sense to anyone) especialy as the 4090 is going to be replaced at some point soon. (I have actually upgraded to a 5090 just havent sold the 4090 yet so have temporarily put it in the threadripper server as a placeholder while I get my head around this LLM buisness.\n\nSo any pointers to useful howto's/articles that youve found valuable to get me some traction and direction would be incredibly helpful. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "can someone point me to some articles/posts they found really informative in understanding which paramters and how to determine value when deploying models in ik_llama.cpp",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1menm37",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.5,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_if95iuzc",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754024378,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hopefully soemthign thats somewhat easy to digest for someone who doesnt really know all the terminology and the technical aspects in this subject area and can gradually build their undertsanding. Im still a bit overwhlemed at the amount of tweaking a user can do to the model at runtime, have been using ollama for several weeks and just the other day moved over to ik_llama.cpp.&lt;/p&gt;\n\n&lt;p&gt;Currently Im running models that comfortably fit entirely into an RTX 4090 but the system has 128GB RAM and I dont really know how to get the best out of it. &lt;/p&gt;\n\n&lt;p&gt;I undertand the scope of my request is vague at best as I havent specified what tasks or my objectives. Thats half the problem, I dont really know what I want to do with all this, but seeign as I&amp;#39;ve just gone and installed VS Codium for the first time in my life, it woudl be fair to say very likely some kind of developing and building of tools and applications that would be of benefit to me is on the cards.&lt;/p&gt;\n\n&lt;p&gt;I have only the last month or so started dabbling with LLMs (mainly due to hardware upgrades for other reasons) and find it very interesting.  Just pulled &lt;a href=\"https://huggingface.co/unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF\"&gt;Qwen3-Coder-30B-A3B&lt;/a&gt;:Q5KM from hf and setup up continue in VS Codium. I&amp;#39;m seeing people using all kinds of confusing regex stuff in their run parameters and calculating how many or which layers are offloaded to GPU vs CPU. I&amp;#39;d hate to be leaving any low hanging performance/capability fruit still on the table (if that mishmash of expressions makes any sense to anyone) especialy as the 4090 is going to be replaced at some point soon. (I have actually upgraded to a 5090 just havent sold the 4090 yet so have temporarily put it in the threadripper server as a placeholder while I get my head around this LLM buisness.&lt;/p&gt;\n\n&lt;p&gt;So any pointers to useful howto&amp;#39;s/articles that youve found valuable to get me some traction and direction would be incredibly helpful. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/cy-9p63w74w2Wsh_XdxWUC4aNr1WfOGqoNbvrUXxtCo.png?auto=webp&amp;s=f1e226a43ae5e51cfae2f7cddc8ddebc62dd8ae6",
                    "width": 1200,
                    "height": 648
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/cy-9p63w74w2Wsh_XdxWUC4aNr1WfOGqoNbvrUXxtCo.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b858451b750eab889b9ebb40dc87b8742e42c132",
                      "width": 108,
                      "height": 58
                    },
                    {
                      "url": "https://external-preview.redd.it/cy-9p63w74w2Wsh_XdxWUC4aNr1WfOGqoNbvrUXxtCo.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=75d02d4ea81276e053f2ef745f72f7c02d839924",
                      "width": 216,
                      "height": 116
                    },
                    {
                      "url": "https://external-preview.redd.it/cy-9p63w74w2Wsh_XdxWUC4aNr1WfOGqoNbvrUXxtCo.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bb7bc356b084a2e34b2352327c017938034394a4",
                      "width": 320,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/cy-9p63w74w2Wsh_XdxWUC4aNr1WfOGqoNbvrUXxtCo.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e971ad56728d72932f272bece193c61032b41cb1",
                      "width": 640,
                      "height": 345
                    },
                    {
                      "url": "https://external-preview.redd.it/cy-9p63w74w2Wsh_XdxWUC4aNr1WfOGqoNbvrUXxtCo.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d570332d37cea5373bb386760eb5f7601963b4a9",
                      "width": 960,
                      "height": 518
                    },
                    {
                      "url": "https://external-preview.redd.it/cy-9p63w74w2Wsh_XdxWUC4aNr1WfOGqoNbvrUXxtCo.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=352dfe5f13adf960b7185365eb74b19d5ae84b32",
                      "width": 1080,
                      "height": 583
                    }
                  ],
                  "variants": {},
                  "id": "cy-9p63w74w2Wsh_XdxWUC4aNr1WfOGqoNbvrUXxtCo"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1menm37",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "munkiemagik",
            "discussion_type": null,
            "num_comments": 1,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1menm37/can_someone_point_me_to_some_articlesposts_they/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1menm37/can_someone_point_me_to_some_articlesposts_they/",
            "subreddit_subscribers": 508190,
            "created_utc": 1754024378,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6asijo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Double-Pollution6273",
            "can_mod_post": false,
            "created_utc": 1754025571,
            "send_replies": true,
            "parent_id": "t3_1menm37",
            "score": 1,
            "author_fullname": "t2_t74kj0a",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "https://blog.steelph0enix.dev/posts/llama-cpp-guide/\n\nI started here. The guide will get you started using llama.cpp and help you understand quite a few parameters. I am yet to use ik_llama.cpp but I think, most commands are same. Please check it though.\n\nhttps://www.reddit.com/r/LocalLLaMA/s/3m2t0920Hm\nThis link will explain the idea of the '-ot' flag. The LLMs can help you build a regex, but I have been happy with the regex provided by team Unsloth on their pages.\n\nSomeone has built an automated tool to get you the optimal tensor override commands, but I am not finding it now. I haven't used it much.\n\nHope this helps you.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6asijo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://blog.steelph0enix.dev/posts/llama-cpp-guide/\"&gt;https://blog.steelph0enix.dev/posts/llama-cpp-guide/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I started here. The guide will get you started using llama.cpp and help you understand quite a few parameters. I am yet to use ik_llama.cpp but I think, most commands are same. Please check it though.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/s/3m2t0920Hm\"&gt;https://www.reddit.com/r/LocalLLaMA/s/3m2t0920Hm&lt;/a&gt;\nThis link will explain the idea of the &amp;#39;-ot&amp;#39; flag. The LLMs can help you build a regex, but I have been happy with the regex provided by team Unsloth on their pages.&lt;/p&gt;\n\n&lt;p&gt;Someone has built an automated tool to get you the optimal tensor override commands, but I am not finding it now. I haven&amp;#39;t used it much.&lt;/p&gt;\n\n&lt;p&gt;Hope this helps you.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1menm37/can_someone_point_me_to_some_articlesposts_they/n6asijo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754025571,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1menm37",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]