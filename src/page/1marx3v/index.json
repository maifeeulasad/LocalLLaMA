[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "There's good hyper around gemini deep think. Can we simulate it using the DeepSeek models or Qwen?\n\nIs that simply gemini 2.5 pro with a much higher thinking budget or it's using some branch of thoughts or Graph of thoughts behind the scenes using multiple parallel instances???? \n\nHas anyone tested something like this? ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "How can we simulate gemini deepthink with models like deepseek/qwen or other open models?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1marx3v",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.89,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 7,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_yfi9sqrzf",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 7,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753636686,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s good hyper around gemini deep think. Can we simulate it using the DeepSeek models or Qwen?&lt;/p&gt;\n\n&lt;p&gt;Is that simply gemini 2.5 pro with a much higher thinking budget or it&amp;#39;s using some branch of thoughts or Graph of thoughts behind the scenes using multiple parallel instances???? &lt;/p&gt;\n\n&lt;p&gt;Has anyone tested something like this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1marx3v",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "True_Requirement_891",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1marx3v/how_can_we_simulate_gemini_deepthink_with_models/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1marx3v/how_can_we_simulate_gemini_deepthink_with_models/",
            "subreddit_subscribers": 505879,
            "created_utc": 1753636686,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5h0l17",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Eden63",
            "can_mod_post": false,
            "created_utc": 1753639744,
            "send_replies": true,
            "parent_id": "t3_1marx3v",
            "score": 1,
            "author_fullname": "t2_mhb0rkd4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Chaining..",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5h0l17",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Chaining..&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1marx3v/how_can_we_simulate_gemini_deepthink_with_models/n5h0l17/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753639744,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1marx3v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5huj35",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "offlinesir",
            "can_mod_post": false,
            "created_utc": 1753648832,
            "send_replies": true,
            "parent_id": "t3_1marx3v",
            "score": 1,
            "author_fullname": "t2_jn5ft2le",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Pretty sure it's Gemini 2.5 Pro with a higher thinking budget, while also being trained to think more (ex, trained on more thinking tokens, but it's impossible to know without Google telling us). It works the same for OpenAI's o4 mini and o4 mini high, o4 mini high just thinks for longer but can be considered the same model in a sense.\n\nIt's possible to chain multiple responses together but that may not work as well as the model won't be trained explicitly on stuff like that.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5huj35",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Pretty sure it&amp;#39;s Gemini 2.5 Pro with a higher thinking budget, while also being trained to think more (ex, trained on more thinking tokens, but it&amp;#39;s impossible to know without Google telling us). It works the same for OpenAI&amp;#39;s o4 mini and o4 mini high, o4 mini high just thinks for longer but can be considered the same model in a sense.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s possible to chain multiple responses together but that may not work as well as the model won&amp;#39;t be trained explicitly on stuff like that.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1marx3v/how_can_we_simulate_gemini_deepthink_with_models/n5huj35/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753648832,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1marx3v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5i9k4p",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ObnoxiouslyVivid",
            "can_mod_post": false,
            "created_utc": 1753653549,
            "send_replies": true,
            "parent_id": "t3_1marx3v",
            "score": 2,
            "author_fullname": "t2_n80ogax",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Start by reading on how to make a multi-agent research process, then apply it to other models.\n\nA good example is [How we built our multi-agent research system \\\\ Anthropic](https://www.anthropic.com/engineering/built-multi-agent-research-system)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5i9k4p",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Start by reading on how to make a multi-agent research process, then apply it to other models.&lt;/p&gt;\n\n&lt;p&gt;A good example is &lt;a href=\"https://www.anthropic.com/engineering/built-multi-agent-research-system\"&gt;How we built our multi-agent research system \\ Anthropic&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1marx3v/how_can_we_simulate_gemini_deepthink_with_models/n5i9k4p/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753653549,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1marx3v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5larqx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Mkengine",
            "can_mod_post": false,
            "created_utc": 1753702524,
            "send_replies": true,
            "parent_id": "t3_1marx3v",
            "score": 1,
            "author_fullname": "t2_9p2xe",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "https://github.com/DavidZWZ/Awesome-Deep-Research",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5larqx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/DavidZWZ/Awesome-Deep-Research\"&gt;https://github.com/DavidZWZ/Awesome-Deep-Research&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1marx3v/how_can_we_simulate_gemini_deepthink_with_models/n5larqx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753702524,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1marx3v",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]