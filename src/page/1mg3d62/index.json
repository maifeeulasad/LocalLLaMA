[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "My own testing results are backed up by the private tests run on dubesor.de. Coder is significantly worse in coding related knowledge than Instruct. If Coder is fine tuned from Instruct, I can only surmise that the additional training on a plethora of programming languages and agentic abilities has resulted in a good dose of catastrophic forgetting.\n\nThe take away is that training data is king at these small model sizes, and that we need coders that are not overwhelmed in the attempt of making a generic Swiss Army knife for all programming use cases.\n\nWe need specialists for individual languages (or perhaps domains, such as web development). These should be at the Instruct level of general ability, with the added speciality of no negative consequence to the model.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Note to the Qwen team re. the new 30B A3B Coder and Instruct versions: Coder is lobotomized when compared to Instruct",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mg3d62",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.81,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 44,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1puly589vf",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 44,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754174302,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My own testing results are backed up by the private tests run on dubesor.de. Coder is significantly worse in coding related knowledge than Instruct. If Coder is fine tuned from Instruct, I can only surmise that the additional training on a plethora of programming languages and agentic abilities has resulted in a good dose of catastrophic forgetting.&lt;/p&gt;\n\n&lt;p&gt;The take away is that training data is king at these small model sizes, and that we need coders that are not overwhelmed in the attempt of making a generic Swiss Army knife for all programming use cases.&lt;/p&gt;\n\n&lt;p&gt;We need specialists for individual languages (or perhaps domains, such as web development). These should be at the Instruct level of general ability, with the added speciality of no negative consequence to the model.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mg3d62",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "jackdareel",
            "discussion_type": null,
            "num_comments": 27,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/",
            "subreddit_subscribers": 509291,
            "created_utc": 1754174302,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6m40hu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Lesser-than",
            "can_mod_post": false,
            "created_utc": 1754180230,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 32,
            "author_fullname": "t2_98d256k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "do you have any non private tests that you can share that show your findings?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6m40hu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;do you have any non private tests that you can share that show your findings?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6m40hu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754180230,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 32
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6n0jhb",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "plankalkul-z1",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6mxo74",
                                                              "score": 2,
                                                              "author_fullname": "t2_w73n3yrsx",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "That was quick! Thank you for taking the time to make the test *and* letting me know of the result.\n\n\nI guess I will have to try it myself... Was holding off because Qwen's HF page is full of warnings for us vLLM/SGLang users, but the hassle should be worth it in my case, as with fp8 version of Qwen 3 and 96Gb VRAM I should be able to use some serious context length.\n\n\nMy main takeaway from your findings is that Qwen 3 Coder is at least not terribly worse that Qwen 2.5, and long context and tool use should more than offset whatever relative weaknesses it might have.\n\n\nThanks again.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6n0jhb",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That was quick! Thank you for taking the time to make the test &lt;em&gt;and&lt;/em&gt; letting me know of the result.&lt;/p&gt;\n\n&lt;p&gt;I guess I will have to try it myself... Was holding off because Qwen&amp;#39;s HF page is full of warnings for us vLLM/SGLang users, but the hassle should be worth it in my case, as with fp8 version of Qwen 3 and 96Gb VRAM I should be able to use some serious context length.&lt;/p&gt;\n\n&lt;p&gt;My main takeaway from your findings is that Qwen 3 Coder is at least not terribly worse that Qwen 2.5, and long context and tool use should more than offset whatever relative weaknesses it might have.&lt;/p&gt;\n\n&lt;p&gt;Thanks again.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mg3d62",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6n0jhb/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754193067,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754193067,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6mxo74",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "DeProgrammer99",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6mugcc",
                                                    "score": 3,
                                                    "author_fullname": "t2_w4j8t",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Okay, here's the result for Qwen2.5-Coder-32B:\n\nIt produced *slightly* more code than Thinking, referenced 2 properties it didn't define, and once again made up textColor and textAlign attributes. It included a few constants and imports that it never used. So it did a lot better than Qwen3-30B-A3B-2507-Thinking, but it still only produced a bit more than half as much code as Qwen3-Coder-30B-A3B, so it *looks* like it made fewer mistakes.\n\nOf course, it took over 3x as long since I didn't use speculative decoding and it's a dense model.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6mxo74",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Okay, here&amp;#39;s the result for Qwen2.5-Coder-32B:&lt;/p&gt;\n\n&lt;p&gt;It produced &lt;em&gt;slightly&lt;/em&gt; more code than Thinking, referenced 2 properties it didn&amp;#39;t define, and once again made up textColor and textAlign attributes. It included a few constants and imports that it never used. So it did a lot better than Qwen3-30B-A3B-2507-Thinking, but it still only produced a bit more than half as much code as Qwen3-Coder-30B-A3B, so it &lt;em&gt;looks&lt;/em&gt; like it made fewer mistakes.&lt;/p&gt;\n\n&lt;p&gt;Of course, it took over 3x as long since I didn&amp;#39;t use speculative decoding and it&amp;#39;s a dense model.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mg3d62",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6mxo74/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754191816,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754191816,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6mugcc",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "plankalkul-z1",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6mt344",
                                          "score": 1,
                                          "author_fullname": "t2_w73n3yrsx",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I see, thanks for the clarification.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6mugcc",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I see, thanks for the clarification.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mg3d62",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6mugcc/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754190458,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754190458,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6mt344",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DeProgrammer99",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6msbjt",
                                "score": 2,
                                "author_fullname": "t2_w4j8t",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I meant \"didn't,\" as in it made no mistakes that Thinking did not *also* make.\n\nI haven't used Qwen 2.5 Coder recently. I'll go download the Q6\\_K version for a fairer comparison, as there's no Q6\\_K\\_XL and I only have Q4\\_K\\_M at the moment.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6mt344",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I meant &amp;quot;didn&amp;#39;t,&amp;quot; as in it made no mistakes that Thinking did not &lt;em&gt;also&lt;/em&gt; make.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t used Qwen 2.5 Coder recently. I&amp;#39;ll go download the Q6_K version for a fairer comparison, as there&amp;#39;s no Q6_K_XL and I only have Q4_K_M at the moment.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mg3d62",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6mt344/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754189891,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754189891,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6msbjt",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "plankalkul-z1",
                      "can_mod_post": false,
                      "created_utc": 1754189577,
                      "send_replies": true,
                      "parent_id": "t1_n6mgc05",
                      "score": 2,
                      "author_fullname": "t2_w73n3yrsx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for the info.\n\n\n&gt; nor did it make other obvious mistakes that Thinking didn't\n\n\nWas it supposed to be \"... that Thinking **did**\"?\n\n\nAlso, did you compare Qwen 3 Coder to Qwen 2.5 Coder? If so, any info on that would be appreciated.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6msbjt",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for the info.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;nor did it make other obvious mistakes that Thinking didn&amp;#39;t&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Was it supposed to be &amp;quot;... that Thinking &lt;strong&gt;did&lt;/strong&gt;&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;Also, did you compare Qwen 3 Coder to Qwen 2.5 Coder? If so, any info on that would be appreciated.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mg3d62",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6msbjt/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754189577,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6mgc05",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "DeProgrammer99",
            "can_mod_post": false,
            "created_utc": 1754184900,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 13,
            "author_fullname": "t2_w4j8t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I told the Thinking version and the Coder version both to generate an entire minigame in TypeScript in one shot based on a spec I've used a few times with Claude and such.\n\nThinking wrote a bit over *half* as much code and made mistakes like assuming fields exist that the spec didn't mention (e.g., color instead of the defined fallbackColor, adding fontSize and fontWeight, using strings in the integer position fields). It didn't use an incrementing variable for Y coordinates in a vertical layout, but hard-coded all the positions individually, unlike the spec. It included a one-liner description of the minigame instead of a \"how to play\" button like the spec indicated. It left out a mandatory (though short) method. It redefined the same property in an object multiple times, and it used nonexistent class properties--syntax errors.\n\nCoder did not make any of those mistakes aside from one nonexistent class property and assuming the existence of extra textSize and textColor fields, nor did it make other obvious mistakes that Thinking didn't. (I say \"obvious\" because I didn't actually execute the code from either. I just skimmed the total 1500 lines and focused on some parts that past models got wrong.)\n\nI compared both as Q6\\_K\\_XL quantizations with the same simple command line:\n\nVulkan\\\\llama-server -m \"Qwen3-30B-A3B-Thinking-2507-UD-Q6\\_K\\_XL.gguf\" -c 16384 --gpu-layers 99 --flash-attn\n\n(ETA a few mistakes I only spotted after pasting them both into Visual Studio.)",
            "edited": 1754185329,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6mgc05",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I told the Thinking version and the Coder version both to generate an entire minigame in TypeScript in one shot based on a spec I&amp;#39;ve used a few times with Claude and such.&lt;/p&gt;\n\n&lt;p&gt;Thinking wrote a bit over &lt;em&gt;half&lt;/em&gt; as much code and made mistakes like assuming fields exist that the spec didn&amp;#39;t mention (e.g., color instead of the defined fallbackColor, adding fontSize and fontWeight, using strings in the integer position fields). It didn&amp;#39;t use an incrementing variable for Y coordinates in a vertical layout, but hard-coded all the positions individually, unlike the spec. It included a one-liner description of the minigame instead of a &amp;quot;how to play&amp;quot; button like the spec indicated. It left out a mandatory (though short) method. It redefined the same property in an object multiple times, and it used nonexistent class properties--syntax errors.&lt;/p&gt;\n\n&lt;p&gt;Coder did not make any of those mistakes aside from one nonexistent class property and assuming the existence of extra textSize and textColor fields, nor did it make other obvious mistakes that Thinking didn&amp;#39;t. (I say &amp;quot;obvious&amp;quot; because I didn&amp;#39;t actually execute the code from either. I just skimmed the total 1500 lines and focused on some parts that past models got wrong.)&lt;/p&gt;\n\n&lt;p&gt;I compared both as Q6_K_XL quantizations with the same simple command line:&lt;/p&gt;\n\n&lt;p&gt;Vulkan\\llama-server -m &amp;quot;Qwen3-30B-A3B-Thinking-2507-UD-Q6_K_XL.gguf&amp;quot; -c 16384 --gpu-layers 99 --flash-attn&lt;/p&gt;\n\n&lt;p&gt;(ETA a few mistakes I only spotted after pasting them both into Visual Studio.)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6mgc05/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754184900,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 13
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6mwu1o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Federal-Effective879",
            "can_mod_post": false,
            "created_utc": 1754191462,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 10,
            "author_fullname": "t2_702zh1r2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It must vary depending on the task. For me, Qwen 3 Coder 30B-A3B has been excellent, and substantially better than the non-coder 2507 Instruct model. While the coder model’s general world knowledge is a lot worse as expected, its knowledge of language features, APIs, popular APIs, and behaviour of APIs is vastly superior to the non-coder for me. Coder has also done substantially better for me at generating working code and understanding large complex codebases.\n\nI’ve been using it for embedded C and Rust things, and some Python web service backend stuff.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6mwu1o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It must vary depending on the task. For me, Qwen 3 Coder 30B-A3B has been excellent, and substantially better than the non-coder 2507 Instruct model. While the coder model’s general world knowledge is a lot worse as expected, its knowledge of language features, APIs, popular APIs, and behaviour of APIs is vastly superior to the non-coder for me. Coder has also done substantially better for me at generating working code and understanding large complex codebases.&lt;/p&gt;\n\n&lt;p&gt;I’ve been using it for embedded C and Rust things, and some Python web service backend stuff.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6mwu1o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754191462,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6n8mpr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Highwaytothebeach",
            "can_mod_post": false,
            "created_utc": 1754196779,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 3,
            "author_fullname": "t2_1qychuraq9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "\"and that we need coders that are not overwhelmed in the attempt of making a generic Swiss Army knife for all programming use cases\".........?????\n\n\"We need specialists for individual languages.......\" ....??????\n\nWho's  we?\n\nI can bet Qwen will make about 300 or more  models for 300 different programming languages for free just at your request, and will keeping upgrading them forever....\n\nIn the meantime , I assume it is possible for everyone to instead running private test runs and complain just invest time or funds into fine tuning a superior model like 30B A3B Coder for a specific programming language, post it at hugging's  and do something good for open source community....",
            "edited": 1754199691,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6n8mpr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;and that we need coders that are not overwhelmed in the attempt of making a generic Swiss Army knife for all programming use cases&amp;quot;.........?????&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;We need specialists for individual languages.......&amp;quot; ....??????&lt;/p&gt;\n\n&lt;p&gt;Who&amp;#39;s  we?&lt;/p&gt;\n\n&lt;p&gt;I can bet Qwen will make about 300 or more  models for 300 different programming languages for free just at your request, and will keeping upgrading them forever....&lt;/p&gt;\n\n&lt;p&gt;In the meantime , I assume it is possible for everyone to instead running private test runs and complain just invest time or funds into fine tuning a superior model like 30B A3B Coder for a specific programming language, post it at hugging&amp;#39;s  and do something good for open source community....&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6n8mpr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754196779,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6n31ke",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Professional-Bear857",
            "can_mod_post": false,
            "created_utc": 1754194177,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 2,
            "author_fullname": "t2_yrl9ztfsa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Thinking definitely works better for coding than the coding model in my experience. Which maybe isn't surprising as the thinking models tend to outperform instruct versions.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6n31ke",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thinking definitely works better for coding than the coding model in my experience. Which maybe isn&amp;#39;t surprising as the thinking models tend to outperform instruct versions.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6n31ke/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754194177,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6nbulu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "boringcynicism",
            "can_mod_post": false,
            "created_utc": 1754198388,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 2,
            "author_fullname": "t2_1hz0lz0k5i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is visible in their own claimed aider results.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6nbulu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is visible in their own claimed aider results.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6nbulu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754198388,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6nyb5u",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "dreamai87",
            "can_mod_post": false,
            "created_utc": 1754211001,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 5,
            "author_fullname": "t2_q1q7nlxa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "First things first : it was your experience with a close project or data that you had. And you generalized the ability of the model based on your experiments, which included data and your prompt skills.\n\nSo I think, it’s not good to generalize just based on experiments, rather than testing on cases that you can share and the community can use to verify/concur your insights.\n\nPersonally, for me, it’s a great step up from previous models of this size. It generates good standalone apps along with nice designs. I found similarities in designs, like what Qwen 480 Coder generates.\n\nIt’s really good for writing Streamlit code, standalone HTML, and simple React apps (which I tried).\nIt works great with MCP , I tested it on LM Studio and its MCP, also worked great with Docker MCP and Continue.dev.\n\nIt has worked well with Rocode and Cline : sometimes it failed, but that’s okay.\n\nSo in my opinion, this is good when you use this model as a co-programmer, rather than just for vibe-coding, as it’s still a small model and holds limited knowledge compared to larger models.\n\nThanks 🙏",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6nyb5u",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;First things first : it was your experience with a close project or data that you had. And you generalized the ability of the model based on your experiments, which included data and your prompt skills.&lt;/p&gt;\n\n&lt;p&gt;So I think, it’s not good to generalize just based on experiments, rather than testing on cases that you can share and the community can use to verify/concur your insights.&lt;/p&gt;\n\n&lt;p&gt;Personally, for me, it’s a great step up from previous models of this size. It generates good standalone apps along with nice designs. I found similarities in designs, like what Qwen 480 Coder generates.&lt;/p&gt;\n\n&lt;p&gt;It’s really good for writing Streamlit code, standalone HTML, and simple React apps (which I tried).\nIt works great with MCP , I tested it on LM Studio and its MCP, also worked great with Docker MCP and Continue.dev.&lt;/p&gt;\n\n&lt;p&gt;It has worked well with Rocode and Cline : sometimes it failed, but that’s okay.&lt;/p&gt;\n\n&lt;p&gt;So in my opinion, this is good when you use this model as a co-programmer, rather than just for vibe-coding, as it’s still a small model and holds limited knowledge compared to larger models.&lt;/p&gt;\n\n&lt;p&gt;Thanks 🙏&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6nyb5u/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754211001,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6obgq9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "vibjelo",
            "can_mod_post": false,
            "created_utc": 1754218683,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 2,
            "author_fullname": "t2_hr2hgnsk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt; Coder is significantly worse in coding related knowledge than Instruct\n\nI think that makes sense? Coder isn't for knowledge, but a \"editing\" model, it's supposed to be good at producing code, but not much more than that. If you need knowledge somewhere in the pipeline, you'd use another model, then make it leverage tools to actually edit code, and that specific part would be where `coder` should be used.\n\nAt least that's how I understand what I've read about it so far.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6obgq9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Coder is significantly worse in coding related knowledge than Instruct&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I think that makes sense? Coder isn&amp;#39;t for knowledge, but a &amp;quot;editing&amp;quot; model, it&amp;#39;s supposed to be good at producing code, but not much more than that. If you need knowledge somewhere in the pipeline, you&amp;#39;d use another model, then make it leverage tools to actually edit code, and that specific part would be where &lt;code&gt;coder&lt;/code&gt; should be used.&lt;/p&gt;\n\n&lt;p&gt;At least that&amp;#39;s how I understand what I&amp;#39;ve read about it so far.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6obgq9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754218683,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6lqyd7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "cvjcvj2",
            "can_mod_post": false,
            "created_utc": 1754175540,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 1,
            "author_fullname": "t2_1775qw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I agree.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6lqyd7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6lqyd7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754175540,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6odsme",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "olympics2022wins",
            "can_mod_post": false,
            "created_utc": 1754219866,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 1,
            "author_fullname": "t2_i6kuh6b9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I wound up with it failing at building json objects whereas the non coder one did them in one shot. I thought it was mildly amusing as I group json with coding but not this time.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6odsme",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I wound up with it failing at building json objects whereas the non coder one did them in one shot. I thought it was mildly amusing as I group json with coding but not this time.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6odsme/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754219866,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6m1spb",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "ThinkExtension2328",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6ly2yf",
                                          "score": 1,
                                          "author_fullname": "t2_8eneodlk",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Hmmmmmmmmmm I need to try this because I do see your point there.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6m1spb",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "e": "text",
                                              "t": "llama.cpp"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hmmmmmmmmmm I need to try this because I do see your point there.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mg3d62",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "light",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6m1spb/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754179400,
                                          "author_flair_text": "llama.cpp",
                                          "treatment_tags": [],
                                          "created_utc": 1754179400,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "#bbbdbf",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6md4qw",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Glittering-Call8746",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6ly2yf",
                                          "score": 1,
                                          "author_fullname": "t2_tqwl6sawb",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "So which speculative model to which generative model..",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6md4qw",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So which speculative model to which generative model..&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mg3d62",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6md4qw/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754183697,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754183697,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6muae1",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "InsideYork",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6ly2yf",
                                          "score": 1,
                                          "author_fullname": "t2_12s3hn4y0b",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Thanks for this tip. What do you think is typically a good model to run speculative? Smaller with what quants?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6muae1",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for this tip. What do you think is typically a good model to run speculative? Smaller with what quants?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mg3d62",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6muae1/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754190388,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754190388,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6ly2yf",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "tomz17",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6lw3do",
                                "score": 7,
                                "author_fullname": "t2_1mhx5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; often is slower than just running the model it self.\n\nNot on coding models (where the hit rate is typically very high).  Getting proper speculative decoding running on 2.5coder nearly doubled my token generation speeds.  You just need hardware where the decode is far faster than the generation (e.g. gpu's with tensor units)",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6ly2yf",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;often is slower than just running the model it self.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Not on coding models (where the hit rate is typically very high).  Getting proper speculative decoding running on 2.5coder nearly doubled my token generation speeds.  You just need hardware where the decode is far faster than the generation (e.g. gpu&amp;#39;s with tensor units)&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mg3d62",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6ly2yf/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754178061,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754178061,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 7
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6lw3do",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "ThinkExtension2328",
                      "can_mod_post": false,
                      "created_utc": 1754177363,
                      "send_replies": true,
                      "parent_id": "t1_n6lqwd2",
                      "score": 6,
                      "author_fullname": "t2_8eneodlk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes but spec dec only sounds good on paper , after testing allot of recent models it’s not worth it. It often is slower than just running the model it self.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6lw3do",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes but spec dec only sounds good on paper , after testing allot of recent models it’s not worth it. It often is slower than just running the model it self.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mg3d62",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6lw3do/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754177363,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6njp79",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "AppearanceHeavy6724",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6nerqi",
                                                    "score": 2,
                                                    "author_fullname": "t2_uz37qfx5",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "are you being serious?",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6njp79",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;are you being serious?&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mg3d62",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6njp79/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754202576,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754202576,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6nerqi",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Glittering-Call8746",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6n57kf",
                                          "score": -1,
                                          "author_fullname": "t2_tqwl6sawb",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Yes a smaller dense model will be good. How old is qwen3 4b though ?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6nerqi",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes a smaller dense model will be good. How old is qwen3 4b though ?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mg3d62",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6nerqi/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754199901,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754199901,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6n57kf",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "AppearanceHeavy6724",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6mnmsn",
                                "score": 1,
                                "author_fullname": "t2_uz37qfx5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "3b active, but a lot more attention weights in use, a3b is pretty heavy due to attention computation when context grows. So qwen3 4b is still faster than a3b.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6n57kf",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3b active, but a lot more attention weights in use, a3b is pretty heavy due to attention computation when context grows. So qwen3 4b is still faster than a3b.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mg3d62",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6n57kf/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754195165,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754195165,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6mnmsn",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "phoiboslykegenes",
                      "can_mod_post": false,
                      "created_utc": 1754187719,
                      "send_replies": true,
                      "parent_id": "t1_n6lqwd2",
                      "score": 2,
                      "author_fullname": "t2_g2m0c",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I’m not sure you’d see any tangible benefits since there’s only 3B parameters active. With Qwen2.5, I think I was using 3B draft for the 32B dense model, so 1/10 ratio. \nSmallest Qwen3 is 0.6B is quite dumb and not really worth it.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6mnmsn",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’m not sure you’d see any tangible benefits since there’s only 3B parameters active. With Qwen2.5, I think I was using 3B draft for the 32B dense model, so 1/10 ratio. \nSmallest Qwen3 is 0.6B is quite dumb and not really worth it.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mg3d62",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6mnmsn/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754187719,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6lqwd2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Glittering-Call8746",
            "can_mod_post": false,
            "created_utc": 1754175520,
            "send_replies": true,
            "parent_id": "t3_1mg3d62",
            "score": 1,
            "author_fullname": "t2_tqwl6sawb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Is there a way to use speculative decoding with qwen3 ?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6lqwd2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to use speculative decoding with qwen3 ?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg3d62/note_to_the_qwen_team_re_the_new_30b_a3b_coder/n6lqwd2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754175520,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg3d62",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]