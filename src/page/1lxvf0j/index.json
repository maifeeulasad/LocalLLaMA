[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "### Background &amp; Brief Setup\nWe need a robust intent/sentiment classification and RAG pipeline, for which we plan on using embeddings, for a latency sensitive consumer facing product. We are planning to deploy a small embedding model on a inference optimized GCE VM for the same. \n\nI am currently running TEI (by HuggingFace) using the official docker image from the repo for inference [output identical with vLLM and infinity-embed]. Using OpenAI python client [results are no different if I switch to direct http requests].\n\n**Model** : Qwen 3 Embeddings 0.6B [should not matter but _downloaded locally_]\n\nNot using any custom instructions or prompts with the embedding since we are creating clusters for our semantic search. We were earlier using BAAI/bge-m3 which was giving good results.\n\n### Problem\n \nLike I don't know how to put this, but the embeddings feel really.. 'bad'? Like same sentence with capitalization and without capitalization have a lower similarity score. Does not work with our existing query clusters which used to capture the intents and semantic meaning of each query quite well. Capitalization changes everything. Clustering followed by BAAI/bge-m3 used to give fantastic results. Qwen3 is routing plain wrong. I can't understand what am I doing wrong. The models are so high up on MTEB and seem to excel at all aspects so I am flabbergasted.\n\n### Questions\n\nIs there something obvious I am missing here?\n\nHas someone else faced similar issues with Qwen3 Embeddings?\n\nAre embeddings tuned for instructions fundamentally different from 'normal' embedding models in any way? \n\nAre there any embedding models less than 1B parameters, that are multilingual and not trained with anglosphere centric data, with demonstrated track record in semantic clustering, that I can use for semantic clustering?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Qwen 3 Embeddings 0.6B faring really poorly inspite of high score on benchmarks",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1lxvf0j",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.96,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 18,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_alrxvbt1",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 18,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1752308700,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h3&gt;Background &amp;amp; Brief Setup&lt;/h3&gt;\n\n&lt;p&gt;We need a robust intent/sentiment classification and RAG pipeline, for which we plan on using embeddings, for a latency sensitive consumer facing product. We are planning to deploy a small embedding model on a inference optimized GCE VM for the same. &lt;/p&gt;\n\n&lt;p&gt;I am currently running TEI (by HuggingFace) using the official docker image from the repo for inference [output identical with vLLM and infinity-embed]. Using OpenAI python client [results are no different if I switch to direct http requests].&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Model&lt;/strong&gt; : Qwen 3 Embeddings 0.6B [should not matter but &lt;em&gt;downloaded locally&lt;/em&gt;]&lt;/p&gt;\n\n&lt;p&gt;Not using any custom instructions or prompts with the embedding since we are creating clusters for our semantic search. We were earlier using BAAI/bge-m3 which was giving good results.&lt;/p&gt;\n\n&lt;h3&gt;Problem&lt;/h3&gt;\n\n&lt;p&gt;Like I don&amp;#39;t know how to put this, but the embeddings feel really.. &amp;#39;bad&amp;#39;? Like same sentence with capitalization and without capitalization have a lower similarity score. Does not work with our existing query clusters which used to capture the intents and semantic meaning of each query quite well. Capitalization changes everything. Clustering followed by BAAI/bge-m3 used to give fantastic results. Qwen3 is routing plain wrong. I can&amp;#39;t understand what am I doing wrong. The models are so high up on MTEB and seem to excel at all aspects so I am flabbergasted.&lt;/p&gt;\n\n&lt;h3&gt;Questions&lt;/h3&gt;\n\n&lt;p&gt;Is there something obvious I am missing here?&lt;/p&gt;\n\n&lt;p&gt;Has someone else faced similar issues with Qwen3 Embeddings?&lt;/p&gt;\n\n&lt;p&gt;Are embeddings tuned for instructions fundamentally different from &amp;#39;normal&amp;#39; embedding models in any way? &lt;/p&gt;\n\n&lt;p&gt;Are there any embedding models less than 1B parameters, that are multilingual and not trained with anglosphere centric data, with demonstrated track record in semantic clustering, that I can use for semantic clustering?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1lxvf0j",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "i4858i",
            "discussion_type": null,
            "num_comments": 10,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/",
            "subreddit_subscribers": 497824,
            "created_utc": 1752308700,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n2q41wv",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "uber-linny",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n2p6a80",
                                "score": 1,
                                "author_fullname": "t2_14166b",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "never realised what i was missing out on .... i compared :\n\n[https://huggingface.co/MesTruck/multilingual-e5-large-instruct-GGUF](https://huggingface.co/MesTruck/multilingual-e5-large-instruct-GGUF)\n\nwhich was next on the MTEB list because i was using 0.6B embed,,,, night and day difference... the things you learn hey !",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n2q41wv",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;never realised what i was missing out on .... i compared :&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/MesTruck/multilingual-e5-large-instruct-GGUF\"&gt;https://huggingface.co/MesTruck/multilingual-e5-large-instruct-GGUF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;which was next on the MTEB list because i was using 0.6B embed,,,, night and day difference... the things you learn hey !&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lxvf0j",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2q41wv/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752327001,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752327001,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n2p6a80",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "uber-linny",
                      "can_mod_post": false,
                      "created_utc": 1752310552,
                      "send_replies": true,
                      "parent_id": "t1_n2p53ko",
                      "score": 2,
                      "author_fullname": "t2_14166b",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks I'm interested... I'm using LM studio,But a absolute rookie at it. \n\nWhat embedding model does everyone suggest until this is merged ?\n\nMy setup interfaces to anythingllm",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n2p6a80",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks I&amp;#39;m interested... I&amp;#39;m using LM studio,But a absolute rookie at it. &lt;/p&gt;\n\n&lt;p&gt;What embedding model does everyone suggest until this is merged ?&lt;/p&gt;\n\n&lt;p&gt;My setup interfaces to anythingllm&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lxvf0j",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2p6a80/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752310552,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n2p53ko",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Chromix_",
            "can_mod_post": false,
            "created_utc": 1752309842,
            "send_replies": true,
            "parent_id": "t3_1lxvf0j",
            "score": 17,
            "author_fullname": "t2_k7w2h",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That's been discussed very recently. If you're using llama.cpp you need to include a patch that hasn't been merged yet. Aside from that it's important to prompt indexing, search and clustering correctly, with the correct settings as documented in their readme.\n\nSee these threads for further information:\n\n[https://www.reddit.com/r/LocalLLaMA/comments/1lt18hg/are\\_qwen3\\_embedding\\_gguf\\_faulty/](https://www.reddit.com/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/)\n\n[https://www.reddit.com/r/LocalLLaMA/comments/1lx66on/issues\\_with\\_qwen\\_3\\_embedding\\_models\\_4b\\_and\\_06b/](https://www.reddit.com/r/LocalLLaMA/comments/1lx66on/issues_with_qwen_3_embedding_models_4b_and_06b/)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2p53ko",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s been discussed very recently. If you&amp;#39;re using llama.cpp you need to include a patch that hasn&amp;#39;t been merged yet. Aside from that it&amp;#39;s important to prompt indexing, search and clustering correctly, with the correct settings as documented in their readme.&lt;/p&gt;\n\n&lt;p&gt;See these threads for further information:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1lt18hg/are_qwen3_embedding_gguf_faulty/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1lx66on/issues_with_qwen_3_embedding_models_4b_and_06b/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1lx66on/issues_with_qwen_3_embedding_models_4b_and_06b/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2p53ko/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752309842,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxvf0j",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 17
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2p45k2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "hapliniste",
            "can_mod_post": false,
            "created_utc": 1752309269,
            "send_replies": true,
            "parent_id": "t3_1lxvf0j",
            "score": 2,
            "author_fullname": "t2_fc7rd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm very interested as well because I planned on using it based on its rank in the leaderborard 😅",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2p45k2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m very interested as well because I planned on using it based on its rank in the leaderborard 😅&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2p45k2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752309269,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxvf0j",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n2pvci3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "__JockY__",
                      "can_mod_post": false,
                      "created_utc": 1752323667,
                      "send_replies": true,
                      "parent_id": "t1_n2pgoln",
                      "score": 1,
                      "author_fullname": "t2_qf8h7ka8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "May I offer a piece of unsolicited advice? Thanks.\n\n&lt;old_man_unsolicited_life_hacks&gt;\nWhen advising someone on any topic (assuming no interference from Messrs. Dunning and Kruger) your advice can be made more actionable - and therefore more useful - by including recommendations _on what to do instead_. \n\nConsider approaching it with a positive angle: “hey, head’s up: the official GGUFs are busted, make sure to use the &lt;notbusted&gt; ones instead”. \n\nThink of it this way: who do you go to for advice about tricky problems? The “try this” person or the “fuck that” person?\n\nFinally, to paraphrase Baz Luhrman: if you succeed at doing this, please tell me how.\n\n&lt;/old_man_unsolicited_life_hacks&gt;",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n2pvci3",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;May I offer a piece of unsolicited advice? Thanks.&lt;/p&gt;\n\n&lt;p&gt;&amp;lt;old_man_unsolicited_life_hacks&amp;gt;\nWhen advising someone on any topic (assuming no interference from Messrs. Dunning and Kruger) your advice can be made more actionable - and therefore more useful - by including recommendations &lt;em&gt;on what to do instead&lt;/em&gt;. &lt;/p&gt;\n\n&lt;p&gt;Consider approaching it with a positive angle: “hey, head’s up: the official GGUFs are busted, make sure to use the &amp;lt;notbusted&amp;gt; ones instead”. &lt;/p&gt;\n\n&lt;p&gt;Think of it this way: who do you go to for advice about tricky problems? The “try this” person or the “fuck that” person?&lt;/p&gt;\n\n&lt;p&gt;Finally, to paraphrase Baz Luhrman: if you succeed at doing this, please tell me how.&lt;/p&gt;\n\n&lt;p&gt;&amp;lt;/old_man_unsolicited_life_hacks&amp;gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lxvf0j",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2pvci3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752323667,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n2pgoln",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "terminoid_",
            "can_mod_post": false,
            "created_utc": 1752316765,
            "send_replies": true,
            "parent_id": "t3_1lxvf0j",
            "score": 3,
            "author_fullname": "t2_1iu07dnz2i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "you have to use the instruction format in the model card, otherwise performance drops a lot, you can't just use it like a normal embedding model.\n\nalso, don't use the official GGUFs, they're busted",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2pgoln",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;you have to use the instruction format in the model card, otherwise performance drops a lot, you can&amp;#39;t just use it like a normal embedding model.&lt;/p&gt;\n\n&lt;p&gt;also, don&amp;#39;t use the official GGUFs, they&amp;#39;re busted&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2pgoln/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752316765,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxvf0j",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2po7sn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "teamclouday",
            "can_mod_post": false,
            "created_utc": 1752320574,
            "send_replies": true,
            "parent_id": "t3_1lxvf0j",
            "score": 1,
            "author_fullname": "t2_210m41fn",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Have you tested the same inputs with sentence transformers? Check out this issue: [https://github.com/huggingface/text-embeddings-inference/issues/668](https://github.com/huggingface/text-embeddings-inference/issues/668)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2po7sn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have you tested the same inputs with sentence transformers? Check out this issue: &lt;a href=\"https://github.com/huggingface/text-embeddings-inference/issues/668\"&gt;https://github.com/huggingface/text-embeddings-inference/issues/668&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2po7sn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752320574,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxvf0j",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2ps2ds",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AskAmbitious5697",
            "can_mod_post": false,
            "created_utc": 1752322293,
            "send_replies": true,
            "parent_id": "t3_1lxvf0j",
            "score": 1,
            "author_fullname": "t2_gm9w5nsf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Works good for me running with llama cpp, although texts are very simple… wierd\n\nEdit: GGUF that I used is 100% faulty, it’s not the same as using it with sentencetransformer.",
            "edited": 1752325703,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2ps2ds",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Works good for me running with llama cpp, although texts are very simple… wierd&lt;/p&gt;\n\n&lt;p&gt;Edit: GGUF that I used is 100% faulty, it’s not the same as using it with sentencetransformer.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2ps2ds/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752322293,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxvf0j",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2psut2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "__JockY__",
            "can_mod_post": false,
            "created_utc": 1752322630,
            "send_replies": true,
            "parent_id": "t3_1lxvf0j",
            "score": 1,
            "author_fullname": "t2_qf8h7ka8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Ah, what you need is `tolower(3)`.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2psut2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah, what you need is &lt;code&gt;tolower(3)&lt;/code&gt;.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2psut2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752322630,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxvf0j",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2q1bnn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "celsowm",
            "can_mod_post": false,
            "created_utc": 1752325986,
            "send_replies": true,
            "parent_id": "t3_1lxvf0j",
            "score": 1,
            "author_fullname": "t2_dyvrh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Not for me in pt-br texts using native transformers + fastapi",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2q1bnn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not for me in pt-br texts using native transformers + fastapi&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxvf0j/qwen_3_embeddings_06b_faring_really_poorly/n2q1bnn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752325986,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxvf0j",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]