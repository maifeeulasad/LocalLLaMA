[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I’m working on an AI project focused on trust, privacy, and symbolic interfaces. I’m looking for someone local to help either build or recommend a PC setup capable of running a local language model (LLM), and support configuring the assistant stack (LLM, memory, light UI).\n\nThe ideal person would be:\n\n* Technically strong with local LLM setups (e.g., Ollama, LLaMA.cpp, Whisper, LangChain)\n* Interested in privacy-first systems, personal infrastructure, or creative AI\n* Based in or near Manchester\n\nThis is a small, paid freelance task to begin with, but there's potential to collaborate further if we align. If you’re into self-hosting, AI, or future-facing tech, drop me a message.\n\nCheers!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Looking for a Manchester-based AI/dev builder to help set up a private assistant system",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1meww7m",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.4,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_9uzmxjrn",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754055897,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m working on an AI project focused on trust, privacy, and symbolic interfaces. I’m looking for someone local to help either build or recommend a PC setup capable of running a local language model (LLM), and support configuring the assistant stack (LLM, memory, light UI).&lt;/p&gt;\n\n&lt;p&gt;The ideal person would be:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Technically strong with local LLM setups (e.g., Ollama, LLaMA.cpp, Whisper, LangChain)&lt;/li&gt;\n&lt;li&gt;Interested in privacy-first systems, personal infrastructure, or creative AI&lt;/li&gt;\n&lt;li&gt;Based in or near Manchester&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This is a small, paid freelance task to begin with, but there&amp;#39;s potential to collaborate further if we align. If you’re into self-hosting, AI, or future-facing tech, drop me a message.&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1meww7m",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Sad_Werewolf_3854",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1meww7m/looking_for_a_manchesterbased_aidev_builder_to/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1meww7m/looking_for_a_manchesterbased_aidev_builder_to/",
            "subreddit_subscribers": 508541,
            "created_utc": 1754055897,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6d6fjc",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "BanaBreadSingularity",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6d4sgk",
                                "score": 1,
                                "author_fullname": "t2_11d4n76hca",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The entire RAM is shared between CPU/ GPU with appropriate bandwith making models with 64GB RAM and up quite viable.\n\nMac Studio would give you the added benefit that - potentially - you could daisy chain them and their bandwith is higher than MacBook Pros.  \n\nHonestly though, given the current state of where things are at, if you invest a day or two, you should have a pretty good direction of how to set things up. \n\nLLMStudio, Jan, Ollama, llama.cpp, Goose would all be tools I look into or search for on Youtube. \n\nYou can use public LLMs to help you in your understanding of the topic as well. \n\nSetup is one thing, maintenance is another. If you wanna own a good private system, it'll serve you very well to have some minimal knowledge of how to maintain it.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6d6fjc",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The entire RAM is shared between CPU/ GPU with appropriate bandwith making models with 64GB RAM and up quite viable.&lt;/p&gt;\n\n&lt;p&gt;Mac Studio would give you the added benefit that - potentially - you could daisy chain them and their bandwith is higher than MacBook Pros.  &lt;/p&gt;\n\n&lt;p&gt;Honestly though, given the current state of where things are at, if you invest a day or two, you should have a pretty good direction of how to set things up. &lt;/p&gt;\n\n&lt;p&gt;LLMStudio, Jan, Ollama, llama.cpp, Goose would all be tools I look into or search for on Youtube. &lt;/p&gt;\n\n&lt;p&gt;You can use public LLMs to help you in your understanding of the topic as well. &lt;/p&gt;\n\n&lt;p&gt;Setup is one thing, maintenance is another. If you wanna own a good private system, it&amp;#39;ll serve you very well to have some minimal knowledge of how to maintain it.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1meww7m",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1meww7m/looking_for_a_manchesterbased_aidev_builder_to/n6d6fjc/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754062095,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754062095,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6d4sgk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Sad_Werewolf_3854",
                      "can_mod_post": false,
                      "created_utc": 1754061623,
                      "send_replies": true,
                      "parent_id": "t1_n6d4krp",
                      "score": 0,
                      "author_fullname": "t2_9uzmxjrn",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Sorry full noob, \n\nWhy is a mac better?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6d4sgk",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sorry full noob, &lt;/p&gt;\n\n&lt;p&gt;Why is a mac better?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1meww7m",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1meww7m/looking_for_a_manchesterbased_aidev_builder_to/n6d4sgk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754061623,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6d4krp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "MHTMakerspace",
            "can_mod_post": false,
            "created_utc": 1754061561,
            "send_replies": true,
            "parent_id": "t3_1meww7m",
            "score": 0,
            "author_fullname": "t2_dv0swue7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "We're based in **a** Manchester, but I suspect not the one you are thinking of.\n\nYou might find it easier to just buy [an appropriate Mac](https://www.reddit.com/r/LocalLLM/comments/1gie5uq/advice_needed_choosing_the_right_macbook_pro/) than build a PC.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6d4krp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re based in &lt;strong&gt;a&lt;/strong&gt; Manchester, but I suspect not the one you are thinking of.&lt;/p&gt;\n\n&lt;p&gt;You might find it easier to just buy &lt;a href=\"https://www.reddit.com/r/LocalLLM/comments/1gie5uq/advice_needed_choosing_the_right_macbook_pro/\"&gt;an appropriate Mac&lt;/a&gt; than build a PC.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meww7m/looking_for_a_manchesterbased_aidev_builder_to/n6d4krp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754061561,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meww7m",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]