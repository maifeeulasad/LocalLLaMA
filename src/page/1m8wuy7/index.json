[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Greetings, we're a state-owned college, and we want to acquire an IA workstation. We have a strict budget and cannot surpass it, so working with our providers, they gave us two options with our budget\n\n  \n1. One Threadripper PRO 9955WX, with WS WRX90E-SAGE SE, 1 PRO 6000 Blackwell, and 256 GB RAM\n\n2. One AMD Ryzen 9 9950X with a ProArt X870E-CREATOR, 2 PRO 6000 Blackwells and 128 GB RAM\n\n  \nBoth models have a 1600W PSU. The idea on the first model is to try to get another budget the next year in order to buy a second PRO 6000 Blackwell.\n\nWe're not extremely concerned about RAM (we can buy RAM later using a different budget) but we're concerned that the Ryzen 9950X only has enough PCIE lanes to run the blackwell on PCIE x8, instead of x16. Our provider told us that this is not very important unless we want to load and unload models all the time, but we have some reservations about that. So, can you guide us a little on that?\n\nThanks a bunch  \n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "How important is to have PRO 6000 Blackwell running on 16 PCIE lanes?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": true,
            "name": "t3_1m8wuy7",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 1,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_lavl5",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753443620,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings, we&amp;#39;re a state-owned college, and we want to acquire an IA workstation. We have a strict budget and cannot surpass it, so working with our providers, they gave us two options with our budget&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;One Threadripper PRO 9955WX, with WS WRX90E-SAGE SE, 1 PRO 6000 Blackwell, and 256 GB RAM&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;One AMD Ryzen 9 9950X with a ProArt X870E-CREATOR, 2 PRO 6000 Blackwells and 128 GB RAM&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Both models have a 1600W PSU. The idea on the first model is to try to get another budget the next year in order to buy a second PRO 6000 Blackwell.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re not extremely concerned about RAM (we can buy RAM later using a different budget) but we&amp;#39;re concerned that the Ryzen 9950X only has enough PCIE lanes to run the blackwell on PCIE x8, instead of x16. Our provider told us that this is not very important unless we want to load and unload models all the time, but we have some reservations about that. So, can you guide us a little on that?&lt;/p&gt;\n\n&lt;p&gt;Thanks a bunch  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m8wuy7",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "ferkte",
            "discussion_type": null,
            "num_comments": 15,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/",
            "subreddit_subscribers": 504254,
            "created_utc": 1753443620,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n52lgnv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "TableSurface",
            "can_mod_post": false,
            "created_utc": 1753444953,
            "send_replies": true,
            "parent_id": "t3_1m8wuy7",
            "score": 4,
            "author_fullname": "t2_r5ot7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You should be more concerned about RAM, especially because of how MOE models work. The X870E platform only allows you a maximum of 256GB, while the Threadripper maxes out at 2TB.\n\n\nSince you're allowed to buy more RAM and can potentially buy more GPUs as early as next year, getting the Threadripper would be a more forward-compatible solution.\n\n\nThe consumer platform is more suited for budget constrained builds where you might only be able to buy hardware once every 5 years.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52lgnv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You should be more concerned about RAM, especially because of how MOE models work. The X870E platform only allows you a maximum of 256GB, while the Threadripper maxes out at 2TB.&lt;/p&gt;\n\n&lt;p&gt;Since you&amp;#39;re allowed to buy more RAM and can potentially buy more GPUs as early as next year, getting the Threadripper would be a more forward-compatible solution.&lt;/p&gt;\n\n&lt;p&gt;The consumer platform is more suited for budget constrained builds where you might only be able to buy hardware once every 5 years.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52lgnv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753444953,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8wuy7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n52og2o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "BrilliantAudience497",
            "can_mod_post": false,
            "created_utc": 1753446084,
            "send_replies": true,
            "parent_id": "t3_1m8wuy7",
            "score": 2,
            "author_fullname": "t2_1p34vnz066",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The vendor is mostly right, it doesn't matter too much if you're only doing things on a single GPU. It *will* have a bigger effect if you're planning to split a model either between cards or between a card and system ram, but its more on the order of a 5-10% performance hit, not half performance.\n\n\nWith that said, have 2x6000s is a way bigger boost than the 2x pcie lanes for performance. You'll be able to run bigger models and/or more models on that system, even if they get slowed down a bit by the pcie lanes.\n\n\nBeyond that, a single rtx 6000 pro should cost more than the non-gpu portion of that workstation. You'll get better performance today with the 2x6000 system, and if you decide you need the extra lanes next year it would be cheaper to replace motherboard/cpu/ram than buying a new 6000.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52og2o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The vendor is mostly right, it doesn&amp;#39;t matter too much if you&amp;#39;re only doing things on a single GPU. It &lt;em&gt;will&lt;/em&gt; have a bigger effect if you&amp;#39;re planning to split a model either between cards or between a card and system ram, but its more on the order of a 5-10% performance hit, not half performance.&lt;/p&gt;\n\n&lt;p&gt;With that said, have 2x6000s is a way bigger boost than the 2x pcie lanes for performance. You&amp;#39;ll be able to run bigger models and/or more models on that system, even if they get slowed down a bit by the pcie lanes.&lt;/p&gt;\n\n&lt;p&gt;Beyond that, a single rtx 6000 pro should cost more than the non-gpu portion of that workstation. You&amp;#39;ll get better performance today with the 2x6000 system, and if you decide you need the extra lanes next year it would be cheaper to replace motherboard/cpu/ram than buying a new 6000.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52og2o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753446084,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8wuy7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n52l0c0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "MaxKruse96",
            "can_mod_post": false,
            "created_utc": 1753444778,
            "send_replies": true,
            "parent_id": "t3_1m8wuy7",
            "score": 3,
            "author_fullname": "t2_pfi81",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "french spotted (noone says IA, its not intelligence artificielle, its Artificial Intelligence).\n\nThe load/unload aspect is valid. If you expect to scale to more than 2 GPUs, get the Threadripper. Otherwise, 2x x8 is fine for you.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52l0c0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;french spotted (noone says IA, its not intelligence artificielle, its Artificial Intelligence).&lt;/p&gt;\n\n&lt;p&gt;The load/unload aspect is valid. If you expect to scale to more than 2 GPUs, get the Threadripper. Otherwise, 2x x8 is fine for you.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52l0c0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753444778,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8wuy7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n52lo6v",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Defiant_Diet9085",
            "can_mod_post": false,
            "created_utc": 1753445034,
            "send_replies": true,
            "parent_id": "t3_1m8wuy7",
            "score": 1,
            "author_fullname": "t2_1airv0szt9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I suggest 5090 + 1TB RAM\n\nThis way you will be able to run any models that will be released in a year or two.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52lo6v",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I suggest 5090 + 1TB RAM&lt;/p&gt;\n\n&lt;p&gt;This way you will be able to run any models that will be released in a year or two.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52lo6v/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753445034,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8wuy7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n52m08f",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "BenniB99",
            "can_mod_post": false,
            "created_utc": 1753445165,
            "send_replies": true,
            "parent_id": "t3_1m8wuy7",
            "score": 1,
            "author_fullname": "t2_17xncyy5vl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Mhh this is tricky and depends largely on what exactly you are going to use this for.  \nThat being said more VRAM and GPU compute usually trumps everything else.\n\nI think having two GPUs running on PCIE 5.0 x8 (which is basically PCIE 4.0 x 16) is negligble, if you are splitting models across GPUs especially when running training workloads this might still become a bottleneck though.\n\nFor future upgrades the Threadripper + WRX90E-SAGE combo would definitely be better (adding more GPUs).\n\nI would say go for option 2., because you can not really beat 192GB VRAM.  \nPlus you can always buy a better motherboard and CPU with a potential budget the next year :D  \nAnd if you end up not getting that budget the GPUs might get you much further than a Threadripper with more RAM will (again this will depend on what you are planning to use this for primarily).\n\nTwo GPUs in the hand is worth one in the bush.",
            "edited": 1753445463,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52m08f",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mhh this is tricky and depends largely on what exactly you are going to use this for.&lt;br/&gt;\nThat being said more VRAM and GPU compute usually trumps everything else.&lt;/p&gt;\n\n&lt;p&gt;I think having two GPUs running on PCIE 5.0 x8 (which is basically PCIE 4.0 x 16) is negligble, if you are splitting models across GPUs especially when running training workloads this might still become a bottleneck though.&lt;/p&gt;\n\n&lt;p&gt;For future upgrades the Threadripper + WRX90E-SAGE combo would definitely be better (adding more GPUs).&lt;/p&gt;\n\n&lt;p&gt;I would say go for option 2., because you can not really beat 192GB VRAM.&lt;br/&gt;\nPlus you can always buy a better motherboard and CPU with a potential budget the next year :D&lt;br/&gt;\nAnd if you end up not getting that budget the GPUs might get you much further than a Threadripper with more RAM will (again this will depend on what you are planning to use this for primarily).&lt;/p&gt;\n\n&lt;p&gt;Two GPUs in the hand is worth one in the bush.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52m08f/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753445165,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8wuy7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n52mpw9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "TacGibs",
            "can_mod_post": false,
            "created_utc": 1753445436,
            "send_replies": true,
            "parent_id": "t3_1m8wuy7",
            "score": 1,
            "author_fullname": "t2_8w0y7ezw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Le chargement sera limité par la vitesse de ton support de stockage (je suppose que tu ne comptes pas stocker les modèles en RAMdisk), par conséquent il est plus intelligent de partir sur le Ryzen et de prendre une deuxième machine plus tard.\n\nL'avantage du Threadripper est d'avoir beaucoup plus de channels pour la RAM, et donc de pouvoir faire de l'offloading CPU (charger un modèle trop gros pour tenir uniquement sur la VRAM) en étant beaucoup moins pénalisé qu'avec le Ryzen, où tout offloading fera immédiatement chuter les performances de façon drastique.\n\nN'hésite pas à venir en MP, je serais content d'aider au bon emploi de l'argent public (pour une fois 😂).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52mpw9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Le chargement sera limité par la vitesse de ton support de stockage (je suppose que tu ne comptes pas stocker les modèles en RAMdisk), par conséquent il est plus intelligent de partir sur le Ryzen et de prendre une deuxième machine plus tard.&lt;/p&gt;\n\n&lt;p&gt;L&amp;#39;avantage du Threadripper est d&amp;#39;avoir beaucoup plus de channels pour la RAM, et donc de pouvoir faire de l&amp;#39;offloading CPU (charger un modèle trop gros pour tenir uniquement sur la VRAM) en étant beaucoup moins pénalisé qu&amp;#39;avec le Ryzen, où tout offloading fera immédiatement chuter les performances de façon drastique.&lt;/p&gt;\n\n&lt;p&gt;N&amp;#39;hésite pas à venir en MP, je serais content d&amp;#39;aider au bon emploi de l&amp;#39;argent public (pour une fois 😂).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52mpw9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753445436,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8wuy7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n52noju",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Goldandsilverape99",
            "can_mod_post": false,
            "created_utc": 1753445801,
            "send_replies": true,
            "parent_id": "t3_1m8wuy7",
            "score": 1,
            "author_fullname": "t2_l8tixwyg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have a 5090 and a 4080 super in the same system. Only using the 5090 i got 54t / sek for a 32B Q5 23 GB model for a particular prompt. Activating both GPU's i got 33.27 t/sek, loading the same model with \"split evenly\". The 4080 super is slower, so if feel like that is the limit and not the PCI express bus. My motherboard only support 8x for the 5090 and 4x for the 4080 super in multi gpu mode.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52noju",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have a 5090 and a 4080 super in the same system. Only using the 5090 i got 54t / sek for a 32B Q5 23 GB model for a particular prompt. Activating both GPU&amp;#39;s i got 33.27 t/sek, loading the same model with &amp;quot;split evenly&amp;quot;. The 4080 super is slower, so if feel like that is the limit and not the PCI express bus. My motherboard only support 8x for the 5090 and 4x for the 4080 super in multi gpu mode.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52noju/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753445801,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8wuy7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n52nt79",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DAlmighty",
            "can_mod_post": false,
            "created_utc": 1753445849,
            "send_replies": true,
            "parent_id": "t3_1m8wuy7",
            "score": 1,
            "author_fullname": "t2_a04uj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I’m kinda shocked no one actually has asked the most important question yet… what will this machine actually be doing? \n\nThe use case matters a lot. If you want to default to “everything” or “I don’t know” go with less GPU and more available PCIE lanes for future growth.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52nt79",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’m kinda shocked no one actually has asked the most important question yet… what will this machine actually be doing? &lt;/p&gt;\n\n&lt;p&gt;The use case matters a lot. If you want to default to “everything” or “I don’t know” go with less GPU and more available PCIE lanes for future growth.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52nt79/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753445849,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8wuy7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n52inn8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "ferkte",
                      "can_mod_post": false,
                      "created_utc": 1753443855,
                      "send_replies": true,
                      "parent_id": "t1_n52ifgt",
                      "score": 4,
                      "author_fullname": "t2_lavl5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Fair point, but we cannot hire consultants due to previous corruption issues on our government part",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n52inn8",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fair point, but we cannot hire consultants due to previous corruption issues on our government part&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8wuy7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52inn8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753443855,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n52k00d",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ShinyAnkleBalls",
                      "can_mod_post": false,
                      "created_utc": 1753444387,
                      "send_replies": true,
                      "parent_id": "t1_n52ifgt",
                      "score": 3,
                      "author_fullname": "t2_2m3au2xb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Not really how it works in non-ivy academic institutions.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n52k00d",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not really how it works in non-ivy academic institutions.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8wuy7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52k00d/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753444387,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n52l9nk",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "stonetriangles",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n52kfjj",
                                "score": 0,
                                "author_fullname": "t2_my6cw9iyo",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "if your organization has &gt;$1m in annual revenue, you don't qualify",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n52l9nk",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;if your organization has &amp;gt;$1m in annual revenue, you don&amp;#39;t qualify&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m8wuy7",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52l9nk/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753444877,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753444877,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n52kfjj",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "VihmaVillu",
                      "can_mod_post": false,
                      "created_utc": 1753444555,
                      "send_replies": true,
                      "parent_id": "t1_n52ifgt",
                      "score": 2,
                      "author_fullname": "t2_qrnpi",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "What's your cap limit for free reddit advice?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n52kfjj",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s your cap limit for free reddit advice?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8wuy7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52kfjj/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753444555,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "50c36eba-fdca-11ee-9735-92a88d7e3b87",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n52khb6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "maifee",
                      "can_mod_post": false,
                      "created_utc": 1753444574,
                      "send_replies": true,
                      "parent_id": "t1_n52ifgt",
                      "score": 1,
                      "author_fullname": "t2_1fuhylzi",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "At least they are being honest, let's appreciate that part.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n52khb6",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Ollama"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;At least they are being honest, let&amp;#39;s appreciate that part.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8wuy7",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52khb6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753444574,
                      "author_flair_text": "Ollama",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n52ifgt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "stonetriangles",
            "can_mod_post": false,
            "created_utc": 1753443764,
            "send_replies": true,
            "parent_id": "t3_1m8wuy7",
            "score": -4,
            "author_fullname": "t2_my6cw9iyo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So you have a $20k+ budget and you want advice for free? Hire a consultant.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52ifgt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So you have a $20k+ budget and you want advice for free? Hire a consultant.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8wuy7/how_important_is_to_have_pro_6000_blackwell/n52ifgt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753443764,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8wuy7",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -4
          }
        }
      ],
      "before": null
    }
  }
]