[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi, I know you are probably tired of seeing these posts, but I'd really appreciate the input\n\nCurrent GPU set up:  \n\\* gtx 1080ti (11Gb)  \n\\* gtx 1050ti (4Gb)  \n\\* pcie gen 3.0  \n\\* 16Gb DDR3 RAM  \n\\* Very old i5-4460 with 4 cores at 3.2GHz\n\nSo CPU inference is out of the question\n\nI want to upgrade it because the 1050ti isn't doing much work with only 4gb, and when it is, it's 2x slower, so most of the time its only the 1080ti.\n\nI don't have much money, so I was thinking of either:\n\n|Sell|Replace with|Total Cost|\n|:-|:-|:-|\n|1050ti|1080ti|$100|\n|1050ti|3060 (12Gb)|$150|\n|1050ti &amp; 1080ti|2x 3060 (12Gb)|$200|\n|1050ti|5060ti (16Gb)|$380|\n|1050ti &amp; 1080ti|2x 5060ti (16Gb)|$660|\n\nlmk if the table is confusing.\n\n  \nRight now I am leaning towards 2x 3060's, but idk if it will have less total compute than 2x 1080's, or if they will be nearly identical and if I am just wasting money there. I am also unsure about the advantages of newer hardware with the 50 series, and if its worth the $660 (wich is at the very outer edge of what I want to spend, so a $750-900 3090 is out of the question). Or maybe at the stage in life I am in, maybe it's just better for me to save the money, and upgrade a few years down the line.\n\nAlso I know from experience having two different GPU's doesn't work very well.\n\nI'd love to hear your thoughts!!!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "GPU Help (1080ti vs 3060 vs 5060ti)",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1map5pe",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.82,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 7,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_idqkwio0",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 7,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753630171,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I know you are probably tired of seeing these posts, but I&amp;#39;d really appreciate the input&lt;/p&gt;\n\n&lt;p&gt;Current GPU set up:&lt;br/&gt;\n* gtx 1080ti (11Gb)&lt;br/&gt;\n* gtx 1050ti (4Gb)&lt;br/&gt;\n* pcie gen 3.0&lt;br/&gt;\n* 16Gb DDR3 RAM&lt;br/&gt;\n* Very old i5-4460 with 4 cores at 3.2GHz&lt;/p&gt;\n\n&lt;p&gt;So CPU inference is out of the question&lt;/p&gt;\n\n&lt;p&gt;I want to upgrade it because the 1050ti isn&amp;#39;t doing much work with only 4gb, and when it is, it&amp;#39;s 2x slower, so most of the time its only the 1080ti.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have much money, so I was thinking of either:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Sell&lt;/th&gt;\n&lt;th align=\"left\"&gt;Replace with&lt;/th&gt;\n&lt;th align=\"left\"&gt;Total Cost&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1050ti&lt;/td&gt;\n&lt;td align=\"left\"&gt;1080ti&lt;/td&gt;\n&lt;td align=\"left\"&gt;$100&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1050ti&lt;/td&gt;\n&lt;td align=\"left\"&gt;3060 (12Gb)&lt;/td&gt;\n&lt;td align=\"left\"&gt;$150&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1050ti &amp;amp; 1080ti&lt;/td&gt;\n&lt;td align=\"left\"&gt;2x 3060 (12Gb)&lt;/td&gt;\n&lt;td align=\"left\"&gt;$200&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1050ti&lt;/td&gt;\n&lt;td align=\"left\"&gt;5060ti (16Gb)&lt;/td&gt;\n&lt;td align=\"left\"&gt;$380&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1050ti &amp;amp; 1080ti&lt;/td&gt;\n&lt;td align=\"left\"&gt;2x 5060ti (16Gb)&lt;/td&gt;\n&lt;td align=\"left\"&gt;$660&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;lmk if the table is confusing.&lt;/p&gt;\n\n&lt;p&gt;Right now I am leaning towards 2x 3060&amp;#39;s, but idk if it will have less total compute than 2x 1080&amp;#39;s, or if they will be nearly identical and if I am just wasting money there. I am also unsure about the advantages of newer hardware with the 50 series, and if its worth the $660 (wich is at the very outer edge of what I want to spend, so a $750-900 3090 is out of the question). Or maybe at the stage in life I am in, maybe it&amp;#39;s just better for me to save the money, and upgrade a few years down the line.&lt;/p&gt;\n\n&lt;p&gt;Also I know from experience having two different GPU&amp;#39;s doesn&amp;#39;t work very well.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your thoughts!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1map5pe",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Expensive-Apricot-25",
            "discussion_type": null,
            "num_comments": 23,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/",
            "subreddit_subscribers": 505617,
            "created_utc": 1753630171,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5hspd2",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "AdamDhahabi",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5ggf0b",
                                          "score": 2,
                                          "author_fullname": "t2_x5lnbc2",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Not true. Llama.cpp offloads some layers to CUDA0, other layers to CUDA1, both GPUs work as fast as they can so the fastest does not adjust its speed downwards.  \nAlso, do you know that the 1080 Ti has 34% more memory bandwidth compared to the 3060?\n\nAnd another note, let's say your model only uses 75% of all available VRAM, which sometimes can happen, then you can use the -ts flag to fully use CUDA0 its VRAM and as little as possible of CUDA1.  \nSoftware support for Pascal eventually will end but not in the short term. Ideally it has to be replaced of course, a good time to go for a second 5060 Ti if budget permits.",
                                          "edited": 1753648593,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5hspd2",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not true. Llama.cpp offloads some layers to CUDA0, other layers to CUDA1, both GPUs work as fast as they can so the fastest does not adjust its speed downwards.&lt;br/&gt;\nAlso, do you know that the 1080 Ti has 34% more memory bandwidth compared to the 3060?&lt;/p&gt;\n\n&lt;p&gt;And another note, let&amp;#39;s say your model only uses 75% of all available VRAM, which sometimes can happen, then you can use the -ts flag to fully use CUDA0 its VRAM and as little as possible of CUDA1.&lt;br/&gt;\nSoftware support for Pascal eventually will end but not in the short term. Ideally it has to be replaced of course, a good time to go for a second 5060 Ti if budget permits.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1map5pe",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5hspd2/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753648279,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753648279,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ggf0b",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "zipperlein",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5gel2y",
                                "score": 2,
                                "author_fullname": "t2_x3duw",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "3060 could be a bottleneck because of the memory bandwith. 1080 ti will limit the setup in terms of software support because of the older cuda compute compability.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ggf0b",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3060 could be a bottleneck because of the memory bandwith. 1080 ti will limit the setup in terms of software support because of the older cuda compute compability.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1map5pe",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5ggf0b/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753633905,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753633905,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gel2y",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Expensive-Apricot-25",
                      "can_mod_post": false,
                      "created_utc": 1753633376,
                      "send_replies": true,
                      "parent_id": "t1_n5g8kf7",
                      "score": 2,
                      "author_fullname": "t2_idqkwio0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That's a good point.\n\nalso when using both the GPU's for the additional memory, would having the blackwell GPU over the 3060 improve the speed? like a 3060 &amp; 1080ti Vs 5060ti &amp; 1080ti, would there be a performance difference/uplift? or would both setups be limited by the 1080ti?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gel2y",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s a good point.&lt;/p&gt;\n\n&lt;p&gt;also when using both the GPU&amp;#39;s for the additional memory, would having the blackwell GPU over the 3060 improve the speed? like a 3060 &amp;amp; 1080ti Vs 5060ti &amp;amp; 1080ti, would there be a performance difference/uplift? or would both setups be limited by the 1080ti?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1map5pe",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5gel2y/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753633376,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g8kf7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "AdamDhahabi",
            "can_mod_post": false,
            "created_utc": 1753631599,
            "send_replies": true,
            "parent_id": "t3_1map5pe",
            "score": 4,
            "author_fullname": "t2_x5lnbc2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "5060 Ti + 1080 Ti will give you 27GB with speed faster than 2x 3060. So you'll have 3 extra GB VRAM and faster speed. A Blackwell GPU as your main GPU, that's win win, for KV cache handling and because of memory bandwidth.  \nAnd when ready, you can go for a swap of your 1080 Ti for a second 5060 Ti.",
            "edited": 1753631950,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g8kf7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;5060 Ti + 1080 Ti will give you 27GB with speed faster than 2x 3060. So you&amp;#39;ll have 3 extra GB VRAM and faster speed. A Blackwell GPU as your main GPU, that&amp;#39;s win win, for KV cache handling and because of memory bandwidth.&lt;br/&gt;\nAnd when ready, you can go for a swap of your 1080 Ti for a second 5060 Ti.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5g8kf7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753631599,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1map5pe",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5i6ap4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Expensive-Apricot-25",
                      "can_mod_post": false,
                      "created_utc": 1753652508,
                      "send_replies": true,
                      "parent_id": "t1_n5g5xgr",
                      "score": 1,
                      "author_fullname": "t2_idqkwio0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Oh nice! Have you tried a dual 3060 set up? how did that work out?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5i6ap4",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh nice! Have you tried a dual 3060 set up? how did that work out?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1map5pe",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5i6ap4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753652508,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g5xgr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Jatilq",
            "can_mod_post": false,
            "created_utc": 1753630824,
            "send_replies": true,
            "parent_id": "t3_1map5pe",
            "score": 2,
            "author_fullname": "t2_3txs3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I just got a 3060 12gb from r/hardwareswap for about 210. I already had one from trading an old card. This went into my old worstation T7910 2xCPU 256ram. Depending on your budget I would do the 3060s for 24GB VRAM. My main machine also has 24VRAM, but its AMD.",
            "edited": 1753640475,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g5xgr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I just got a 3060 12gb from &lt;a href=\"/r/hardwareswap\"&gt;r/hardwareswap&lt;/a&gt; for about 210. I already had one from trading an old card. This went into my old worstation T7910 2xCPU 256ram. Depending on your budget I would do the 3060s for 24GB VRAM. My main machine also has 24VRAM, but its AMD.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5g5xgr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753630824,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1map5pe",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5gd3ji",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "duyntnet",
            "can_mod_post": false,
            "created_utc": 1753632940,
            "send_replies": true,
            "parent_id": "t3_1map5pe",
            "score": 2,
            "author_fullname": "t2_4d4pk3c4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I would go with second option first to see if a 3060 is enough for your use case then continue from there.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gd3ji",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would go with second option first to see if a 3060 is enough for your use case then continue from there.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5gd3ji/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753632940,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1map5pe",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5i8vbc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Expensive-Apricot-25",
                      "can_mod_post": false,
                      "created_utc": 1753653328,
                      "send_replies": true,
                      "parent_id": "t1_n5gdsvz",
                      "score": 1,
                      "author_fullname": "t2_idqkwio0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "that is what I thought, however I read up on this benchmark someone ran were they tested 3060 vs 1080ti:\n\nhttps://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080\\_ti\\_vs\\_3060\\_12gb/#:\\~:text=So%2C%20based%20on%20this%20simple,card%20for%20running%20LLMs%20locally.\n\nthe 3060 was actually 30% faster than the 1080ti, I think it might be because of the additional tensor cores, or newer memory.\n\nI don't think I'll be able to easily afford the last option or the 3090's price range for another few years, still considering it, but right now i'm leaning towards the 2x3060's and holding out for another 2-3 years b4 upgrading to more serious hardware when i can more easily afford it.\n\nthanks for the feedback! super helpful and I really appreciate it",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5i8vbc",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;that is what I thought, however I read up on this benchmark someone ran were they tested 3060 vs 1080ti:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080%5C_ti%5C_vs%5C_3060%5C_12gb/#:%5C%7E:text=So%2C%20based%20on%20this%20simple,card%20for%20running%20LLMs%20locally\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080\\_ti\\_vs\\_3060\\_12gb/#:\\~:text=So%2C%20based%20on%20this%20simple,card%20for%20running%20LLMs%20locally&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;the 3060 was actually 30% faster than the 1080ti, I think it might be because of the additional tensor cores, or newer memory.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think I&amp;#39;ll be able to easily afford the last option or the 3090&amp;#39;s price range for another few years, still considering it, but right now i&amp;#39;m leaning towards the 2x3060&amp;#39;s and holding out for another 2-3 years b4 upgrading to more serious hardware when i can more easily afford it.&lt;/p&gt;\n\n&lt;p&gt;thanks for the feedback! super helpful and I really appreciate it&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1map5pe",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5i8vbc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753653328,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5gdsvz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Cergorach",
            "can_mod_post": false,
            "created_utc": 1753633147,
            "send_replies": true,
            "parent_id": "t3_1map5pe",
            "score": 2,
            "author_fullname": "t2_cs4w88d2l",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "A 3060 is about 25% slower then a 1080 ti in inference (memory bandwidth).\n\nA 1050 ti isbout 75% slower then a 1080 ti in inference (memory bandwidth).\n\nA 5060 ti is almost as fast as a 1080 ti in inference (memory bandwidth).\n\nI'm seeing 3090 cards going as low as €675 (inc. VAT, is \\~$660 ex VAT). 1080 ti being sold for €150 (\\~$145). Sell the old cards, buy a cheap second hand 3090 (test before buying). This is probably your best option, almost twice as fast as your 1080 ti with 24GB on a single card, easier to use, faster, more efficient. And if you can't afford it now, safe a bit more. But I would sell either of your existing cards now, those will devalue over time even more. Don't know how you use your PC overal, but if you can miss the 1080 ti, that will net you the most bucks at the moment.\n\nIf this is money you can't miss, just wait until you can, and play around with LLM online (often for free).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gdsvz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A 3060 is about 25% slower then a 1080 ti in inference (memory bandwidth).&lt;/p&gt;\n\n&lt;p&gt;A 1050 ti isbout 75% slower then a 1080 ti in inference (memory bandwidth).&lt;/p&gt;\n\n&lt;p&gt;A 5060 ti is almost as fast as a 1080 ti in inference (memory bandwidth).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seeing 3090 cards going as low as €675 (inc. VAT, is ~$660 ex VAT). 1080 ti being sold for €150 (~$145). Sell the old cards, buy a cheap second hand 3090 (test before buying). This is probably your best option, almost twice as fast as your 1080 ti with 24GB on a single card, easier to use, faster, more efficient. And if you can&amp;#39;t afford it now, safe a bit more. But I would sell either of your existing cards now, those will devalue over time even more. Don&amp;#39;t know how you use your PC overal, but if you can miss the 1080 ti, that will net you the most bucks at the moment.&lt;/p&gt;\n\n&lt;p&gt;If this is money you can&amp;#39;t miss, just wait until you can, and play around with LLM online (often for free).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5gdsvz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753633147,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1map5pe",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5hg5rx",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "muxxington",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5gu3w5",
                                          "score": 1,
                                          "author_fullname": "t2_1ktdmsvo",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Damn, my fault. You are right. I remembered some PR but none of them was merged.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5hg5rx",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Damn, my fault. You are right. I remembered some PR but none of them was merged.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1map5pe",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5hg5rx/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753644437,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753644437,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5gu3w5",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "zipperlein",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5gslol",
                                "score": 1,
                                "author_fullname": "t2_x3duw",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "llama.cpp has no tensor-parallel. vllm fork for pascal is not maintained. New models may need new configurations. It can work, but it's a hassle.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5gu3w5",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;llama.cpp has no tensor-parallel. vllm fork for pascal is not maintained. New models may need new configurations. It can work, but it&amp;#39;s a hassle.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1map5pe",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5gu3w5/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753637870,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753637870,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gslol",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "muxxington",
                      "can_mod_post": false,
                      "created_utc": 1753637438,
                      "send_replies": true,
                      "parent_id": "t1_n5ge0u8",
                      "score": 1,
                      "author_fullname": "t2_1ktdmsvo",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Ollama not supporting tensor-parallelism on P40 is an Ollama issue, not a P40 issue. llama.cpp works fine with P40. Beside that a vLLM fork for pascal exists.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gslol",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ollama not supporting tensor-parallelism on P40 is an Ollama issue, not a P40 issue. llama.cpp works fine with P40. Beside that a vLLM fork for pascal exists.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1map5pe",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5gslol/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753637438,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5i9to1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Expensive-Apricot-25",
                      "can_mod_post": false,
                      "created_utc": 1753653635,
                      "send_replies": true,
                      "parent_id": "t1_n5ge0u8",
                      "score": 1,
                      "author_fullname": "t2_idqkwio0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah, that is one thing I was wondering myself, but I saw this post where they directly compared the two cards:\n\nhttps://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080\\_ti\\_vs\\_3060\\_12gb/#:\\~:text=So%2C%20based%20on%20this%20simple,card%20for%20running%20LLMs%20locally.\n\nThe 3060 ended up being 30% faster with token gen, and ever so slightly slower with PP speeds but basically the same. not sure why this is bc the 1080ti has quite a lot more bandwidth, might be the tensor cores, newer memory, or maybe newer software. but not entirely sure if that would hold up for a dual GPU set up.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5i9to1",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, that is one thing I was wondering myself, but I saw this post where they directly compared the two cards:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080%5C_ti%5C_vs%5C_3060%5C_12gb/#:%5C%7E:text=So%2C%20based%20on%20this%20simple,card%20for%20running%20LLMs%20locally\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1jb34lf/1080\\_ti\\_vs\\_3060\\_12gb/#:\\~:text=So%2C%20based%20on%20this%20simple,card%20for%20running%20LLMs%20locally&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The 3060 ended up being 30% faster with token gen, and ever so slightly slower with PP speeds but basically the same. not sure why this is bc the 1080ti has quite a lot more bandwidth, might be the tensor cores, newer memory, or maybe newer software. but not entirely sure if that would hold up for a dual GPU set up.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1map5pe",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5i9to1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753653635,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5ge0u8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "zipperlein",
            "can_mod_post": false,
            "created_utc": 1753633212,
            "send_replies": true,
            "parent_id": "t3_1map5pe",
            "score": 2,
            "author_fullname": "t2_x3duw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "3060 has less memory bandwith than a 1080 TI. (360 vs 484) I'd skip it. I had 2 P40 (basically a 1080 with 24GB VRAM) and the problem with multi-gpu setups on pascal is, that vllm for example does not really support it. Ollama did work fine, but u want tensor-parallel normally. No exp with AMD. Best call is probabbly just another 1080 for cheaps or replace both with 1 or 2x5060s. (can always later get a 2nd one) Another option may be, depending on used prices at your end, an 7900 xt. 7900 xt with 20GB has way more bandwith than a 5060 TI. (800 vs 448) With one GPU you can also just stick with GGUFs without leaving so much performance on the table.",
            "edited": 1753633436,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ge0u8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3060 has less memory bandwith than a 1080 TI. (360 vs 484) I&amp;#39;d skip it. I had 2 P40 (basically a 1080 with 24GB VRAM) and the problem with multi-gpu setups on pascal is, that vllm for example does not really support it. Ollama did work fine, but u want tensor-parallel normally. No exp with AMD. Best call is probabbly just another 1080 for cheaps or replace both with 1 or 2x5060s. (can always later get a 2nd one) Another option may be, depending on used prices at your end, an 7900 xt. 7900 xt with 20GB has way more bandwith than a 5060 TI. (800 vs 448) With one GPU you can also just stick with GGUFs without leaving so much performance on the table.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5ge0u8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753633212,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1map5pe",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5gixk7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AppearanceHeavy6724",
            "can_mod_post": false,
            "created_utc": 1753634633,
            "send_replies": true,
            "parent_id": "t3_1map5pe",
            "score": 2,
            "author_fullname": "t2_uz37qfx5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Forget about 1080ti - the support in CUDA will be dropped very soon, and it has no FP16 support, no flash attention,  therefore in reality, with growth of context it will be slower than 3060, also eats too much energy. The best combo imo sell your old crap and buy 5060ti+3060",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5gixk7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Forget about 1080ti - the support in CUDA will be dropped very soon, and it has no FP16 support, no flash attention,  therefore in reality, with growth of context it will be slower than 3060, also eats too much energy. The best combo imo sell your old crap and buy 5060ti+3060&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5gixk7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753634633,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1map5pe",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5h0any",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Roubbes",
            "can_mod_post": false,
            "created_utc": 1753639658,
            "send_replies": true,
            "parent_id": "t3_1map5pe",
            "score": 2,
            "author_fullname": "t2_aoir7erh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Dual undervolted 5060s Ti might be one of the best home setups per watt",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5h0any",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Dual undervolted 5060s Ti might be one of the best home setups per watt&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5h0any/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753639658,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1map5pe",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5g3xmk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Expensive-Apricot-25",
            "can_mod_post": false,
            "created_utc": 1753630225,
            "send_replies": true,
            "parent_id": "t3_1map5pe",
            "score": 1,
            "author_fullname": "t2_idqkwio0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Also, I can post some benchmarks (before or after upgrade) for anyone who wants them.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g3xmk",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Also, I can post some benchmarks (before or after upgrade) for anyone who wants them.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5g3xmk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753630225,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1map5pe",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5gdpyp",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Gold-Map161",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5gbwm8",
                                "score": 1,
                                "author_fullname": "t2_1rch6owlwb",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It depends on the size of the models you are planning to run.   \nIf you are not gettin terrible tps's with the models you are using, i dont think its wise to upgrade 15 gb vram to 16 gb single vram.  \nAlso for tps comparison, I have 2x 5060 ti right now, have used 5060 ti with 3060 before.   \n  \nIf you write down which models are you running right now, what tps you are getting and which models are you planning to run when you get 2x 5060 ti i can give you the approx. tps for 5060ti stack. So you can better compare what will you get.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5gdpyp",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It depends on the size of the models you are planning to run.&lt;br/&gt;\nIf you are not gettin terrible tps&amp;#39;s with the models you are using, i dont think its wise to upgrade 15 gb vram to 16 gb single vram.&lt;br/&gt;\nAlso for tps comparison, I have 2x 5060 ti right now, have used 5060 ti with 3060 before.   &lt;/p&gt;\n\n&lt;p&gt;If you write down which models are you running right now, what tps you are getting and which models are you planning to run when you get 2x 5060 ti i can give you the approx. tps for 5060ti stack. So you can better compare what will you get.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1map5pe",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5gdpyp/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753633123,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753633123,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5gbwm8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Expensive-Apricot-25",
                      "can_mod_post": false,
                      "created_utc": 1753632589,
                      "send_replies": true,
                      "parent_id": "t1_n5g7vko",
                      "score": 1,
                      "author_fullname": "t2_idqkwio0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah, I figured as much, blackwell is crazy, and surprisingly, 5060ti is actually in stock.\n\nHowever, I'm about to graduate from college and I don't have anything lined up yet, so its a little bit hard for me to justify the premium cost.\n\nMaybe I could consider selling both GPU's and replacing it with a single 5060ti and buying a second later down the line.\n\nThanks for the feedback, really appreciate it!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5gbwm8",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, I figured as much, blackwell is crazy, and surprisingly, 5060ti is actually in stock.&lt;/p&gt;\n\n&lt;p&gt;However, I&amp;#39;m about to graduate from college and I don&amp;#39;t have anything lined up yet, so its a little bit hard for me to justify the premium cost.&lt;/p&gt;\n\n&lt;p&gt;Maybe I could consider selling both GPU&amp;#39;s and replacing it with a single 5060ti and buying a second later down the line.&lt;/p&gt;\n\n&lt;p&gt;Thanks for the feedback, really appreciate it!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1map5pe",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5gbwm8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753632589,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5g7vko",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Gold-Map161",
            "can_mod_post": false,
            "created_utc": 1753631396,
            "send_replies": true,
            "parent_id": "t3_1map5pe",
            "score": 1,
            "author_fullname": "t2_1rch6owlwb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "get 2x 5060 ti. it has best bandwight amongts them.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5g7vko",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;get 2x 5060 ti. it has best bandwight amongts them.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1map5pe/gpu_help_1080ti_vs_3060_vs_5060ti/n5g7vko/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753631396,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1map5pe",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]