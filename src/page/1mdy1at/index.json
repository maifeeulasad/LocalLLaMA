[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi, it's Emre from the Jan team.\n\nJan v0.6.6 is out. Over the past few weeks we've ripped out Cortex, the backend layer on top of llama.cpp. It's finally gone, every local model now runs directly on llama.cpp.\n\nPlus, you can switch to any llama.cpp build under Settings, Model Providers, llama.cpp (see the video above).\n\nJan v0.6.6 Highlights:\n\n* Cortex is removed, local models now run on `llama.cpp`\n* Hugging Face is integrated in Model Providers. So you can paste your HF token and run models in the cloud via Jan\n* Jan Hub has been a bit updated for faster model search and less clutter when browsing models\n* Inline-image support from MCP servers: If an MCP server returns an image (e.g. web search MCP).\n   * It's an experimental feature, please activate Experimental Features in Settings to see MCP settings.\n* Plus, we've also fixed a bunch of bugs\n\nUpdate your Jan or download the latest here: [https://jan.ai/](https://jan.ai/)\n\nFull release notes are here: [https://github.com/menloresearch/jan/releases](https://github.com/menloresearch/jan/releases)\n\n**Quick notes:**\n\n1. We removed Cortex because it added an extra hop and maintenance overhead. Folding its logic into Jan cuts latency and makes future mobile / server work simpler.\n2.  Regarding bugs &amp; previous requests: I'll reply to earlier requests and reports in the previous comments later today.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Jan now runs fully on llama.cpp &amp; auto-updates the backend",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "News"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 111,
            "top_awarded_type": null,
            "hide_score": true,
            "name": "t3_1mdy1at",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.96,
            "author_flair_background_color": null,
            "ups": 68,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_g6cmmsdd",
            "secure_media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/6tdds5rcr6gf1/DASH_1080.mp4?source=fallback",
                "has_audio": false,
                "height": 1080,
                "width": 1356,
                "scrubber_media_url": "https://v.redd.it/6tdds5rcr6gf1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/6tdds5rcr6gf1/DASHPlaylist.mpd?a=1756556957%2CZTJjODI4ZDEwNzIyYmJkMDFhYzIzNWE0MGU0ZWUxY2Q0ZmJkYzMxYzUwMWI4ZDc4MzQyN2QyZDRlYTYzZjUxNQ%3D%3D&amp;v=1&amp;f=sd",
                "duration": 9,
                "hls_url": "https://v.redd.it/6tdds5rcr6gf1/HLSPlaylist.m3u8?a=1756556957%2COTMxNTQwYjQxOTRmNTM5Mjg1YzJlMjg0NTNmMGUwNTE3YzA3YTU3NDFkZDY0MTkzY2ViZDViM2JjMDYxNGYyYQ%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "News",
            "can_mod_post": false,
            "score": 68,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=140&amp;height=111&amp;crop=140:111,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=57743d41c68dc489572118ded5f1d929e7abeba3",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "hosted:video",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753958074,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "v.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, it&amp;#39;s Emre from the Jan team.&lt;/p&gt;\n\n&lt;p&gt;Jan v0.6.6 is out. Over the past few weeks we&amp;#39;ve ripped out Cortex, the backend layer on top of llama.cpp. It&amp;#39;s finally gone, every local model now runs directly on llama.cpp.&lt;/p&gt;\n\n&lt;p&gt;Plus, you can switch to any llama.cpp build under Settings, Model Providers, llama.cpp (see the video above).&lt;/p&gt;\n\n&lt;p&gt;Jan v0.6.6 Highlights:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Cortex is removed, local models now run on &lt;code&gt;llama.cpp&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Hugging Face is integrated in Model Providers. So you can paste your HF token and run models in the cloud via Jan&lt;/li&gt;\n&lt;li&gt;Jan Hub has been a bit updated for faster model search and less clutter when browsing models&lt;/li&gt;\n&lt;li&gt;Inline-image support from MCP servers: If an MCP server returns an image (e.g. web search MCP).\n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s an experimental feature, please activate Experimental Features in Settings to see MCP settings.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Plus, we&amp;#39;ve also fixed a bunch of bugs&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Update your Jan or download the latest here: &lt;a href=\"https://jan.ai/\"&gt;https://jan.ai/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Full release notes are here: &lt;a href=\"https://github.com/menloresearch/jan/releases\"&gt;https://github.com/menloresearch/jan/releases&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick notes:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;We removed Cortex because it added an extra hop and maintenance overhead. Folding its logic into Jan cuts latency and makes future mobile / server work simpler.&lt;/li&gt;\n&lt;li&gt; Regarding bugs &amp;amp; previous requests: I&amp;#39;ll reply to earlier requests and reports in the previous comments later today.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://v.redd.it/6tdds5rcr6gf1",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?format=pjpg&amp;auto=webp&amp;s=0e1c5efd621cd98139d0e6f762c83f3c37e7fea5",
                    "width": 1356,
                    "height": 1080
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f859c3bb7426a18c330ce87e3736a28dafc099f8",
                      "width": 108,
                      "height": 86
                    },
                    {
                      "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=6cb9d82211a044a07e0f4b70dfed27d01999f9f4",
                      "width": 216,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=c95516a9359bd83519226daa998fe6d691200ba6",
                      "width": 320,
                      "height": 254
                    },
                    {
                      "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=00d6e43fd5842c4ff17dcac2371f246a689ce076",
                      "width": 640,
                      "height": 509
                    },
                    {
                      "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=25d7157f5ce696d297059ecb73ed2080cffbd80c",
                      "width": 960,
                      "height": 764
                    },
                    {
                      "url": "https://external-preview.redd.it/OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb.png?width=1080&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=79790394777eecaa52d5cec4ae8f93b678e4a94d",
                      "width": 1080,
                      "height": 860
                    }
                  ],
                  "variants": {},
                  "id": "OThqM3A3cmNyNmdmMarVaHVhDy4CK4NoO0kgn6HbxLEdRYxLZuUtk8wS5NEb"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#cc3600",
            "id": "1mdy1at",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "eck72",
            "discussion_type": null,
            "num_comments": 17,
            "send_replies": true,
            "media": {
              "reddit_video": {
                "bitrate_kbps": 5000,
                "fallback_url": "https://v.redd.it/6tdds5rcr6gf1/DASH_1080.mp4?source=fallback",
                "has_audio": false,
                "height": 1080,
                "width": 1356,
                "scrubber_media_url": "https://v.redd.it/6tdds5rcr6gf1/DASH_96.mp4",
                "dash_url": "https://v.redd.it/6tdds5rcr6gf1/DASHPlaylist.mpd?a=1756556957%2CZTJjODI4ZDEwNzIyYmJkMDFhYzIzNWE0MGU0ZWUxY2Q0ZmJkYzMxYzUwMWI4ZDc4MzQyN2QyZDRlYTYzZjUxNQ%3D%3D&amp;v=1&amp;f=sd",
                "duration": 9,
                "hls_url": "https://v.redd.it/6tdds5rcr6gf1/HLSPlaylist.m3u8?a=1756556957%2COTMxNTQwYjQxOTRmNTM5Mjg1YzJlMjg0NTNmMGUwNTE3YzA3YTU3NDFkZDY0MTkzY2ViZDViM2JjMDYxNGYyYQ%3D%3D&amp;v=1&amp;f=sd",
                "is_gif": false,
                "transcoding_status": "completed"
              }
            },
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/",
            "stickied": false,
            "url": "https://v.redd.it/6tdds5rcr6gf1",
            "subreddit_subscribers": 507576,
            "created_utc": 1753958074,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": true
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n654dzs",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Several-Confusion673",
            "can_mod_post": false,
            "created_utc": 1753958775,
            "send_replies": true,
            "parent_id": "t3_1mdy1at",
            "score": 14,
            "author_fullname": "t2_1pffwbrr2k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That's very nice and adds day-0 support for freshly merged models into llama.cpp in Jan ! Thank you for this ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n654dzs",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s very nice and adds day-0 support for freshly merged models into llama.cpp in Jan ! Thank you for this &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n654dzs/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753958775,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdy1at",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 14
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n65fejw",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Secure_Reflection409",
                      "can_mod_post": false,
                      "created_utc": 1753963452,
                      "send_replies": true,
                      "parent_id": "t1_n65ezuu",
                      "score": 4,
                      "author_fullname": "t2_by77ogdhr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes, this is the killer feature all the slick frontends are missing.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n65fejw",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, this is the killer feature all the slick frontends are missing.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdy1at",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65fejw/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753963452,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n65ezuu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Lowkey_LokiSN",
            "can_mod_post": false,
            "created_utc": 1753963298,
            "send_replies": true,
            "parent_id": "t3_1mdy1at",
            "score": 5,
            "author_fullname": "t2_xg2jtdg74",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Unrelated: Does Jan allow selectively offloading model tensors to CPU? (For MoE models)  \nIf yes, I would migrate from LM Studio to Jan just for that!\n\nI just love the convenience of a GUI but I'm having to go raw llama.cpp just for this atm",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n65ezuu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Unrelated: Does Jan allow selectively offloading model tensors to CPU? (For MoE models)&lt;br/&gt;\nIf yes, I would migrate from LM Studio to Jan just for that!&lt;/p&gt;\n\n&lt;p&gt;I just love the convenience of a GUI but I&amp;#39;m having to go raw llama.cpp just for this atm&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65ezuu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753963298,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdy1at",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n65ct2i",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "No-Source-9920",
            "can_mod_post": false,
            "created_utc": 1753962449,
            "send_replies": true,
            "parent_id": "t3_1mdy1at",
            "score": 4,
            "author_fullname": "t2_1gew47j6vy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "oh my fucking god yes finally",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n65ct2i",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;oh my fucking god yes finally&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65ct2i/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753962449,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdy1at",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n65bz3e",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "__JockY__",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n65btc3",
                                "score": 3,
                                "author_fullname": "t2_qf8h7ka8",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Woohoo!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n65bz3e",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Woohoo!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mdy1at",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65bz3e/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753962109,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753962109,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n65btc3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "eck72",
                      "can_mod_post": false,
                      "created_utc": 1753962043,
                      "send_replies": true,
                      "parent_id": "t1_n658of8",
                      "score": 7,
                      "author_fullname": "t2_g6cmmsdd",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks! This update sets things up for multimodal. It's planned for the next release, but might land in the one after.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n65btc3",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks! This update sets things up for multimodal. It&amp;#39;s planned for the next release, but might land in the one after.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdy1at",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65btc3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753962043,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n658of8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "__JockY__",
            "can_mod_post": false,
            "created_utc": 1753960714,
            "send_replies": true,
            "parent_id": "t3_1mdy1at",
            "score": 3,
            "author_fullname": "t2_qf8h7ka8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Great stuff!\n\n Now… ahem… wen eta multimodal?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n658of8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great stuff!&lt;/p&gt;\n\n&lt;p&gt;Now… ahem… wen eta multimodal?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n658of8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753960714,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdy1at",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n65hpo0",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "No-Source-9920",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n65h3ga",
                                "score": 1,
                                "author_fullname": "t2_1gew47j6vy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Usually people that use local apps are more tech savvy and want to test the latest even if it breaks some things. I’d rather have the option to use a “Jan stable” version or the latest llama cpp release and I can judge for myself which one I want and if it breaks something for me",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n65hpo0",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Usually people that use local apps are more tech savvy and want to test the latest even if it breaks some things. I’d rather have the option to use a “Jan stable” version or the latest llama cpp release and I can judge for myself which one I want and if it breaks something for me&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mdy1at",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65hpo0/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753964304,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753964304,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n65h3ga",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "eck72",
                      "can_mod_post": false,
                      "created_utc": 1753964081,
                      "send_replies": true,
                      "parent_id": "t1_n65dpb8",
                      "score": 2,
                      "author_fullname": "t2_g6cmmsdd",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Ah, it's a bit tricky. We haven't updated to b6040 yet - we test every llama.cpp release before integrating it into Jan, since auto-releasing can easily break things. We'll test and add the latest soon. For future updates, we're building an auto-QA system to speed this up. + More on that in an upcoming blog post.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n65h3ga",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah, it&amp;#39;s a bit tricky. We haven&amp;#39;t updated to b6040 yet - we test every llama.cpp release before integrating it into Jan, since auto-releasing can easily break things. We&amp;#39;ll test and add the latest soon. For future updates, we&amp;#39;re building an auto-QA system to speed this up. + More on that in an upcoming blog post.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdy1at",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65h3ga/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753964081,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n65dpb8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No-Source-9920",
            "can_mod_post": false,
            "created_utc": 1753962805,
            "send_replies": true,
            "parent_id": "t3_1mdy1at",
            "score": 3,
            "author_fullname": "t2_1gew47j6vy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I see b5857 as the latest version on your app but the latest version is  b6040?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n65dpb8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I see b5857 as the latest version on your app but the latest version is  b6040?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65dpb8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753962805,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdy1at",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n659ug9",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Zestyclose_Yak_3174",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n656r64",
                                "score": 4,
                                "author_fullname": "t2_o0jgdhlij",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Well I'm glad the team changed direction. This more polished, cleaner, leaner, faster way of Jan development is bound to result in great progress!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n659ug9",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well I&amp;#39;m glad the team changed direction. This more polished, cleaner, leaner, faster way of Jan development is bound to result in great progress!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mdy1at",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n659ug9/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753961219,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753961219,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n656r64",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "eck72",
                      "can_mod_post": false,
                      "created_utc": 1753959858,
                      "send_replies": true,
                      "parent_id": "t1_n6565sw",
                      "score": 7,
                      "author_fullname": "t2_g6cmmsdd",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "We had different plans for Cortex, that's why we insisted on keeping it for a while, but maintaining it with the new plans became pretty tough. It just made more sense to support llama.cpp directly instead of going through an extra layer.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n656r64",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We had different plans for Cortex, that&amp;#39;s why we insisted on keeping it for a while, but maintaining it with the new plans became pretty tough. It just made more sense to support llama.cpp directly instead of going through an extra layer.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdy1at",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n656r64/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753959858,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6565sw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Zestyclose_Yak_3174",
            "can_mod_post": false,
            "created_utc": 1753959592,
            "send_replies": true,
            "parent_id": "t3_1mdy1at",
            "score": 5,
            "author_fullname": "t2_o0jgdhlij",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That's good news! Have been asking them for this for over two years",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6565sw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s good news! Have been asking them for this for over two years&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n6565sw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753959592,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdy1at",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n65e848",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "eck72",
                      "can_mod_post": false,
                      "created_utc": 1753963003,
                      "send_replies": true,
                      "parent_id": "t1_n657vkg",
                      "score": 1,
                      "author_fullname": "t2_g6cmmsdd",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Cortex was the engine behind Jan. It ran on llama.cpp and worked kind of like an alternative to Ollama. We used to update it whenever llama.cpp got updated. Since we've changed our plans, we removed it with Jan v0.6.6.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n65e848",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Cortex was the engine behind Jan. It ran on llama.cpp and worked kind of like an alternative to Ollama. We used to update it whenever llama.cpp got updated. Since we&amp;#39;ve changed our plans, we removed it with Jan v0.6.6.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdy1at",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65e848/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753963003,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n657vkg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GabryIta",
            "can_mod_post": false,
            "created_utc": 1753960360,
            "send_replies": true,
            "parent_id": "t3_1mdy1at",
            "score": 2,
            "author_fullname": "t2_pv1nb9469",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I always thought you had been using llama.cpp from the start! (What the heck is Cortex?)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n657vkg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I always thought you had been using llama.cpp from the start! (What the heck is Cortex?)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n657vkg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753960360,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdy1at",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n65jfhr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Available_Load_5334",
            "can_mod_post": false,
            "created_utc": 1753964916,
            "send_replies": true,
            "parent_id": "t3_1mdy1at",
            "score": 1,
            "author_fullname": "t2_oxguhk8bl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "the default settings froze my laptop and crashed some applications – since linux-vulkan-x64 was selected by default. after it gave me this error message: Failed to load llama-server: llamacpp error: Error: llama\\_model\\_load: error loading model: vk::Queue::submit: ErrorDeviceLost\n\nmanually switching to linux-avx-x64 fixed this issue. which i would have never came up with, have i not saw this post before updating.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n65jfhr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;the default settings froze my laptop and crashed some applications – since linux-vulkan-x64 was selected by default. after it gave me this error message: Failed to load llama-server: llamacpp error: Error: llama_model_load: error loading model: vk::Queue::submit: ErrorDeviceLost&lt;/p&gt;\n\n&lt;p&gt;manually switching to linux-avx-x64 fixed this issue. which i would have never came up with, have i not saw this post before updating.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdy1at/jan_now_runs_fully_on_llamacpp_autoupdates_the/n65jfhr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753964916,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdy1at",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]