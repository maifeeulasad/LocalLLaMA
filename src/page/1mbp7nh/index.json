[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I found a React SDK that turns LLM responses into interactive UIs rendered live, on the spot.\n\nIt uses the concept of \"Generative UI\" which allows the interface to assemble itself dynamically for each user. The system gathers context &amp; AI uses an existing library of UI elements (so it doesn't hallucinate).\n\nUnder the hood, it uses:\n\na) **C1 API**: OpenAI-compatible (same `endpoints/params`) backend that returns a JSON-based UI spec from any prompt.\n\nYou can call it with any OpenAI client (JS or Python SDK), just by pointing your `baseURL` to `https://api.thesys.dev/v1/embed`.\n\nIf you already have an LLM pipeline (chatbot/agent), you can take its output and pass it to C1 as a second step, just to generate a visual layout.\n\nb) **GenUI SDK** (frontend): framework that takes the spec and renders it using pre-built components.\n\nYou can then call `client.chat.completions.create({...})` with your messages. Using the special model name (such as `\"c1/anthropic/claude-sonnet-4/v-20250617\"`), the Thesys API will invoke the LLM and return a UI spec.\n\ndetailed writeup: [here](https://www.thesys.dev/blogs/how-to-build-generative-ui-applications)  \ndemos: [here](https://demo.thesys.dev/)  \ndocs: [here](https://docs.thesys.dev/welcome)\n\nThe concept seems very exciting to me but still I can understand the risks. What do you think?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Found a React SDK that turns LLM responses into real-time UI that adapts based on context",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mbp7nh",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.44,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1hro18widg",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753729565,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found a React SDK that turns LLM responses into interactive UIs rendered live, on the spot.&lt;/p&gt;\n\n&lt;p&gt;It uses the concept of &amp;quot;Generative UI&amp;quot; which allows the interface to assemble itself dynamically for each user. The system gathers context &amp;amp; AI uses an existing library of UI elements (so it doesn&amp;#39;t hallucinate).&lt;/p&gt;\n\n&lt;p&gt;Under the hood, it uses:&lt;/p&gt;\n\n&lt;p&gt;a) &lt;strong&gt;C1 API&lt;/strong&gt;: OpenAI-compatible (same &lt;code&gt;endpoints/params&lt;/code&gt;) backend that returns a JSON-based UI spec from any prompt.&lt;/p&gt;\n\n&lt;p&gt;You can call it with any OpenAI client (JS or Python SDK), just by pointing your &lt;code&gt;baseURL&lt;/code&gt; to &lt;code&gt;https://api.thesys.dev/v1/embed&lt;/code&gt;.&lt;/p&gt;\n\n&lt;p&gt;If you already have an LLM pipeline (chatbot/agent), you can take its output and pass it to C1 as a second step, just to generate a visual layout.&lt;/p&gt;\n\n&lt;p&gt;b) &lt;strong&gt;GenUI SDK&lt;/strong&gt; (frontend): framework that takes the spec and renders it using pre-built components.&lt;/p&gt;\n\n&lt;p&gt;You can then call &lt;code&gt;client.chat.completions.create({...})&lt;/code&gt; with your messages. Using the special model name (such as &lt;code&gt;&amp;quot;c1/anthropic/claude-sonnet-4/v-20250617&amp;quot;&lt;/code&gt;), the Thesys API will invoke the LLM and return a UI spec.&lt;/p&gt;\n\n&lt;p&gt;detailed writeup: &lt;a href=\"https://www.thesys.dev/blogs/how-to-build-generative-ui-applications\"&gt;here&lt;/a&gt;&lt;br/&gt;\ndemos: &lt;a href=\"https://demo.thesys.dev/\"&gt;here&lt;/a&gt;&lt;br/&gt;\ndocs: &lt;a href=\"https://docs.thesys.dev/welcome\"&gt;here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The concept seems very exciting to me but still I can understand the risks. What do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mbp7nh",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "anmolbaranwal",
            "discussion_type": null,
            "num_comments": 0,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mbp7nh/found_a_react_sdk_that_turns_llm_responses_into/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mbp7nh/found_a_react_sdk_that_turns_llm_responses_into/",
            "subreddit_subscribers": 506191,
            "created_utc": 1753729565,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [],
      "before": null
    }
  }
]