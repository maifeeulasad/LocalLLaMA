[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "In terms of minutes/hours or number of query/response?\n\nI'm averaging around 90 minutes on good days and 30 minutes on bad days.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "How much do you use your local model on average on a day?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": true,
            "name": "t3_1lxbynb",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.8,
            "author_flair_background_color": "#bbbdbf",
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "is_original_content": false,
            "author_fullname": "t2_ah13x",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1752252611,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In terms of minutes/hours or number of query/response?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m averaging around 90 minutes on good days and 30 minutes on bad days.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1lxbynb",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "segmond",
            "discussion_type": null,
            "num_comments": 7,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "light",
            "permalink": "/r/LocalLLaMA/comments/1lxbynb/how_much_do_you_use_your_local_model_on_average/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lxbynb/how_much_do_you_use_your_local_model_on_average/",
            "subreddit_subscribers": 497502,
            "created_utc": 1752252611,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n2l9ad3",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DinoAmino",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n2l3sk5",
                                "score": 1,
                                "author_fullname": "t2_j1v7f",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Ah, when you put it that way then ... I almost never use LLMs locally for anything but coding for work. Sometimes I'll use it for websearx as a stepping stone. I just don't trust their internal knowledge.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n2l9ad3",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah, when you put it that way then ... I almost never use LLMs locally for anything but coding for work. Sometimes I&amp;#39;ll use it for websearx as a stepping stone. I just don&amp;#39;t trust their internal knowledge.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lxbynb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lxbynb/how_much_do_you_use_your_local_model_on_average/n2l9ad3/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752256718,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752256718,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n2l3sk5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "segmond",
                      "can_mod_post": false,
                      "created_utc": 1752255204,
                      "send_replies": true,
                      "parent_id": "t1_n2l246b",
                      "score": 1,
                      "author_fullname": "t2_ah13x",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "wowzers, so I guess you are using it for work?  I'm more curious on the personal side of things outside of work, those using it at home or before/after work.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n2l3sk5",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;wowzers, so I guess you are using it for work?  I&amp;#39;m more curious on the personal side of things outside of work, those using it at home or before/after work.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lxbynb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lxbynb/how_much_do_you_use_your_local_model_on_average/n2l3sk5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752255204,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n2l246b",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Lissanro",
            "can_mod_post": false,
            "created_utc": 1752254743,
            "send_replies": true,
            "parent_id": "t3_1lxbynb",
            "score": 2,
            "author_fullname": "t2_fpfao9g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don't have long-term stats, but over the last few days, I am using R1 0528 (I am running IQ4\\_K\\_M quant using ik\\_llama.cpp) around 12-15 hours per day. When I need vision, I use Qwen2.5-VL 72B. On goods days that include overnight agentic tasks it may be over 20 hours/day. Not sure how many queries, today I am using Cline and it did many dozens of queries, but if counting only my prompts, it still more than a dozen today, and today is not even close to be over. I also use normal chat about just as much, it is often more efficient than Cline because I can precisely control context, but Cline is helpful when there are a bunch of small files to edit or create, or to bootstrap a project.",
            "edited": 1752255866,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2l246b",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t have long-term stats, but over the last few days, I am using R1 0528 (I am running IQ4_K_M quant using ik_llama.cpp) around 12-15 hours per day. When I need vision, I use Qwen2.5-VL 72B. On goods days that include overnight agentic tasks it may be over 20 hours/day. Not sure how many queries, today I am using Cline and it did many dozens of queries, but if counting only my prompts, it still more than a dozen today, and today is not even close to be over. I also use normal chat about just as much, it is often more efficient than Cline because I can precisely control context, but Cline is helpful when there are a bunch of small files to edit or create, or to bootstrap a project.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxbynb/how_much_do_you_use_your_local_model_on_average/n2l246b/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752254743,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxbynb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2l1fnw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Boricua-vet",
            "can_mod_post": false,
            "created_utc": 1752254556,
            "send_replies": true,
            "parent_id": "t3_1lxbynb",
            "score": 1,
            "author_fullname": "t2_vnvnb9oa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I use 4 LLM's primarily every single day, one fine tuned to control music assistant which I can ask it to play any artist, song or playlist on any speaker across the entire home or multiple speakers depending on how I form the request. The second one is my conversational LLM which is integrated into home assistant and it handles conversations and anything related to home assistant that assist would not be able to do. The third is a fine tuned vision fine tuned LLM that works with frigate that process all video feeds and provides context to snapshots and provides voice alerts on any room I am located using presence sensors and the fourth one is used for general code production, Yaml verification and correction.  I have a fifth one for Immich for processing images but that is all automated and I really have no interaction with it so it does not count.\n\nI would say 2 to 3 hours daily at a minimum between all models and on a very productive day 4 to 5 hours a day.\n\nMy conversational LLM, Music LLM and code production LLM are what I certainly use the most.\n\nIf you need to know the order of which I use the most,\n\n1- Conversational LLM as it handles my reminders, appointments and house automation's.\n\n2- Code LLM. no explanation needed here.\n\n3- LLM for music assistant, I use this a lot.\n\n4- Security Vision model.\n\nOrdered from most used to least.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2l1fnw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I use 4 LLM&amp;#39;s primarily every single day, one fine tuned to control music assistant which I can ask it to play any artist, song or playlist on any speaker across the entire home or multiple speakers depending on how I form the request. The second one is my conversational LLM which is integrated into home assistant and it handles conversations and anything related to home assistant that assist would not be able to do. The third is a fine tuned vision fine tuned LLM that works with frigate that process all video feeds and provides context to snapshots and provides voice alerts on any room I am located using presence sensors and the fourth one is used for general code production, Yaml verification and correction.  I have a fifth one for Immich for processing images but that is all automated and I really have no interaction with it so it does not count.&lt;/p&gt;\n\n&lt;p&gt;I would say 2 to 3 hours daily at a minimum between all models and on a very productive day 4 to 5 hours a day.&lt;/p&gt;\n\n&lt;p&gt;My conversational LLM, Music LLM and code production LLM are what I certainly use the most.&lt;/p&gt;\n\n&lt;p&gt;If you need to know the order of which I use the most,&lt;/p&gt;\n\n&lt;p&gt;1- Conversational LLM as it handles my reminders, appointments and house automation&amp;#39;s.&lt;/p&gt;\n\n&lt;p&gt;2- Code LLM. no explanation needed here.&lt;/p&gt;\n\n&lt;p&gt;3- LLM for music assistant, I use this a lot.&lt;/p&gt;\n\n&lt;p&gt;4- Security Vision model.&lt;/p&gt;\n\n&lt;p&gt;Ordered from most used to least.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxbynb/how_much_do_you_use_your_local_model_on_average/n2l1fnw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752254556,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxbynb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2l3lxk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Red_Redditor_Reddit",
            "can_mod_post": false,
            "created_utc": 1752255153,
            "send_replies": true,
            "parent_id": "t3_1lxbynb",
            "score": 1,
            "author_fullname": "t2_8eelmfjg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I use it to make engineering notes more presentable and clear.  I trained my LLM over a week or two to take chicken scratch or some recording and turn it into a clear and understandable report.  My computer is CPU only, so usually I will give it the crap report and come back after fifteen minutes when it's done.\n\nEdit: that's also just for work.  Sometimes when I'm at home, I'll have the LLM give me a summery and details of long texts like bills in congress.  The most recent example was the \"big beautiful bill\".  I was able to get a baseline idea of what was in the bill without having to spend hours or days reading it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2l3lxk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I use it to make engineering notes more presentable and clear.  I trained my LLM over a week or two to take chicken scratch or some recording and turn it into a clear and understandable report.  My computer is CPU only, so usually I will give it the crap report and come back after fifteen minutes when it&amp;#39;s done.&lt;/p&gt;\n\n&lt;p&gt;Edit: that&amp;#39;s also just for work.  Sometimes when I&amp;#39;m at home, I&amp;#39;ll have the LLM give me a summery and details of long texts like bills in congress.  The most recent example was the &amp;quot;big beautiful bill&amp;quot;.  I was able to get a baseline idea of what was in the bill without having to spend hours or days reading it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxbynb/how_much_do_you_use_your_local_model_on_average/n2l3lxk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752255153,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxbynb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "d2642412-d9ce-11ed-ae30-32b11309f5bd",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2l917z",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ortegaalfredo",
            "can_mod_post": false,
            "created_utc": 1752256647,
            "send_replies": true,
            "parent_id": "t3_1lxbynb",
            "score": 1,
            "author_fullname": "t2_g177e",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Just heated a whole room for 96 hours with qwen-235B at 150 tok/s",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2l917z",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Alpaca"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just heated a whole room for 96 hours with qwen-235B at 150 tok/s&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxbynb/how_much_do_you_use_your_local_model_on_average/n2l917z/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752256647,
            "author_flair_text": "Alpaca",
            "treatment_tags": [],
            "link_id": "t3_1lxbynb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bd9e9e",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]