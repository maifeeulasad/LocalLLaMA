[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I’ve been building an AI assistant (Caelum) that can control a system using natural language, but I didn’t want it running raw shell commands or hallucinating `subprocess` calls. That’s unreliable and messy, so I built a structured `do()` system with plugin routing, safety flags, and argument parsing. Each command is a plugin, and you can write one in like 10–15 lines of code. Plugins auto-register and are isolated, so there’s no hardcoded logic or brittle wrappers.\n\nRight now it supports 39 commands, all modular, and you can interact with it using structured phrases or natural language if you add a mapping layer. It’s async-friendly, works with local agents, and is designed to grow without becoming a spaghetti monster.\n\nI originally posted this in another thread and realized quickly that it was the wrong crowd. This isn’t a CLI enhancement. It’s a system automation backbone that gives LLMs a safe, predictable way to control the OS through plugins, not shell access.\n\nIf you’re working on local agents or LLM-powered tools and want something that bridges into actual system control without chaos, I’d be happy to talk more about how it works. \n\n[https://github.com/BlackBeardJW/caelum-sys](https://github.com/BlackBeardJW/caelum-sys)  \n[https://pypi.org/project/caelum-sys/](https://pypi.org/project/caelum-sys/)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Built a plugin-based system automation layer for LLMs, safe, modular, and dead simple to extend",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": true,
            "name": "t3_1lyuxj5",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 1,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_dhf7dmo0",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1752418915,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’ve been building an AI assistant (Caelum) that can control a system using natural language, but I didn’t want it running raw shell commands or hallucinating &lt;code&gt;subprocess&lt;/code&gt; calls. That’s unreliable and messy, so I built a structured &lt;code&gt;do()&lt;/code&gt; system with plugin routing, safety flags, and argument parsing. Each command is a plugin, and you can write one in like 10–15 lines of code. Plugins auto-register and are isolated, so there’s no hardcoded logic or brittle wrappers.&lt;/p&gt;\n\n&lt;p&gt;Right now it supports 39 commands, all modular, and you can interact with it using structured phrases or natural language if you add a mapping layer. It’s async-friendly, works with local agents, and is designed to grow without becoming a spaghetti monster.&lt;/p&gt;\n\n&lt;p&gt;I originally posted this in another thread and realized quickly that it was the wrong crowd. This isn’t a CLI enhancement. It’s a system automation backbone that gives LLMs a safe, predictable way to control the OS through plugins, not shell access.&lt;/p&gt;\n\n&lt;p&gt;If you’re working on local agents or LLM-powered tools and want something that bridges into actual system control without chaos, I’d be happy to talk more about how it works. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/BlackBeardJW/caelum-sys\"&gt;https://github.com/BlackBeardJW/caelum-sys&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://pypi.org/project/caelum-sys/\"&gt;https://pypi.org/project/caelum-sys/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/wGF2WkFacBqaY1u9I-h9qjml9wj3Hxc5p-hofX39V7U.png?auto=webp&amp;s=2a2a988a09da5bc5ad4f13e5a79bd3559c0d9808",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/wGF2WkFacBqaY1u9I-h9qjml9wj3Hxc5p-hofX39V7U.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=603529e7fcabe20144806792dd5e7c2476b13cfe",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/wGF2WkFacBqaY1u9I-h9qjml9wj3Hxc5p-hofX39V7U.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=64e3526af339fa9467fd5d5e7d75032005389d24",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/wGF2WkFacBqaY1u9I-h9qjml9wj3Hxc5p-hofX39V7U.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fb3942c412a45a44ec1098ffb7f97bab33ea85e4",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/wGF2WkFacBqaY1u9I-h9qjml9wj3Hxc5p-hofX39V7U.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=417f48a9f26f6fdf936c7f469c3797e861d17912",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/wGF2WkFacBqaY1u9I-h9qjml9wj3Hxc5p-hofX39V7U.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=de6ca03a4ece691622a59b07094afb40147cfb4a",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/wGF2WkFacBqaY1u9I-h9qjml9wj3Hxc5p-hofX39V7U.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d4bd124f47d49ba62d35cdffc6ded4e2d57584d7",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "wGF2WkFacBqaY1u9I-h9qjml9wj3Hxc5p-hofX39V7U"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1lyuxj5",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "BlackBeardJW",
            "discussion_type": null,
            "num_comments": 0,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lyuxj5/built_a_pluginbased_system_automation_layer_for/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lyuxj5/built_a_pluginbased_system_automation_layer_for/",
            "subreddit_subscribers": 498343,
            "created_utc": 1752418915,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [],
      "before": null
    }
  }
]