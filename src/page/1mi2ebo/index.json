[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "For a bit of context, I'm a software developer with 4 years of exp, in dotnet and I've worked with python as well. My goal is to hit the ground running by creating projects using LLMs, I feel like the way to learn is by doing the thing, but I'm a bit lost on probably getting started.\n\nFor the most part there seems to be a lot of snake oil content out there, the usual learn LLMs in 30 mins kinda of stuff, where all they \"teach\" you is to clone a git report and run ollama, **what I'm looking for is a hands on way to built actual projects with LLMs and then integrate newer tech like RAG, MCP etc etc.**\n\nI would really appreciate any books, videos lectures, series that you can recommend. I'm not looking for the academic side of this, honestly I don't know if it's worth spending all that time, learning how an LLMs is made when I can just start using it (please feel free to object to my ignorance here). I feel like this industry is moving at the speed of light with something new everyday.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "How does someone with programming exp get started with LLMs?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mi2ebo",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.6,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_eevwuk4z0",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754377801,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a bit of context, I&amp;#39;m a software developer with 4 years of exp, in dotnet and I&amp;#39;ve worked with python as well. My goal is to hit the ground running by creating projects using LLMs, I feel like the way to learn is by doing the thing, but I&amp;#39;m a bit lost on probably getting started.&lt;/p&gt;\n\n&lt;p&gt;For the most part there seems to be a lot of snake oil content out there, the usual learn LLMs in 30 mins kinda of stuff, where all they &amp;quot;teach&amp;quot; you is to clone a git report and run ollama, &lt;strong&gt;what I&amp;#39;m looking for is a hands on way to built actual projects with LLMs and then integrate newer tech like RAG, MCP etc etc.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I would really appreciate any books, videos lectures, series that you can recommend. I&amp;#39;m not looking for the academic side of this, honestly I don&amp;#39;t know if it&amp;#39;s worth spending all that time, learning how an LLMs is made when I can just start using it (please feel free to object to my ignorance here). I feel like this industry is moving at the speed of light with something new everyday.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mi2ebo",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "parleG_OP",
            "discussion_type": null,
            "num_comments": 11,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/",
            "subreddit_subscribers": 510540,
            "created_utc": 1754377801,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n70m2ae",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "anoni_nato",
            "can_mod_post": false,
            "created_utc": 1754380662,
            "send_replies": true,
            "parent_id": "t3_1mi2ebo",
            "score": 4,
            "author_fullname": "t2_9vj4tf6d",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Use an LLM to learn. Not kidding, use a free chatgpt account to explain what you want to learn, with which tools and it can create a plan.\n\nMy personal advice:  \n\\- Learn to run local models first, you don't want to face API pricing/restrictions for experimenting. Learn about system prompts, parameters like temperature/TopN/TopK/etc., prompt engineering, and so on.  \n\\- Program a simple query -&gt; response call using OpenAI-compatible API (it's a de-facto standard and most local libraries serve one). You can just use the OpenAI SDK for your language if you don't want to query directly the REST API.  \n\\- From here on you can explore more. A whole chat session (on streaming mode) so you learn how the flow goes, tool/function calls...  \n\\- Then you can move to agents, MCP, etc.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70m2ae",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Use an LLM to learn. Not kidding, use a free chatgpt account to explain what you want to learn, with which tools and it can create a plan.&lt;/p&gt;\n\n&lt;p&gt;My personal advice:&lt;br/&gt;\n- Learn to run local models first, you don&amp;#39;t want to face API pricing/restrictions for experimenting. Learn about system prompts, parameters like temperature/TopN/TopK/etc., prompt engineering, and so on.&lt;br/&gt;\n- Program a simple query -&amp;gt; response call using OpenAI-compatible API (it&amp;#39;s a de-facto standard and most local libraries serve one). You can just use the OpenAI SDK for your language if you don&amp;#39;t want to query directly the REST API.&lt;br/&gt;\n- From here on you can explore more. A whole chat session (on streaming mode) so you learn how the flow goes, tool/function calls...&lt;br/&gt;\n- Then you can move to agents, MCP, etc.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/n70m2ae/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754380662,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi2ebo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n70ibh9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "QFGTrialByFire",
            "can_mod_post": false,
            "created_utc": 1754378521,
            "send_replies": true,
            "parent_id": "t3_1mi2ebo",
            "score": 5,
            "author_fullname": "t2_1h4o7f23eh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The best way i've found is\n\n1. To try and run a model locally first - see how its loaded, how you send prompts to it. Teaches you about its structure/prompting/eos tokens etc. Just pick something small and try.\n\n2. Try training a model on datasets - most real world applications will need some kind of fine tuning of a model to their data/use case. Try loading a model and directly fine tuning it, if you need to fit it in a smaller gpu/cpu/vram/ram then try using a lora to fine tune it. You get to learn about getting data in the right format, what learning rates/batch size etc work. e.g. [https://github.com/aatri2021/qwen-lora-windows-guide](https://github.com/aatri2021/qwen-lora-windows-guide)\n\nLike with most of those youtube/tutorials just following along doesn't work at least for me. Its better to try and do this yourself for a specific case of what you want to solve - just like learning programming i need something i'm trying to solve to learn. Give something simple a go eg i first tried teaching llama 8B how to ad chords to song lyrics and it worked pretty well. Chat gpt is surprisingly good at guiding you through it if you get stuck.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70ibh9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The best way i&amp;#39;ve found is&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;To try and run a model locally first - see how its loaded, how you send prompts to it. Teaches you about its structure/prompting/eos tokens etc. Just pick something small and try.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Try training a model on datasets - most real world applications will need some kind of fine tuning of a model to their data/use case. Try loading a model and directly fine tuning it, if you need to fit it in a smaller gpu/cpu/vram/ram then try using a lora to fine tune it. You get to learn about getting data in the right format, what learning rates/batch size etc work. e.g. &lt;a href=\"https://github.com/aatri2021/qwen-lora-windows-guide\"&gt;https://github.com/aatri2021/qwen-lora-windows-guide&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Like with most of those youtube/tutorials just following along doesn&amp;#39;t work at least for me. Its better to try and do this yourself for a specific case of what you want to solve - just like learning programming i need something i&amp;#39;m trying to solve to learn. Give something simple a go eg i first tried teaching llama 8B how to ad chords to song lyrics and it worked pretty well. Chat gpt is surprisingly good at guiding you through it if you get stuck.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/n70ibh9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754378521,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi2ebo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n70tv5p",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "rhetoricalcalligraph",
            "can_mod_post": false,
            "created_utc": 1754385212,
            "send_replies": true,
            "parent_id": "t3_1mi2ebo",
            "score": 3,
            "author_fullname": "t2_1kw4d36gz8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Always amazed that people don't just ask ChatGPT instead of making posts like this. Ironic.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70tv5p",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Always amazed that people don&amp;#39;t just ask ChatGPT instead of making posts like this. Ironic.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/n70tv5p/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754385212,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi2ebo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n70oiuj",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Fussy-Fur3608",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n70mqzh",
                                "score": 1,
                                "author_fullname": "t2_8383arktn",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "i just add the confidence value to the output format and i always get a value. i set up a bunch of experiments to test if this \"confidence level\" can be trusted and i couldn't fault it so i kept it in there.  \nit seems useful in the response to the first prompt, when i feed that output along with the final prompt it helps get me reliable answers. i always give my last prompt a possible response of \"unsure\", as in (yes,no,unsure) so it can judge it's own response. seems to work so i'll run with it.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n70oiuj",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;i just add the confidence value to the output format and i always get a value. i set up a bunch of experiments to test if this &amp;quot;confidence level&amp;quot; can be trusted and i couldn&amp;#39;t fault it so i kept it in there.&lt;br/&gt;\nit seems useful in the response to the first prompt, when i feed that output along with the final prompt it helps get me reliable answers. i always give my last prompt a possible response of &amp;quot;unsure&amp;quot;, as in (yes,no,unsure) so it can judge it&amp;#39;s own response. seems to work so i&amp;#39;ll run with it.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi2ebo",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/n70oiuj/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754382089,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754382089,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n70mqzh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Fetlocks_Glistening",
                      "can_mod_post": false,
                      "created_utc": 1754381057,
                      "send_replies": true,
                      "parent_id": "t1_n70jpcw",
                      "score": 1,
                      "author_fullname": "t2_lq9vco2g",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "How do you calculate 'confidence', do you just take next token probability when disclosed by your specific model/ does it actually work? ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n70mqzh",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How do you calculate &amp;#39;confidence&amp;#39;, do you just take next token probability when disclosed by your specific model/ does it actually work? &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi2ebo",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/n70mqzh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754381057,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n70jpcw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Fussy-Fur3608",
            "can_mod_post": false,
            "created_utc": 1754379312,
            "send_replies": true,
            "parent_id": "t3_1mi2ebo",
            "score": 1,
            "author_fullname": "t2_8383arktn",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "honestly, just get ollama start messing around with prompts.\n\ni use LM Studio and sometimes Jan just to run models and try out different settings.  \nollama gives you an OpenAI API server. make calls, get responses.  \nas for prompting, well that's everyone's own special sauce.  \ni prefer two shot prompting since it reduces the scope of the responses.  \npersonally, i always end my system prompt with   \nOnly respond in JSON format {\"confidence\":\"integer 0-10\", \"answer\":\"string\"}, do not explain, ask questions or otherwise embellish the response.\n\ni set temperature to 0, and seed to 42. i find this helps with deterministic results.  \ni guess once you get more proficient you can have a go at running python services with whatever flavor model you prefer, transformers is a good place to start.  \nIf you run out of local compute, check our runpod...or any API provider.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70jpcw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;honestly, just get ollama start messing around with prompts.&lt;/p&gt;\n\n&lt;p&gt;i use LM Studio and sometimes Jan just to run models and try out different settings.&lt;br/&gt;\nollama gives you an OpenAI API server. make calls, get responses.&lt;br/&gt;\nas for prompting, well that&amp;#39;s everyone&amp;#39;s own special sauce.&lt;br/&gt;\ni prefer two shot prompting since it reduces the scope of the responses.&lt;br/&gt;\npersonally, i always end my system prompt with&lt;br/&gt;\nOnly respond in JSON format {&amp;quot;confidence&amp;quot;:&amp;quot;integer 0-10&amp;quot;, &amp;quot;answer&amp;quot;:&amp;quot;string&amp;quot;}, do not explain, ask questions or otherwise embellish the response.&lt;/p&gt;\n\n&lt;p&gt;i set temperature to 0, and seed to 42. i find this helps with deterministic results.&lt;br/&gt;\ni guess once you get more proficient you can have a go at running python services with whatever flavor model you prefer, transformers is a good place to start.&lt;br/&gt;\nIf you run out of local compute, check our runpod...or any API provider.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/n70jpcw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754379312,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi2ebo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n70ju7a",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Ok-Kangaroo6055",
            "can_mod_post": false,
            "created_utc": 1754379390,
            "send_replies": true,
            "parent_id": "t3_1mi2ebo",
            "score": 1,
            "author_fullname": "t2_dmg3f1uq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Running a model is pretty easy, lm studio/ollama/docker and you've got an API, usually openai API compatible so you can use many frameworks to interface with it. \n\nA RAG pipeline can just be an elastic search vector index, which is what my company is using in production rather than the new fancy dedicated vector dbs. You could do pgvector in postgress too. The difficulty is with chunking strategy, document ingestion. We've been struggling at extracting text from complex pdfs and chunking that in a good way. So that's probably the hardest problem.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70ju7a",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Running a model is pretty easy, lm studio/ollama/docker and you&amp;#39;ve got an API, usually openai API compatible so you can use many frameworks to interface with it. &lt;/p&gt;\n\n&lt;p&gt;A RAG pipeline can just be an elastic search vector index, which is what my company is using in production rather than the new fancy dedicated vector dbs. You could do pgvector in postgress too. The difficulty is with chunking strategy, document ingestion. We&amp;#39;ve been struggling at extracting text from complex pdfs and chunking that in a good way. So that&amp;#39;s probably the hardest problem.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/n70ju7a/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754379390,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi2ebo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n70rq25",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "perelmanych",
            "can_mod_post": false,
            "created_utc": 1754383952,
            "send_replies": true,
            "parent_id": "t3_1mi2ebo",
            "score": 1,
            "author_fullname": "t2_63q8kong",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The most difficult part now is not about writing scripts, especially taking into account that you have solid coding experience. The most difficult part is to come with viable idea for your project, since you will compete with thousands of others. Once you know what you want to do you plus/minus understand what parts you need to be present in your project then just go to ChatGPT or any other big LLM and start asking questions.  \n  \nThe advise to start to fiddle with local LLM is also very valuable, since this is the easiest and cheapest way to get feeling what you can do with LLMs.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70rq25",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The most difficult part now is not about writing scripts, especially taking into account that you have solid coding experience. The most difficult part is to come with viable idea for your project, since you will compete with thousands of others. Once you know what you want to do you plus/minus understand what parts you need to be present in your project then just go to ChatGPT or any other big LLM and start asking questions.  &lt;/p&gt;\n\n&lt;p&gt;The advise to start to fiddle with local LLM is also very valuable, since this is the easiest and cheapest way to get feeling what you can do with LLMs.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/n70rq25/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754383952,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi2ebo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n70rm6n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AppearanceHeavy6724",
            "can_mod_post": false,
            "created_utc": 1754383889,
            "send_replies": true,
            "parent_id": "t3_1mi2ebo",
            "score": 1,
            "author_fullname": "t2_uz37qfx5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "**Do not use Ollama** if you are already a technical person, use the classics - llama.cpp or vLLM. Ollama is a wrapper with its own quirks. The lower level you get the better you will understand the whole picture.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n70rm6n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Do not use Ollama&lt;/strong&gt; if you are already a technical person, use the classics - llama.cpp or vLLM. Ollama is a wrapper with its own quirks. The lower level you get the better you will understand the whole picture.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi2ebo/how_does_someone_with_programming_exp_get_started/n70rm6n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754383889,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi2ebo",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]