[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hello,\n\nI've been watching this thread for a while now and I'm looking for a laptop at around the 1500eur mark, and i can not decide for my usecase. I'm trying to build something basic, yet challenging. The plan is to make a local law assistant using RAG and a 7b modell, and learn more about the usecases of local LLMs.\n\nMy problem is that I travel a lot and therefore I can't have really reliable internet in hotels, etc. so I can't connect to my home PC, that has a 3090.\n\nSo I decided to get a laptop for myself. I have basically two choices, because of budget reasons.\n\n16\" MacBook Pro M1 Pro 32GB Ram (which would be used)\n\nor\n\nAsus Vivobook with Ryzen AI 9 370HX and 32GB Ram (which would be new)\n\nI'm pretty comfortable on both systems since I'm running a 16GB MBP right now, and a PC at home. Just performance wise what would be the better choice for my usecase?\n\nThank you all for your time, and have a great day!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Ryzen AI HX 370 or Mx Pro for travellers",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m5ff1k",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 1,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_vgoid361",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1753095887,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753094017,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been watching this thread for a while now and I&amp;#39;m looking for a laptop at around the 1500eur mark, and i can not decide for my usecase. I&amp;#39;m trying to build something basic, yet challenging. The plan is to make a local law assistant using RAG and a 7b modell, and learn more about the usecases of local LLMs.&lt;/p&gt;\n\n&lt;p&gt;My problem is that I travel a lot and therefore I can&amp;#39;t have really reliable internet in hotels, etc. so I can&amp;#39;t connect to my home PC, that has a 3090.&lt;/p&gt;\n\n&lt;p&gt;So I decided to get a laptop for myself. I have basically two choices, because of budget reasons.&lt;/p&gt;\n\n&lt;p&gt;16&amp;quot; MacBook Pro M1 Pro 32GB Ram (which would be used)&lt;/p&gt;\n\n&lt;p&gt;or&lt;/p&gt;\n\n&lt;p&gt;Asus Vivobook with Ryzen AI 9 370HX and 32GB Ram (which would be new)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m pretty comfortable on both systems since I&amp;#39;m running a 16GB MBP right now, and a PC at home. Just performance wise what would be the better choice for my usecase?&lt;/p&gt;\n\n&lt;p&gt;Thank you all for your time, and have a great day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m5ff1k",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "0ner0z",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m5ff1k/ryzen_ai_hx_370_or_mx_pro_for_travellers/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m5ff1k/ryzen_ai_hx_370_or_mx_pro_for_travellers/",
            "subreddit_subscribers": 502721,
            "created_utc": 1753094017,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4bylxf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "comefaith",
            "can_mod_post": false,
            "created_utc": 1753101914,
            "send_replies": true,
            "parent_id": "t3_1m5ff1k",
            "score": 3,
            "author_fullname": "t2_80hkj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "mbp will be times faster in tokens/second because of faster memory. you can even try 32b quantizations with at least 10 tok/s",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4bylxf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;mbp will be times faster in tokens/second because of faster memory. you can even try 32b quantizations with at least 10 tok/s&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m5ff1k/ryzen_ai_hx_370_or_mx_pro_for_travellers/n4bylxf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753101914,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m5ff1k",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4des68",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "FieldProgrammable",
            "can_mod_post": false,
            "created_utc": 1753117589,
            "send_replies": true,
            "parent_id": "t3_1m5ff1k",
            "score": 2,
            "author_fullname": "t2_moet0t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You need to be looking at Strix Halo class CPUs not Strix Point if you want an x86 mobile that can trade blows with  the Mx series. E.g. Ryzen AI Max+ 395 in say an HP Zbook ultra. Even then you need to confirm your backend has the requisite Rocm support for it.\n\nIf it doesn't have unified memory then you will need a discrete GPU which will be limited to about 12GB for a laptop at that price point. Unless of course you are fine with 1 token/sec",
            "edited": 1753118112,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4des68",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You need to be looking at Strix Halo class CPUs not Strix Point if you want an x86 mobile that can trade blows with  the Mx series. E.g. Ryzen AI Max+ 395 in say an HP Zbook ultra. Even then you need to confirm your backend has the requisite Rocm support for it.&lt;/p&gt;\n\n&lt;p&gt;If it doesn&amp;#39;t have unified memory then you will need a discrete GPU which will be limited to about 12GB for a laptop at that price point. Unless of course you are fine with 1 token/sec&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m5ff1k/ryzen_ai_hx_370_or_mx_pro_for_travellers/n4des68/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753117589,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m5ff1k",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]