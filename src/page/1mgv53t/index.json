[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi,\n\nI encountered a strange situation with GLM-4.5-Air 3bit mlx that maybe others can shed light on:  I tried to reproduce the Flappy Bird game featured in the [z.ai/blog/glm-4.5](http://z.ai/blog/glm-4.5) blog post, using the exact same prompt, but failed 3 times - the generated game either fails during collision detection (.i.e. the bird dies without hitting the pipes), or the top and bottom pipes merge and there's no way through.\n\nI gave up on the model for a while, thinking that it was due to the 3-bit quant.  But upon reading a reddit post decided to try something: adding /nothink to the end of the prompt.  This not only eliminated the \"thinking\" part of the output tokens, but generated a working game in one shot, with correct collision detection but also with added cloud in the background, just like in the blog post.\n\nCan anyone with 4, 6 or 8 bit mlx version verify if they have this problem?  Here's the exact prompt: \"Write a Flappy Bird game for me in a single HTML page. Keep the gravity weak so that the game is not too hard.\"\n\nPS.  I am running this on M1 Max Mac Studio w/ 64GB and 32C GPU, and get about 22 tokens/sec in LM Studio.  Also, Qwen3-Coder-30B-A3B (unlsoth Q8\\_0) generated this game, and others, in one shot without problem, at about 50 tokens/sec with flash attention on.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "GLM 4.5 Air Produces Better Code Without Thinking, Using 3-bit MLX (/nothink)?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mgv53t",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.91,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 35,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_3xif6p3z",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 35,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754256522,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I encountered a strange situation with GLM-4.5-Air 3bit mlx that maybe others can shed light on:  I tried to reproduce the Flappy Bird game featured in the &lt;a href=\"http://z.ai/blog/glm-4.5\"&gt;z.ai/blog/glm-4.5&lt;/a&gt; blog post, using the exact same prompt, but failed 3 times - the generated game either fails during collision detection (.i.e. the bird dies without hitting the pipes), or the top and bottom pipes merge and there&amp;#39;s no way through.&lt;/p&gt;\n\n&lt;p&gt;I gave up on the model for a while, thinking that it was due to the 3-bit quant.  But upon reading a reddit post decided to try something: adding /nothink to the end of the prompt.  This not only eliminated the &amp;quot;thinking&amp;quot; part of the output tokens, but generated a working game in one shot, with correct collision detection but also with added cloud in the background, just like in the blog post.&lt;/p&gt;\n\n&lt;p&gt;Can anyone with 4, 6 or 8 bit mlx version verify if they have this problem?  Here&amp;#39;s the exact prompt: &amp;quot;Write a Flappy Bird game for me in a single HTML page. Keep the gravity weak so that the game is not too hard.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;PS.  I am running this on M1 Max Mac Studio w/ 64GB and 32C GPU, and get about 22 tokens/sec in LM Studio.  Also, Qwen3-Coder-30B-A3B (unlsoth Q8_0) generated this game, and others, in one shot without problem, at about 50 tokens/sec with flash attention on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mgv53t",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "jcmyang",
            "discussion_type": null,
            "num_comments": 27,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/",
            "subreddit_subscribers": 509913,
            "created_utc": 1754256522,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": "",
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n6sqxr5",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "knownboyofno",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n6sg9ab",
                                                                        "score": 2,
                                                                        "author_fullname": "t2_5y9divj7",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "No pressure.  I like to see if it works for other models. I normally only have 1 model running at a time.",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n6sqxr5",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No pressure.  I like to see if it works for other models. I normally only have 1 model running at a time.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mgv53t",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sqxr5/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754272194,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754272194,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 2
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6sg9ab",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "DorphinPack",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6sfb7r",
                                                              "score": 1,
                                                              "author_fullname": "t2_zebuyjw9s",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "It’s on the list! I’m backlogged and haven’t had uninterrupted project time in a bit.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6sg9ab",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It’s on the list! I’m backlogged and haven’t had uninterrupted project time in a bit.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mgv53t",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sg9ab/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754268377,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754268377,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6sfb7r",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "knownboyofno",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6sf1dw",
                                                    "score": 1,
                                                    "author_fullname": "t2_5y9divj7",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "No problem. If you remember let me know how it works and the model it worked on.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6sfb7r",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No problem. If you remember let me know how it works and the model it worked on.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mgv53t",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sfb7r/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754268032,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754268032,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6sf1dw",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "DorphinPack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6sdjwy",
                                          "score": 2,
                                          "author_fullname": "t2_zebuyjw9s",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Nice :) thanks for sharing!",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6sf1dw",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice :) thanks for sharing!&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mgv53t",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sf1dw/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754267935,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754267935,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6sdjwy",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "knownboyofno",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6rp1c3",
                                "score": 2,
                                "author_fullname": "t2_5y9divj7",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yea, I have done this before but what I have started doing that works just as well for me. Is that I write the prompt as normal then I ask what are the important missing points and what else is needed to achieve this goal.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6sdjwy",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yea, I have done this before but what I have started doing that works just as well for me. Is that I write the prompt as normal then I ask what are the important missing points and what else is needed to achieve this goal.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgv53t",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sdjwy/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754267396,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754267396,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6rp1c3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "DorphinPack",
                      "can_mod_post": false,
                      "created_utc": 1754258928,
                      "send_replies": true,
                      "parent_id": "t1_n6rm92c",
                      "score": 6,
                      "author_fullname": "t2_zebuyjw9s",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I’ve come to think of CoT as built-in prompt enhancement. I know the training encourages following traditional problem solving, but my observation is that usually when it HELPS I could have been clearer in my prompt.\n\nIt makes me think that we should split that workflow to address the token bloat from thinking. Come up with the prompt by rapidly iterating while watching where the CoT reveals ambiguities or challenging predictions. Then, cut it loose on a bigger, slower model with less chance of having to try it all over again.\n\nI do this thing where I watch the thinking text and stop the model when it reveals a flaw in my prompt. It helps me iterate towards better prompts AND pick up some prompt engineering praxis to balance out the ocean of theory out there. IMO it’s worth trying.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6rp1c3",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’ve come to think of CoT as built-in prompt enhancement. I know the training encourages following traditional problem solving, but my observation is that usually when it HELPS I could have been clearer in my prompt.&lt;/p&gt;\n\n&lt;p&gt;It makes me think that we should split that workflow to address the token bloat from thinking. Come up with the prompt by rapidly iterating while watching where the CoT reveals ambiguities or challenging predictions. Then, cut it loose on a bigger, slower model with less chance of having to try it all over again.&lt;/p&gt;\n\n&lt;p&gt;I do this thing where I watch the thinking text and stop the model when it reveals a flaw in my prompt. It helps me iterate towards better prompts AND pick up some prompt engineering praxis to balance out the ocean of theory out there. IMO it’s worth trying.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rp1c3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754258928,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6se8ir",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AnticitizenPrime",
                      "can_mod_post": false,
                      "created_utc": 1754267643,
                      "send_replies": true,
                      "parent_id": "t1_n6rm92c",
                      "score": 1,
                      "author_fullname": "t2_66km3",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This is just my subjective experience, but to me, reasoning seems to show the best improvements on smaller models when doing things like solving logic puzzles. It can result in, say, a 9b reasoning model getting things right that previously only a 32b or similar size would get, for example. But I don't see big improvements in the big model really getting better than it was, if it was already good, and like you mention, sometimes it actually seems to hurt. So there might be a diminishing returns thing going on here. And of course, there's many other things to consider, such as how long they think, what their contexts windows are, etc. \n\nThese are just my totally unscientific observations, and I'm not a coder so I'm not talking about coding stuff here, just logical reasoning stuff.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6se8ir",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is just my subjective experience, but to me, reasoning seems to show the best improvements on smaller models when doing things like solving logic puzzles. It can result in, say, a 9b reasoning model getting things right that previously only a 32b or similar size would get, for example. But I don&amp;#39;t see big improvements in the big model really getting better than it was, if it was already good, and like you mention, sometimes it actually seems to hurt. So there might be a diminishing returns thing going on here. And of course, there&amp;#39;s many other things to consider, such as how long they think, what their contexts windows are, etc. &lt;/p&gt;\n\n&lt;p&gt;These are just my totally unscientific observations, and I&amp;#39;m not a coder so I&amp;#39;m not talking about coding stuff here, just logical reasoning stuff.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6se8ir/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754267643,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6tc48y",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Irisi11111",
                      "can_mod_post": false,
                      "created_utc": 1754280618,
                      "send_replies": true,
                      "parent_id": "t1_n6rm92c",
                      "score": 1,
                      "author_fullname": "t2_27amtukh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Reasoning models are very good at understanding prompts and following instructions. They can generate human-like responses with proper prompts. However, they can be stubborn. I experienced a lot with o1 pro and Gemini 2.5, they sometimes argue and won't change their minds without detailed explanations. In most cases, non-reasoning models like GPT-4.1 also perform well with clear guidance. My approach is to use reasoning models for complex instructions and apply those for non-reasoning models, see feedback and adjust the prompts accordingly until I get the desired output.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6tc48y",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Reasoning models are very good at understanding prompts and following instructions. They can generate human-like responses with proper prompts. However, they can be stubborn. I experienced a lot with o1 pro and Gemini 2.5, they sometimes argue and won&amp;#39;t change their minds without detailed explanations. In most cases, non-reasoning models like GPT-4.1 also perform well with clear guidance. My approach is to use reasoning models for complex instructions and apply those for non-reasoning models, see feedback and adjust the prompts accordingly until I get the desired output.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6tc48y/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754280618,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6rm92c",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "mikael110",
            "can_mod_post": false,
            "created_utc": 1754258006,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 19,
            "author_fullname": "t2_4amlo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The more I've played around with reasoning models the more I've come to realize that reasoning is not really a universal improvement in the way a lot of people seem to think. There are plenty of tasks where enabling thinking for a model either have no measurable improvement in real tasks, or actively hurts it. And surprisingly I've found coding to be one of them.\n\nYou'd really think otherwise, and I can see reasoning helping for really complex coding queries, but for most coding requests I've found that running a non-reasoning model (or a reasoning model in non-think mode) produces as good or better results.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rm92c",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The more I&amp;#39;ve played around with reasoning models the more I&amp;#39;ve come to realize that reasoning is not really a universal improvement in the way a lot of people seem to think. There are plenty of tasks where enabling thinking for a model either have no measurable improvement in real tasks, or actively hurts it. And surprisingly I&amp;#39;ve found coding to be one of them.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;d really think otherwise, and I can see reasoning helping for really complex coding queries, but for most coding requests I&amp;#39;ve found that running a non-reasoning model (or a reasoning model in non-think mode) produces as good or better results.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rm92c/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754258006,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 19
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6rjv77",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "nullmove",
            "can_mod_post": false,
            "created_utc": 1754257237,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 4,
            "author_fullname": "t2_aq4j0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Wouldn't be surprised, iirc in discord one of the z.ai staff recommended using nothink mode for Claude Code and such, because that's what it's optimised for.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rjv77",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wouldn&amp;#39;t be surprised, iirc in discord one of the z.ai staff recommended using nothink mode for Claude Code and such, because that&amp;#39;s what it&amp;#39;s optimised for.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rjv77/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754257237,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "d2642412-d9ce-11ed-ae30-32b11309f5bd",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6s6mag",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ortegaalfredo",
            "can_mod_post": false,
            "created_utc": 1754264942,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 3,
            "author_fullname": "t2_g177e",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "GLM-4.5-air fp8 produces a working flappy bird game in one shot, as expected. In fact it looked better than the one in their blogpost, with gradient textured pipes.\n\nTried on Qwen3-235B web version and thinking-mode produced much better results, similar quality to the glm-4.5-air fp8. Non-thinking is much lower quality, but also worked one-shot.\n\nSurprisingly the best quality game I got wat GLM-4.5, almost the same as GLM-4.5 air. Qwen3-coder second, sonnet with much less quality. Maybe GLM training on flappy bird games?",
            "edited": 1754266052,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6s6mag",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Alpaca"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GLM-4.5-air fp8 produces a working flappy bird game in one shot, as expected. In fact it looked better than the one in their blogpost, with gradient textured pipes.&lt;/p&gt;\n\n&lt;p&gt;Tried on Qwen3-235B web version and thinking-mode produced much better results, similar quality to the glm-4.5-air fp8. Non-thinking is much lower quality, but also worked one-shot.&lt;/p&gt;\n\n&lt;p&gt;Surprisingly the best quality game I got wat GLM-4.5, almost the same as GLM-4.5 air. Qwen3-coder second, sonnet with much less quality. Maybe GLM training on flappy bird games?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6s6mag/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754264942,
            "author_flair_text": "Alpaca",
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bd9e9e",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6tv3jv",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Holiday_Purpose_3166",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6tsg7l",
                                "score": 1,
                                "author_fullname": "t2_x3txpugjv",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Ah! touche then",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6tv3jv",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah! touche then&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgv53t",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6tv3jv/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754290252,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754290252,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6tsg7l",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "boringcynicism",
                      "can_mod_post": false,
                      "created_utc": 1754288781,
                      "send_replies": true,
                      "parent_id": "t1_n6t3uj0",
                      "score": 1,
                      "author_fullname": "t2_1hz0lz0k5i",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Qwen3 official results omit for example aider scores for the thinking models. Guess why 😁",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6tsg7l",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen3 official results omit for example aider scores for the thinking models. Guess why 😁&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6tsg7l/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754288781,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6t3uj0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Holiday_Purpose_3166",
            "can_mod_post": false,
            "created_utc": 1754277100,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 2,
            "author_fullname": "t2_x3txpugjv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Same behaviour I came across Qwen3 30B A3B 2507 Thinking model. It wasn't great on my testing prompts, but if I use the Instruct model (without reasoning feature) it provides a higher output score.\n\nI stick the reasoning models outside coding, or for orchestration. They seem to shine better here, despite the company's benchmarks say otherwise.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6t3uj0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Same behaviour I came across Qwen3 30B A3B 2507 Thinking model. It wasn&amp;#39;t great on my testing prompts, but if I use the Instruct model (without reasoning feature) it provides a higher output score.&lt;/p&gt;\n\n&lt;p&gt;I stick the reasoning models outside coding, or for orchestration. They seem to shine better here, despite the company&amp;#39;s benchmarks say otherwise.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6t3uj0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754277100,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6tc9wj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Southern_Sun_2106",
            "can_mod_post": false,
            "created_utc": 1754280687,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 2,
            "author_fullname": "t2_ajuxt3cr4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hello. 5-bit mlx one-shotted the flappy birds for me. When I asked it for Skyrim, it searched online in a panic; then \"one-shotted\" \"Skyrim\" too\n\nhttps://preview.redd.it/miadd8f5hxgf1.png?width=2224&amp;format=png&amp;auto=webp&amp;s=bffa81082c8a3991dc1f2e766198ec1217aa93fb\n\nedit: I tried /nothink, but it still 'thunk' a little",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6tc9wj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hello. 5-bit mlx one-shotted the flappy birds for me. When I asked it for Skyrim, it searched online in a panic; then &amp;quot;one-shotted&amp;quot; &amp;quot;Skyrim&amp;quot; too&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/miadd8f5hxgf1.png?width=2224&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bffa81082c8a3991dc1f2e766198ec1217aa93fb\"&gt;https://preview.redd.it/miadd8f5hxgf1.png?width=2224&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bffa81082c8a3991dc1f2e766198ec1217aa93fb&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;edit: I tried /nothink, but it still &amp;#39;thunk&amp;#39; a little&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6tc9wj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754280687,
            "media_metadata": {
              "miadd8f5hxgf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 81,
                    "x": 108,
                    "u": "https://preview.redd.it/miadd8f5hxgf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=af53ebcae24119751d9ef9cb6ff0b989ca28eb8a"
                  },
                  {
                    "y": 163,
                    "x": 216,
                    "u": "https://preview.redd.it/miadd8f5hxgf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3730e5c4279f8d7659412ee5396627c5de9e2f84"
                  },
                  {
                    "y": 241,
                    "x": 320,
                    "u": "https://preview.redd.it/miadd8f5hxgf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=994b544f56c37fb2376ced86a75e03d5d4459610"
                  },
                  {
                    "y": 483,
                    "x": 640,
                    "u": "https://preview.redd.it/miadd8f5hxgf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=1f3bb100f4de82401f70e89acb7c053299465e4f"
                  },
                  {
                    "y": 725,
                    "x": 960,
                    "u": "https://preview.redd.it/miadd8f5hxgf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=cdd48df27af576ec0b89d5e79036dab47a04ef69"
                  },
                  {
                    "y": 815,
                    "x": 1080,
                    "u": "https://preview.redd.it/miadd8f5hxgf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d690e60f655530b1153834ae11a0dad42f124d11"
                  }
                ],
                "s": {
                  "y": 1680,
                  "x": 2224,
                  "u": "https://preview.redd.it/miadd8f5hxgf1.png?width=2224&amp;format=png&amp;auto=webp&amp;s=bffa81082c8a3991dc1f2e766198ec1217aa93fb"
                },
                "id": "miadd8f5hxgf1"
              }
            },
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6sxra3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "jcmyang",
                      "can_mod_post": false,
                      "created_utc": 1754274705,
                      "send_replies": true,
                      "parent_id": "t1_n6rmnuc",
                      "score": 1,
                      "author_fullname": "t2_3xif6p3z",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Great.  Thanks for the data point.  So 6bit mlx has no problem with this prompt, even with thinking.  Also, the M4 Max performance is impressive - despite double the quant size (6bit vs 3bit), it manages to have 45% faster speed than the M1 Max.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6sxra3",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great.  Thanks for the data point.  So 6bit mlx has no problem with this prompt, even with thinking.  Also, the M4 Max performance is impressive - despite double the quant size (6bit vs 3bit), it manages to have 45% faster speed than the M1 Max.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sxra3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754274705,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6u39hf",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "EmergencyLetter135",
                      "can_mod_post": false,
                      "created_utc": 1754294956,
                      "send_replies": true,
                      "parent_id": "t1_n6rmnuc",
                      "score": 1,
                      "author_fullname": "t2_ioyqqx8pe",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thought for 5.88 seconds.\n\n25.12 tok/sek • 4061 tokens • 1.19s to first token • Mac Studio M1 Ultra 128GB - LM Studio 0.3.21 MLX v0.21.1 - GLM 4.5 Air: Context: 32668 ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6u39hf",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thought for 5.88 seconds.&lt;/p&gt;\n\n&lt;p&gt;25.12 tok/sek • 4061 tokens • 1.19s to first token • Mac Studio M1 Ultra 128GB - LM Studio 0.3.21 MLX v0.21.1 - GLM 4.5 Air: Context: 32668 &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6u39hf/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754294956,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6rmnuc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Baldur-Norddahl",
            "can_mod_post": false,
            "created_utc": 1754258140,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_bvqb8ng0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "`glm-4.5-air@6bit`\n\n`Thought for 5.86 seconds.`\n\n`30.93 tok/sec • 3530 tokens • 16.25s to first token • Stop reason: EOS Token Found`\n\nUsing LM Studio with Qwen3 settings because I don't have any GLM specific settings. The computer is M4 Max MacBook Pro 128 GB.\n\nThe game I got was fully functional with skies and everything.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rmnuc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;code&gt;glm-4.5-air@6bit&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Thought for 5.86 seconds.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;30.93 tok/sec • 3530 tokens • 16.25s to first token • Stop reason: EOS Token Found&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Using LM Studio with Qwen3 settings because I don&amp;#39;t have any GLM specific settings. The computer is M4 Max MacBook Pro 128 GB.&lt;/p&gt;\n\n&lt;p&gt;The game I got was fully functional with skies and everything.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rmnuc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754258140,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6rsaha",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Admirable-Star7088",
            "can_mod_post": false,
            "created_utc": 1754260024,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_qhlcbiy3k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm a sad user who can't run GLM 4.5 Air yet because I'm using llama.cpp, but I have noticed the same thing with the GLM 4 9b models, the thinking version is worse at coding than the non-thinking version.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rsaha",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a sad user who can&amp;#39;t run GLM 4.5 Air yet because I&amp;#39;m using llama.cpp, but I have noticed the same thing with the GLM 4 9b models, the thinking version is worse at coding than the non-thinking version.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rsaha/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754260024,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6tayoq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "gamblingapocalypse",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6syvut",
                                "score": 1,
                                "author_fullname": "t2_fz3utn30",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Depends on the size of the model as well.  Larger models tend to handle larger prompts without much drop in accuracy.  However, I remember you are using glm air, I’ve been having great results with this one and am surprised to hear the accuracy drop being that noticeable on only that many extra tokens.\n\nPersonally, I think that thinking has its place in some use cases, I would be happy without it.  If you do use it, be prepared for trade offs.",
                                "edited": 1754280383,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6tayoq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Depends on the size of the model as well.  Larger models tend to handle larger prompts without much drop in accuracy.  However, I remember you are using glm air, I’ve been having great results with this one and am surprised to hear the accuracy drop being that noticeable on only that many extra tokens.&lt;/p&gt;\n\n&lt;p&gt;Personally, I think that thinking has its place in some use cases, I would be happy without it.  If you do use it, be prepared for trade offs.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgv53t",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6tayoq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754280112,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754280112,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6syvut",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "jcmyang",
                      "can_mod_post": false,
                      "created_utc": 1754275132,
                      "send_replies": true,
                      "parent_id": "t1_n6rvlei",
                      "score": 1,
                      "author_fullname": "t2_3xif6p3z",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I see.  In this case the thinking part was only about 150 tokens, out of 3400 tokens total.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6syvut",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I see.  In this case the thinking part was only about 150 tokens, out of 3400 tokens total.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6syvut/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754275132,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6rvlei",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "gamblingapocalypse",
            "can_mod_post": false,
            "created_utc": 1754261155,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_fz3utn30",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I recall a paper, though I can’t remember the exact source, that discussed the relationship between context window length and model accuracy. The core idea was that longer prompts tend to lower accuracy, and since \"thinking\" often results in longer prompts, it indirectly reduces output accuracy.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rvlei",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I recall a paper, though I can’t remember the exact source, that discussed the relationship between context window length and model accuracy. The core idea was that longer prompts tend to lower accuracy, and since &amp;quot;thinking&amp;quot; often results in longer prompts, it indirectly reduces output accuracy.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rvlei/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754261155,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6tjy0b",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Conscious_Cut_6144",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6szaux",
                                "score": 1,
                                "author_fullname": "t2_9hl4ymvj",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Context includes your input and the thinking, but sounds like you are probably fine still.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6tjy0b",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Context includes your input and the thinking, but sounds like you are probably fine still.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgv53t",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6tjy0b/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754284296,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754284296,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6szaux",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "jcmyang",
                      "can_mod_post": false,
                      "created_utc": 1754275292,
                      "send_replies": true,
                      "parent_id": "t1_n6skgx6",
                      "score": 1,
                      "author_fullname": "t2_3xif6p3z",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I set the context limit at 16,384, but the total output was only about 3400 tokens.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6szaux",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I set the context limit at 16,384, but the total output was only about 3400 tokens.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6szaux/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754275292,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6skgx6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Conscious_Cut_6144",
            "can_mod_post": false,
            "created_utc": 1754269877,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_9hl4ymvj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I’m not familiar with mlx inference tools, but you aren’t exceeding your context limit and clipping are you?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6skgx6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’m not familiar with mlx inference tools, but you aren’t exceeding your context limit and clipping are you?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6skgx6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754269877,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6u3png",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "crantob",
            "can_mod_post": false,
            "created_utc": 1754295220,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_gyg8tngx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "GLM-4.5 helped me solve a pixel-art rotation problem i've been wanting to solve for 30 years. And yes nobody really did it to my satisfaction before.  The closed areas I want to preserve remain closed more often, after a transform.  Super happy.\nThis kicks rotsprite and everything else's ass.\nNot robust, but tweakable: https://envs.sh/EW6.png",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6u3png",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GLM-4.5 helped me solve a pixel-art rotation problem i&amp;#39;ve been wanting to solve for 30 years. And yes nobody really did it to my satisfaction before.  The closed areas I want to preserve remain closed more often, after a transform.  Super happy.\nThis kicks rotsprite and everything else&amp;#39;s ass.\nNot robust, but tweakable: &lt;a href=\"https://envs.sh/EW6.png\"&gt;https://envs.sh/EW6.png&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6u3png/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754295220,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6uyugg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "FullOf_Bad_Ideas",
            "can_mod_post": false,
            "created_utc": 1754310577,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_9s7pmakgx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Did you set temp to around 0.6, top_p to around 0.95 and top_k to 20/40, for the experiments you did with thinking mode?\n\nI find, based on my own experience, that people forget that samplers exist when they plug an LLM to a coding assistant tool like Cline or Claude Code (with router), and reasoning models are sensitive to those, so this kind of big difference could be explained by sampler setup.\n\nI think that reasoning helps with coding performance, like one shotting a flappy bird game, empirically. It tends to reduce the number of silly errors that non-reasoning models get stuck on in my experience. I don't know what impact it would have on a bigger project.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6uyugg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Did you set temp to around 0.6, top_p to around 0.95 and top_k to 20/40, for the experiments you did with thinking mode?&lt;/p&gt;\n\n&lt;p&gt;I find, based on my own experience, that people forget that samplers exist when they plug an LLM to a coding assistant tool like Cline or Claude Code (with router), and reasoning models are sensitive to those, so this kind of big difference could be explained by sampler setup.&lt;/p&gt;\n\n&lt;p&gt;I think that reasoning helps with coding performance, like one shotting a flappy bird game, empirically. It tends to reduce the number of silly errors that non-reasoning models get stuck on in my experience. I don&amp;#39;t know what impact it would have on a bigger project.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6uyugg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754310577,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]