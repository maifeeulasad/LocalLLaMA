[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi,\n\nI encountered a strange situation with GLM-4.5-Air 3bit mlx that maybe others can shed light on:  I tried to reproduce the Flappy Bird game featured in the [z.ai/blog/glm-4.5](http://z.ai/blog/glm-4.5) blog post, using the exact same prompt, but failed 3 times - the generated game either fails during collision detection (.i.e. the bird dies without hitting the pipes), or the top and bottom pipes merge and there's no way through.\n\nI gave up on the model for a while, thinking that it was due to the 3-bit quant.  But upon reading a reddit post decided to try something: adding /nothink to the end of the prompt.  This not only eliminated the \"thinking\" part of the output tokens, but generated a working game in one shot, with correct collision detection but also with added cloud in the background, just like in the blog post.\n\nCan anyone with 4, 6 or 8 bit mlx version verify if they have this problem?  Here's the exact prompt: \"Write a Flappy Bird game for me in a single HTML page. Keep the gravity weak so that the game is not too hard.\"\n\nPS.  I am running this on M1 Max Mac Studio w/ 64GB and 32C GPU, and get about 22 tokens/sec in LM Studio.  Also, Qwen3-Coder-30B-A3B (unlsoth Q8\\_0) generated this game, and others, in one shot without problem, at about 50 tokens/sec with flash attention on.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "GLM 4.5 Air Produces Better Code Without Thinking, Using 3-bit MLX (/nothink)?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mgv53t",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.88,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 17,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_3xif6p3z",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 17,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754256522,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I encountered a strange situation with GLM-4.5-Air 3bit mlx that maybe others can shed light on:  I tried to reproduce the Flappy Bird game featured in the &lt;a href=\"http://z.ai/blog/glm-4.5\"&gt;z.ai/blog/glm-4.5&lt;/a&gt; blog post, using the exact same prompt, but failed 3 times - the generated game either fails during collision detection (.i.e. the bird dies without hitting the pipes), or the top and bottom pipes merge and there&amp;#39;s no way through.&lt;/p&gt;\n\n&lt;p&gt;I gave up on the model for a while, thinking that it was due to the 3-bit quant.  But upon reading a reddit post decided to try something: adding /nothink to the end of the prompt.  This not only eliminated the &amp;quot;thinking&amp;quot; part of the output tokens, but generated a working game in one shot, with correct collision detection but also with added cloud in the background, just like in the blog post.&lt;/p&gt;\n\n&lt;p&gt;Can anyone with 4, 6 or 8 bit mlx version verify if they have this problem?  Here&amp;#39;s the exact prompt: &amp;quot;Write a Flappy Bird game for me in a single HTML page. Keep the gravity weak so that the game is not too hard.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;PS.  I am running this on M1 Max Mac Studio w/ 64GB and 32C GPU, and get about 22 tokens/sec in LM Studio.  Also, Qwen3-Coder-30B-A3B (unlsoth Q8_0) generated this game, and others, in one shot without problem, at about 50 tokens/sec with flash attention on.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mgv53t",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "jcmyang",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/",
            "subreddit_subscribers": 509625,
            "created_utc": 1754256522,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6sg9ab",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "DorphinPack",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6sfb7r",
                                                              "score": 1,
                                                              "author_fullname": "t2_zebuyjw9s",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "It’s on the list! I’m backlogged and haven’t had uninterrupted project time in a bit.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6sg9ab",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It’s on the list! I’m backlogged and haven’t had uninterrupted project time in a bit.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mgv53t",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sg9ab/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754268377,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754268377,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6sfb7r",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "knownboyofno",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6sf1dw",
                                                    "score": 1,
                                                    "author_fullname": "t2_5y9divj7",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "No problem. If you remember let me know how it works and the model it worked on.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6sfb7r",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No problem. If you remember let me know how it works and the model it worked on.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mgv53t",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sfb7r/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754268032,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754268032,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6sf1dw",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "DorphinPack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6sdjwy",
                                          "score": 1,
                                          "author_fullname": "t2_zebuyjw9s",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Nice :) thanks for sharing!",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6sf1dw",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice :) thanks for sharing!&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mgv53t",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sf1dw/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754267935,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754267935,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6sdjwy",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "knownboyofno",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6rp1c3",
                                "score": 2,
                                "author_fullname": "t2_5y9divj7",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yea, I have done this before but what I have started doing that works just as well for me. Is that I write the prompt as normal then I ask what are the important missing points and what else is needed to achieve this goal.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6sdjwy",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yea, I have done this before but what I have started doing that works just as well for me. Is that I write the prompt as normal then I ask what are the important missing points and what else is needed to achieve this goal.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgv53t",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6sdjwy/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754267396,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754267396,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6rp1c3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "DorphinPack",
                      "can_mod_post": false,
                      "created_utc": 1754258928,
                      "send_replies": true,
                      "parent_id": "t1_n6rm92c",
                      "score": 5,
                      "author_fullname": "t2_zebuyjw9s",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I’ve come to think of CoT as built-in prompt enhancement. I know the training encourages following traditional problem solving, but my observation is that usually when it HELPS I could have been clearer in my prompt.\n\nIt makes me think that we should split that workflow to address the token bloat from thinking. Come up with the prompt by rapidly iterating while watching where the CoT reveals ambiguities or challenging predictions. Then, cut it loose on a bigger, slower model with less chance of having to try it all over again.\n\nI do this thing where I watch the thinking text and stop the model when it reveals a flaw in my prompt. It helps me iterate towards better prompts AND pick up some prompt engineering praxis to balance out the ocean of theory out there. IMO it’s worth trying.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6rp1c3",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’ve come to think of CoT as built-in prompt enhancement. I know the training encourages following traditional problem solving, but my observation is that usually when it HELPS I could have been clearer in my prompt.&lt;/p&gt;\n\n&lt;p&gt;It makes me think that we should split that workflow to address the token bloat from thinking. Come up with the prompt by rapidly iterating while watching where the CoT reveals ambiguities or challenging predictions. Then, cut it loose on a bigger, slower model with less chance of having to try it all over again.&lt;/p&gt;\n\n&lt;p&gt;I do this thing where I watch the thinking text and stop the model when it reveals a flaw in my prompt. It helps me iterate towards better prompts AND pick up some prompt engineering praxis to balance out the ocean of theory out there. IMO it’s worth trying.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rp1c3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754258928,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6se8ir",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AnticitizenPrime",
                      "can_mod_post": false,
                      "created_utc": 1754267643,
                      "send_replies": true,
                      "parent_id": "t1_n6rm92c",
                      "score": 1,
                      "author_fullname": "t2_66km3",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This is just my subjective experience, but to me, reasoning seems to show the best improvements on smaller models when doing things like solving logic puzzles. It can result in, say, a 9b reasoning model getting things right that previously only a 32b or similar size would get, for example. But I don't see big improvements in the big model really getting better than it was, if it was already good, and like you mention, sometimes it actually seems to hurt. So there might be a diminishing returns thing going on here. And of course, there's many other things to consider, such as how long they think, what their contexts windows are, etc. \n\nThese are just my totally unscientific observations, and I'm not a coder so I'm not talking about coding stuff here, just logical reasoning stuff.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6se8ir",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is just my subjective experience, but to me, reasoning seems to show the best improvements on smaller models when doing things like solving logic puzzles. It can result in, say, a 9b reasoning model getting things right that previously only a 32b or similar size would get, for example. But I don&amp;#39;t see big improvements in the big model really getting better than it was, if it was already good, and like you mention, sometimes it actually seems to hurt. So there might be a diminishing returns thing going on here. And of course, there&amp;#39;s many other things to consider, such as how long they think, what their contexts windows are, etc. &lt;/p&gt;\n\n&lt;p&gt;These are just my totally unscientific observations, and I&amp;#39;m not a coder so I&amp;#39;m not talking about coding stuff here, just logical reasoning stuff.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgv53t",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6se8ir/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754267643,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6rm92c",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "mikael110",
            "can_mod_post": false,
            "created_utc": 1754258006,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 6,
            "author_fullname": "t2_4amlo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The more I've played around with reasoning models the more I've come to realize that reasoning is not really a universal improvement in the way a lot of people seem to think. There are plenty of tasks where enabling thinking for a model either have no measurable improvement in real tasks, or actively hurts it. And surprisingly I've found coding to be one of them.\n\nYou'd really think otherwise, and I can see reasoning helping for really complex coding queries, but for most coding requests I've found that running a non-reasoning model (or a reasoning model in non-think mode) produces as good or better results.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rm92c",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The more I&amp;#39;ve played around with reasoning models the more I&amp;#39;ve come to realize that reasoning is not really a universal improvement in the way a lot of people seem to think. There are plenty of tasks where enabling thinking for a model either have no measurable improvement in real tasks, or actively hurts it. And surprisingly I&amp;#39;ve found coding to be one of them.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;d really think otherwise, and I can see reasoning helping for really complex coding queries, but for most coding requests I&amp;#39;ve found that running a non-reasoning model (or a reasoning model in non-think mode) produces as good or better results.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rm92c/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754258006,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6rjv77",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "nullmove",
            "can_mod_post": false,
            "created_utc": 1754257237,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 2,
            "author_fullname": "t2_aq4j0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Wouldn't be surprised, iirc in discord one of the z.ai staff recommended using nothink mode for Claude Code and such, because that's what it's optimised for.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rjv77",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wouldn&amp;#39;t be surprised, iirc in discord one of the z.ai staff recommended using nothink mode for Claude Code and such, because that&amp;#39;s what it&amp;#39;s optimised for.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rjv77/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754257237,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "d2642412-d9ce-11ed-ae30-32b11309f5bd",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6s6mag",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ortegaalfredo",
            "can_mod_post": false,
            "created_utc": 1754264942,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 2,
            "author_fullname": "t2_g177e",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "GLM-4.5-air fp8 produces a working flappy bird game in one shot, as expected. In fact it looked better than the one in their blogpost, with gradient textured pipes.\n\nTried on Qwen3-235B web version and thinking-mode produced much better results, similar quality to the glm-4.5-air fp8. Non-thinking is much lower quality, but also worked one-shot.\n\nSurprisingly the best quality game I got wat GLM-4.5, almost the same as GLM-4.5 air. Qwen3-coder second, sonnet with much less quality. Maybe GLM training on flappy bird games?",
            "edited": 1754266052,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6s6mag",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Alpaca"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GLM-4.5-air fp8 produces a working flappy bird game in one shot, as expected. In fact it looked better than the one in their blogpost, with gradient textured pipes.&lt;/p&gt;\n\n&lt;p&gt;Tried on Qwen3-235B web version and thinking-mode produced much better results, similar quality to the glm-4.5-air fp8. Non-thinking is much lower quality, but also worked one-shot.&lt;/p&gt;\n\n&lt;p&gt;Surprisingly the best quality game I got wat GLM-4.5, almost the same as GLM-4.5 air. Qwen3-coder second, sonnet with much less quality. Maybe GLM training on flappy bird games?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6s6mag/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754264942,
            "author_flair_text": "Alpaca",
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bd9e9e",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6rmnuc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Baldur-Norddahl",
            "can_mod_post": false,
            "created_utc": 1754258140,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_bvqb8ng0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "`glm-4.5-air@6bit`\n\n`Thought for 5.86 seconds.`\n\n`30.93 tok/sec • 3530 tokens • 16.25s to first token • Stop reason: EOS Token Found`\n\nUsing LM Studio with Qwen3 settings because I don't have any GLM specific settings. The computer is M4 Max MacBook Pro 128 GB.\n\nThe game I got was fully functional with skies and everything.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rmnuc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;code&gt;glm-4.5-air@6bit&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Thought for 5.86 seconds.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;30.93 tok/sec • 3530 tokens • 16.25s to first token • Stop reason: EOS Token Found&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;Using LM Studio with Qwen3 settings because I don&amp;#39;t have any GLM specific settings. The computer is M4 Max MacBook Pro 128 GB.&lt;/p&gt;\n\n&lt;p&gt;The game I got was fully functional with skies and everything.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rmnuc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754258140,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6rsaha",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Admirable-Star7088",
            "can_mod_post": false,
            "created_utc": 1754260024,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_qhlcbiy3k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm a sad user who can't run GLM 4.5 Air yet because I'm using llama.cpp, but I have noticed the same thing with the GLM 4 9b models, the thinking version is worse at coding than the non-thinking version.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rsaha",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a sad user who can&amp;#39;t run GLM 4.5 Air yet because I&amp;#39;m using llama.cpp, but I have noticed the same thing with the GLM 4 9b models, the thinking version is worse at coding than the non-thinking version.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rsaha/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754260024,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6rvlei",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "gamblingapocalypse",
            "can_mod_post": false,
            "created_utc": 1754261155,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_fz3utn30",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I recall a paper, though I can’t remember the exact source, that discussed the relationship between context window length and model accuracy. The core idea was that longer prompts tend to lower accuracy, and since \"thinking\" often results in longer prompts, it indirectly reduces output accuracy.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rvlei",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I recall a paper, though I can’t remember the exact source, that discussed the relationship between context window length and model accuracy. The core idea was that longer prompts tend to lower accuracy, and since &amp;quot;thinking&amp;quot; often results in longer prompts, it indirectly reduces output accuracy.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6rvlei/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754261155,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6skgx6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Conscious_Cut_6144",
            "can_mod_post": false,
            "created_utc": 1754269877,
            "send_replies": true,
            "parent_id": "t3_1mgv53t",
            "score": 1,
            "author_fullname": "t2_9hl4ymvj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I’m not familiar with mlx inference tools, but you aren’t exceeding your context limit and clipping are you?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6skgx6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’m not familiar with mlx inference tools, but you aren’t exceeding your context limit and clipping are you?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgv53t/glm_45_air_produces_better_code_without_thinking/n6skgx6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754269877,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgv53t",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]