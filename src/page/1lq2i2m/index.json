[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Anything that would work as an agentic code assistant? Trying to decide if it’s worth investing if it means I don’t have to pay for Claude code anymore. I understand it won’t be near Claude code but that’s fine. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Is there a legit code assistant that can run on a m3 ultra 256 or 96gb?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1lq2i2m",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.71,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 7,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_dmc3swt9s",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 7,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1751478677,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anything that would work as an agentic code assistant? Trying to decide if it’s worth investing if it means I don’t have to pay for Claude code anymore. I understand it won’t be near Claude code but that’s fine. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1lq2i2m",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "tru3relativity",
            "discussion_type": null,
            "num_comments": 12,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/",
            "subreddit_subscribers": 494198,
            "created_utc": 1751478677,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n10eao4",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "robiinn",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n10a090",
                                "score": 4,
                                "author_fullname": "t2_709lt",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yep, $7k is a good chunk of cash to spend on this. Maybe if they are only allowed to run local models it would make sense, however this was not stated. \n\nThanks for the provided info, hopefully that helps OP.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n10eao4",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yep, $7k is a good chunk of cash to spend on this. Maybe if they are only allowed to run local models it would make sense, however this was not stated. &lt;/p&gt;\n\n&lt;p&gt;Thanks for the provided info, hopefully that helps OP.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lq2i2m",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n10eao4/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751489718,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751489718,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n15h72c",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "AstroZombie138",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n142rnn",
                                          "score": 1,
                                          "author_fullname": "t2_3sicn",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I didn't realize it was that much different.  Did you mean MLX models under lmstudio?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n15h72c",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I didn&amp;#39;t realize it was that much different.  Did you mean MLX models under lmstudio?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1lq2i2m",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n15h72c/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1751560036,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1751560036,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n142rnn",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "gpupoor",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n10a090",
                                "score": 2,
                                "author_fullname": "t2_1hcyral852",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "prompt reval rate 13 and 1t/s with 32b and 235ba22b respectively???? My god, this is in the realm of basically unusable for agentic coding tools or any kind of service with a prompt that is a few hundred tokens long. e-waste tier even. \n\nYou should try MLX, ollama is quite unoptimized. won't be that much faster I think, since AI models are supposed to be run on the Neural Engine which neither actually supports, but oh well.",
                                "edited": 1751545017,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n142rnn",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;prompt reval rate 13 and 1t/s with 32b and 235ba22b respectively???? My god, this is in the realm of basically unusable for agentic coding tools or any kind of service with a prompt that is a few hundred tokens long. e-waste tier even. &lt;/p&gt;\n\n&lt;p&gt;You should try MLX, ollama is quite unoptimized. won&amp;#39;t be that much faster I think, since AI models are supposed to be run on the Neural Engine which neither actually supports, but oh well.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lq2i2m",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n142rnn/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751544395,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751544395,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n10a090",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "AstroZombie138",
                      "can_mod_post": false,
                      "created_utc": 1751488490,
                      "send_replies": true,
                      "parent_id": "t1_n0zu306",
                      "score": 6,
                      "author_fullname": "t2_3sicn",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "FWIW I'm getting better results with qwen3:32b-fp16 which is 65gb vs qwen3:235b-a22b which is 142gb likely because the 235b is q4.   \n\nIf OP doesn't have a specific need then spending the $7k for the mac studio will never be recovered vs. just paying for Claude code.\n\nThe M3 ultra feels like a dump truck - it can load large models, but responses are pretty darn slow:\n\nollama run qwen3:32b-fp16 \"Write me a 100 word essay on cats\" --verbose  \ntotal duration:       1m2.578191417s\n\nload duration:        23.629124667s\n\nprompt eval count:    21 token(s)\n\nprompt eval duration: 1.544453s\n\nprompt eval rate:     13.60 tokens/s\n\neval count:           392 token(s)\n\neval duration:        37.402778875s\n\neval rate:            10.48 tokens/s\n\n  \nollama run qwen3:235b-a22b \"Write me a 100 word essay on cats\" --verbose  \ntotal duration:       1m19.884717625s\n\nload duration:        47.346249292s\n\nprompt eval count:    21 token(s)\n\nprompt eval duration: 13.834450542s\n\nprompt eval rate:     1.52 tokens/s\n\neval count:           421 token(s)\n\neval duration:        18.702590791s\n\neval rate:            22.51 tokens/s",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n10a090",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;FWIW I&amp;#39;m getting better results with qwen3:32b-fp16 which is 65gb vs qwen3:235b-a22b which is 142gb likely because the 235b is q4.   &lt;/p&gt;\n\n&lt;p&gt;If OP doesn&amp;#39;t have a specific need then spending the $7k for the mac studio will never be recovered vs. just paying for Claude code.&lt;/p&gt;\n\n&lt;p&gt;The M3 ultra feels like a dump truck - it can load large models, but responses are pretty darn slow:&lt;/p&gt;\n\n&lt;p&gt;ollama run qwen3:32b-fp16 &amp;quot;Write me a 100 word essay on cats&amp;quot; --verbose&lt;br/&gt;\ntotal duration:       1m2.578191417s&lt;/p&gt;\n\n&lt;p&gt;load duration:        23.629124667s&lt;/p&gt;\n\n&lt;p&gt;prompt eval count:    21 token(s)&lt;/p&gt;\n\n&lt;p&gt;prompt eval duration: 1.544453s&lt;/p&gt;\n\n&lt;p&gt;prompt eval rate:     13.60 tokens/s&lt;/p&gt;\n\n&lt;p&gt;eval count:           392 token(s)&lt;/p&gt;\n\n&lt;p&gt;eval duration:        37.402778875s&lt;/p&gt;\n\n&lt;p&gt;eval rate:            10.48 tokens/s&lt;/p&gt;\n\n&lt;p&gt;ollama run qwen3:235b-a22b &amp;quot;Write me a 100 word essay on cats&amp;quot; --verbose&lt;br/&gt;\ntotal duration:       1m19.884717625s&lt;/p&gt;\n\n&lt;p&gt;load duration:        47.346249292s&lt;/p&gt;\n\n&lt;p&gt;prompt eval count:    21 token(s)&lt;/p&gt;\n\n&lt;p&gt;prompt eval duration: 13.834450542s&lt;/p&gt;\n\n&lt;p&gt;prompt eval rate:     1.52 tokens/s&lt;/p&gt;\n\n&lt;p&gt;eval count:           421 token(s)&lt;/p&gt;\n\n&lt;p&gt;eval duration:        18.702590791s&lt;/p&gt;\n\n&lt;p&gt;eval rate:            22.51 tokens/s&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lq2i2m",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n10a090/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751488490,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n0zu306",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "robiinn",
            "can_mod_post": false,
            "created_utc": 1751483760,
            "send_replies": true,
            "parent_id": "t3_1lq2i2m",
            "score": 8,
            "author_fullname": "t2_709lt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Maybe Qwen3-235B-A22B, it is 134gb in q4 from or q6 at 200gb, both from Unsloth. Those should also give you plenty of space for context. It would also set you up for any potential releases in the future, ie Qwen3 coder or future larger models.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n0zu306",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe Qwen3-235B-A22B, it is 134gb in q4 from or q6 at 200gb, both from Unsloth. Those should also give you plenty of space for context. It would also set you up for any potential releases in the future, ie Qwen3 coder or future larger models.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n0zu306/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751483760,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lq2i2m",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1064qu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "FullOf_Bad_Ideas",
            "can_mod_post": false,
            "created_utc": 1751487374,
            "send_replies": true,
            "parent_id": "t3_1lq2i2m",
            "score": 5,
            "author_fullname": "t2_9s7pmakgx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt; if it’s worth investing if it means I don’t have to pay for Claude code anymore\n\nNo, it won't be cheaper.\n\nIf you need cheaper, use Qwen3 32B or Qwen3 235B from OpenRouter with some agentic scaffold. Qwen3 32B is hosted by Cerebras with 1k+ t/s output speed, you won't get that on Mac locally, and it's probably cheaper than electricity of the Mac would be if you choose the cheapest provider.\n\nRunning LLMs locally isn't economically better than using API, there are cases where it could work, but in 90% of them it's more expensive and takes more time to set up.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1064qu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;if it’s worth investing if it means I don’t have to pay for Claude code anymore&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No, it won&amp;#39;t be cheaper.&lt;/p&gt;\n\n&lt;p&gt;If you need cheaper, use Qwen3 32B or Qwen3 235B from OpenRouter with some agentic scaffold. Qwen3 32B is hosted by Cerebras with 1k+ t/s output speed, you won&amp;#39;t get that on Mac locally, and it&amp;#39;s probably cheaper than electricity of the Mac would be if you choose the cheapest provider.&lt;/p&gt;\n\n&lt;p&gt;Running LLMs locally isn&amp;#39;t economically better than using API, there are cases where it could work, but in 90% of them it&amp;#39;s more expensive and takes more time to set up.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n1064qu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751487374,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lq2i2m",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n0zthkw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "offlinesir",
            "can_mod_post": false,
            "created_utc": 1751483582,
            "send_replies": true,
            "parent_id": "t3_1lq2i2m",
            "score": 3,
            "author_fullname": "t2_jn5ft2le",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "For local models, the Mac at 96 gb will be able to run larger models, but at some times slow speeds. You could run Qwen 3 235B A22B (maybe) or GLM 32B. However these models might not be as \"agentic\" as you need them to be.\n\nIf you decide you don't want to pay for a new Mac (because it's literally $4000 and that's enough money to have a ton of usage with Claude), Gemini CLI or Gemini code assist is free, and powered by Gemini 2.5 pro, if you are looking for something that's closer to Claude code (still not as good, but free).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n0zthkw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For local models, the Mac at 96 gb will be able to run larger models, but at some times slow speeds. You could run Qwen 3 235B A22B (maybe) or GLM 32B. However these models might not be as &amp;quot;agentic&amp;quot; as you need them to be.&lt;/p&gt;\n\n&lt;p&gt;If you decide you don&amp;#39;t want to pay for a new Mac (because it&amp;#39;s literally $4000 and that&amp;#39;s enough money to have a ton of usage with Claude), Gemini CLI or Gemini code assist is free, and powered by Gemini 2.5 pro, if you are looking for something that&amp;#39;s closer to Claude code (still not as good, but free).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n0zthkw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751483582,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lq2i2m",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n118hnp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "daaain",
            "can_mod_post": false,
            "created_utc": 1751499266,
            "send_replies": true,
            "parent_id": "t3_1lq2i2m",
            "score": 3,
            "author_fullname": "t2_47j85",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Not really, the prompt processing speed isn't great on the Mac, but code assistants – especially agentic ones – need a big system prompt, documentation, and code in the context, which will just keep growing as the agent works.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n118hnp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not really, the prompt processing speed isn&amp;#39;t great on the Mac, but code assistants – especially agentic ones – need a big system prompt, documentation, and code in the context, which will just keep growing as the agent works.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n118hnp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751499266,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lq2i2m",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n10nh3j",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "tibbon",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n10mh2y",
                                "score": 2,
                                "author_fullname": "t2_334qa",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Sure, but what % of its use can you assign to this and run the math on?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n10nh3j",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sure, but what % of its use can you assign to this and run the math on?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lq2i2m",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n10nh3j/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751492457,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751492457,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n10mh2y",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "tru3relativity",
                      "can_mod_post": false,
                      "created_utc": 1751492154,
                      "send_replies": true,
                      "parent_id": "t1_n10lq28",
                      "score": 1,
                      "author_fullname": "t2_dmc3swt9s",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I have other uses for the studio. I am not wanting one just for this.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n10mh2y",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have other uses for the studio. I am not wanting one just for this.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lq2i2m",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n10mh2y/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751492154,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n10lq28",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "tibbon",
            "can_mod_post": false,
            "created_utc": 1751491925,
            "send_replies": true,
            "parent_id": "t3_1lq2i2m",
            "score": 2,
            "author_fullname": "t2_334qa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Can you run the math on this for me? I fail to see the ROI",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n10lq28",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you run the math on this for me? I fail to see the ROI&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n10lq28/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751491925,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lq2i2m",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n0zvmpp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Red_Redditor_Reddit",
            "can_mod_post": false,
            "created_utc": 1751484230,
            "send_replies": true,
            "parent_id": "t3_1lq2i2m",
            "score": 1,
            "author_fullname": "t2_8eelmfjg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "THUDM is my goto, especially THUDM_GLM-4.  It's only 32B and it's the only one that will reliably write things like bash scripts and such.  The context window is a little small, but other than that it's been above the rest.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n0zvmpp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;THUDM is my goto, especially THUDM_GLM-4.  It&amp;#39;s only 32B and it&amp;#39;s the only one that will reliably write things like bash scripts and such.  The context window is a little small, but other than that it&amp;#39;s been above the rest.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lq2i2m/is_there_a_legit_code_assistant_that_can_run_on_a/n0zvmpp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751484230,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lq2i2m",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]