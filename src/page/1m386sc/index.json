[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I am looking to build a system that can run DeepSeekR1 and Kimi K2.\nItems I am not sure of, they are shown side by side.\n\nAMD Epyc 9175F/9375F/9655P - $2,617/$3,550/$5,781\nSP5 Cooler - $130\nH13SSL-NT Motherboard - $730\nCorsair 1500W PSU - $350\n64GB/96GBx12 6400 ECC DDR5 - $4,585 / $7,000\nNvidia 5090 - $3,000\nCase - $200\n\nIt was mentioned a 9015 may work, but I am not sure if would be enough.\n\nI am hoping for ~20 tokens/second.  The math seems to support that range but the cpu is an unknown what the lowest I can get away with without affecting throughput.\n\nI was originally planning to do Q8, but the ram costs are just too much, especially when you factor in the speed hit.  I could get away with 64GB modules, but I'd be limited to less than the full context window.  \n\nWith the middle CPU and 96GB ram, it is looking around $15K.  I do have a 3090 lying around, that would shave $3K off the price, from what I understand the difference in through put will be very minor, but it is significantly faster for prompt processing.  I can always add it later when nvidia gets back to me with the reserve program.  \n\nI do plan on using together.ai to test my use case against DeepSeekR1 and Kimi K2 to see which works best for what I need and if there is enough benefit over Qwen3 32B/235B to justify it.  \n\n~20 tokens/second I feel is a good speed that I can justify running local, much lower and it is just too slow to be practical.\n\nI really wanted to go the route of a RTX 6000 Pro, but unless I am running a 32B/70B model, it just doesn't provide enough performance to justify it with the larger models and I can't justify 7-10 of them.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Thoughts on this DeepSeekR1/Kimi K2 build",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": true,
            "name": "t3_1m386sc",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.5,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_ijzb7",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1752859002,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to build a system that can run DeepSeekR1 and Kimi K2.\nItems I am not sure of, they are shown side by side.&lt;/p&gt;\n\n&lt;p&gt;AMD Epyc 9175F/9375F/9655P - $2,617/$3,550/$5,781\nSP5 Cooler - $130\nH13SSL-NT Motherboard - $730\nCorsair 1500W PSU - $350\n64GB/96GBx12 6400 ECC DDR5 - $4,585 / $7,000\nNvidia 5090 - $3,000\nCase - $200&lt;/p&gt;\n\n&lt;p&gt;It was mentioned a 9015 may work, but I am not sure if would be enough.&lt;/p&gt;\n\n&lt;p&gt;I am hoping for ~20 tokens/second.  The math seems to support that range but the cpu is an unknown what the lowest I can get away with without affecting throughput.&lt;/p&gt;\n\n&lt;p&gt;I was originally planning to do Q8, but the ram costs are just too much, especially when you factor in the speed hit.  I could get away with 64GB modules, but I&amp;#39;d be limited to less than the full context window.  &lt;/p&gt;\n\n&lt;p&gt;With the middle CPU and 96GB ram, it is looking around $15K.  I do have a 3090 lying around, that would shave $3K off the price, from what I understand the difference in through put will be very minor, but it is significantly faster for prompt processing.  I can always add it later when nvidia gets back to me with the reserve program.  &lt;/p&gt;\n\n&lt;p&gt;I do plan on using together.ai to test my use case against DeepSeekR1 and Kimi K2 to see which works best for what I need and if there is enough benefit over Qwen3 32B/235B to justify it.  &lt;/p&gt;\n\n&lt;p&gt;~20 tokens/second I feel is a good speed that I can justify running local, much lower and it is just too slow to be practical.&lt;/p&gt;\n\n&lt;p&gt;I really wanted to go the route of a RTX 6000 Pro, but unless I am running a 32B/70B model, it just doesn&amp;#39;t provide enough performance to justify it with the larger models and I can&amp;#39;t justify 7-10 of them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1m386sc",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "MidnightProgrammer",
            "discussion_type": null,
            "num_comments": 6,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m386sc/thoughts_on_this_deepseekr1kimi_k2_build/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m386sc/thoughts_on_this_deepseekr1kimi_k2_build/",
            "subreddit_subscribers": 500896,
            "created_utc": 1752859002,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "7dba5c08-72f1-11ee-9b6f-ca195bc297d4",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n3v3jri",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "PraxisOG",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n3utjpp",
                                "score": 1,
                                "author_fullname": "t2_3f9vjjno",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "AFAIK you'd be limited by the bandwidth of the cpu to cpu interconnect. It might be massively faster on newer platforms, I've only really looked into 2nd and 3rd gen epyc seriously.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n3v3jri",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "Llama 70B"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;AFAIK you&amp;#39;d be limited by the bandwidth of the cpu to cpu interconnect. It might be massively faster on newer platforms, I&amp;#39;ve only really looked into 2nd and 3rd gen epyc seriously.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m386sc",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m386sc/thoughts_on_this_deepseekr1kimi_k2_build/n3v3jri/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752863903,
                                "author_flair_text": "Llama 70B",
                                "treatment_tags": [],
                                "created_utc": 1752863903,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n3utjpp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MidnightProgrammer",
                      "can_mod_post": false,
                      "created_utc": 1752860995,
                      "send_replies": true,
                      "parent_id": "t1_n3ut57u",
                      "score": 1,
                      "author_fullname": "t2_ijzb7",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I read that dual CPU is only marginally faster and sometimes even worse.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n3utjpp",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I read that dual CPU is only marginally faster and sometimes even worse.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m386sc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m386sc/thoughts_on_this_deepseekr1kimi_k2_build/n3utjpp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752860995,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n3ut57u",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Baldur-Norddahl",
            "can_mod_post": false,
            "created_utc": 1752860882,
            "send_replies": true,
            "parent_id": "t3_1m386sc",
            "score": 1,
            "author_fullname": "t2_bvqb8ng0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What about dual socket motherboard and 2x 9175F ? With 24x 64 GB RAM. More expensive, but could potentially double tps. Ktransformers has a trick with doubling the weights in memory, so each CPU has direct access to the weights without going through the interconnect. Having two CPUs should also be superior to a single with double the cores due to power limits and higher clock frequency.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3ut57u",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What about dual socket motherboard and 2x 9175F ? With 24x 64 GB RAM. More expensive, but could potentially double tps. Ktransformers has a trick with doubling the weights in memory, so each CPU has direct access to the weights without going through the interconnect. Having two CPUs should also be superior to a single with double the cores due to power limits and higher clock frequency.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m386sc/thoughts_on_this_deepseekr1kimi_k2_build/n3ut57u/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752860882,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m386sc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n3v0nrx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "MidnightProgrammer",
                      "can_mod_post": false,
                      "created_utc": 1752863054,
                      "send_replies": true,
                      "parent_id": "t1_n3v02m9",
                      "score": 2,
                      "author_fullname": "t2_ijzb7",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Not enough vram would need 8-16 of them.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n3v0nrx",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not enough vram would need 8-16 of them.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m386sc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m386sc/thoughts_on_this_deepseekr1kimi_k2_build/n3v0nrx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752863054,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n3v02m9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GPTrack_ai",
            "can_mod_post": false,
            "created_utc": 1752862882,
            "send_replies": true,
            "parent_id": "t3_1m386sc",
            "score": 0,
            "author_fullname": "t2_1tpuoj72sa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "RTX Pro 6000...",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3v02m9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;RTX Pro 6000...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m386sc/thoughts_on_this_deepseekr1kimi_k2_build/n3v02m9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752862882,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m386sc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]