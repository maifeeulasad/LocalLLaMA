[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I’m developing an agentic RAG application, and needed your guys’ advice on which open source LLM to use. In your experience, which LLM has the best citation grounding? (i.e, claims it makes with citations should actually exist in the respective citation’s content)\n\nI need near perfect grounding accuracy, and don’t want to rely on too many self-critique iterations ideally. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Best open source LLM for long context RAG?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mel6ma",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.5,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_14c01jhvdt",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754016614,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m developing an agentic RAG application, and needed your guys’ advice on which open source LLM to use. In your experience, which LLM has the best citation grounding? (i.e, claims it makes with citations should actually exist in the respective citation’s content)&lt;/p&gt;\n\n&lt;p&gt;I need near perfect grounding accuracy, and don’t want to rely on too many self-critique iterations ideally. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mel6ma",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "ButterscotchVast2948",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mel6ma/best_open_source_llm_for_long_context_rag/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mel6ma/best_open_source_llm_for_long_context_rag/",
            "subreddit_subscribers": 508191,
            "created_utc": 1754016614,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6a9g1e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ttkciar",
            "can_mod_post": false,
            "created_utc": 1754017189,
            "send_replies": true,
            "parent_id": "t3_1mel6ma",
            "score": 3,
            "author_fullname": "t2_cpegz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Assuming you mean open-weight, I have found Gemma3 to have excellent RAG skills, in both its 12B and 27B sizes.\n\nIn theory it supports up to 128K context, but in practice I have found its inference quality drops off noticeably after about 90K.\n\nI have not formally evaluated it for citation grounding, nor used it this way in production, but just now I prompted  Gemma3-12B to provide citations with a RAG task, and it did refer back to the injected content in its replies, so that is promising.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6a9g1e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Assuming you mean open-weight, I have found Gemma3 to have excellent RAG skills, in both its 12B and 27B sizes.&lt;/p&gt;\n\n&lt;p&gt;In theory it supports up to 128K context, but in practice I have found its inference quality drops off noticeably after about 90K.&lt;/p&gt;\n\n&lt;p&gt;I have not formally evaluated it for citation grounding, nor used it this way in production, but just now I prompted  Gemma3-12B to provide citations with a RAG task, and it did refer back to the injected content in its replies, so that is promising.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mel6ma/best_open_source_llm_for_long_context_rag/n6a9g1e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754017189,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mel6ma",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6a9i2u",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "exaknight21",
            "can_mod_post": false,
            "created_utc": 1754017211,
            "send_replies": true,
            "parent_id": "t3_1mel6ma",
            "score": 2,
            "author_fullname": "t2_1nprbkmy5x",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think it boils down to how good your prompt is. You can go for anything 7-8B plus where anything big is better.\n\nHowever. I recently tried the q4-qwen-30b-a3b in ollama/openwebui for just some test and this thing is noice. Like it packs a punch even at q4 so I can’t even fathom how good this is at higher precisions. \n\nI think the qwen-30b-3b thinking model will be good for agentic rag. \n\nI’m personally trying this tonight and I cannot wait.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6a9i2u",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it boils down to how good your prompt is. You can go for anything 7-8B plus where anything big is better.&lt;/p&gt;\n\n&lt;p&gt;However. I recently tried the q4-qwen-30b-a3b in ollama/openwebui for just some test and this thing is noice. Like it packs a punch even at q4 so I can’t even fathom how good this is at higher precisions. &lt;/p&gt;\n\n&lt;p&gt;I think the qwen-30b-3b thinking model will be good for agentic rag. &lt;/p&gt;\n\n&lt;p&gt;I’m personally trying this tonight and I cannot wait.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mel6ma/best_open_source_llm_for_long_context_rag/n6a9i2u/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754017211,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mel6ma",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]