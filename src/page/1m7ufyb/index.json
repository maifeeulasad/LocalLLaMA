[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "[https://huggingface.co/Kwaipilot/KAT-V1-40B](https://huggingface.co/Kwaipilot/KAT-V1-40B)\n\nNote: I am not affiliated with the model creators",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "KAT-V1-40B: mitigates over-thinking by learning when to produce explicit chain-of-thought and when to answer directly.",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 51,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m7ufyb",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.92,
            "author_flair_background_color": "#bbbdbf",
            "ups": 66,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "is_original_content": false,
            "author_fullname": "t2_fmd6oq5v6",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 66,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/b7Cpt1an0rQVEqyrYVS52lr_kisl0R4_s5HEZLDdmvY.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753329919,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://huggingface.co/Kwaipilot/KAT-V1-40B\"&gt;https://huggingface.co/Kwaipilot/KAT-V1-40B&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Note: I am not affiliated with the model creators&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/nylqnllzxqef1.png",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/nylqnllzxqef1.png?auto=webp&amp;s=2a76625c6790f1b1e80e764391f5c307c370cac0",
                    "width": 4640,
                    "height": 1717
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/nylqnllzxqef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d6375cdf7b48070d3cc2476ca76a5c824b7cacb4",
                      "width": 108,
                      "height": 39
                    },
                    {
                      "url": "https://preview.redd.it/nylqnllzxqef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c177774e33c2e31dc5b68a0742a2340ece6b0bfd",
                      "width": 216,
                      "height": 79
                    },
                    {
                      "url": "https://preview.redd.it/nylqnllzxqef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3d8b0034caf798b019ae8747d6d0f57c58f5c99f",
                      "width": 320,
                      "height": 118
                    },
                    {
                      "url": "https://preview.redd.it/nylqnllzxqef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=10b88450320c1a803baf4cb0625160a4299439c8",
                      "width": 640,
                      "height": 236
                    },
                    {
                      "url": "https://preview.redd.it/nylqnllzxqef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=81b1f737fa5b44c20211f599efaff8fc2d6bda56",
                      "width": 960,
                      "height": 355
                    },
                    {
                      "url": "https://preview.redd.it/nylqnllzxqef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9e969e45713b0734281931d9f2f5f8644a87b5bf",
                      "width": 1080,
                      "height": 399
                    }
                  ],
                  "variants": {},
                  "id": "SMfOoqn7DPSHVtY5DIibrtsaeBB9lXPO6KjdcjAeF8s"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1m7ufyb",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "random-tomato",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "light",
            "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/",
            "stickied": false,
            "url": "https://i.redd.it/nylqnllzxqef1.png",
            "subreddit_subscribers": 503759,
            "created_utc": 1753329919,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4v2mkc",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "LagOps91",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4v1isi",
                                "score": 3,
                                "author_fullname": "t2_3wi6j7vwh",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "let me know how it goes! the model is a bit too large to test for me. looks good if you have 32gb vram however.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4v2mkc",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;let me know how it goes! the model is a bit too large to test for me. looks good if you have 32gb vram however.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7ufyb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4v2mkc/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753343952,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753343952,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4v55od",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "HumerousGorgon8",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4v1isi",
                                "score": 2,
                                "author_fullname": "t2_gbxja",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I mean hey, it's definitely not wrong in its judgement right? Model of the year? /s",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4v55od",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I mean hey, it&amp;#39;s definitely not wrong in its judgement right? Model of the year? /s&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7ufyb",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4v55od/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753345409,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753345409,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4v1isi",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "random-tomato",
                      "can_mod_post": false,
                      "created_utc": 1753343335,
                      "send_replies": true,
                      "parent_id": "t1_n4uwvt0",
                      "score": 5,
                      "author_fullname": "t2_fmd6oq5v6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "sounds a bit too good to be true, downloading right now to test...\n\nEdit: Looks like something with the chat template is wrong:\n\n    Me: What is the integral of cot^4(x) + 3x^2 dx ?\n    Model: The core task is to compute an indefinite integral involving trigonometric and polynomial terms, requiring decomposition and integration techniques. This involves multiple steps like rewriting cotangent and applying integration rules. Solving this demands careful mathematical analysis.\n    &lt;/judge&gt;\n    [model stops here]\n\nEdit 2: Actually it looks quite nice: [https://gist.github.com/qingy1337/095000194b743aef87c433b34aa7b079](https://gist.github.com/qingy1337/095000194b743aef87c433b34aa7b079)\n\nReasoning is concise and surprisingly well formatted",
                      "edited": 1753346166,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4v1isi",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;sounds a bit too good to be true, downloading right now to test...&lt;/p&gt;\n\n&lt;p&gt;Edit: Looks like something with the chat template is wrong:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Me: What is the integral of cot^4(x) + 3x^2 dx ?\nModel: The core task is to compute an indefinite integral involving trigonometric and polynomial terms, requiring decomposition and integration techniques. This involves multiple steps like rewriting cotangent and applying integration rules. Solving this demands careful mathematical analysis.\n&amp;lt;/judge&amp;gt;\n[model stops here]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Edit 2: Actually it looks quite nice: &lt;a href=\"https://gist.github.com/qingy1337/095000194b743aef87c433b34aa7b079\"&gt;https://gist.github.com/qingy1337/095000194b743aef87c433b34aa7b079&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Reasoning is concise and surprisingly well formatted&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7ufyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4v1isi/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753343335,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uwvt0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "LagOps91",
            "can_mod_post": false,
            "created_utc": 1753340728,
            "send_replies": true,
            "parent_id": "t3_1m7ufyb",
            "score": 15,
            "author_fullname": "t2_3wi6j7vwh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "These scores are wild. A 40b model on the level of R1? That's really hard to belive. Did anyone test this model yet? Is it benchmaxxed to hell and back or are these legit scores?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uwvt0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;These scores are wild. A 40b model on the level of R1? That&amp;#39;s really hard to belive. Did anyone test this model yet? Is it benchmaxxed to hell and back or are these legit scores?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4uwvt0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753340728,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7ufyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4vts59",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ReadyAndSalted",
                      "can_mod_post": false,
                      "created_utc": 1753357819,
                      "send_replies": true,
                      "parent_id": "t1_n4v5nj0",
                      "score": 1,
                      "author_fullname": "t2_5vi1y294",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "They used deepseek for data generation? How did their student model beat the teacher model?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4vts59",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They used deepseek for data generation? How did their student model beat the teacher model?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7ufyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4vts59/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753357819,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4v5nj0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Chromix_",
            "can_mod_post": false,
            "created_utc": 1753345696,
            "send_replies": true,
            "parent_id": "t3_1m7ufyb",
            "score": 9,
            "author_fullname": "t2_k7w2h",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The model page doesn't mention it, but this model is Qwen 2.5 32B \"upscaled\" to 40B and then trained further. The additional training was performed with 10M examples (so maybe 10B tokens). DeepSeek V3 was used to generate training data for no-think mode, and an API-only model was used to sort it out. The thinking data was generated using an agentic framework. DeepSeek V3 and R1 generated the auto-think data.\n\nTraining topics were mostly code, math, science, (multi-turn) dialogue and tool use. The science questions were multiple-choice questions - so the same format as used in GPQA for example. A 40B model being close to or winning over V3/R1 in those selected benchmarks requires additional benchmarking to see if it generalizes.\n\nThey plan to release models with less params than 40B (not upscaled, just fine-tuned), as well as their 200B model later, along with the training data. That could be used to more easily check for containing benchmark data.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v5nj0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The model page doesn&amp;#39;t mention it, but this model is Qwen 2.5 32B &amp;quot;upscaled&amp;quot; to 40B and then trained further. The additional training was performed with 10M examples (so maybe 10B tokens). DeepSeek V3 was used to generate training data for no-think mode, and an API-only model was used to sort it out. The thinking data was generated using an agentic framework. DeepSeek V3 and R1 generated the auto-think data.&lt;/p&gt;\n\n&lt;p&gt;Training topics were mostly code, math, science, (multi-turn) dialogue and tool use. The science questions were multiple-choice questions - so the same format as used in GPQA for example. A 40B model being close to or winning over V3/R1 in those selected benchmarks requires additional benchmarking to see if it generalizes.&lt;/p&gt;\n\n&lt;p&gt;They plan to release models with less params than 40B (not upscaled, just fine-tuned), as well as their 200B model later, along with the training data. That could be used to more easily check for containing benchmark data.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4v5nj0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753345696,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7ufyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4uk15v",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "mtmttuan",
            "can_mod_post": false,
            "created_utc": 1753334028,
            "send_replies": true,
            "parent_id": "t3_1m7ufyb",
            "score": 3,
            "author_fullname": "t2_6mjqz0at",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Weird that overthinking seems to happen more on simpler tasks, but their benchmark shows that they're performing better on math and thinking heavy tasks.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uk15v",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Weird that overthinking seems to happen more on simpler tasks, but their benchmark shows that they&amp;#39;re performing better on math and thinking heavy tasks.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4uk15v/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753334028,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7ufyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4ufk5t",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "eloquentemu",
            "can_mod_post": false,
            "created_utc": 1753331914,
            "send_replies": true,
            "parent_id": "t3_1m7ufyb",
            "score": 2,
            "author_fullname": "t2_lpdsy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "For those curious: the 200B is not open and seems like it's TBD if it'll be released.  While initially disappointing, considering it consistently only slightly outperforms the 40B, I'm guessing they used the same relatively small dataset for both or something.  It would be 200B-A40B MoE and sounds like it might actually still be in training?  [Their paper is here](https://arxiv.org/abs/2507.08297)\n\nIt's definitely an interesting approach and I wonder if it has advantages over Qwen3 where they seem to believe that user-selectable thinking degraded performance.  But model-selected might actually not hurt as bad.",
            "edited": 1753332654,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4ufk5t",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For those curious: the 200B is not open and seems like it&amp;#39;s TBD if it&amp;#39;ll be released.  While initially disappointing, considering it consistently only slightly outperforms the 40B, I&amp;#39;m guessing they used the same relatively small dataset for both or something.  It would be 200B-A40B MoE and sounds like it might actually still be in training?  &lt;a href=\"https://arxiv.org/abs/2507.08297\"&gt;Their paper is here&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s definitely an interesting approach and I wonder if it has advantages over Qwen3 where they seem to believe that user-selectable thinking degraded performance.  But model-selected might actually not hurt as bad.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4ufk5t/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753331914,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7ufyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4vl7q1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "tarruda",
            "can_mod_post": false,
            "created_utc": 1753354137,
            "send_replies": true,
            "parent_id": "t3_1m7ufyb",
            "score": 1,
            "author_fullname": "t2_dphk4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Interesting. Before thinking or producing any answer, it starts with a `&lt;judge&gt;` section where it decides if the question or task requires thinking. If it is simple, it outputs a &lt;think_off&gt; tag and immediately starts answering. Its thinking stage is more concise than with deepseek/qwen.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4vl7q1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Interesting. Before thinking or producing any answer, it starts with a &lt;code&gt;&amp;lt;judge&amp;gt;&lt;/code&gt; section where it decides if the question or task requires thinking. If it is simple, it outputs a &amp;lt;think_off&amp;gt; tag and immediately starts answering. Its thinking stage is more concise than with deepseek/qwen.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4vl7q1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753354137,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7ufyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4vqgbf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Normal-Ad-7114",
            "can_mod_post": false,
            "created_utc": 1753356450,
            "send_replies": true,
            "parent_id": "t3_1m7ufyb",
            "score": 1,
            "author_fullname": "t2_8fu8sqhz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "gguf wen",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4vqgbf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;gguf wen&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4vqgbf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753356450,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7ufyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4uznil",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "robiinn",
                      "can_mod_post": false,
                      "created_utc": 1753342269,
                      "send_replies": true,
                      "parent_id": "t1_n4uk2qz",
                      "score": 1,
                      "author_fullname": "t2_709lt",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Nice table to keep track of the latest models, thanks!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4uznil",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice table to keep track of the latest models, thanks!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7ufyb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4uznil/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753342269,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uk2qz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "adt",
            "can_mod_post": false,
            "created_utc": 1753334050,
            "send_replies": true,
            "parent_id": "t3_1m7ufyb",
            "score": 1,
            "author_fullname": "t2_3c2a",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "[https://lifearchitect.ai/models-table/](https://lifearchitect.ai/models-table/)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uk2qz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://lifearchitect.ai/models-table/\"&gt;https://lifearchitect.ai/models-table/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4uk2qz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753334050,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7ufyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4uq6a7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "HistorianPotential48",
            "can_mod_post": false,
            "created_utc": 1753337134,
            "send_replies": true,
            "parent_id": "t3_1m7ufyb",
            "score": 1,
            "author_fullname": "t2_4dzthia7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "i love how each new model adds 1\\~2 new one-model-use XML tags haha",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uq6a7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;i love how each new model adds 1~2 new one-model-use XML tags haha&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7ufyb/katv140b_mitigates_overthinking_by_learning_when/n4uq6a7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753337134,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7ufyb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]