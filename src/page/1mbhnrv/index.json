[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I have both Qwen3-14B-FP8 and Qwen3-32B hosted with vLLM. Both have tool calling enabled. \n\nIn my prompt i have few-shot examples. What i am observing is the bigger model hallucinating with values present in the few-shot examples instead of fetching the data from tools and also tool calls being very inconsistent. In contrast, the quantized lower 14B model is not giving such issues.\n\nBoth were downloaded from Hugging face official Qwen repository. How to explain this",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Qwen3-14B-FP8 vs Qwen3-32B - Hallucination and Tool Calling",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mbhnrv",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.89,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 7,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_bvk1o",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 7,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753712861,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have both Qwen3-14B-FP8 and Qwen3-32B hosted with vLLM. Both have tool calling enabled. &lt;/p&gt;\n\n&lt;p&gt;In my prompt i have few-shot examples. What i am observing is the bigger model hallucinating with values present in the few-shot examples instead of fetching the data from tools and also tool calls being very inconsistent. In contrast, the quantized lower 14B model is not giving such issues.&lt;/p&gt;\n\n&lt;p&gt;Both were downloaded from Hugging face official Qwen repository. How to explain this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mbhnrv",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "dnivra26",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mbhnrv/qwen314bfp8_vs_qwen332b_hallucination_and_tool/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mbhnrv/qwen314bfp8_vs_qwen332b_hallucination_and_tool/",
            "subreddit_subscribers": 506191,
            "created_utc": 1753712861,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5mg2ua",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Lesser-than",
            "can_mod_post": false,
            "created_utc": 1753716279,
            "send_replies": true,
            "parent_id": "t3_1mbhnrv",
            "score": 3,
            "author_fullname": "t2_98d256k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I assume you are presenting the tooling the same to both? I find depending how you are presenting the tooling qwen3 models of different sizes can present problems and I do not have any idea why either, smaller models make better decisions so far in my tests, where the larger the models they seem to over explore all parameters infinitly if allowed. if you can narrow the scope of the tools you allow them to know about per request is all I can say.",
            "edited": 1753726015,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5mg2ua",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I assume you are presenting the tooling the same to both? I find depending how you are presenting the tooling qwen3 models of different sizes can present problems and I do not have any idea why either, smaller models make better decisions so far in my tests, where the larger the models they seem to over explore all parameters infinitly if allowed. if you can narrow the scope of the tools you allow them to know about per request is all I can say.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbhnrv/qwen314bfp8_vs_qwen332b_hallucination_and_tool/n5mg2ua/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753716279,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbhnrv",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5mgti5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GortKlaatu_",
            "can_mod_post": false,
            "created_utc": 1753716493,
            "send_replies": true,
            "parent_id": "t3_1mbhnrv",
            "score": 1,
            "author_fullname": "t2_ixeagk4w",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What does your react prompt look like? Are your sections clear?\n\nIn your few shot examples are you only giving examples of the tool calls or are you including observations leading to confusion?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5mgti5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What does your react prompt look like? Are your sections clear?&lt;/p&gt;\n\n&lt;p&gt;In your few shot examples are you only giving examples of the tool calls or are you including observations leading to confusion?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbhnrv/qwen314bfp8_vs_qwen332b_hallucination_and_tool/n5mgti5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753716493,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbhnrv",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]