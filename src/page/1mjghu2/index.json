[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "As the title says Qwen3-4B is a gift for us people without a dedicated GPU. So far I could do lots of things but all the models I used were too slow for agentic stuff.\n\nThe problem used to be that agents need a lot of context. Prompts with 3000+ tokens are completely normal. \n\nWith a bigger model it would take ages to process the prompt, even if the response then was of good quality. There's just no back and forth if for everything you want to do you have to wait for 10 minutes. \n\nThe combination of the speed of a 4B model with the agentic capabilities plus its coding knowledge which is really decent for a model that size unlocks a whole lot of new use cases for me.\n\nOn my AMD Ryzen 7 7735HS  with DDR5 RAM I get around 90t/s for prompt processing and 17t/s for generation. But as I said: Processing is almost more important than generation in agentic use cases.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Qwen3-4B enables agentic use cases for us iGPU folks",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Other"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjghu2",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.93,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 46,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_17gl7k",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Other",
            "can_mod_post": false,
            "score": 46,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754513879,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title says Qwen3-4B is a gift for us people without a dedicated GPU. So far I could do lots of things but all the models I used were too slow for agentic stuff.&lt;/p&gt;\n\n&lt;p&gt;The problem used to be that agents need a lot of context. Prompts with 3000+ tokens are completely normal. &lt;/p&gt;\n\n&lt;p&gt;With a bigger model it would take ages to process the prompt, even if the response then was of good quality. There&amp;#39;s just no back and forth if for everything you want to do you have to wait for 10 minutes. &lt;/p&gt;\n\n&lt;p&gt;The combination of the speed of a 4B model with the agentic capabilities plus its coding knowledge which is really decent for a model that size unlocks a whole lot of new use cases for me.&lt;/p&gt;\n\n&lt;p&gt;On my AMD Ryzen 7 7735HS  with DDR5 RAM I get around 90t/s for prompt processing and 17t/s for generation. But as I said: Processing is almost more important than generation in agentic use cases.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#94e044",
            "id": "1mjghu2",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "leuchtetgruen",
            "discussion_type": null,
            "num_comments": 15,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/",
            "subreddit_subscribers": 512875,
            "created_utc": 1754513879,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dw5ln",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "InsideYork",
                      "can_mod_post": false,
                      "created_utc": 1754557595,
                      "send_replies": true,
                      "parent_id": "t1_n7ccqjn",
                      "score": 2,
                      "author_fullname": "t2_12s3hn4y0b",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Be the change you want to be https://i.imgur.com/4wb0GuO.png",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dw5ln",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Be the change you want to be &lt;a href=\"https://i.imgur.com/4wb0GuO.png\"&gt;https://i.imgur.com/4wb0GuO.png&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjghu2",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7dw5ln/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754557595,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7ccqjn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ElectronSpiderwort",
            "can_mod_post": false,
            "created_utc": 1754531370,
            "send_replies": true,
            "parent_id": "t3_1mjghu2",
            "score": 12,
            "author_fullname": "t2_mxbu5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This model is amazing on large prompts. It handles certain (non-coding, non-agentic) 40K token prompts I've been testing as well as any 32b model I've tried, and much, MUCH better than any smaller model I've tried. With all the OSS-20B noise I'm afraid this one is getting lost in the shuffle",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7ccqjn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This model is amazing on large prompts. It handles certain (non-coding, non-agentic) 40K token prompts I&amp;#39;ve been testing as well as any 32b model I&amp;#39;ve tried, and much, MUCH better than any smaller model I&amp;#39;ve tried. With all the OSS-20B noise I&amp;#39;m afraid this one is getting lost in the shuffle&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7ccqjn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754531370,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjghu2",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 12
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7bz8t5",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "leuchtetgruen",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7bhd22",
                                          "score": 4,
                                          "author_fullname": "t2_17gl7k",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "The new seems to have improved a lot",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7bz8t5",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The new seems to have improved a lot&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjghu2",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7bz8t5/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754526692,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754526692,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7bhd22",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "cms2307",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7bd9pj",
                                "score": 5,
                                "author_fullname": "t2_1otju2ya",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Is it really good for mcp? Personally both the regular Qwen3 4b and a finetune called Jan-nano both perform pretty bad with mcp, even when I explain how and when to use what tools",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7bhd22",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is it really good for mcp? Personally both the regular Qwen3 4b and a finetune called Jan-nano both perform pretty bad with mcp, even when I explain how and when to use what tools&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjghu2",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7bhd22/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754520726,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754520726,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7bd9pj",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "leuchtetgruen",
                      "can_mod_post": false,
                      "created_utc": 1754519365,
                      "send_replies": true,
                      "parent_id": "t1_n7b88ni",
                      "score": 8,
                      "author_fullname": "t2_17gl7k",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "\\- Coding with Aider or QwenCLI .   \n\\- Using MCP servers in Msty.   \n\\- I'm currently looking into smolagents to see if I can build something useful with it.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7bd9pj",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;- Coding with Aider or QwenCLI .&lt;br/&gt;\n- Using MCP servers in Msty.&lt;br/&gt;\n- I&amp;#39;m currently looking into smolagents to see if I can build something useful with it.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjghu2",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7bd9pj/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754519365,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 8
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7b93k0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BanaBreadSingularity",
                      "can_mod_post": false,
                      "created_utc": 1754518037,
                      "send_replies": true,
                      "parent_id": "t1_n7b88ni",
                      "score": 1,
                      "author_fullname": "t2_11d4n76hca",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I'd also be curious on that front!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7b93k0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d also be curious on that front!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjghu2",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7b93k0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754518037,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7b88ni",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "jackdareel",
            "can_mod_post": false,
            "created_utc": 1754517767,
            "send_replies": true,
            "parent_id": "t3_1mjghu2",
            "score": 6,
            "author_fullname": "t2_1puly589vf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What sort of agentic things do you do with this setup and how do you implement them?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7b88ni",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What sort of agentic things do you do with this setup and how do you implement them?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7b88ni/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754517767,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjghu2",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7cx0o0",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "PermanentLiminality",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7c69v2",
                                "score": 2,
                                "author_fullname": "t2_19zqycaf",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "eBay.  I bought mine for $40;but the price has gone up.  Pretty much Linux only.  You can get it to load windows drivers, but it's not easy",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7cx0o0",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;eBay.  I bought mine for $40;but the price has gone up.  Pretty much Linux only.  You can get it to load windows drivers, but it&amp;#39;s not easy&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjghu2",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7cx0o0/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754539124,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754539124,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7c69v2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "DarKresnik",
                      "can_mod_post": false,
                      "created_utc": 1754529112,
                      "send_replies": true,
                      "parent_id": "t1_n7aybmr",
                      "score": 4,
                      "author_fullname": "t2_tooo5sfu4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "$60? Where?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7c69v2",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;$60? Where?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjghu2",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7c69v2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754529112,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7b8qx4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "hehsteve",
                      "can_mod_post": false,
                      "created_utc": 1754517928,
                      "send_replies": true,
                      "parent_id": "t1_n7aybmr",
                      "score": 3,
                      "author_fullname": "t2_4ucpgien",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This with the 4B model?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7b8qx4",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This with the 4B model?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjghu2",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7b8qx4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754517928,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7aybmr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "PermanentLiminality",
            "can_mod_post": false,
            "created_utc": 1754514770,
            "send_replies": true,
            "parent_id": "t3_1mjghu2",
            "score": 6,
            "author_fullname": "t2_19zqycaf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Drop $60 on a P102-100 and get up to 1000 tk/s prompt processing.  I get 20 to 35 tk/s of generation speed with the lower numbers when I drop a lot of context on it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7aybmr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Drop $60 on a P102-100 and get up to 1000 tk/s prompt processing.  I get 20 to 35 tk/s of generation speed with the lower numbers when I drop a lot of context on it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7aybmr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754514770,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjghu2",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7b8yld",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "hehsteve",
            "can_mod_post": false,
            "created_utc": 1754517994,
            "send_replies": true,
            "parent_id": "t3_1mjghu2",
            "score": 1,
            "author_fullname": "t2_4ucpgien",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you have luck getting this model to use tools let me know. Have been looking for something this size that can!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7b8yld",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you have luck getting this model to use tools let me know. Have been looking for something this size that can!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7b8yld/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754517994,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjghu2",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7dpuop",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Iory1998",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7dokrw",
                                "score": 4,
                                "author_fullname": "t2_byt5wa14",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I agree, but what impressed me with this model is it's ability to understand long context in an article about 76K tokens. What I do is provide a paper written by Hawkins about Black holes, and in it I randomly insert the phase \"MY PASSWORD IS xxx\". Then I ask the model to find the most out of context sentence or a phrase. \n\nThis does not only require the model to retrieve a piece of info from a text, but the understand the text in order for it to identify the most out of context sentence. \n\nFor your info, many many models failed this text. The Qwen-4B-Instuct model managed to find the sentence in a text of 38K but failed at 76K. The thinking version managed to find the odd phrase in both texts.\n\nhttps://preview.redd.it/ksy4pfe51khf1.png?width=998&amp;format=png&amp;auto=webp&amp;s=3a328e7178492ec6598d64b8f3143b84808de0e7",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7dpuop",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree, but what impressed me with this model is it&amp;#39;s ability to understand long context in an article about 76K tokens. What I do is provide a paper written by Hawkins about Black holes, and in it I randomly insert the phase &amp;quot;MY PASSWORD IS xxx&amp;quot;. Then I ask the model to find the most out of context sentence or a phrase. &lt;/p&gt;\n\n&lt;p&gt;This does not only require the model to retrieve a piece of info from a text, but the understand the text in order for it to identify the most out of context sentence. &lt;/p&gt;\n\n&lt;p&gt;For your info, many many models failed this text. The Qwen-4B-Instuct model managed to find the sentence in a text of 38K but failed at 76K. The thinking version managed to find the odd phrase in both texts.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ksy4pfe51khf1.png?width=998&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3a328e7178492ec6598d64b8f3143b84808de0e7\"&gt;https://preview.redd.it/ksy4pfe51khf1.png?width=998&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3a328e7178492ec6598d64b8f3143b84808de0e7&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjghu2",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7dpuop/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754553932,
                                "media_metadata": {
                                  "ksy4pfe51khf1": {
                                    "status": "valid",
                                    "e": "Image",
                                    "m": "image/png",
                                    "p": [
                                      {
                                        "y": 93,
                                        "x": 108,
                                        "u": "https://preview.redd.it/ksy4pfe51khf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b1ef31fe519d0629d09e4e9919c429e99ef6a36c"
                                      },
                                      {
                                        "y": 186,
                                        "x": 216,
                                        "u": "https://preview.redd.it/ksy4pfe51khf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ffcce1a20f009627081882436afeabc6e76e8c5a"
                                      },
                                      {
                                        "y": 276,
                                        "x": 320,
                                        "u": "https://preview.redd.it/ksy4pfe51khf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c242fe18ee9bba2be1eb2d4030e345df45ebf052"
                                      },
                                      {
                                        "y": 553,
                                        "x": 640,
                                        "u": "https://preview.redd.it/ksy4pfe51khf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c0499d54cc03c22ffdd4ee1e98505d7f6a3f9d3c"
                                      },
                                      {
                                        "y": 830,
                                        "x": 960,
                                        "u": "https://preview.redd.it/ksy4pfe51khf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=37267dc6d6b977c1e100d22646eca9cb46b188af"
                                      }
                                    ],
                                    "s": {
                                      "y": 863,
                                      "x": 998,
                                      "u": "https://preview.redd.it/ksy4pfe51khf1.png?width=998&amp;format=png&amp;auto=webp&amp;s=3a328e7178492ec6598d64b8f3143b84808de0e7"
                                    },
                                    "id": "ksy4pfe51khf1"
                                  }
                                },
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754553932,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7dokrw",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "leuchtetgruen",
                      "can_mod_post": false,
                      "created_utc": 1754553208,
                      "send_replies": true,
                      "parent_id": "t1_n7dnxtk",
                      "score": 5,
                      "author_fullname": "t2_17gl7k",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "it is. but oftentimes you can get away with just the instruct version if you don't want it to do something complicated. saves a lot of time and makes using it more interactive.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7dokrw",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it is. but oftentimes you can get away with just the instruct version if you don&amp;#39;t want it to do something complicated. saves a lot of time and makes using it more interactive.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjghu2",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7dokrw/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754553208,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7dnxtk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Iory1998",
            "can_mod_post": false,
            "created_utc": 1754552837,
            "send_replies": true,
            "parent_id": "t3_1mjghu2",
            "score": 1,
            "author_fullname": "t2_byt5wa14",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The thinking version of Qwen3-4B is amazing.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7dnxtk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The thinking version of Qwen3-4B is amazing.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjghu2/qwen34b_enables_agentic_use_cases_for_us_igpu/n7dnxtk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754552837,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mjghu2",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]