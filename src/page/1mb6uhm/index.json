[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "This 96GB device cost around $1000. Has anyone tried it before? Can it host small LLMs?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "is_gallery": true,
            "title": "Pi AI studio",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 140,
            "top_awarded_type": null,
            "name": "t3_1mb6uhm",
            "media_metadata": {
              "io3zh7vvljff1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 216,
                    "x": 108,
                    "u": "https://preview.redd.it/io3zh7vvljff1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5a031dd6a78ca78f710666be866e981ee7135dc9"
                  },
                  {
                    "y": 432,
                    "x": 216,
                    "u": "https://preview.redd.it/io3zh7vvljff1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=39cfe9174a7a74e10f48ae66d3175072b1ef8664"
                  },
                  {
                    "y": 640,
                    "x": 320,
                    "u": "https://preview.redd.it/io3zh7vvljff1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=74632cfc94fc37c9342bb614007f396ff2301b8a"
                  },
                  {
                    "y": 1280,
                    "x": 640,
                    "u": "https://preview.redd.it/io3zh7vvljff1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=37ace78e69a187b8dbb49ab43de2bc8d0f528cca"
                  },
                  {
                    "y": 1920,
                    "x": 960,
                    "u": "https://preview.redd.it/io3zh7vvljff1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9ef8fdf6bbdd3f7aa4b294eed48b04dfbd1821d4"
                  },
                  {
                    "y": 2160,
                    "x": 1080,
                    "u": "https://preview.redd.it/io3zh7vvljff1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=01fd6463d6b1d1538256fb3a7bad2e9f6f1c9122"
                  }
                ],
                "s": {
                  "y": 2400,
                  "x": 1080,
                  "u": "https://preview.redd.it/io3zh7vvljff1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=ddf4ff8a9b818944ac69cbaca2259b5ab8a6f84e"
                },
                "id": "io3zh7vvljff1"
              },
              "mxj32e7wljff1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 216,
                    "x": 108,
                    "u": "https://preview.redd.it/mxj32e7wljff1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9a34a029a632dba6beec578ec95443846312054c"
                  },
                  {
                    "y": 432,
                    "x": 216,
                    "u": "https://preview.redd.it/mxj32e7wljff1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2648b94731a5cf86cc8d56b83c22b31d7177fd6c"
                  },
                  {
                    "y": 640,
                    "x": 320,
                    "u": "https://preview.redd.it/mxj32e7wljff1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1126982e218fe456c6e5bdc9a4ad505cdf0dd9b7"
                  },
                  {
                    "y": 1280,
                    "x": 640,
                    "u": "https://preview.redd.it/mxj32e7wljff1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=249569c0a5f5e7b11183d4a40927f597fce8ebb2"
                  },
                  {
                    "y": 1920,
                    "x": 960,
                    "u": "https://preview.redd.it/mxj32e7wljff1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0b85d11e9a23df0d1b970019ec2b17c6bc4933b8"
                  },
                  {
                    "y": 2160,
                    "x": 1080,
                    "u": "https://preview.redd.it/mxj32e7wljff1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=59333d0ac25ca41bedfe7183438d1dafd6d1c58e"
                  }
                ],
                "s": {
                  "y": 2400,
                  "x": 1080,
                  "u": "https://preview.redd.it/mxj32e7wljff1.png?width=1080&amp;format=png&amp;auto=webp&amp;s=5c585ab548f34f58a7f7e9091d86c861ec8817f6"
                },
                "id": "mxj32e7wljff1"
              }
            },
            "hide_score": false,
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.91,
            "author_flair_background_color": null,
            "ups": 122,
            "domain": "reddit.com",
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_25by3xfc",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "gallery_data": {
              "items": [
                {
                  "caption": "",
                  "media_id": "io3zh7vvljff1",
                  "id": 715628465
                },
                {
                  "caption": "",
                  "media_id": "mxj32e7wljff1",
                  "id": 715628466
                }
              ]
            },
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 122,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/CP9KFtIHMzNxz_IXwevaJpIQ_DH-LieoKpFIOifsV_Q.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753676939,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This 96GB device cost around $1000. Has anyone tried it before? Can it host small LLMs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://www.reddit.com/gallery/1mb6uhm",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mb6uhm",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "koumoua01",
            "discussion_type": null,
            "num_comments": 27,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/",
            "stickied": false,
            "url": "https://www.reddit.com/gallery/1mb6uhm",
            "subreddit_subscribers": 506191,
            "created_utc": 1753676939,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5kkbwa",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "qado",
                      "can_mod_post": false,
                      "created_utc": 1753688135,
                      "send_replies": true,
                      "parent_id": "t1_n5k02vi",
                      "score": 16,
                      "author_fullname": "t2_i4zxm",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Minimum",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5kkbwa",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Minimum&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb6uhm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kkbwa/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753688135,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 16
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5k02vi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Robos_Basilisk",
            "can_mod_post": false,
            "created_utc": 1753677303,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 69,
            "author_fullname": "t2_ta1dmorpo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "LPDDR4X is slow, should be 5X",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5k02vi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;LPDDR4X is slow, should be 5X&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5k02vi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753677303,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 69
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5k04ke",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Mysterious_Finish543",
            "can_mod_post": false,
            "created_utc": 1753677326,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 45,
            "author_fullname": "t2_gbx2bcdvl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Haven't seen much about the Ascend 310, but I believe it is pretty weak, likely comparable to Nvidia's Jetson Orin Nano. Good enough for some simpler neural nets, but decent LLMs are likely a stretch.\n\nAlso, LPDDR4x memory won't offer nearly enough memory bandwidth.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5k04ke",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Haven&amp;#39;t seen much about the Ascend 310, but I believe it is pretty weak, likely comparable to Nvidia&amp;#39;s Jetson Orin Nano. Good enough for some simpler neural nets, but decent LLMs are likely a stretch.&lt;/p&gt;\n\n&lt;p&gt;Also, LPDDR4x memory won&amp;#39;t offer nearly enough memory bandwidth.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5k04ke/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753677326,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 45
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5lr4tu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Velicoma",
                      "can_mod_post": false,
                      "created_utc": 1753708739,
                      "send_replies": true,
                      "parent_id": "t1_n5kyyhz",
                      "score": 6,
                      "author_fullname": "t2_5j9pj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That's gotta be 3.8GB/s per chip or something, because SK Hynix 8GB sticks were hitting 34GB/s here: https://www.anandtech.com/show/11021/sk-hynix-announces-8-gb-lpddr4x4266-dram-packages",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5lr4tu",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s gotta be 3.8GB/s per chip or something, because SK Hynix 8GB sticks were hitting 34GB/s here: &lt;a href=\"https://www.anandtech.com/show/11021/sk-hynix-announces-8-gb-lpddr4x4266-dram-packages\"&gt;https://www.anandtech.com/show/11021/sk-hynix-announces-8-gb-lpddr4x4266-dram-packages&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb6uhm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5lr4tu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753708739,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5pbk4u",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Virtual-Cobbler-9930",
                      "can_mod_post": false,
                      "created_utc": 1753746496,
                      "send_replies": true,
                      "parent_id": "t1_n5kyyhz",
                      "score": 2,
                      "author_fullname": "t2_7vrhfr9d",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "You pulling numbers out of your ass, don't you? ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5pbk4u",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You pulling numbers out of your ass, don&amp;#39;t you? &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb6uhm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5pbk4u/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753746496,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5kyyhz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "sunshinecheung",
            "can_mod_post": false,
            "created_utc": 1753696661,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 17,
            "author_fullname": "t2_u398xzta",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "LPDDR4X bandwidth 3.8GB/s\n\nand mac ai studio bandwidth  546GB/s ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kyyhz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;LPDDR4X bandwidth 3.8GB/s&lt;/p&gt;\n\n&lt;p&gt;and mac ai studio bandwidth  546GB/s &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kyyhz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753696661,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 17
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5lzxim",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "fonix232",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5lr96j",
                                          "score": 4,
                                          "author_fullname": "t2_aricd",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I think they might have meant MT/s which would give a much more manageable ~100GBps, making it in line with LPDDR4X in general.\n\nStill quite slow but should be usable for small to medium models and it's quite low power usage, especially compared to a 3090.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5lzxim",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think they might have meant MT/s which would give a much more manageable ~100GBps, making it in line with LPDDR4X in general.&lt;/p&gt;\n\n&lt;p&gt;Still quite slow but should be usable for small to medium models and it&amp;#39;s quite low power usage, especially compared to a 3090.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mb6uhm",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5lzxim/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753711553,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753711553,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5lr96j",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Lissanro",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5l3p38",
                                "score": 3,
                                "author_fullname": "t2_fpfao9g",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "4266 Mbps = 533 MB/s...  compared to 3090 memory bandwidth 936.2 GB/s, that's nothing.  These days even 8-channel DDR4 bandwidth of 204.80 GB/s feels slow.\n\nEven if they made typo in specs and meant MB/s and not Mbps, using 48GB or 96GB of memory that slow for LLM is not going to be practical, even if MoE. At best, maybe it could run Qwen3 30B-A3B, perhaps even modified A1.5B version to speed things up; anything larger is not going to be practical with memory this slow.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5lr96j",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;4266 Mbps = 533 MB/s...  compared to 3090 memory bandwidth 936.2 GB/s, that&amp;#39;s nothing.  These days even 8-channel DDR4 bandwidth of 204.80 GB/s feels slow.&lt;/p&gt;\n\n&lt;p&gt;Even if they made typo in specs and meant MB/s and not Mbps, using 48GB or 96GB of memory that slow for LLM is not going to be practical, even if MoE. At best, maybe it could run Qwen3 30B-A3B, perhaps even modified A1.5B version to speed things up; anything larger is not going to be practical with memory this slow.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mb6uhm",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5lr96j/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753708780,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753708780,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5m969n",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Double_Cause4609",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5l3p38",
                                "score": 3,
                                "author_fullname": "t2_1kubzxt2ww",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "No, that's the speed of an individual lane I'm pretty sure. The issue is LPDDR can have anywhere between 16 and 256 lanes (or possibly more. Maybe 386 is possible).\n\nThat puts it at anywhere between 8GB/s and \\~250GB/s.\n\nThis is why I hate LPDDR as a spec, because nobody ever gives you the information you need to infer the bandwidth. It's super annoying.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5m969n",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, that&amp;#39;s the speed of an individual lane I&amp;#39;m pretty sure. The issue is LPDDR can have anywhere between 16 and 256 lanes (or possibly more. Maybe 386 is possible).&lt;/p&gt;\n\n&lt;p&gt;That puts it at anywhere between 8GB/s and ~250GB/s.&lt;/p&gt;\n\n&lt;p&gt;This is why I hate LPDDR as a spec, because nobody ever gives you the information you need to infer the bandwidth. It&amp;#39;s super annoying.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mb6uhm",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5m969n/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753714297,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753714297,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5l3p38",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "fonix232",
                      "can_mod_post": false,
                      "created_utc": 1753699209,
                      "send_replies": true,
                      "parent_id": "t1_n5k186b",
                      "score": 2,
                      "author_fullname": "t2_aricd",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "We do know the memory bandwidth: a maximum of 4266Mbps. It's written right in the specs.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5l3p38",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We do know the memory bandwidth: a maximum of 4266Mbps. It&amp;#39;s written right in the specs.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb6uhm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5l3p38/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753699209,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5k186b",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Double_Cause4609",
            "can_mod_post": false,
            "created_utc": 1753677858,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 11,
            "author_fullname": "t2_1kubzxt2ww",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don't believe we know the memory bandwidth from just these specs, which is the important part.\n\nThe problem with LPDDR is it's a massive PITA to get clear numbers on how fast it actually is because there's so many variations in the implementation (and in particular the aggregate bus width), so it's like...\n\nThis could be anywhere between 5 T/s on a 7B model and 40 T/s, and it's not immediately obvious which it is.\n\nEither way it would run small language models, and it would run medium sized MoE models probably about the same, too (ie: qwen 3 30B, maybe DOTS, etc).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5k186b",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t believe we know the memory bandwidth from just these specs, which is the important part.&lt;/p&gt;\n\n&lt;p&gt;The problem with LPDDR is it&amp;#39;s a massive PITA to get clear numbers on how fast it actually is because there&amp;#39;s so many variations in the implementation (and in particular the aggregate bus width), so it&amp;#39;s like...&lt;/p&gt;\n\n&lt;p&gt;This could be anywhere between 5 T/s on a 7B model and 40 T/s, and it&amp;#39;s not immediately obvious which it is.&lt;/p&gt;\n\n&lt;p&gt;Either way it would run small language models, and it would run medium sized MoE models probably about the same, too (ie: qwen 3 30B, maybe DOTS, etc).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5k186b/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753677858,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 11
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5k0jcp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ViRROOO",
            "can_mod_post": false,
            "created_utc": 1753677526,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 19,
            "author_fullname": "t2_11nncq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You could run 70b (8-bit quants) or some 100b+ models at int4 in that, if the specs are real. Im less impressed by the memory speed, as that will affect your token/s quite heavily.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5k0jcp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You could run 70b (8-bit quants) or some 100b+ models at int4 in that, if the specs are real. Im less impressed by the memory speed, as that will affect your token/s quite heavily.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5k0jcp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753677526,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 19
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5kd006",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "aliencaocao",
            "can_mod_post": false,
            "created_utc": 1753684026,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 7,
            "author_fullname": "t2_tbgpfrb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "the 310 is dog shit, tried before on huawei cloud. Slower than t4",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kd006",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;the 310 is dog shit, tried before on huawei cloud. Slower than t4&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kd006/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753684026,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5kuggw",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "LegitMichel777",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5kjpy4",
                                "score": 1,
                                "author_fullname": "t2_e0eciwl",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "you’re absolutely right. checking the typical specs for lpddr4x, a single package is typically 16GB capacity with 32-bit bus width, meaning that each package has 4266\\*32/8=17GB/s. this is half of what i calculated, so it’ll actually have around 17\\*6=102 GB/s of memory bandwidth. but this is assuming 16GB per package. if they used 8GB per package, it could actually achieve 204GB/s, though the large amount of packages will make it expensive. let me know if there are any other potential inaccuracies!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5kuggw",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;you’re absolutely right. checking the typical specs for lpddr4x, a single package is typically 16GB capacity with 32-bit bus width, meaning that each package has 4266*32/8=17GB/s. this is half of what i calculated, so it’ll actually have around 17*6=102 GB/s of memory bandwidth. but this is assuming 16GB per package. if they used 8GB per package, it could actually achieve 204GB/s, though the large amount of packages will make it expensive. let me know if there are any other potential inaccuracies!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mb6uhm",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kuggw/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753694097,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753694097,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5kjpy4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Dr_Allcome",
                      "can_mod_post": false,
                      "created_utc": 1753687777,
                      "send_replies": true,
                      "parent_id": "t1_n5kdemv",
                      "score": 6,
                      "author_fullname": "t2_10ekxq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "There is no way that thing has even close to 200GB/s on DDR4",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5kjpy4",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There is no way that thing has even close to 200GB/s on DDR4&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb6uhm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kjpy4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753687777,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5ky0q1",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "LegitMichel777",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5ki74p",
                                "score": 3,
                                "author_fullname": "t2_e0eciwl",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "it’s the same math; take the 102GB/s number and divide it by the size of the model’s activated parameters plus the expected KV cache size; for example, for Qwen 30BA3B, 3B are activated. at Q4, that’s about 1.5GB for activated parameters. assuming 1GB for kv cache, that’s 2.5GB total. 102/2.5=40.8 tokens / second.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5ky0q1",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it’s the same math; take the 102GB/s number and divide it by the size of the model’s activated parameters plus the expected KV cache size; for example, for Qwen 30BA3B, 3B are activated. at Q4, that’s about 1.5GB for activated parameters. assuming 1GB for kv cache, that’s 2.5GB total. 102/2.5=40.8 tokens / second.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mb6uhm",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5ky0q1/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753696149,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753696149,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ki74p",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "SpecialBeatForce",
                      "can_mod_post": false,
                      "created_utc": 1753686892,
                      "send_replies": true,
                      "parent_id": "t1_n5kdemv",
                      "score": 1,
                      "author_fullname": "t2_6p2gux0e",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Im definetly pasting this into Gemini for explanation 😂\n\nSo QWQ:32B would work… Can you do Quick Math for a MoE Model? They seem to be more optimal for this Kind of Hardware Or am I wrong here?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ki74p",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Im definetly pasting this into Gemini for explanation 😂&lt;/p&gt;\n\n&lt;p&gt;So QWQ:32B would work… Can you do Quick Math for a MoE Model? They seem to be more optimal for this Kind of Hardware Or am I wrong here?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb6uhm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5ki74p/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753686892,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5kp69u",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Dr_Allcome",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5kl6ce",
                                "score": 2,
                                "author_fullname": "t2_10ekxq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The 408GB/s was only for the AI accelerator card (Atlas 300I duo inference card) not for the machine itself.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5kp69u",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The 408GB/s was only for the AI accelerator card (Atlas 300I duo inference card) not for the machine itself.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mb6uhm",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kp69u/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753690972,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753690972,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5kl6ce",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Dramatic-Zebra-7213",
                      "can_mod_post": false,
                      "created_utc": 1753688633,
                      "send_replies": true,
                      "parent_id": "t1_n5kdemv",
                      "score": 1,
                      "author_fullname": "t2_4tpi1g8j8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This calculation is correct. I saw the specs for this earlier and it has two models Pro and non-pro. The Pro was claimed to have a memory bandwidth of 408GB/s, and it had twice the compute and ram compared to non-pro, so it is fair to assume the pro is just 2X version in every way, meaning the regular version will have a bandwidth of 204GB/s.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5kl6ce",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This calculation is correct. I saw the specs for this earlier and it has two models Pro and non-pro. The Pro was claimed to have a memory bandwidth of 408GB/s, and it had twice the compute and ram compared to non-pro, so it is fair to assume the pro is just 2X version in every way, meaning the regular version will have a bandwidth of 204GB/s.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mb6uhm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kl6ce/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753688633,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5kdemv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "LegitMichel777",
            "can_mod_post": false,
            "created_utc": 1753684246,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 7,
            "author_fullname": "t2_e0eciwl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "let’s do some napkin math. at the claimed 4266Mb/s memory bandwidth, it’s 4266/8=533.25MB/s. okay that doesn’t make sense, that’s far too low. let’s assume they meant 4266MT/s. at 4266MT/s, each die transmits about 17GB/s. assuming 16GB/die, there’s 6 memory dies on the 96GB version for a total of 17*6=102 GB/s of memory bandwidth. inference is typically bandwidth-constrained, and one token decode requires a loading of all weights and KV cache from memory. so for a 34B LLM at 4-bit quant, you’re looking at around 20GB of memory usage, so 102/20=5 tokens/sec for a 34B dense LLM. slow, but acceptable depending on your use case, especially given that the massive 96GB of total memory means you can run 100B+ models. you might do things like document indexing and summarization where waiting overnight for a result is perfectly acceptable.",
            "edited": 1753695992,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kdemv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;let’s do some napkin math. at the claimed 4266Mb/s memory bandwidth, it’s 4266/8=533.25MB/s. okay that doesn’t make sense, that’s far too low. let’s assume they meant 4266MT/s. at 4266MT/s, each die transmits about 17GB/s. assuming 16GB/die, there’s 6 memory dies on the 96GB version for a total of 17*6=102 GB/s of memory bandwidth. inference is typically bandwidth-constrained, and one token decode requires a loading of all weights and KV cache from memory. so for a 34B LLM at 4-bit quant, you’re looking at around 20GB of memory usage, so 102/20=5 tokens/sec for a 34B dense LLM. slow, but acceptable depending on your use case, especially given that the massive 96GB of total memory means you can run 100B+ models. you might do things like document indexing and summarization where waiting overnight for a result is perfectly acceptable.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kdemv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753684246,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5kcect",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "po_stulate",
            "can_mod_post": false,
            "created_utc": 1753683693,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 3,
            "author_fullname": "t2_86bhfy6r",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The only good thing about the 96GB RAM is that you can keep many small models loaded and don't need to unload and reload them each time. But you will not want to run any model that's close to its RAM size unless you don't care about speed at all.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kcect",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The only good thing about the 96GB RAM is that you can keep many small models loaded and don&amp;#39;t need to unload and reload them each time. But you will not want to run any model that&amp;#39;s close to its RAM size unless you don&amp;#39;t care about speed at all.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kcect/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753683693,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5kneiw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "kironlau",
            "can_mod_post": false,
            "created_utc": 1753689924,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 2,
            "author_fullname": "t2_tb0dz2ds",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "No pls, \"unless you (your company) has a huawei techincian support staying in you company.\"  \nI just read a comment below a video promoting this thing, a Chinese programmer says.\n\nAscend is buggy, only Huawei could solve it. You can't find any solutions on internet.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kneiw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No pls, &amp;quot;unless you (your company) has a huawei techincian support staying in you company.&amp;quot;&lt;br/&gt;\nI just read a comment below a video promoting this thing, a Chinese programmer says.&lt;/p&gt;\n\n&lt;p&gt;Ascend is buggy, only Huawei could solve it. You can&amp;#39;t find any solutions on internet.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5kneiw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753689924,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5l1i39",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "moko990",
            "can_mod_post": false,
            "created_utc": 1753698054,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 1,
            "author_fullname": "t2_1kh1rmhlhh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Keep in mind the software stack for AI is a very important ingredient too. Their previous OPi 5 Plus (32GB) with Rockhip didn't deliver on the performance promised.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5l1i39",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Keep in mind the software stack for AI is a very important ingredient too. Their previous OPi 5 Plus (32GB) with Rockhip didn&amp;#39;t deliver on the performance promised.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5l1i39/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753698054,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5m9a7w",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Mugen0815",
            "can_mod_post": false,
            "created_utc": 1753714329,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 1,
            "author_fullname": "t2_ecwattqe",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I found news about the CPU that says its great. Or it was in 2018...",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5m9a7w",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I found news about the CPU that says its great. Or it was in 2018...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5m9a7w/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753714329,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5krbkk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "zball_",
            "can_mod_post": false,
            "created_utc": 1753692246,
            "send_replies": true,
            "parent_id": "t3_1mb6uhm",
            "score": 1,
            "author_fullname": "t2_d4bqkyg1",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "its memory looks like shit",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5krbkk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;its memory looks like shit&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mb6uhm/pi_ai_studio/n5krbkk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753692246,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mb6uhm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]