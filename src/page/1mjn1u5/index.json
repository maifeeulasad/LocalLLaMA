[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi all,\n\nAs a fan of obscure retro computers, I would like to \"teach\" a LLM how to program them.\n\nExample: the Rocky Mountain BASIC language (also known as RM-BASIC, HP-BASIC or BASIC/WS names changed a lot during it's life) for the HP9000 series of computers from the 80's.\n\nAll LLMs I tried either don't know sh\\*t about this one and start hallucinating Apple II BASIC code then apologize or know a bit but start to hallucinate and start telling me I'm wrong.\n\nThis BASIC dialect very nicely and thoroughly documented but:\n\n* The scanned material sometimes look like a captcha and most likely all automated OCRs useless;\n* HP used funky graphical diagrams to represent command syntax;\n* There are 6 major versions and more minor versions that have different capabilities and even syntax depending on what system they are running. And those are described in different documents.\n* The minimal quantity of data for a single version/release exceeds the context length of all LLMs i tried (just the language reference manuals volumes 1+2 are \\~1000 pages)\n\nThus: How can I do the grunt work and manually prepare a fine-tuning dataset in which I can represent the syntax of each command and for what version/releases/hardware it applies ? What else do I need ?\n\nMy end goal is to be able to ask a LLM on my local machine: \"Write me a Breakout game in RM-BASIC 5.0 that will run on a HP 9000 model 216 and use the keyboard knob to move the paddle and the space key to fire\"\n\nI will happily RTFM if someone points me to a good FM. Or examples of such training files.\n\nThen, if there's a way to make those finetuning/training files public, I will make them available for anyone to enjoy.\n\nThank you all very much !",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "n00b question: How to teach a LLM to program in a niche language ?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjn1u5",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.78,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 8,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_avmqd",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 8,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754530491,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;As a fan of obscure retro computers, I would like to &amp;quot;teach&amp;quot; a LLM how to program them.&lt;/p&gt;\n\n&lt;p&gt;Example: the Rocky Mountain BASIC language (also known as RM-BASIC, HP-BASIC or BASIC/WS names changed a lot during it&amp;#39;s life) for the HP9000 series of computers from the 80&amp;#39;s.&lt;/p&gt;\n\n&lt;p&gt;All LLMs I tried either don&amp;#39;t know sh*t about this one and start hallucinating Apple II BASIC code then apologize or know a bit but start to hallucinate and start telling me I&amp;#39;m wrong.&lt;/p&gt;\n\n&lt;p&gt;This BASIC dialect very nicely and thoroughly documented but:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The scanned material sometimes look like a captcha and most likely all automated OCRs useless;&lt;/li&gt;\n&lt;li&gt;HP used funky graphical diagrams to represent command syntax;&lt;/li&gt;\n&lt;li&gt;There are 6 major versions and more minor versions that have different capabilities and even syntax depending on what system they are running. And those are described in different documents.&lt;/li&gt;\n&lt;li&gt;The minimal quantity of data for a single version/release exceeds the context length of all LLMs i tried (just the language reference manuals volumes 1+2 are ~1000 pages)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thus: How can I do the grunt work and manually prepare a fine-tuning dataset in which I can represent the syntax of each command and for what version/releases/hardware it applies ? What else do I need ?&lt;/p&gt;\n\n&lt;p&gt;My end goal is to be able to ask a LLM on my local machine: &amp;quot;Write me a Breakout game in RM-BASIC 5.0 that will run on a HP 9000 model 216 and use the keyboard knob to move the paddle and the space key to fire&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I will happily RTFM if someone points me to a good FM. Or examples of such training files.&lt;/p&gt;\n\n&lt;p&gt;Then, if there&amp;#39;s a way to make those finetuning/training files public, I will make them available for anyone to enjoy.&lt;/p&gt;\n\n&lt;p&gt;Thank you all very much !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mjn1u5",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "psergiu",
            "discussion_type": null,
            "num_comments": 11,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/",
            "subreddit_subscribers": 512874,
            "created_utc": 1754530491,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7cmrbg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "DinoAmino",
            "can_mod_post": false,
            "created_utc": 1754534999,
            "send_replies": true,
            "parent_id": "t3_1mjn1u5",
            "score": 10,
            "author_fullname": "t2_j1v7f",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Everyone seems to think of fine-tuning right off the bat. It's a lofty goal for noobs that will not bring immediate value and likely fail to perform well at all. It takes a lot of time and resources to pull it off even reasonably well - and that's if you have prior experience. And even then it *will still* hallucinate.\n\nRAG First! It's far more accessible and can provide grounded results you can work with much faster. Not talking about dumping entire documents into context, but embeddings using vector DBs. Big plus if you also use a Graph DB with it. \n\nGather all \"text\" documentation you can. Code examples. Tutorials. Got a codebase to work with?  Here's a tutorial you could start learning from:\n\nhttps://huggingface.co/learn/cookbook/code_search\n\nThen later on down the line, when you have it all working well, you can use your RAG to generate  datasets and *then* give fine-tuning a try.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7cmrbg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Everyone seems to think of fine-tuning right off the bat. It&amp;#39;s a lofty goal for noobs that will not bring immediate value and likely fail to perform well at all. It takes a lot of time and resources to pull it off even reasonably well - and that&amp;#39;s if you have prior experience. And even then it &lt;em&gt;will still&lt;/em&gt; hallucinate.&lt;/p&gt;\n\n&lt;p&gt;RAG First! It&amp;#39;s far more accessible and can provide grounded results you can work with much faster. Not talking about dumping entire documents into context, but embeddings using vector DBs. Big plus if you also use a Graph DB with it. &lt;/p&gt;\n\n&lt;p&gt;Gather all &amp;quot;text&amp;quot; documentation you can. Code examples. Tutorials. Got a codebase to work with?  Here&amp;#39;s a tutorial you could start learning from:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/learn/cookbook/code_search\"&gt;https://huggingface.co/learn/cookbook/code_search&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Then later on down the line, when you have it all working well, you can use your RAG to generate  datasets and &lt;em&gt;then&lt;/em&gt; give fine-tuning a try.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7cmrbg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754534999,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjn1u5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7cniov",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Affectionate-Hat-536",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7cjic7",
                                          "score": 4,
                                          "author_fullname": "t2_7htykppj",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "For last 30 years or so, COBOL can run on windows, Unix and Linux either natively or using emulators like Micro Focus and many enterprises do that.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7cniov",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For last 30 years or so, COBOL can run on windows, Unix and Linux either natively or using emulators like Micro Focus and many enterprises do that.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mjn1u5",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7cniov/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754535289,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754535289,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7cjic7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "No_Afternoon_4260",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7cgedr",
                                "score": 0,
                                "author_fullname": "t2_cj9kap4bx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "That thing is made to run on mainframe system built and sold by ibm. Not everybody has it in the first place.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7cjic7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That thing is made to run on mainframe system built and sold by ibm. Not everybody has it in the first place.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjn1u5",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7cjic7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754533792,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754533792,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7cnegv",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "fonix232",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7cgedr",
                                "score": 0,
                                "author_fullname": "t2_aricd",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "LLMs? Not on the level banks demand.\n\nBanks? No. COBOL knowledge is a dying breed. The few engineers they manage to snatch, usually end up costing 5-10x more than a similarly skilled engineer in any other position.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7cnegv",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;LLMs? Not on the level banks demand.&lt;/p&gt;\n\n&lt;p&gt;Banks? No. COBOL knowledge is a dying breed. The few engineers they manage to snatch, usually end up costing 5-10x more than a similarly skilled engineer in any other position.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjn1u5",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7cnegv/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754535244,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754535244,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7cgedr",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "HugoCortell",
                      "can_mod_post": false,
                      "created_utc": 1754532662,
                      "send_replies": true,
                      "parent_id": "t1_n7cbef0",
                      "score": 3,
                      "author_fullname": "t2_61s8b5gv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Can't they already do Cobol?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7cgedr",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can&amp;#39;t they already do Cobol?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjn1u5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7cgedr/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754532662,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7cncb5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Affectionate-Hat-536",
                      "can_mod_post": false,
                      "created_utc": 1754535221,
                      "send_replies": true,
                      "parent_id": "t1_n7cbef0",
                      "score": 1,
                      "author_fullname": "t2_7htykppj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "LLMs are already doing this. Claude models are quite good at converting COBOL to Java or .net. Obviously, you need language experts to promp, create working apps from generated code with fixes, integration and so on. Vendors like IBM and AWS are bringing tools embedded with LLM capabilities.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7cncb5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;LLMs are already doing this. Claude models are quite good at converting COBOL to Java or .net. Obviously, you need language experts to promp, create working apps from generated code with fixes, integration and so on. Vendors like IBM and AWS are bringing tools embedded with LLM capabilities.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjn1u5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7cncb5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754535221,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7cbef0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "MrMagoo5003",
            "can_mod_post": false,
            "created_utc": 1754530896,
            "send_replies": true,
            "parent_id": "t3_1mjn1u5",
            "score": 3,
            "author_fullname": "t2_mr5aimm6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you can teach an LLM to program in Cobol, there would be a number of banks that would be interested in that.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7cbef0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you can teach an LLM to program in Cobol, there would be a number of banks that would be interested in that.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7cbef0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754530896,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjn1u5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7crvmu",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "13henday",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7cl545",
                                "score": 6,
                                "author_fullname": "t2_81577uk2",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Rented a 2xh100 rig pulled deepseek with beeg context gave it some examples and had it generate permutations that followed structure syntax naming conventions boilerplate etc. have a couple samples the old ocular pat-down to check for obvious errors. Then started feeding them through our compiler which raised a couple errors which I had to troubleshoot manually and catalogue. Then just fed the fixes for errors along with the initial prompt during a second pass with deepseek. Second set had a 70+% pass rate which was good enough for me. Chucked everything that didn’t compile and fine tuned Qwen 8b off the rest.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7crvmu",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Rented a 2xh100 rig pulled deepseek with beeg context gave it some examples and had it generate permutations that followed structure syntax naming conventions boilerplate etc. have a couple samples the old ocular pat-down to check for obvious errors. Then started feeding them through our compiler which raised a couple errors which I had to troubleshoot manually and catalogue. Then just fed the fixes for errors along with the initial prompt during a second pass with deepseek. Second set had a 70+% pass rate which was good enough for me. Chucked everything that didn’t compile and fine tuned Qwen 8b off the rest.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjn1u5",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7crvmu/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754537002,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754537002,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7cl545",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "psergiu",
                      "can_mod_post": false,
                      "created_utc": 1754534395,
                      "send_replies": true,
                      "parent_id": "t1_n7cct1d",
                      "score": 3,
                      "author_fullname": "t2_avmqd",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "How ? :-D",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7cl545",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How ? :-D&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjn1u5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7cl545/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754534395,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7cct1d",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "13henday",
            "can_mod_post": false,
            "created_utc": 1754531394,
            "send_replies": true,
            "parent_id": "t3_1mjn1u5",
            "score": 4,
            "author_fullname": "t2_81577uk2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Taught Qwen a very company and hardware specific version of Fortran.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7cct1d",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Taught Qwen a very company and hardware specific version of Fortran.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7cct1d/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754531394,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjn1u5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7e1k38",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Corporate_Drone31",
            "can_mod_post": false,
            "created_utc": 1754560645,
            "send_replies": true,
            "parent_id": "t3_1mjn1u5",
            "score": 1,
            "author_fullname": "t2_32o8hu91",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Like /u/DinoAmino said, RAG is a good bet. You've identified that you need reference materials, and you've identified that your dataset that contains them needs cleaning - I have no experience with paper document cleaning or with diagram processing, but, here's what you should do after you get the data into a presentable text-only format:\n\n* use a larger LLM to rewrite the materials into something briefer. This may mean omitting some features, functions, or syntax. But the good thing is that if this resembles a BASIC to some degree, you can have the derivation pipeline simply produce text that explains ONLY the difference: it's like XYZ but without features U, V and W, and there's also this and that. Do it for every part of the documentation. Between shortening the text itself and the \"deduplication\" you achieve by simply pointing to existing model knowledge and saying \"like this, but differing in those ways\", you can likely shrink everything to fit into RAG.\n\n* don't try to bite off more than the LLM can chew. If there are multiple variants of the language, prepare several RAG document DBs that contain documentation tailored to only this language. Don't even mention the other variants of the language in the RAG - pretend it's the only version. You're going to help the model out by only providing what's strictly relevant. If some document duplication is there between DBs, that's fine - If they share, say, 88% of the documentation, then just duplicate that 88% for each DB.\n\n* provide sample programs in the RAG database, or maybe even in a secondary RAG database this feeds into the context alongside the results from the primary. \"Here are some programs that may contain syntax, constructions, and function calls that may or may not be relevant to the current task\" kind of thing.\n\n* Besides RAG, if you can fit that minimised documentation set into the context entirely, that might be a good bet. That way you aren't at the mercy or the RAG mechanism when it comes to not omitting helpful examples/reference material\n\n* if you choose to RAG, do not do dumb chunking. Split along chapter boundaries, or section boundaries, or function documentation boundaries. You'll need to post-process your data to derive those chunks in a smart way, but between some manual work, LLMs, regexes and some rudimentary text processing scripts, you can get there",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7e1k38",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Like &lt;a href=\"/u/DinoAmino\"&gt;/u/DinoAmino&lt;/a&gt; said, RAG is a good bet. You&amp;#39;ve identified that you need reference materials, and you&amp;#39;ve identified that your dataset that contains them needs cleaning - I have no experience with paper document cleaning or with diagram processing, but, here&amp;#39;s what you should do after you get the data into a presentable text-only format:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;use a larger LLM to rewrite the materials into something briefer. This may mean omitting some features, functions, or syntax. But the good thing is that if this resembles a BASIC to some degree, you can have the derivation pipeline simply produce text that explains ONLY the difference: it&amp;#39;s like XYZ but without features U, V and W, and there&amp;#39;s also this and that. Do it for every part of the documentation. Between shortening the text itself and the &amp;quot;deduplication&amp;quot; you achieve by simply pointing to existing model knowledge and saying &amp;quot;like this, but differing in those ways&amp;quot;, you can likely shrink everything to fit into RAG.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;don&amp;#39;t try to bite off more than the LLM can chew. If there are multiple variants of the language, prepare several RAG document DBs that contain documentation tailored to only this language. Don&amp;#39;t even mention the other variants of the language in the RAG - pretend it&amp;#39;s the only version. You&amp;#39;re going to help the model out by only providing what&amp;#39;s strictly relevant. If some document duplication is there between DBs, that&amp;#39;s fine - If they share, say, 88% of the documentation, then just duplicate that 88% for each DB.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;provide sample programs in the RAG database, or maybe even in a secondary RAG database this feeds into the context alongside the results from the primary. &amp;quot;Here are some programs that may contain syntax, constructions, and function calls that may or may not be relevant to the current task&amp;quot; kind of thing.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Besides RAG, if you can fit that minimised documentation set into the context entirely, that might be a good bet. That way you aren&amp;#39;t at the mercy or the RAG mechanism when it comes to not omitting helpful examples/reference material&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;if you choose to RAG, do not do dumb chunking. Split along chapter boundaries, or section boundaries, or function documentation boundaries. You&amp;#39;ll need to post-process your data to derive those chunks in a smart way, but between some manual work, LLMs, regexes and some rudimentary text processing scripts, you can get there&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjn1u5/n00b_question_how_to_teach_a_llm_to_program_in_a/n7e1k38/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754560645,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjn1u5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]