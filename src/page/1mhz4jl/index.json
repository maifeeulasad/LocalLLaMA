[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Task example, with the question being \"What was net sales by reportable segment in europe in 2016?\" an a table in a text format like the following:\n\n    | | | | | | | | | | | | | | | | |   \n     | 2018|  | Change|  | 2017|  | Change|  | 2016  \n    Net Sales by Reportable Segment:|  |  |  |  |  |  |  |  |    \n    Americas| $| 112,093|  \n    |  | 16|  %|  | $| 96,600|   \n    |  | 12|  %|  | $| 86,613|   \n      \n    Europe| 62,420|  \n    |  | 14|  %|  | 54,938|   \n    |  | 10|  %|  | 49,952|   \n      \n    Greater China| 51,942|  \n    |  | 16|  %|  | 44,764|   \n    |  | (8| )%|  | 48,492|   \n      \n    Japan| 21,733|  \n    |  | 23|  %|  | 17,733|   \n    |  | 5|  %|  | 16,928|   \n    ...\n\nI'd like to find a model that can run quickly on a single GPU and can handle this task. gemma-12b (and I'm sure others) can do it, but ideally there are smaller models that can handle this sort of QA reliably. I tried tinyllama but those don't work very well.\n\nI've also tried some of the huggingface roberta-style models (purely extractive), but those don't seem to work well on this specific task, which is why I've been testing LLMs mainly. The markup is similar to what the html2text python library provides, so I guess I could finetune on existing QA/table datasets though (by converting the tables to this text format first). If you have any ideas regarding this, please share. Thank you.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Finding a local model for text table QA",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mhz4jl",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.33,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_122pue6ib1",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754366370,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Task example, with the question being &amp;quot;What was net sales by reportable segment in europe in 2016?&amp;quot; an a table in a text format like the following:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;| | | | | | | | | | | | | | | | |   \n | 2018|  | Change|  | 2017|  | Change|  | 2016  \nNet Sales by Reportable Segment:|  |  |  |  |  |  |  |  |    \nAmericas| $| 112,093|  \n|  | 16|  %|  | $| 96,600|   \n|  | 12|  %|  | $| 86,613|   \n\nEurope| 62,420|  \n|  | 14|  %|  | 54,938|   \n|  | 10|  %|  | 49,952|   \n\nGreater China| 51,942|  \n|  | 16|  %|  | 44,764|   \n|  | (8| )%|  | 48,492|   \n\nJapan| 21,733|  \n|  | 23|  %|  | 17,733|   \n|  | 5|  %|  | 16,928|   \n...\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;d like to find a model that can run quickly on a single GPU and can handle this task. gemma-12b (and I&amp;#39;m sure others) can do it, but ideally there are smaller models that can handle this sort of QA reliably. I tried tinyllama but those don&amp;#39;t work very well.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also tried some of the huggingface roberta-style models (purely extractive), but those don&amp;#39;t seem to work well on this specific task, which is why I&amp;#39;ve been testing LLMs mainly. The markup is similar to what the html2text python library provides, so I guess I could finetune on existing QA/table datasets though (by converting the tables to this text format first). If you have any ideas regarding this, please share. Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mhz4jl",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Sea_Pomegranate_7803",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mhz4jl/finding_a_local_model_for_text_table_qa/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mhz4jl/finding_a_local_model_for_text_table_qa/",
            "subreddit_subscribers": 510540,
            "created_utc": 1754366370,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n701169",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Sea_Pomegranate_7803",
                      "can_mod_post": false,
                      "created_utc": 1754369280,
                      "send_replies": true,
                      "parent_id": "t1_n6zxcy2",
                      "score": 1,
                      "author_fullname": "t2_122pue6ib1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "A text autoencoder used to reconstruct the tables is an interesting idea. The tables are somewhat unstructured and don't necessarily have columns that align perfectly, or rows that align perfectly, however. How might I go about doing step 1) in practice?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n701169",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A text autoencoder used to reconstruct the tables is an interesting idea. The tables are somewhat unstructured and don&amp;#39;t necessarily have columns that align perfectly, or rows that align perfectly, however. How might I go about doing step 1) in practice?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mhz4jl",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mhz4jl/finding_a_local_model_for_text_table_qa/n701169/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754369280,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6zxcy2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Efficiency_1144",
            "can_mod_post": false,
            "created_utc": 1754367565,
            "send_replies": true,
            "parent_id": "t3_1mhz4jl",
            "score": 1,
            "author_fullname": "t2_1nkj9l14b0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you want to do it really well then do this:\n\n\n1. Train encoders cell-wise, row-wise, column-wise or table-wise. They could be classic auto-encoders, variational auto-encoders, denoising auto-encoders, masked auto-encoders etc\n\n\n2. Train downstream models on the encoder latents. Carefully match the inductive bias of the model architecture to the data. They could be MLP, CNN, RNN, GNN etc",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6zxcy2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you want to do it really well then do this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Train encoders cell-wise, row-wise, column-wise or table-wise. They could be classic auto-encoders, variational auto-encoders, denoising auto-encoders, masked auto-encoders etc&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Train downstream models on the encoder latents. Carefully match the inductive bias of the model architecture to the data. They could be MLP, CNN, RNN, GNN etc&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mhz4jl/finding_a_local_model_for_text_table_qa/n6zxcy2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754367565,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mhz4jl",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]