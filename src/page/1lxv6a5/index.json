[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I am assuming most LLMs today use more or less a similar architecture. I am also assuming the initial training data is mostly the same (i.e. books, wikipedia etc), and probably close to being exhausted already?\n\nSo what would make a future major version of an LLM much better than the previous one?\n\nI get post training and finetuning. But in terms of general intelligence and performance, are we slowing down until the next breakthroughs?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "What drives progress in newer LLMs?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1lxv6a5",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.95,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 14,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1441omqx4c",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 14,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1752307718,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am assuming most LLMs today use more or less a similar architecture. I am also assuming the initial training data is mostly the same (i.e. books, wikipedia etc), and probably close to being exhausted already?&lt;/p&gt;\n\n&lt;p&gt;So what would make a future major version of an LLM much better than the previous one?&lt;/p&gt;\n\n&lt;p&gt;I get post training and finetuning. But in terms of general intelligence and performance, are we slowing down until the next breakthroughs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1lxv6a5",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "cangaroo_hamam",
            "discussion_type": null,
            "num_comments": 14,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/",
            "subreddit_subscribers": 497824,
            "created_utc": 1752307718,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n2p5l9n",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "custodiam99",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n2p2y74",
                                          "score": 1,
                                          "author_fullname": "t2_nqnhgqqf5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I'm a little bit more optimistic, because we were able to partly reconstruct those non-linguistic patterns. So now we know there are real cognitive patterns in the human brain and we know their partial essence. The task is to approximate them using algorithms and refine the partial patterns.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n2p5l9n",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a little bit more optimistic, because we were able to partly reconstruct those non-linguistic patterns. So now we know there are real cognitive patterns in the human brain and we know their partial essence. The task is to approximate them using algorithms and refine the partial patterns.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1lxv6a5",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2p5l9n/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1752310134,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1752310134,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n2p2y74",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "BidWestern1056",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n2p2hn3",
                                "score": 5,
                                "author_fullname": "t2_uzxql7po",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "exactly. and no algorithmic process of trying to RL on test sets will get us beyond these limitations",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n2p2y74",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;exactly. and no algorithmic process of trying to RL on test sets will get us beyond these limitations&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lxv6a5",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2p2y74/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752308543,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752308543,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n2q74tu",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Expensive-Apricot-25",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n2p2hn3",
                                "score": 1,
                                "author_fullname": "t2_idqkwio0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Not to mention, all of the model “thoughts” and “reasoning” happens during a single forward pass, and all of that gets compressed to a single discrete token will very little information, before it has to reconstruct all of that in the next forward pass from scratch + that last single token.\n\nIt’s a good method for modeling human writing on the surface, and mimic human writing, but it’s not good at modeling the underlying cognitive processes that govern that writing. Which at the end of the day is the real goal, not the writing itself.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n2q74tu",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not to mention, all of the model “thoughts” and “reasoning” happens during a single forward pass, and all of that gets compressed to a single discrete token will very little information, before it has to reconstruct all of that in the next forward pass from scratch + that last single token.&lt;/p&gt;\n\n&lt;p&gt;It’s a good method for modeling human writing on the surface, and mimic human writing, but it’s not good at modeling the underlying cognitive processes that govern that writing. Which at the end of the day is the real goal, not the writing itself.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lxv6a5",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2q74tu/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752328120,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752328120,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n2p2hn3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "custodiam99",
                      "can_mod_post": false,
                      "created_utc": 1752308266,
                      "send_replies": true,
                      "parent_id": "t1_n2p1yfp",
                      "score": 9,
                      "author_fullname": "t2_nqnhgqqf5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes, natural language is a lossy communication format. Using natural language we can only partially reconstruct the non-linguistic original inner structure of human thought processes.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n2p2hn3",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, natural language is a lossy communication format. Using natural language we can only partially reconstruct the non-linguistic original inner structure of human thought processes.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lxv6a5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2p2hn3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752308266,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 9
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n2p1yfp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "BidWestern1056",
            "can_mod_post": false,
            "created_utc": 1752307946,
            "send_replies": true,
            "parent_id": "t3_1lxv6a5",
            "score": 10,
            "author_fullname": "t2_uzxql7po",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "well this is the issue, were kinda plateauing into minor incremental improvements because were running into a fundamental limitation that LLMs face /because/ they use natural language .\nI've written a paper on this recently that details the information theory constraints on natural language and why we need to move language only models.\nhttps://arxiv.org/abs/2506.10077",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2p1yfp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;well this is the issue, were kinda plateauing into minor incremental improvements because were running into a fundamental limitation that LLMs face /because/ they use natural language .\nI&amp;#39;ve written a paper on this recently that details the information theory constraints on natural language and why we need to move language only models.\n&lt;a href=\"https://arxiv.org/abs/2506.10077\"&gt;https://arxiv.org/abs/2506.10077&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2p1yfp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752307946,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxv6a5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2p345l",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "brown2green",
            "can_mod_post": false,
            "created_utc": 1752308642,
            "send_replies": true,
            "parent_id": "t3_1lxv6a5",
            "score": 8,
            "author_fullname": "t2_f010l",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think the next step will be augmenting and rewriting the entire training data, from pretraining onward; there's a lot to improve there given current methods. There's no real training data exhaustion problem yet, _just_ a lack of \"high-quality\" training data, which could be solved (at high compute costs) with rewriting/augmentation using powerful LLMs. There are problems to solve, but I think it's doable.\n\nPost-training already comprises tens of billions, if not close to hundred**s** of billions (see the latest [SmolLM3](https://huggingface.co/HuggingFaceTB/SmolLM3-3B) for example) of synthetic data anyway. Extending that to pretraining seems only natural and large companies like Meta are [already thinking about it](https://arxiv.org/abs/2506.04689).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2p345l",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the next step will be augmenting and rewriting the entire training data, from pretraining onward; there&amp;#39;s a lot to improve there given current methods. There&amp;#39;s no real training data exhaustion problem yet, &lt;em&gt;just&lt;/em&gt; a lack of &amp;quot;high-quality&amp;quot; training data, which could be solved (at high compute costs) with rewriting/augmentation using powerful LLMs. There are problems to solve, but I think it&amp;#39;s doable.&lt;/p&gt;\n\n&lt;p&gt;Post-training already comprises tens of billions, if not close to hundred&lt;strong&gt;s&lt;/strong&gt; of billions (see the latest &lt;a href=\"https://huggingface.co/HuggingFaceTB/SmolLM3-3B\"&gt;SmolLM3&lt;/a&gt; for example) of synthetic data anyway. Extending that to pretraining seems only natural and large companies like Meta are &lt;a href=\"https://arxiv.org/abs/2506.04689\"&gt;already thinking about it&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2p345l/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752308642,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxv6a5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n2pkjr1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "thirteen-bit",
                      "can_mod_post": false,
                      "created_utc": 1752318790,
                      "send_replies": true,
                      "parent_id": "t1_n2p3s5t",
                      "score": 2,
                      "author_fullname": "t2_9l12dgc5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Babel-17 by Samuel R. Delany immediately comes to mind.\n\n[https://en.wikipedia.org/wiki/Babel-17](https://en.wikipedia.org/wiki/Babel-17)\n\nIt was amazing reading when I've first read it.\n\nActually I've to find and reread this book.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n2pkjr1",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Babel-17 by Samuel R. Delany immediately comes to mind.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://en.wikipedia.org/wiki/Babel-17\"&gt;https://en.wikipedia.org/wiki/Babel-17&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It was amazing reading when I&amp;#39;ve first read it.&lt;/p&gt;\n\n&lt;p&gt;Actually I&amp;#39;ve to find and reread this book.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lxv6a5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2pkjr1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752318790,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n2p3s5t",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Teetota",
            "can_mod_post": false,
            "created_utc": 1752309044,
            "send_replies": true,
            "parent_id": "t3_1lxv6a5",
            "score": 3,
            "author_fullname": "t2_8bu5nb0n",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Probably an artificial language which is more suitable  than natural language. It's quite possible that a phrase in natural language would translate to a dozen of phrases in this new language, expanding on defaults, assumptions and simplifications we inherently have in a natural language model. \nLojban language is actually a good low effort candidate since it has been designed with computer communication in mind, exists for long time, has rich vocabulary, documentation and community.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2p3s5t",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Probably an artificial language which is more suitable  than natural language. It&amp;#39;s quite possible that a phrase in natural language would translate to a dozen of phrases in this new language, expanding on defaults, assumptions and simplifications we inherently have in a natural language model. \nLojban language is actually a good low effort candidate since it has been designed with computer communication in mind, exists for long time, has rich vocabulary, documentation and community.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2p3s5t/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752309044,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxv6a5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2p5aaf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "erazortt",
            "can_mod_post": false,
            "created_utc": 1752309953,
            "send_replies": true,
            "parent_id": "t3_1lxv6a5",
            "score": 1,
            "author_fullname": "t2_6z7m9i7r",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Not sure I understand it correctly but isn’t language the only way we save our knowledge in all non-STEM-sciences? Take philosophy or history, we save our knowledge in form of written books which use only natural language. So the problem of the inexact language is not LLM specific but actually a flaw in how humanity saves knowledge.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2p5aaf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not sure I understand it correctly but isn’t language the only way we save our knowledge in all non-STEM-sciences? Take philosophy or history, we save our knowledge in form of written books which use only natural language. So the problem of the inexact language is not LLM specific but actually a flaw in how humanity saves knowledge.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2p5aaf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752309953,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxv6a5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2p9wp5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "randomfoo2",
            "can_mod_post": false,
            "created_utc": 1752312790,
            "send_replies": true,
            "parent_id": "t3_1lxv6a5",
            "score": 1,
            "author_fullname": "t2_eztox",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "While there is only one internet, there's still a lot of \"easy\" ways  to improve the training data. I think there's a fair argument to be made that all the big breakthroughs in LLM capabilities have been largely driven by data breakthroughs.\n\nStille, we've seen this past year a number of other breakthroughs/trends - universal adoption of MoE for efficiency, use of RL for reasoning but also across any verifiable or verifiable by proxy domain. Also hybrid/alternative attention to increase efficiency, extend context length. I think we're seeing just this past week a couple more interesting things - use of Muon at scale, potentially massive improvements to traditional tokenization, etc.\n\nI think we're still seeing big improvements in basically every aspect: architecture, data, and training techniques. I think there's also a lot on the inference front as well (eg, thinking models, parallel \"heavy\" strategies, and different ways of using output from different models to generate better/more reliable results).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2p9wp5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;While there is only one internet, there&amp;#39;s still a lot of &amp;quot;easy&amp;quot; ways  to improve the training data. I think there&amp;#39;s a fair argument to be made that all the big breakthroughs in LLM capabilities have been largely driven by data breakthroughs.&lt;/p&gt;\n\n&lt;p&gt;Stille, we&amp;#39;ve seen this past year a number of other breakthroughs/trends - universal adoption of MoE for efficiency, use of RL for reasoning but also across any verifiable or verifiable by proxy domain. Also hybrid/alternative attention to increase efficiency, extend context length. I think we&amp;#39;re seeing just this past week a couple more interesting things - use of Muon at scale, potentially massive improvements to traditional tokenization, etc.&lt;/p&gt;\n\n&lt;p&gt;I think we&amp;#39;re still seeing big improvements in basically every aspect: architecture, data, and training techniques. I think there&amp;#39;s also a lot on the inference front as well (eg, thinking models, parallel &amp;quot;heavy&amp;quot; strategies, and different ways of using output from different models to generate better/more reliable results).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2p9wp5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752312790,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxv6a5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2pauhp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "adviceguru25",
            "can_mod_post": false,
            "created_utc": 1752313365,
            "send_replies": true,
            "parent_id": "t3_1lxv6a5",
            "score": 1,
            "author_fullname": "t2_c3b3edv5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don’t think we’re slowing down. I think we haven’t even we’re even close to a slow down.\n\nThe data these models are being trained on just sucks and you can see it in what the models are [producing](https://www.designarena.ai/). If the model were just trained on a high quality data distribution, then theoretically with high likelihood it should sample something that’s close to that distribution. \n\nI think a lot of people really think a breakthrough is having better and more high quality data to drive on.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2pauhp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don’t think we’re slowing down. I think we haven’t even we’re even close to a slow down.&lt;/p&gt;\n\n&lt;p&gt;The data these models are being trained on just sucks and you can see it in what the models are &lt;a href=\"https://www.designarena.ai/\"&gt;producing&lt;/a&gt;. If the model were just trained on a high quality data distribution, then theoretically with high likelihood it should sample something that’s close to that distribution. &lt;/p&gt;\n\n&lt;p&gt;I think a lot of people really think a breakthrough is having better and more high quality data to drive on.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2pauhp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752313365,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxv6a5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2pcv4u",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "EntertainmentLast729",
            "can_mod_post": false,
            "created_utc": 1752314571,
            "send_replies": true,
            "parent_id": "t3_1lxv6a5",
            "score": 1,
            "author_fullname": "t2_115lwe1fsx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Ar the moment complex models need expensive data centre spec hardware to run operations like fine tuning and inference. \n\nAs the demand increases we will see consumer level cards eg. RTX series with 128gb+ vram for affordable (&lt;$1k) prices. \n\nWhile not directly a breakthrough in LLMs it will allow a lot more people with a lot less money to experiment,  which is where the actual innovation will come from.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2pcv4u",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ar the moment complex models need expensive data centre spec hardware to run operations like fine tuning and inference. &lt;/p&gt;\n\n&lt;p&gt;As the demand increases we will see consumer level cards eg. RTX series with 128gb+ vram for affordable (&amp;lt;$1k) prices. &lt;/p&gt;\n\n&lt;p&gt;While not directly a breakthrough in LLMs it will allow a lot more people with a lot less money to experiment,  which is where the actual innovation will come from.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2pcv4u/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752314571,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxv6a5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n2pvfuz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "pitchblackfriday",
            "can_mod_post": false,
            "created_utc": 1752323705,
            "send_replies": true,
            "parent_id": "t3_1lxv6a5",
            "score": 1,
            "author_fullname": "t2_1dt829ipgg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Non-Transformer based architectures I assume. Like Diffusion Langauge Model. There are some novel approaches being researched so I hope any of them to be proven to exceed the plateauing Transformer performance.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n2pvfuz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Non-Transformer based architectures I assume. Like Diffusion Langauge Model. There are some novel approaches being researched so I hope any of them to be proven to exceed the plateauing Transformer performance.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lxv6a5/what_drives_progress_in_newer_llms/n2pvfuz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752323705,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lxv6a5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]