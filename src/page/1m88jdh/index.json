[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "https://x.com/casper_hansen_/status/1948402352320360811?t=sPHOGEKIcaucRVzENlIr1g&amp;s=19",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Ok next big open source model also from China only ! Which is about to release",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 140,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m88jdh",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.96,
            "author_flair_background_color": null,
            "ups": 878,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1lnt2rs3qb",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 878,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/c08j-el568SvKGYGEd0gZbFM3-WDn7gmHlrwY9mVv5E.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753373337,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://x.com/casper_hansen_/status/1948402352320360811?t=sPHOGEKIcaucRVzENlIr1g&amp;amp;s=19\"&gt;https://x.com/casper_hansen_/status/1948402352320360811?t=sPHOGEKIcaucRVzENlIr1g&amp;amp;s=19&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/j6rwug34juef1.png",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/j6rwug34juef1.png?auto=webp&amp;s=18f17b9ceaa2b5d279bcbb0bb243851740e717c4",
                    "width": 1080,
                    "height": 1419
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/j6rwug34juef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb9a593e1fb7f521dc0f069833d5296c3e11f7e9",
                      "width": 108,
                      "height": 141
                    },
                    {
                      "url": "https://preview.redd.it/j6rwug34juef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6484155fe20574b23faf0c91f18281d0b64f0ef8",
                      "width": 216,
                      "height": 283
                    },
                    {
                      "url": "https://preview.redd.it/j6rwug34juef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=168aa62e13429a9a7659a2b00480eeed71c2b0ec",
                      "width": 320,
                      "height": 420
                    },
                    {
                      "url": "https://preview.redd.it/j6rwug34juef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a04ad517c7ca8eeeb00ee48288d8f17c562ca63c",
                      "width": 640,
                      "height": 840
                    },
                    {
                      "url": "https://preview.redd.it/j6rwug34juef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=66e086c5c04e9638800c62f55dfe3f8b4b914e18",
                      "width": 960,
                      "height": 1261
                    },
                    {
                      "url": "https://preview.redd.it/j6rwug34juef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e86fd4d029b2f6132d30619ca2201a26cba6b494",
                      "width": 1080,
                      "height": 1419
                    }
                  ],
                  "variants": {},
                  "id": "yDDBcSzVcQ88JLp4cep6OXeVFwV_1fmwTlslE0j_6FU"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1m88jdh",
            "is_robot_indexable": true,
            "num_duplicates": 3,
            "report_reasons": null,
            "author": "Independent-Wind4462",
            "discussion_type": null,
            "num_comments": 160,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/",
            "stickied": false,
            "url": "https://i.redd.it/j6rwug34juef1.png",
            "subreddit_subscribers": 504692,
            "created_utc": 1753373337,
            "num_crossposts": 3,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xcgxi",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Zc5Gwu",
                      "can_mod_post": false,
                      "created_utc": 1753374462,
                      "send_replies": true,
                      "parent_id": "t1_n4xa7jp",
                      "score": 68,
                      "author_fullname": "t2_67qrvlir",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That does sound like a great size and active params combo.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xcgxi",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That does sound like a great size and active params combo.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xcgxi/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753374462,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 68
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4yexj7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Accomplished_Mode170",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xob96",
                                "score": 19,
                                "author_fullname": "t2_4hfmiefj",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Oof 😥- zuck-pretending-he-doesn’t-care",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4yexj7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oof 😥- zuck-pretending-he-doesn’t-care&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yexj7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753385079,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753385079,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 19
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4z02cp",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "colin_colout",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xob96",
                                "score": 8,
                                "author_fullname": "t2_14l4ya",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Seriously... I loved how scout performed on my rig. Just wish it had a bit more knowledge and wasn't lazy and didn't get confused.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4z02cp",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Seriously... I loved how scout performed on my rig. Just wish it had a bit more knowledge and wasn&amp;#39;t lazy and didn&amp;#39;t get confused.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4z02cp/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753391001,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753391001,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 8
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xob96",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "ForsookComparison",
                      "can_mod_post": false,
                      "created_utc": 1753377662,
                      "send_replies": true,
                      "parent_id": "t1_n4xa7jp",
                      "score": 56,
                      "author_fullname": "t2_on5es7pe3",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Scout-But-Good",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xob96",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Scout-But-Good&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xob96/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753377662,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 56
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": "",
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n51g3g2",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": false,
                                                                        "author": "Peterianer",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n4z2ame",
                                                                        "score": 6,
                                                                        "author_fullname": "t2_3tstfjy0",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "good human",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n51g3g2",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;good human&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1m88jdh",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51g3g2/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1753423468,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1753423468,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 6
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n4z2ame",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "kenybz",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n4yeegb",
                                                              "score": 46,
                                                              "author_fullname": "t2_g4y4l",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "I am a real human. Beep boop",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n4z2ame",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am a real human. Beep boop&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m88jdh",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4z2ame/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753391653,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753391653,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 46
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n4yeegb",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "Caffdy",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4y1oot",
                                                    "score": 18,
                                                    "author_fullname": "t2_ql2vu0wz",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "good bot",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n4yeegb",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;good bot&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yeegb/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753384928,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753384928,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 18
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4y1oot",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "kenybz",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xkqh7",
                                          "score": 20,
                                          "author_fullname": "t2_g4y4l",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "40 GB = 37.253 GiB",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4y1oot",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;40 GB = 37.253 GiB&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y1oot/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753381297,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753381297,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 20
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n4zc1y5",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "tinykidtoo",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4y8e4u",
                                                    "score": 1,
                                                    "author_fullname": "t2_8dlwk",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Wonder if we can apply the methods used by Level1Techs for Deepseek recently to get that working on 128GB for a 500B model.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n4zc1y5",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wonder if we can apply the methods used by Level1Techs for Deepseek recently to get that working on 128GB for a 500B model.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zc1y5/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753394574,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753394574,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4y8e4u",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "michaelsoft__binbows",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xkqh7",
                                          "score": 5,
                                          "author_fullname": "t2_iifi6ul2l",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "nice, yeah my rule of thumb has been take the params and divide it by two to get GB with a 4-quant, and then add some more for headroom. haven't read about 3bpw quants convincingly performing well enough, but obviously if your memory is coming just short, being able to run one sure as hell beats not. That could be powerful though being able to run such a model off a single 48GB card or something like dual 3090s hopefully.\n\nSince deepseek r1 dropped its been becoming clear that &lt;100GB will become \"viable\" but to have this class of capability reach down to 50GB of memory is really great. For example many midrange consumer rigs are gonna have 64gb of system memory. I wouldn't build even a gaming pc without at least 64GB these days.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4y8e4u",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;nice, yeah my rule of thumb has been take the params and divide it by two to get GB with a 4-quant, and then add some more for headroom. haven&amp;#39;t read about 3bpw quants convincingly performing well enough, but obviously if your memory is coming just short, being able to run one sure as hell beats not. That could be powerful though being able to run such a model off a single 48GB card or something like dual 3090s hopefully.&lt;/p&gt;\n\n&lt;p&gt;Since deepseek r1 dropped its been becoming clear that &amp;lt;100GB will become &amp;quot;viable&amp;quot; but to have this class of capability reach down to 50GB of memory is really great. For example many midrange consumer rigs are gonna have 64gb of system memory. I wouldn&amp;#39;t build even a gaming pc without at least 64GB these days.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y8e4u/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753383222,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753383222,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 5
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n50vrbh",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "teachersecret",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5002oa",
                                                    "score": 1,
                                                    "author_fullname": "t2_ddyte",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Probably going to work nicely on 64gb ram+24gb vram rigs with that ik llama setup. I bet that’ll be the sweet spot for this one.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n50vrbh",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Probably going to work nicely on 64gb ram+24gb vram rigs with that ik llama setup. I bet that’ll be the sweet spot for this one.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n50vrbh/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753414160,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753414160,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5002oa",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "SkyFeistyLlama8",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xkqh7",
                                          "score": 1,
                                          "author_fullname": "t2_1hgbaqgbnq",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "q4 should be around 53 GB RAM which is still usable on a 64 GB RAM unified memory system.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5002oa",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;q4 should be around 53 GB RAM which is still usable on a 64 GB RAM unified memory system.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n5002oa/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753402519,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753402519,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xkqh7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "KeinNiemand",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xhg0a",
                                "score": 22,
                                "author_fullname": "t2_nuxa9",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; thereabouts\n\nit's like 106B at 3bpw should be about ~40GB (that's GB not GiB)",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xkqh7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;thereabouts&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;it&amp;#39;s like 106B at 3bpw should be about ~40GB (that&amp;#39;s GB not GiB)&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xkqh7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753376710,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753376710,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 22
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xi1e6",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Roubbes",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xhg0a",
                                "score": 3,
                                "author_fullname": "t2_aoir7erh",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I was thinking Q4",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xi1e6",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking Q4&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xi1e6/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753376000,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753376000,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n584ics",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "michaelsoft__binbows",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n56aed5",
                                          "score": 1,
                                          "author_fullname": "t2_iifi6ul2l",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "i'm generally heavily avoiding that type of use case but it's a pretty compelling one tbh. it depends a lot on the speed of your system ram but basically its going to be in the middle. being able to put some layers in your vram will allow you to run the large model that wont all fit in there somewhat faster than if you don't have a GPU but it will not be anywhere near the speed youd get if you could fit it all into fast vram.\n\ni def would just try to find people with examples of speed they are able to get with the same type of system. you have a fairly common setup i would say.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n584ics",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;i&amp;#39;m generally heavily avoiding that type of use case but it&amp;#39;s a pretty compelling one tbh. it depends a lot on the speed of your system ram but basically its going to be in the middle. being able to put some layers in your vram will allow you to run the large model that wont all fit in there somewhat faster than if you don&amp;#39;t have a GPU but it will not be anywhere near the speed youd get if you could fit it all into fast vram.&lt;/p&gt;\n\n&lt;p&gt;i def would just try to find people with examples of speed they are able to get with the same type of system. you have a fairly common setup i would say.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n584ics/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753512353,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753512353,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n56aed5",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "PatienceKitchen6726",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xhg0a",
                                "score": 1,
                                "author_fullname": "t2_1rxetzin7f",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Could you explain to me, a noob, how much of a performance hit I take if I’m using 128gb ram but only 20gb of vram, on a model that requires more than 20gb? Or is that not really worth it? Really trying to figure it out since my gaming pc is about as good as I’m going to make it, want to find the nuance.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n56aed5",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Could you explain to me, a noob, how much of a performance hit I take if I’m using 128gb ram but only 20gb of vram, on a model that requires more than 20gb? Or is that not really worth it? Really trying to figure it out since my gaming pc is about as good as I’m going to make it, want to find the nuance.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n56aed5/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753484870,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753484870,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xhg0a",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "michaelsoft__binbows",
                      "can_mod_post": false,
                      "created_utc": 1753375840,
                      "send_replies": true,
                      "parent_id": "t1_n4xa7jp",
                      "score": 21,
                      "author_fullname": "t2_iifi6ul2l",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "We're gonna need 96gb for that or thereabouts? 72gb with 3 bit or so quant?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xhg0a",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re gonna need 96gb for that or thereabouts? 72gb with 3 bit or so quant?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xhg0a/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753375840,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 21
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n4z2kj9",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "colin_colout",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n4yrj7p",
                                                              "score": 5,
                                                              "author_fullname": "t2_14l4ya",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Check your prompt processing speed difference. I find it affects prompt processing more than generation. \n\nAlso try tweaking batch and ubatch. Higher numbers will help but use more vram (bonus if you make it a multiple of your shader count)\n\nI chatted this out with Claude and got a great working setup",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n4z2kj9",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check your prompt processing speed difference. I find it affects prompt processing more than generation. &lt;/p&gt;\n\n&lt;p&gt;Also try tweaking batch and ubatch. Higher numbers will help but use more vram (bonus if you make it a multiple of your shader count)&lt;/p&gt;\n\n&lt;p&gt;I chatted this out with Claude and got a great working setup&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m88jdh",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4z2kj9/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753391734,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753391734,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 5
                                                            }
                                                          },
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "text",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": null,
                                                                                            "likes": null,
                                                                                            "replies": {
                                                                                              "kind": "Listing",
                                                                                              "data": {
                                                                                                "after": null,
                                                                                                "dist": null,
                                                                                                "modhash": "",
                                                                                                "geo_filter": "",
                                                                                                "children": [
                                                                                                  {
                                                                                                    "kind": "t1",
                                                                                                    "data": {
                                                                                                      "subreddit_id": "t5_81eyvm",
                                                                                                      "approved_at_utc": null,
                                                                                                      "author_is_blocked": false,
                                                                                                      "comment_type": null,
                                                                                                      "awarders": [],
                                                                                                      "mod_reason_by": null,
                                                                                                      "banned_by": null,
                                                                                                      "author_flair_type": "text",
                                                                                                      "total_awards_received": 0,
                                                                                                      "subreddit": "LocalLLaMA",
                                                                                                      "author_flair_template_id": null,
                                                                                                      "likes": null,
                                                                                                      "replies": {
                                                                                                        "kind": "Listing",
                                                                                                        "data": {
                                                                                                          "after": null,
                                                                                                          "dist": null,
                                                                                                          "modhash": "",
                                                                                                          "geo_filter": "",
                                                                                                          "children": [
                                                                                                            {
                                                                                                              "kind": "more",
                                                                                                              "data": {
                                                                                                                "count": 0,
                                                                                                                "name": "t1__",
                                                                                                                "id": "_",
                                                                                                                "parent_id": "t1_n51u7uo",
                                                                                                                "depth": 10,
                                                                                                                "children": []
                                                                                                              }
                                                                                                            }
                                                                                                          ],
                                                                                                          "before": null
                                                                                                        }
                                                                                                      },
                                                                                                      "user_reports": [],
                                                                                                      "saved": false,
                                                                                                      "id": "n51u7uo",
                                                                                                      "banned_at_utc": null,
                                                                                                      "mod_reason_title": null,
                                                                                                      "gilded": 0,
                                                                                                      "archived": false,
                                                                                                      "collapsed_reason_code": null,
                                                                                                      "no_follow": true,
                                                                                                      "author": "eloquentemu",
                                                                                                      "can_mod_post": false,
                                                                                                      "created_utc": 1753431232,
                                                                                                      "send_replies": true,
                                                                                                      "parent_id": "t1_n51rtas",
                                                                                                      "score": 1,
                                                                                                      "author_fullname": "t2_lpdsy",
                                                                                                      "approved_by": null,
                                                                                                      "mod_note": null,
                                                                                                      "all_awardings": [],
                                                                                                      "collapsed": false,
                                                                                                      "body": "No...  That was ambiguous on my part: the \"235B-A22B\" means there are 235B _total_ but only 22B are used per token.  The 1/3 - 2/3 is of the 22B rather than the 235B.  So you need like ~4GB of VRAM (22/3 * 4.5bpw) for the common active parameters and 130GB for the experts (134GB for that quant - 4GB).  Note that's over your system RAM so you might want to try a smaller quant (and might explain your bad performance).  Could you offload a couple layers to the GPU?  Yes, but keep in mind the the GPU also needs to hold the context (~1GB/5k).  This fits on my 24GB, but it's a different quant so you might need to tweak it:\n\n    llama-cli -c 50000 -ngl 99 -ot '\\.[0-7]\\.=CUDA0' -ot exps=CPU -m Qwen3-235B-A22B-Instruct-2507-Q4_K_M.gguf\n\nI also don't 100% trust that the weights I offload to GPU won't get touched in system RAM.  You should test, of course, but if you get bad performance switch to a Q3.",
                                                                                                      "edited": false,
                                                                                                      "top_awarded_type": null,
                                                                                                      "author_flair_css_class": null,
                                                                                                      "name": "t1_n51u7uo",
                                                                                                      "is_submitter": false,
                                                                                                      "downs": 0,
                                                                                                      "author_flair_richtext": [],
                                                                                                      "author_patreon_flair": false,
                                                                                                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No...  That was ambiguous on my part: the &amp;quot;235B-A22B&amp;quot; means there are 235B &lt;em&gt;total&lt;/em&gt; but only 22B are used per token.  The 1/3 - 2/3 is of the 22B rather than the 235B.  So you need like ~4GB of VRAM (22/3 * 4.5bpw) for the common active parameters and 130GB for the experts (134GB for that quant - 4GB).  Note that&amp;#39;s over your system RAM so you might want to try a smaller quant (and might explain your bad performance).  Could you offload a couple layers to the GPU?  Yes, but keep in mind the the GPU also needs to hold the context (~1GB/5k).  This fits on my 24GB, but it&amp;#39;s a different quant so you might need to tweak it:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;llama-cli -c 50000 -ngl 99 -ot &amp;#39;\\.[0-7]\\.=CUDA0&amp;#39; -ot exps=CPU -m Qwen3-235B-A22B-Instruct-2507-Q4_K_M.gguf\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I also don&amp;#39;t 100% trust that the weights I offload to GPU won&amp;#39;t get touched in system RAM.  You should test, of course, but if you get bad performance switch to a Q3.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                                      "removal_reason": null,
                                                                                                      "collapsed_reason": null,
                                                                                                      "distinguished": null,
                                                                                                      "associated_award": null,
                                                                                                      "stickied": false,
                                                                                                      "author_premium": false,
                                                                                                      "can_gild": false,
                                                                                                      "gildings": {},
                                                                                                      "unrepliable_reason": null,
                                                                                                      "author_flair_text_color": null,
                                                                                                      "score_hidden": false,
                                                                                                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51u7uo/",
                                                                                                      "subreddit_type": "public",
                                                                                                      "locked": false,
                                                                                                      "report_reasons": null,
                                                                                                      "created": 1753431232,
                                                                                                      "author_flair_text": null,
                                                                                                      "treatment_tags": [],
                                                                                                      "link_id": "t3_1m88jdh",
                                                                                                      "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                                      "controversiality": 0,
                                                                                                      "depth": 9,
                                                                                                      "author_flair_background_color": null,
                                                                                                      "collapsed_because_crowd_control": null,
                                                                                                      "mod_reports": [],
                                                                                                      "num_reports": null,
                                                                                                      "ups": 1
                                                                                                    }
                                                                                                  }
                                                                                                ],
                                                                                                "before": null
                                                                                              }
                                                                                            },
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n51rtas",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": true,
                                                                                            "author": "Mediocre-Waltz6792",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1753429869,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n51qsjp",
                                                                                            "score": 1,
                                                                                            "author_fullname": "t2_r7wlk6atm",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "ah so you need enough Vram to fix roughly 2/3 of the model to get good speeds? \n\nI have 128gb with a 3090 and 3060 ti. Getting around 1.6 t/s with the Qwen3-235B-A22B-Instruct-2507-UD-Q4\\_K\\_XL",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n51rtas",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ah so you need enough Vram to fix roughly 2/3 of the model to get good speeds? &lt;/p&gt;\n\n&lt;p&gt;I have 128gb with a 3090 and 3060 ti. Getting around 1.6 t/s with the Qwen3-235B-A22B-Instruct-2507-UD-Q4_K_XL&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": null,
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51rtas/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1753429869,
                                                                                            "author_flair_text": null,
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1m88jdh",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": null,
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 1
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n51qsjp",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": true,
                                                                                  "author": "eloquentemu",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1753429289,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n51pokv",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_lpdsy",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "I get 50% improvement and perhaps more importantly I see less dropoff with longer context.  This sort of checks out because most MoEs have about 2/3 of their active parameters in experts and 1/3 in common weights (varies by architecture but roughly).  If you handwave those as happening instantly on the GPU you get 3/2 == 150% speed up, so I would guess this is probably somewhat independent of system unless you have like a really slow GPU and very fast CPU somehow.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n51qsjp",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I get 50% improvement and perhaps more importantly I see less dropoff with longer context.  This sort of checks out because most MoEs have about 2/3 of their active parameters in experts and 1/3 in common weights (varies by architecture but roughly).  If you handwave those as happening instantly on the GPU you get 3/2 == 150% speed up, so I would guess this is probably somewhat independent of system unless you have like a really slow GPU and very fast CPU somehow.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1m88jdh",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51qsjp/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1753429289,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n51pokv",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "Mediocre-Waltz6792",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n4zqzwn",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_r7wlk6atm",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "When you off load all the experts what kind of speed increase should a person see?",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n51pokv",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;When you off load all the experts what kind of speed increase should a person see?&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1m88jdh",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51pokv/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1753428650,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1753428650,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    },
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "text",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": null,
                                                                                            "likes": null,
                                                                                            "replies": {
                                                                                              "kind": "Listing",
                                                                                              "data": {
                                                                                                "after": null,
                                                                                                "dist": null,
                                                                                                "modhash": "",
                                                                                                "geo_filter": "",
                                                                                                "children": [
                                                                                                  {
                                                                                                    "kind": "t1",
                                                                                                    "data": {
                                                                                                      "subreddit_id": "t5_81eyvm",
                                                                                                      "approved_at_utc": null,
                                                                                                      "author_is_blocked": false,
                                                                                                      "comment_type": null,
                                                                                                      "awarders": [],
                                                                                                      "mod_reason_by": null,
                                                                                                      "banned_by": null,
                                                                                                      "author_flair_type": "text",
                                                                                                      "total_awards_received": 0,
                                                                                                      "subreddit": "LocalLLaMA",
                                                                                                      "author_flair_template_id": null,
                                                                                                      "likes": null,
                                                                                                      "replies": {
                                                                                                        "kind": "Listing",
                                                                                                        "data": {
                                                                                                          "after": null,
                                                                                                          "dist": null,
                                                                                                          "modhash": "",
                                                                                                          "geo_filter": "",
                                                                                                          "children": [
                                                                                                            {
                                                                                                              "kind": "more",
                                                                                                              "data": {
                                                                                                                "count": 0,
                                                                                                                "name": "t1__",
                                                                                                                "id": "_",
                                                                                                                "parent_id": "t1_n54r99u",
                                                                                                                "depth": 10,
                                                                                                                "children": []
                                                                                                              }
                                                                                                            }
                                                                                                          ],
                                                                                                          "before": null
                                                                                                        }
                                                                                                      },
                                                                                                      "user_reports": [],
                                                                                                      "saved": false,
                                                                                                      "id": "n54r99u",
                                                                                                      "banned_at_utc": null,
                                                                                                      "mod_reason_title": null,
                                                                                                      "gilded": 0,
                                                                                                      "archived": false,
                                                                                                      "collapsed_reason_code": null,
                                                                                                      "no_follow": true,
                                                                                                      "author": "eloquentemu",
                                                                                                      "can_mod_post": false,
                                                                                                      "created_utc": 1753468023,
                                                                                                      "send_replies": true,
                                                                                                      "parent_id": "t1_n54kaoa",
                                                                                                      "score": 2,
                                                                                                      "author_fullname": "t2_lpdsy",
                                                                                                      "approved_by": null,
                                                                                                      "mod_note": null,
                                                                                                      "all_awardings": [],
                                                                                                      "collapsed": false,
                                                                                                      "body": "Excellent!  Ah, yeah, I checked my machine with SMT enabled and they do populate with 0-N as physical and N-2N as the SMT.  You might want to try `1-14` too, since core 0 tends to be a bit busier than others, at least historically.\n\nI haven't tried `ik_llama.cpp`.  I probably _should_ but I also don't feel like any benchmarks I've seen really wowed me.  Maybe I'll give it a try today, though.  The bug in the server with GPU-hybrid in MoE hits me quite hard so if ik_llama.cpp fixes that it'll be my new BFF.  It does claim better mixed CPU-GPU inference, so might be worth it for you\n\nEDIT: Not off to a good start. Top is llama.cpp, bottom is ik_llama.cpp.  Note that ik_llama.cpp needed `--runtime-repack 1` or I was getting like 3t/s.  I'm making a ik-native quant now so we'll see.  The PP increase is nice, but I don't think it's worth the TG loss.  I wonder if you might have more luck... I sort of get the impression its main target is more desktop machines.\n\n| model                            |       size |     params | backend    | ngl | ot        | threads |    test |             t/s |\n| -------------------------------- | ---------: | ---------: | ---------- | --: | --------- | ------: | ------: | --------------: |\n| qwen3moe 235B.A22B Q4_K - Medium | 132.39 GiB |   235.09 B | CUDA       |  99 | exps=CPU  |      48 |   pp512 |    75.75 ± 0.00 |\n| qwen3moe 235B.A22B Q4_K - Medium | 132.39 GiB |   235.09 B | CUDA       |  99 | exps=CPU  |      48 |   tg128 |    18.92 ± 0.00 |\n| qwen3moe ?B Q4_K - Medium        | 132.39 GiB |   235.09 B | CPU        |     | exps=CPU  |      48 |   pp512 |   124.46 ± 0.00 |\n| qwen3moe ?B Q4_K - Medium        | 132.39 GiB |   235.09 B | CPU        |     | exps=CPU  |      48 |   tg128 |    14.17 ± 0.00 |\n| qwen3moe ?B Q4_K - Medium        | 132.39 GiB |   235.09 B | CUDA       |  99 | exps=CPU  |      48 |   pp512 |   167.45 ± 0.00 |\n| qwen3moe ?B Q4_K - Medium        | 132.39 GiB |   235.09 B | CUDA       |  99 | exps=CPU  |      48 |   tg128 |     3.01 ± 0.00 |\n| qwen3moe ?B IQ4_K - 4.5 bpw      | 124.02 GiB |   235.09 B | CUDA       |  99 | exps=CPU  |       8 |   pp512 |    82.78 ± 0.00 |\n| qwen3moe ?B IQ4_K - 4.5 bpw      | 124.02 GiB |   235.09 B | CUDA       |  99 | exps=CPU  |       8 |   tg128 |     8.77 ± 0.00 |\n\n\nEDIT2: The initial table was actually with GPU disabled for ik.  Using normal Q4_K_M.  With GPU enabled it's way worse, though still credit for PP, I guess?\n\nEDIT3: It does seem like it's under utilizing the CPU.  Using `IQ4_K` and `--threads=8` gives best tg128, though 4 threads only drops off by like 10%.  Tweaking batch sizes doesn't affect the tg128 meaningfully at 16 threads - it's always worse than 8.",
                                                                                                      "edited": 1753478971,
                                                                                                      "top_awarded_type": null,
                                                                                                      "author_flair_css_class": null,
                                                                                                      "name": "t1_n54r99u",
                                                                                                      "is_submitter": false,
                                                                                                      "downs": 0,
                                                                                                      "author_flair_richtext": [],
                                                                                                      "author_patreon_flair": false,
                                                                                                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Excellent!  Ah, yeah, I checked my machine with SMT enabled and they do populate with 0-N as physical and N-2N as the SMT.  You might want to try &lt;code&gt;1-14&lt;/code&gt; too, since core 0 tends to be a bit busier than others, at least historically.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t tried &lt;code&gt;ik_llama.cpp&lt;/code&gt;.  I probably &lt;em&gt;should&lt;/em&gt; but I also don&amp;#39;t feel like any benchmarks I&amp;#39;ve seen really wowed me.  Maybe I&amp;#39;ll give it a try today, though.  The bug in the server with GPU-hybrid in MoE hits me quite hard so if ik_llama.cpp fixes that it&amp;#39;ll be my new BFF.  It does claim better mixed CPU-GPU inference, so might be worth it for you&lt;/p&gt;\n\n&lt;p&gt;EDIT: Not off to a good start. Top is llama.cpp, bottom is ik_llama.cpp.  Note that ik_llama.cpp needed &lt;code&gt;--runtime-repack 1&lt;/code&gt; or I was getting like 3t/s.  I&amp;#39;m making a ik-native quant now so we&amp;#39;ll see.  The PP increase is nice, but I don&amp;#39;t think it&amp;#39;s worth the TG loss.  I wonder if you might have more luck... I sort of get the impression its main target is more desktop machines.&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;model&lt;/th&gt;\n&lt;th align=\"right\"&gt;size&lt;/th&gt;\n&lt;th align=\"right\"&gt;params&lt;/th&gt;\n&lt;th&gt;backend&lt;/th&gt;\n&lt;th align=\"right\"&gt;ngl&lt;/th&gt;\n&lt;th&gt;ot&lt;/th&gt;\n&lt;th align=\"right\"&gt;threads&lt;/th&gt;\n&lt;th align=\"right\"&gt;test&lt;/th&gt;\n&lt;th align=\"right\"&gt;t/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 235B.A22B Q4_K - Medium&lt;/td&gt;\n&lt;td align=\"right\"&gt;132.39 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;235.09 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;48&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;75.75 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe 235B.A22B Q4_K - Medium&lt;/td&gt;\n&lt;td align=\"right\"&gt;132.39 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;235.09 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;48&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;18.92 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe ?B Q4_K - Medium&lt;/td&gt;\n&lt;td align=\"right\"&gt;132.39 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;235.09 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;48&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;124.46 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe ?B Q4_K - Medium&lt;/td&gt;\n&lt;td align=\"right\"&gt;132.39 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;235.09 B&lt;/td&gt;\n&lt;td&gt;CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;48&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;14.17 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe ?B Q4_K - Medium&lt;/td&gt;\n&lt;td align=\"right\"&gt;132.39 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;235.09 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;48&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;167.45 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe ?B Q4_K - Medium&lt;/td&gt;\n&lt;td align=\"right\"&gt;132.39 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;235.09 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;48&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;3.01 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe ?B IQ4_K - 4.5 bpw&lt;/td&gt;\n&lt;td align=\"right\"&gt;124.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;235.09 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;8&lt;/td&gt;\n&lt;td align=\"right\"&gt;pp512&lt;/td&gt;\n&lt;td align=\"right\"&gt;82.78 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;qwen3moe ?B IQ4_K - 4.5 bpw&lt;/td&gt;\n&lt;td align=\"right\"&gt;124.02 GiB&lt;/td&gt;\n&lt;td align=\"right\"&gt;235.09 B&lt;/td&gt;\n&lt;td&gt;CUDA&lt;/td&gt;\n&lt;td align=\"right\"&gt;99&lt;/td&gt;\n&lt;td&gt;exps=CPU&lt;/td&gt;\n&lt;td align=\"right\"&gt;8&lt;/td&gt;\n&lt;td align=\"right\"&gt;tg128&lt;/td&gt;\n&lt;td align=\"right\"&gt;8.77 ± 0.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;EDIT2: The initial table was actually with GPU disabled for ik.  Using normal Q4_K_M.  With GPU enabled it&amp;#39;s way worse, though still credit for PP, I guess?&lt;/p&gt;\n\n&lt;p&gt;EDIT3: It does seem like it&amp;#39;s under utilizing the CPU.  Using &lt;code&gt;IQ4_K&lt;/code&gt; and &lt;code&gt;--threads=8&lt;/code&gt; gives best tg128, though 4 threads only drops off by like 10%.  Tweaking batch sizes doesn&amp;#39;t affect the tg128 meaningfully at 16 threads - it&amp;#39;s always worse than 8.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                                      "removal_reason": null,
                                                                                                      "collapsed_reason": null,
                                                                                                      "distinguished": null,
                                                                                                      "associated_award": null,
                                                                                                      "stickied": false,
                                                                                                      "author_premium": false,
                                                                                                      "can_gild": false,
                                                                                                      "gildings": {},
                                                                                                      "unrepliable_reason": null,
                                                                                                      "author_flair_text_color": null,
                                                                                                      "score_hidden": false,
                                                                                                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n54r99u/",
                                                                                                      "subreddit_type": "public",
                                                                                                      "locked": false,
                                                                                                      "report_reasons": null,
                                                                                                      "created": 1753468023,
                                                                                                      "author_flair_text": null,
                                                                                                      "treatment_tags": [],
                                                                                                      "link_id": "t3_1m88jdh",
                                                                                                      "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                                      "controversiality": 0,
                                                                                                      "depth": 9,
                                                                                                      "author_flair_background_color": null,
                                                                                                      "collapsed_because_crowd_control": null,
                                                                                                      "mod_reports": [],
                                                                                                      "num_reports": null,
                                                                                                      "ups": 2
                                                                                                    }
                                                                                                  }
                                                                                                ],
                                                                                                "before": null
                                                                                              }
                                                                                            },
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n54kaoa",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": true,
                                                                                            "author": "perelmanych",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1753466036,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n549f7x",
                                                                                            "score": 1,
                                                                                            "author_fullname": "t2_63q8kong",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "I used binding to physical cores with --threads 14 --cpu-range 0-13 --cpu-strict 1 command and speed for CPU only variant went up from 2.7 to 3.2. So thanks for idea!  \n  \nBtw, have you tried ik\\_llama.cpp? Do I need to bother with it for big MOE models?",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n54kaoa",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I used binding to physical cores with --threads 14 --cpu-range 0-13 --cpu-strict 1 command and speed for CPU only variant went up from 2.7 to 3.2. So thanks for idea!  &lt;/p&gt;\n\n&lt;p&gt;Btw, have you tried ik_llama.cpp? Do I need to bother with it for big MOE models?&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": null,
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n54kaoa/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1753466036,
                                                                                            "author_flair_text": null,
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1m88jdh",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": null,
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 1
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n549f7x",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": true,
                                                                                  "author": "eloquentemu",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1753463061,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n521grm",
                                                                                  "score": 2,
                                                                                  "author_fullname": "t2_lpdsy",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "Don't test with llama-server.  There is [a bug](https://github.com/ggml-org/llama.cpp/issues/14201) that can make the llama-server performance very unpredictable in these situations.  Regardless of whether you're effected, `llama-bench` is there for testing and will do multiple runs to ensure more accurate performance measurement.  I would also suggest not having so many http-thread and turning off SMT (or use `--cpu-mask 55555554`) - it might not matter too much, but should improve consistency.\n\nFor memory bandwith calc, keep in mind that \"Q2\" doesn't mean 2bpw average: consider that the UD-Q2_K_XL is 88GB or ~3bpw on average.  These quants occur in blocks so it's like a bunch of 2b values and a 16b scale.  On top of that, not all tensors are Q2, some are Q4+.  On top of that, derate your CPU memory bandwidth by about 50% - CPUs lose bus cycles to cache flushes and other processes and 50% seems roughly right IME.  Taken together, the 2.7t/s on pure CPU is exactly what I would expect.\n\nFor mulit-GPU, I think `llama.cpp` is just bad at it, TBH.  Everyone says that the PCIe link makes very little difference... Like I have 2 GPUs, both Gen4 x16 and I basically get the same results as you: second GPU adds like 10% TG, 25% PP.  Well, like approximately the same since your numbers are so inconsistent (again, use llama-bench).  You could try `vllm`, maybe, but I haven't really bothered since I don't usually run dual-GPU.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n549f7x",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Don&amp;#39;t test with llama-server.  There is &lt;a href=\"https://github.com/ggml-org/llama.cpp/issues/14201\"&gt;a bug&lt;/a&gt; that can make the llama-server performance very unpredictable in these situations.  Regardless of whether you&amp;#39;re effected, &lt;code&gt;llama-bench&lt;/code&gt; is there for testing and will do multiple runs to ensure more accurate performance measurement.  I would also suggest not having so many http-thread and turning off SMT (or use &lt;code&gt;--cpu-mask 55555554&lt;/code&gt;) - it might not matter too much, but should improve consistency.&lt;/p&gt;\n\n&lt;p&gt;For memory bandwith calc, keep in mind that &amp;quot;Q2&amp;quot; doesn&amp;#39;t mean 2bpw average: consider that the UD-Q2_K_XL is 88GB or ~3bpw on average.  These quants occur in blocks so it&amp;#39;s like a bunch of 2b values and a 16b scale.  On top of that, not all tensors are Q2, some are Q4+.  On top of that, derate your CPU memory bandwidth by about 50% - CPUs lose bus cycles to cache flushes and other processes and 50% seems roughly right IME.  Taken together, the 2.7t/s on pure CPU is exactly what I would expect.&lt;/p&gt;\n\n&lt;p&gt;For mulit-GPU, I think &lt;code&gt;llama.cpp&lt;/code&gt; is just bad at it, TBH.  Everyone says that the PCIe link makes very little difference... Like I have 2 GPUs, both Gen4 x16 and I basically get the same results as you: second GPU adds like 10% TG, 25% PP.  Well, like approximately the same since your numbers are so inconsistent (again, use llama-bench).  You could try &lt;code&gt;vllm&lt;/code&gt;, maybe, but I haven&amp;#39;t really bothered since I don&amp;#39;t usually run dual-GPU.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1m88jdh",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n549f7x/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1753463061,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 2
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n521grm",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "perelmanych",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n4zqzwn",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_63q8kong",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "So I did my home work. CPU only is when there is no ngl parameter. I checked GPU memory load is zero.\n\nFirst configuration:  \nAMD Ryzen 5950X @ 4Gh  \nRAM DDR4 32+32+16+16 @ 3000 (aida64 42Gb/s read)  \nRTX 3090 PCIEx2 + RTX 3090 PCIEx16 with power limit at 250W\n\nMy command line:\n\n    llama-server ^\n    \t--model C:\\Users\\rchuh\\.cache\\lm-studio\\models\\unsloth\\Qwen3-235B-A22B-Instruct-2507-GGUF\\Qwen3-235B-A22B-Instruct-2507-UD-Q2_K_XL-00001-of-00002.gguf ^\n    \t--alias Qwen3-235B-A22B-Instruct-2507 ^\n            --threads 14 ^\n            --threads-http 14 ^\n            --flash-attn ^\n            --cache-type-k q8_0 --cache-type-v q8_0 ^\n            --no-context-shift ^\n    \t--main-gpu 0 ^\n            --temp 0.6 --top-k 20 --top-p 0.8 --min-p 0 --repeat-penalty 1.0 --presence-penalty 2.0 ^\n    \t--ctx-size 12000 ^\n            --n-predict 12000 ^\n    \t--host 0.0.0.0 --port 8000 ^\n    \t--no-mmap ^\n    \t-ts 1,1 ^\n    \t--n-gpu-layers 999 ^\n    \t--override-tensor \"blk\\.(?:[1-9]?[13579])\\.ffn_.*_exps\\.weight=CPU\" ^\n    \t--batch_size 2048 --ubatch_size 512\n\nI don't know how I happen to get 3.3t/s yesterday with CPU only. Today I consistently get 2.7t/s. Here is a table with different batch and ubatch configs:\n\nhttps://preview.redd.it/vcbwg98n00ff1.png?width=1533&amp;format=png&amp;auto=webp&amp;s=bdb2239d1511ca56de0e0bc1424b78de73db767e\n\nThere are two things that absolutely doesn't make sense to me. First, if we have 22B active parameters then at Q2 it should be around 5.5Gb. With my memory bandwidth it should give around 8 t/s instead of 2.7 t/s that I observe. Second, how that happens that with offloading only to 1 GPU I have higher tg speed than with 2 GPUs (see 1GPU column in the table).\n\nEdited: Added PCIE lanes and results for second GPU. Now it starts to make more sense as second GPU has x8 more PCIE lanes which is reflected in pp speed.",
                                                                        "edited": 1753439939,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n521grm",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So I did my home work. CPU only is when there is no ngl parameter. I checked GPU memory load is zero.&lt;/p&gt;\n\n&lt;p&gt;First configuration:&lt;br/&gt;\nAMD Ryzen 5950X @ 4Gh&lt;br/&gt;\nRAM DDR4 32+32+16+16 @ 3000 (aida64 42Gb/s read)&lt;br/&gt;\nRTX 3090 PCIEx2 + RTX 3090 PCIEx16 with power limit at 250W&lt;/p&gt;\n\n&lt;p&gt;My command line:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;llama-server ^\n    --model C:\\Users\\rchuh\\.cache\\lm-studio\\models\\unsloth\\Qwen3-235B-A22B-Instruct-2507-GGUF\\Qwen3-235B-A22B-Instruct-2507-UD-Q2_K_XL-00001-of-00002.gguf ^\n    --alias Qwen3-235B-A22B-Instruct-2507 ^\n        --threads 14 ^\n        --threads-http 14 ^\n        --flash-attn ^\n        --cache-type-k q8_0 --cache-type-v q8_0 ^\n        --no-context-shift ^\n    --main-gpu 0 ^\n        --temp 0.6 --top-k 20 --top-p 0.8 --min-p 0 --repeat-penalty 1.0 --presence-penalty 2.0 ^\n    --ctx-size 12000 ^\n        --n-predict 12000 ^\n    --host 0.0.0.0 --port 8000 ^\n    --no-mmap ^\n    -ts 1,1 ^\n    --n-gpu-layers 999 ^\n    --override-tensor &amp;quot;blk\\.(?:[1-9]?[13579])\\.ffn_.*_exps\\.weight=CPU&amp;quot; ^\n    --batch_size 2048 --ubatch_size 512\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I don&amp;#39;t know how I happen to get 3.3t/s yesterday with CPU only. Today I consistently get 2.7t/s. Here is a table with different batch and ubatch configs:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vcbwg98n00ff1.png?width=1533&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bdb2239d1511ca56de0e0bc1424b78de73db767e\"&gt;https://preview.redd.it/vcbwg98n00ff1.png?width=1533&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bdb2239d1511ca56de0e0bc1424b78de73db767e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;There are two things that absolutely doesn&amp;#39;t make sense to me. First, if we have 22B active parameters then at Q2 it should be around 5.5Gb. With my memory bandwidth it should give around 8 t/s instead of 2.7 t/s that I observe. Second, how that happens that with offloading only to 1 GPU I have higher tg speed than with 2 GPUs (see 1GPU column in the table).&lt;/p&gt;\n\n&lt;p&gt;Edited: Added PCIE lanes and results for second GPU. Now it starts to make more sense as second GPU has x8 more PCIE lanes which is reflected in pp speed.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1m88jdh",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n521grm/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1753435423,
                                                                        "media_metadata": {
                                                                          "vcbwg98n00ff1": {
                                                                            "status": "valid",
                                                                            "e": "Image",
                                                                            "m": "image/png",
                                                                            "p": [
                                                                              {
                                                                                "y": 9,
                                                                                "x": 108,
                                                                                "u": "https://preview.redd.it/vcbwg98n00ff1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f7a6cd2dedf3761cf62c8360300786d8128c3049"
                                                                              },
                                                                              {
                                                                                "y": 19,
                                                                                "x": 216,
                                                                                "u": "https://preview.redd.it/vcbwg98n00ff1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a8d6a7023bd4ac0b62b180417dff47a8a4361dd6"
                                                                              },
                                                                              {
                                                                                "y": 28,
                                                                                "x": 320,
                                                                                "u": "https://preview.redd.it/vcbwg98n00ff1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e3a906b836e8d2aab0b6e239892466dd10799d0c"
                                                                              },
                                                                              {
                                                                                "y": 57,
                                                                                "x": 640,
                                                                                "u": "https://preview.redd.it/vcbwg98n00ff1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7ee63c2634c737f1126deeaf2ba7d4663012b2f3"
                                                                              },
                                                                              {
                                                                                "y": 85,
                                                                                "x": 960,
                                                                                "u": "https://preview.redd.it/vcbwg98n00ff1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=95eaf5bff5cef676ac418b7da03ad4a3cfd5f92d"
                                                                              },
                                                                              {
                                                                                "y": 96,
                                                                                "x": 1080,
                                                                                "u": "https://preview.redd.it/vcbwg98n00ff1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=30d4f4d55014c665f8a79d3163da38ba9634dc1c"
                                                                              }
                                                                            ],
                                                                            "s": {
                                                                              "y": 137,
                                                                              "x": 1533,
                                                                              "u": "https://preview.redd.it/vcbwg98n00ff1.png?width=1533&amp;format=png&amp;auto=webp&amp;s=bdb2239d1511ca56de0e0bc1424b78de73db767e"
                                                                            },
                                                                            "id": "vcbwg98n00ff1"
                                                                          }
                                                                        },
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1753435423,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n4zqzwn",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "eloquentemu",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n4yrj7p",
                                                              "score": 3,
                                                              "author_fullname": "t2_lpdsy",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "I guess to sanity check, was your 3.3t/s with `CUDA_VISIBLE_DEVICES=-1`?  How much RAM do you have?  DDR4?  What happens if you do `CUDA_VISIBLE_DEVICES=0` and `-ngl 99 -op exps=CPU` (i.e use one GPU and offload all experts).  I can't replicate anything like what you're seeing...",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n4zqzwn",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I guess to sanity check, was your 3.3t/s with &lt;code&gt;CUDA_VISIBLE_DEVICES=-1&lt;/code&gt;?  How much RAM do you have?  DDR4?  What happens if you do &lt;code&gt;CUDA_VISIBLE_DEVICES=0&lt;/code&gt; and &lt;code&gt;-ngl 99 -op exps=CPU&lt;/code&gt; (i.e use one GPU and offload all experts).  I can&amp;#39;t replicate anything like what you&amp;#39;re seeing...&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m88jdh",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zqzwn/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753399457,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753399457,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 3
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n4yrj7p",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "perelmanych",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4y2hk4",
                                                    "score": 2,
                                                    "author_fullname": "t2_63q8kong",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "May be you can help me with my quest. When I run Qwen3-235B-A22B-Instruct-2507-UD-Q2\\_K\\_XL purely on CPU I get 3.3t/s. When I offload part of LLM to two RTX 3090 cards with string \"blk\\\\.(?:\\[1-9\\]?\\[13579\\])\\\\.ffn\\_.\\*\\_exps\\\\.weight=CPU\" I get at most 4.4t/s. Basically I am offloading half of the LLM to GPU and speed increase is so negligible. What am I doing wrong?",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n4yrj7p",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;May be you can help me with my quest. When I run Qwen3-235B-A22B-Instruct-2507-UD-Q2_K_XL purely on CPU I get 3.3t/s. When I offload part of LLM to two RTX 3090 cards with string &amp;quot;blk\\.(?:[1-9]?[13579])\\.ffn_.*_exps\\.weight=CPU&amp;quot; I get at most 4.4t/s. Basically I am offloading half of the LLM to GPU and speed increase is so negligible. What am I doing wrong?&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yrj7p/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753388606,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753388606,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n4znfns",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "Affectionate-Cap-600",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4y2hk4",
                                                    "score": 1,
                                                    "author_fullname": "t2_5oltmr5b",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "&gt;I thought you meant guessing about the new model rather than Qwen3-235B.  Well, no, you don't have to guess because the model is released and you can just look at the tensors. \n\n\nyeah thanks!\n\nbtw I did the math in my other message, it is ~7B (routed) active parameters~(https://www.reddit.com/r/LocalLLaMA/s/f2aq3b4hJI)",
                                                    "edited": 1753401296,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n4znfns",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I thought you meant guessing about the new model rather than Qwen3-235B.  Well, no, you don&amp;#39;t have to guess because the model is released and you can just look at the tensors. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;yeah thanks!&lt;/p&gt;\n\n&lt;p&gt;btw I did the math in my other message, it is ~7B (routed) active parameters~(&lt;a href=\"https://www.reddit.com/r/LocalLLaMA/s/f2aq3b4hJI\"&gt;https://www.reddit.com/r/LocalLLaMA/s/f2aq3b4hJI&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4znfns/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753398284,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753398284,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4y2hk4",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "eloquentemu",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xoeec",
                                          "score": 4,
                                          "author_fullname": "t2_lpdsy",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I mean, I think that's tacit in the \"we will see\" - they're guessing\n\nWhile A22B means 22B active, there is a mix of tensors involved in that.  Yes, _most_ are experts, but even without shared experts there are still plenty of others and these are common to all LLMs.  So, Kimi-K2 has 1 shared expert and 8 routed experts.  Some quick math says that it only has 20.5B routed parameters (58 layer \\* 8 expert \\* 3\\*7168\\*2048 params).  Qwen3-Coder-480B-A35B has 0 shared experts and ~22.2B routed.  So it's a very reasonable assumption that there are &lt;12B active.  If it wasn't they'd probably be advertising a fundamental change to LLM architecture.\n\nEDIT: I thought you meant guessing about the new model rather than Qwen3-235B.  Well, no, you don't have to guess because the model is released and you can just look at the tensors.  By my math it has 14B routed: 92 layer \\* 8 expert \\* 3\\*1536\\*4096.  I'm guessing the parent remembered backwards: ~14B routed would mean ~8B shared which is within rounding error of the 7B they said to be routed.",
                                          "edited": 1753383006,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4y2hk4",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I mean, I think that&amp;#39;s tacit in the &amp;quot;we will see&amp;quot; - they&amp;#39;re guessing&lt;/p&gt;\n\n&lt;p&gt;While A22B means 22B active, there is a mix of tensors involved in that.  Yes, &lt;em&gt;most&lt;/em&gt; are experts, but even without shared experts there are still plenty of others and these are common to all LLMs.  So, Kimi-K2 has 1 shared expert and 8 routed experts.  Some quick math says that it only has 20.5B routed parameters (58 layer * 8 expert * 3*7168*2048 params).  Qwen3-Coder-480B-A35B has 0 shared experts and ~22.2B routed.  So it&amp;#39;s a very reasonable assumption that there are &amp;lt;12B active.  If it wasn&amp;#39;t they&amp;#39;d probably be advertising a fundamental change to LLM architecture.&lt;/p&gt;\n\n&lt;p&gt;EDIT: I thought you meant guessing about the new model rather than Qwen3-235B.  Well, no, you don&amp;#39;t have to guess because the model is released and you can just look at the tensors.  By my math it has 14B routed: 92 layer * 8 expert * 3*1536*4096.  I&amp;#39;m guessing the parent remembered backwards: ~14B routed would mean ~8B shared which is within rounding error of the 7B they said to be routed.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y2hk4/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753381521,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753381521,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4zmzlq",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Affectionate-Cap-600",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xoeec",
                                          "score": 2,
                                          "author_fullname": "t2_5oltmr5b",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "why  \"guess\"? it is a open weigh model, you can easily make the math yourself .... \n\n&gt;no public split between routed vs shared\n\nwhat are you talking about?\n\n\n(...I honestly don't know how this comment can be upvoted. are we on local llama right?)\n \nfor qwen 3 235B22A:\n\n- hiddden dim: 4096.\n- head dim: 128. \n- n heads (GQA): 64/8/8. \n- MoE FFN intermediate dim: 1536. \n- dense FFN intermediate dim: 11288 (exactly Moe interm dim * active experts). \n- n layers: 94. \n- active experts per token: 8.\n\n(for reference, since it is open weight and I'm not \"guessing\": https://huggingface.co/Qwen/Qwen3-235B-A22B/blob/main/config.json)\n\nattention parameters:\n(4.096×128×(64+8+8)+(128×64×4.096))×94 =  7.096.762.368\n\ndense layers FFN:\n4.096×12.288×3×94÷2 = 7.096.762.368\n\nMoE layers FFN:\n4.096×1.536×3×8×94÷2 = 7.096.762.368\n\nfunny how they are all the same? \n\ntotal active : 21.290.287.104 \n\ntotal always active: 14.193.524.736\n\nto that, you have to add the embedding layer parameters and the LM head parameters + some parameters for the router.\n\nyou can easily do the same for llama 4.\nit has less layers but higher hidden dim and intermediate dim for the dense FFN, + only 2 active experts, of which one is always active (so it end up on the 'always active' side)\n\n\n**edit: I made an error, I'm sorry, the kv heads are 4 not 8**\n\nso the attention parameters are \n(4.096×128×(64+4+4)+(128×64×4.096))x94= 6.702.497,792 \n\nnow you end up 13.799.260.160 always active parameters and a total of 20.896.022.528 active parameters. \n\nit doesn't change much... it seemed incredibly beautiful/elegant to me  that every component (attention, dense FFN and active MoE FNN) had the same parameters count, but now it make more sense, having the same parameters for dense and active expert and something less for attention. \n\nside note:\nto that you still have to add 151936 * 4096 (that also are always active parameters) \n\nplease note that in their paper (https://arxiv.org/pdf/2505.09388, see tab 1 and 2) they don't say explicitly if they tied the embeddings of the embedding layer and the LM head, they have a tab (tab 1) but it only list this info for the dense versions of qwen 3, while in the tab about the MoEs (tab 2), the column that should say in they tied those embeddings is absent. so, we will ignore that and assume they are tied, since the difference is just ~0.6B. same for the parameters for the parameters of the router/s, (what will make even less difference) \n\n*side note 2:\njust a personal opinion, but their paper is all about benchmarks and didn't include any kind of justification/explanation for any of their architectural choices. also, not a single ablation about that.*\n\n\n**EDIT 2: i admit that i may have made a crucial error.**\n\n**I misunderstood the effect of  \"\"decoder_sparse_step\" (https://github.com/huggingface/transformers/blob/5a81d7e0b388fb2b86fc1279cdc07d9dc7e84b4c/src/transformers/models/qwen3_moe/modeling_qwen3_moe.py), since it is set to 1 as in their config, it don't create any dense layer. so my calculation is wrong.**\n\n**the FFN MoEs parameters are 4.096×1.536×3×8×94 (without the '/2'), so 14.193,524736.**\n\n**consequently the 'always active' parameters are 6.702.497,792 (just the attention parameters)**\n\n(still, this make the difference between llama4 and qwen 3 that I was pointing out in my previous comment even more relevant) \n\nbtw, as you can see from the modeling file, each router is a linear layer with dimensionality hidden dim to total number of expert. so 4096 * 128 * 96, ~ 0.05B.\nthe embedding parameters and LM head are tied so this add just 150k * 4096 ~0.62B",
                                          "edited": 1753406282,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4zmzlq",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;why  &amp;quot;guess&amp;quot;? it is a open weigh model, you can easily make the math yourself .... &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;no public split between routed vs shared&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;what are you talking about?&lt;/p&gt;\n\n&lt;p&gt;(...I honestly don&amp;#39;t know how this comment can be upvoted. are we on local llama right?)&lt;/p&gt;\n\n&lt;p&gt;for qwen 3 235B22A:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;hiddden dim: 4096.&lt;/li&gt;\n&lt;li&gt;head dim: 128. &lt;/li&gt;\n&lt;li&gt;n heads (GQA): 64/8/8. &lt;/li&gt;\n&lt;li&gt;MoE FFN intermediate dim: 1536. &lt;/li&gt;\n&lt;li&gt;dense FFN intermediate dim: 11288 (exactly Moe interm dim * active experts). &lt;/li&gt;\n&lt;li&gt;n layers: 94. &lt;/li&gt;\n&lt;li&gt;active experts per token: 8.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;(for reference, since it is open weight and I&amp;#39;m not &amp;quot;guessing&amp;quot;: &lt;a href=\"https://huggingface.co/Qwen/Qwen3-235B-A22B/blob/main/config.json\"&gt;https://huggingface.co/Qwen/Qwen3-235B-A22B/blob/main/config.json&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;attention parameters:\n(4.096×128×(64+8+8)+(128×64×4.096))×94 =  7.096.762.368&lt;/p&gt;\n\n&lt;p&gt;dense layers FFN:\n4.096×12.288×3×94÷2 = 7.096.762.368&lt;/p&gt;\n\n&lt;p&gt;MoE layers FFN:\n4.096×1.536×3×8×94÷2 = 7.096.762.368&lt;/p&gt;\n\n&lt;p&gt;funny how they are all the same? &lt;/p&gt;\n\n&lt;p&gt;total active : 21.290.287.104 &lt;/p&gt;\n\n&lt;p&gt;total always active: 14.193.524.736&lt;/p&gt;\n\n&lt;p&gt;to that, you have to add the embedding layer parameters and the LM head parameters + some parameters for the router.&lt;/p&gt;\n\n&lt;p&gt;you can easily do the same for llama 4.\nit has less layers but higher hidden dim and intermediate dim for the dense FFN, + only 2 active experts, of which one is always active (so it end up on the &amp;#39;always active&amp;#39; side)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;edit: I made an error, I&amp;#39;m sorry, the kv heads are 4 not 8&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;so the attention parameters are \n(4.096×128×(64+4+4)+(128×64×4.096))x94= 6.702.497,792 &lt;/p&gt;\n\n&lt;p&gt;now you end up 13.799.260.160 always active parameters and a total of 20.896.022.528 active parameters. &lt;/p&gt;\n\n&lt;p&gt;it doesn&amp;#39;t change much... it seemed incredibly beautiful/elegant to me  that every component (attention, dense FFN and active MoE FNN) had the same parameters count, but now it make more sense, having the same parameters for dense and active expert and something less for attention. &lt;/p&gt;\n\n&lt;p&gt;side note:\nto that you still have to add 151936 * 4096 (that also are always active parameters) &lt;/p&gt;\n\n&lt;p&gt;please note that in their paper (&lt;a href=\"https://arxiv.org/pdf/2505.09388\"&gt;https://arxiv.org/pdf/2505.09388&lt;/a&gt;, see tab 1 and 2) they don&amp;#39;t say explicitly if they tied the embeddings of the embedding layer and the LM head, they have a tab (tab 1) but it only list this info for the dense versions of qwen 3, while in the tab about the MoEs (tab 2), the column that should say in they tied those embeddings is absent. so, we will ignore that and assume they are tied, since the difference is just ~0.6B. same for the parameters for the parameters of the router/s, (what will make even less difference) &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;side note 2:\njust a personal opinion, but their paper is all about benchmarks and didn&amp;#39;t include any kind of justification/explanation for any of their architectural choices. also, not a single ablation about that.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;EDIT 2: i admit that i may have made a crucial error.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I misunderstood the effect of  &amp;quot;&amp;quot;decoder_sparse_step&amp;quot; (&lt;a href=\"https://github.com/huggingface/transformers/blob/5a81d7e0b388fb2b86fc1279cdc07d9dc7e84b4c/src/transformers/models/qwen3_moe/modeling_qwen3_moe.py\"&gt;https://github.com/huggingface/transformers/blob/5a81d7e0b388fb2b86fc1279cdc07d9dc7e84b4c/src/transformers/models/qwen3_moe/modeling_qwen3_moe.py&lt;/a&gt;), since it is set to 1 as in their config, it don&amp;#39;t create any dense layer. so my calculation is wrong.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;the FFN MoEs parameters are 4.096×1.536×3×8×94 (without the &amp;#39;/2&amp;#39;), so 14.193,524736.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;consequently the &amp;#39;always active&amp;#39; parameters are 6.702.497,792 (just the attention parameters)&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;(still, this make the difference between llama4 and qwen 3 that I was pointing out in my previous comment even more relevant) &lt;/p&gt;\n\n&lt;p&gt;btw, as you can see from the modeling file, each router is a linear layer with dimensionality hidden dim to total number of expert. so 4096 * 128 * 96, ~ 0.05B.\nthe embedding parameters and LM head are tied so this add just 150k * 4096 ~0.62B&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zmzlq/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753398135,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753398135,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xoeec",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "pineh2",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xl7i4",
                                "score": 4,
                                "author_fullname": "t2_fifter7i",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Where’d you get “7B routed” from? Qwen A22B just means 22B active per pass, no public split between routed vs shared. You’re guessing.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xoeec",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Where’d you get “7B routed” from? Qwen A22B just means 22B active per pass, no public split between routed vs shared. You’re guessing.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xoeec/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753377685,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753377685,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xl7i4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Affectionate-Cap-600",
                      "can_mod_post": false,
                      "created_utc": 1753376838,
                      "send_replies": true,
                      "parent_id": "t1_n4xa7jp",
                      "score": 11,
                      "author_fullname": "t2_5oltmr5b",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "106B A12B will be interesting for a gpu+ ram setup...\n\nwe will see how many of those 12B active are always active and how many of those are actually routed.... \n\nie, in llama 4 just 3B of the 17B active parameters are routed, so if you keep on gpu the 14B of always active parameters the cpu end up having to compute for just 3B parameters... while with qwen 235B 22A you have 7B routed parameters, making it much slower (relatively obv) that what one could think just looking at the difference between the total active parameters count (17 Vs 22)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xl7i4",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;106B A12B will be interesting for a gpu+ ram setup...&lt;/p&gt;\n\n&lt;p&gt;we will see how many of those 12B active are always active and how many of those are actually routed.... &lt;/p&gt;\n\n&lt;p&gt;ie, in llama 4 just 3B of the 17B active parameters are routed, so if you keep on gpu the 14B of always active parameters the cpu end up having to compute for just 3B parameters... while with qwen 235B 22A you have 7B routed parameters, making it much slower (relatively obv) that what one could think just looking at the difference between the total active parameters count (17 Vs 22)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xl7i4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753376838,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 11
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n540w00",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "CoqueTornado",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n52o8t2",
                                          "score": 1,
                                          "author_fullname": "t2_35jvqsfa",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I've read there won't be more laptops.. there is one minipc around 1600 bucks",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n540w00",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve read there won&amp;#39;t be more laptops.. there is one minipc around 1600 bucks&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n540w00/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753460662,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753460662,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n52o8t2",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Roubbes",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n527ruv",
                                "score": 2,
                                "author_fullname": "t2_aoir7erh",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I hope they get reasonable priced eventually",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n52o8t2",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I hope they get reasonable priced eventually&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n52o8t2/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753446010,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753446010,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n527ruv",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "CoqueTornado",
                      "can_mod_post": false,
                      "created_utc": 1753438864,
                      "send_replies": true,
                      "parent_id": "t1_n4xa7jp",
                      "score": 1,
                      "author_fullname": "t2_35jvqsfa",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "for Strix Halo computers!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n527ruv",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;for Strix Halo computers!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n527ruv/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753438864,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n583hve",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Massive-Question-550",
                      "can_mod_post": false,
                      "created_utc": 1753511787,
                      "send_replies": true,
                      "parent_id": "t1_n4xa7jp",
                      "score": 1,
                      "author_fullname": "t2_72xxv3wb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes, something that can fit on 128gb of ram would be nice.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n583hve",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, something that can fit on 128gb of ram would be nice.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n583hve/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753511787,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": "",
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n4z37p4",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": true,
                                                                        "author": "colin_colout",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n4xn71d",
                                                                        "score": 2,
                                                                        "author_fullname": "t2_14l4ya",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "Ah that's why I like tiny moes. I don't use it for creative writing. A3B was great as a summarization or tool call agent (or making decisions based on what's in context), but I wouldn't expect it to come up with a creative thought or recall well known facts.",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n4z37p4",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah that&amp;#39;s why I like tiny moes. I don&amp;#39;t use it for creative writing. A3B was great as a summarization or tool call agent (or making decisions based on what&amp;#39;s in context), but I wouldn&amp;#39;t expect it to come up with a creative thought or recall well known facts.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1m88jdh",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4z37p4/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1753391924,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1753391924,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 2
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n4xn71d",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Super_Sierra",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n4xgm9y",
                                                              "score": 2,
                                                              "author_fullname": "t2_9757bxah",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "They are terrible at writing and dialogue. It is one of the biggest things people cope about here alongside '250gb/s bandwidth bad.'",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n4xn71d",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They are terrible at writing and dialogue. It is one of the biggest things people cope about here alongside &amp;#39;250gb/s bandwidth bad.&amp;#39;&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m88jdh",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xn71d/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753377365,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753377365,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 1,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          },
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n4y4kto",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "a_beautiful_rhind",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n4xgm9y",
                                                              "score": 0,
                                                              "author_fullname": "t2_h5utwre7",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Mistral-large, command-r/a, the various 70B haven't really let me down. \n\n&gt;But they are fantastic when finetuned for just a single job imho.\n\nAnd that's the fatal flaw for something that is A12 but the size of a 100b.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n4y4kto",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mistral-large, command-r/a, the various 70B haven&amp;#39;t really let me down. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;But they are fantastic when finetuned for just a single job imho.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;And that&amp;#39;s the fatal flaw for something that is A12 but the size of a 100b.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m88jdh",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y4kto/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753382115,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753382115,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 0
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n4xgm9y",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "Former-Ad-5757",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4xehog",
                                                    "score": 8,
                                                    "author_fullname": "t2_ihsdiwk6k",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "What are you trying to do with them? They are basically terrible for general usage but that is basically everything down from cloud / deepseek / Kimi.\nBut they are fantastic when finetuned for just a single job imho.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n4xgm9y",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "e": "text",
                                                        "t": "Llama 3"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What are you trying to do with them? They are basically terrible for general usage but that is basically everything down from cloud / deepseek / Kimi.\nBut they are fantastic when finetuned for just a single job imho.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "light",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xgm9y/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753375614,
                                                    "author_flair_text": "Llama 3",
                                                    "collapsed": false,
                                                    "created_utc": 1753375614,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "#c7b594",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 8
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4xehog",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": "LOW_SCORE",
                                          "no_follow": true,
                                          "author": "trololololo2137",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xe55l",
                                          "score": -7,
                                          "author_fullname": "t2_129mr2pstm",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": true,
                                          "body": "what's so good about them? they are pretty awful in my experience",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4xehog",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;what&amp;#39;s so good about them? they are pretty awful in my experience&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": "comment score below threshold",
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xehog/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753375024,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753375024,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -7
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xe55l",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "lordpuddingcup",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xdhep",
                                "score": 12,
                                "author_fullname": "t2_vc4z2",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You say that like modern 7b-20b models haven’t been pretty damn amazing lol",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xe55l",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You say that like modern 7b-20b models haven’t been pretty damn amazing lol&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xe55l/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753374928,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753374928,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 12
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xe3ri",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Roubbes",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xdhep",
                                "score": 1,
                                "author_fullname": "t2_aoir7erh",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Why?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xe3ri",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xe3ri/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753374917,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753374917,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xdhep",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "trololololo2137",
                      "can_mod_post": false,
                      "created_utc": 1753374743,
                      "send_replies": true,
                      "parent_id": "t1_n4xa7jp",
                      "score": -12,
                      "author_fullname": "t2_129mr2pstm",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "A12 sounds awful",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xdhep",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A12 sounds awful&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xdhep/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753374743,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -12
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xa7jp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Roubbes",
            "can_mod_post": false,
            "created_utc": 1753373842,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 234,
            "author_fullname": "t2_aoir7erh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "106B MoE sounds great",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xa7jp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;106B MoE sounds great&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xa7jp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753373842,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 234
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4ypje7",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "LagOps91",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4yeugx",
                                          "score": 4,
                                          "author_fullname": "t2_3wi6j7vwh",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "it was posted here a few days ago. someone asked if it was runable on a 64gb macbook (i think). and there was the response that it would fit. i'm not really on x, so i only know it from a screenshot.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4ypje7",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it was posted here a few days ago. someone asked if it was runable on a 64gb macbook (i think). and there was the response that it would fit. i&amp;#39;m not really on x, so i only know it from a screenshot.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4ypje7/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753388050,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753388050,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4yeugx",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Caffdy",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xadh6",
                                "score": 11,
                                "author_fullname": "t2_ql2vu0wz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; at least we \"know\" it should fit into 64gb from a tweet\n\nthey only mentioned \"several server grade gpus\". Where's the 64GB coming from?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4yeugx",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;at least we &amp;quot;know&amp;quot; it should fit into 64gb from a tweet&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;they only mentioned &amp;quot;several server grade gpus&amp;quot;. Where&amp;#39;s the 64GB coming from?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yeugx/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753385055,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753385055,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 11
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xadh6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "LagOps91",
                      "can_mod_post": false,
                      "created_utc": 1753373887,
                      "send_replies": true,
                      "parent_id": "t1_n4x9smz",
                      "score": 55,
                      "author_fullname": "t2_3wi6j7vwh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I just wonder what open ai is doing... they were talking big about releasing a frontier open source model, but really, with so many strong releases in the last few weeks, it will be hard for their model to stand out.  \n  \nwell, at least we \"know\" it should fit into 64gb from a tweet, so it should at most be around the 100b range.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xadh6",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I just wonder what open ai is doing... they were talking big about releasing a frontier open source model, but really, with so many strong releases in the last few weeks, it will be hard for their model to stand out.  &lt;/p&gt;\n\n&lt;p&gt;well, at least we &amp;quot;know&amp;quot; it should fit into 64gb from a tweet, so it should at most be around the 100b range.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xadh6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753373887,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 55
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xoy91",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "ForsookComparison",
                      "can_mod_post": false,
                      "created_utc": 1753377831,
                      "send_replies": true,
                      "parent_id": "t1_n4x9smz",
                      "score": 4,
                      "author_fullname": "t2_on5es7pe3",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "...so long as it doesn't use its whole context window worth of reasoning tokens :)\n\nI don't know if I'd be excited for a QwQ-2",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xoy91",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;...so long as it doesn&amp;#39;t use its whole context window worth of reasoning tokens :)&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if I&amp;#39;d be excited for a QwQ-2&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xoy91/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753377831,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4x9smz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "LagOps91",
            "can_mod_post": false,
            "created_utc": 1753373728,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 115,
            "author_fullname": "t2_3wi6j7vwh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "it's GLM-4.5. If it's o3 level, especially the smaller one, i would be very happy with that!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4x9smz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it&amp;#39;s GLM-4.5. If it&amp;#39;s o3 level, especially the smaller one, i would be very happy with that!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4x9smz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753373728,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 115
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n4zpfnt",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "__JockY__",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n4zp4jn",
                                                              "score": 43,
                                                              "author_fullname": "t2_qf8h7ka8",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "American companies would never do such a thing, they’re too busy open-sourcing all their best models… wait a minute…",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n4zpfnt",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;American companies would never do such a thing, they’re too busy open-sourcing all their best models… wait a minute…&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m88jdh",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zpfnt/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753398943,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753398943,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 43
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n4zp4jn",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "serige",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4yhafz",
                                                    "score": 25,
                                                    "author_fullname": "t2_kxwnu",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "A Chinese company based in China provides tech to the military of their own country…sounds suspicious enough for sanctioning.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n4zp4jn",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A Chinese company based in China provides tech to the military of their own country…sounds suspicious enough for sanctioning.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zp4jn/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753398841,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753398841,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 25
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4yhafz",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "__JockY__",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4ygfr2",
                                          "score": 26,
                                          "author_fullname": "t2_qf8h7ka8",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "The US government has listed them under export controls because of allegedly supplying the Chinese military with advanced AI.\n\nhttps://amp.scmp.com/tech/tech-war/article/3295002/tech-war-us-adds-chinese-ai-unicorn-zhipu-trade-blacklist-bidens-exit",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4yhafz",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The US government has listed them under export controls because of allegedly supplying the Chinese military with advanced AI.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://amp.scmp.com/tech/tech-war/article/3295002/tech-war-us-adds-chinese-ai-unicorn-zhipu-trade-blacklist-bidens-exit\"&gt;https://amp.scmp.com/tech/tech-war/article/3295002/tech-war-us-adds-chinese-ai-unicorn-zhipu-trade-blacklist-bidens-exit&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yhafz/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753385757,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753385757,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 26
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4ygfr2",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "daynighttrade",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xjgh0",
                                "score": 8,
                                "author_fullname": "t2_b5v0spvp",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Why are they sanctioned?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4ygfr2",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why are they sanctioned?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4ygfr2/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753385511,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753385511,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 8
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xjgh0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "tengo_harambe",
                      "can_mod_post": false,
                      "created_utc": 1753376372,
                      "send_replies": true,
                      "parent_id": "t1_n4x8xx8",
                      "score": 75,
                      "author_fullname": "t2_sgx7w7mb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "There is no lab called GLM, it's Zhipu AI. They are directly sanctioned by the US (unlike Deepseek) which doesn't seem to have stopped their progress in any way.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xjgh0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There is no lab called GLM, it&amp;#39;s Zhipu AI. They are directly sanctioned by the US (unlike Deepseek) which doesn&amp;#39;t seem to have stopped their progress in any way.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xjgh0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753376372,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 75
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xsvgr",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "orrzxz",
                      "can_mod_post": false,
                      "created_utc": 1753378869,
                      "send_replies": true,
                      "parent_id": "t1_n4x8xx8",
                      "score": 12,
                      "author_fullname": "t2_huzar",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Man, Kimi still has Kimi VL 2503 which IMO is one of the best and lightest VL models out there. I really wish it got the love it deserved.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xsvgr",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Man, Kimi still has Kimi VL 2503 which IMO is one of the best and lightest VL models out there. I really wish it got the love it deserved.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xsvgr/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753378869,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 12
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n560qs8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "PutMyDickOnYourHead",
                      "can_mod_post": false,
                      "created_utc": 1753481631,
                      "send_replies": true,
                      "parent_id": "t1_n4x8xx8",
                      "score": 1,
                      "author_fullname": "t2_7qfrq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "InternVL3 is my go-to. The only thing that sucks is very few inference engines support it (I use it on LMDeploy) and I don't think any of the ones that do support have CPU offloading.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n560qs8",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;InternVL3 is my go-to. The only thing that sucks is very few inference engines support it (I use it on LMDeploy) and I don&amp;#39;t think any of the ones that do support have CPU offloading.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n560qs8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753481631,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4x8xx8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Few_Painter_5588",
            "can_mod_post": false,
            "created_utc": 1753373495,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 130,
            "author_fullname": "t2_uvgafqnfy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Happy to see GLM get more love. GLM and InternLM are two of the most underrated AI labs coming from China.",
            "edited": 1753374210,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4x8xx8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Happy to see GLM get more love. GLM and InternLM are two of the most underrated AI labs coming from China.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4x8xx8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753373495,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 130
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n52siam",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "DisturbedNeo",
                                                    "can_mod_post": false,
                                                    "send_replies": false,
                                                    "parent_id": "t1_n4xwdi9",
                                                    "score": 2,
                                                    "author_fullname": "t2_adnhw",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "It sucks that the only models getting any attention are the bench-maxxers",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n52siam",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It sucks that the only models getting any attention are the bench-maxxers&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n52siam/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753447548,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753447548,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4xwdi9",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Egoz3ntrum",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xh19x",
                                          "score": 12,
                                          "author_fullname": "t2_h7b8z",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "It is actually not that bad. Llama 4 was not trained to fit most benchmarks but still holds up very well for general purpose tasks.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4xwdi9",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is actually not that bad. Llama 4 was not trained to fit most benchmarks but still holds up very well for general purpose tasks.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xwdi9/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753379810,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753379810,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 12
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4xxddi",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "True_Requirement_891",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xh19x",
                                          "score": 4,
                                          "author_fullname": "t2_yfi9sqrzf",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Don't even bother man...",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4xxddi",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Don&amp;#39;t even bother man...&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xxddi/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753380087,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753380087,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 1,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xh19x",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Awwtifishal",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xbe5z",
                                "score": 23,
                                "author_fullname": "t2_1d96a8k10t",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thank you, I didn't think of that. I forgot about it since it was so criticized but when I have the hardware I guess I will compare it against others for my purposes.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xh19x",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you, I didn&amp;#39;t think of that. I forgot about it since it was so criticized but when I have the hardware I guess I will compare it against others for my purposes.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xh19x/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753375728,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753375728,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 23
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xbe5z",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Klutzy-Snow8016",
                      "can_mod_post": false,
                      "created_utc": 1753374168,
                      "send_replies": true,
                      "parent_id": "t1_n4x9lcx",
                      "score": 45,
                      "author_fullname": "t2_1d5l610jz3",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Llama 4 Scout is 109B.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xbe5z",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Llama 4 Scout is 109B.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xbe5z/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753374168,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 45
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4x9lcx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Awwtifishal",
            "can_mod_post": false,
            "created_utc": 1753373673,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 36,
            "author_fullname": "t2_1d96a8k10t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Is there any open \\~100B MoE (existing or upcoming) with multimodal capabilities?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4x9lcx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is there any open ~100B MoE (existing or upcoming) with multimodal capabilities?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4x9lcx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753373673,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 36
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5424lx",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Fault23",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4z3fsp",
                                "score": 1,
                                "author_fullname": "t2_6lobb53e",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "On my personal vibe test, It was nothing special or a big improvement compared to other top models, but for only closed ones of course. It'll be so much better when we use this model's quantized versions and use it as a distillation model for others in the future (And shamefully, I don't know anything about GLM, I just heard it)",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5424lx",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;On my personal vibe test, It was nothing special or a big improvement compared to other top models, but for only closed ones of course. It&amp;#39;ll be so much better when we use this model&amp;#39;s quantized versions and use it as a distillation model for others in the future (And shamefully, I don&amp;#39;t know anything about GLM, I just heard it)&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n5424lx/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753461014,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753461014,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4z3fsp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Duarteeeeee",
                      "can_mod_post": false,
                      "created_utc": 1753391990,
                      "send_replies": true,
                      "parent_id": "t1_n4yr1jg",
                      "score": 6,
                      "author_fullname": "t2_ljov5l52",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "So tomorrow we will have qwen3-235b-a22b-thinking-2507 and soon GLM 4.5 🔥",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4z3fsp",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So tomorrow we will have qwen3-235b-a22b-thinking-2507 and soon GLM 4.5 🔥&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4z3fsp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753391990,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4yr1jg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "kaaos77",
            "can_mod_post": false,
            "created_utc": 1753388469,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 16,
            "author_fullname": "t2_64qbrf72",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Tomorrow\n\nhttps://preview.redd.it/vxwdsru4svef1.jpeg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=156359a57ea2c7e1d00b83bf768fc92b450b3ce0",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4yr1jg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Tomorrow&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vxwdsru4svef1.jpeg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=156359a57ea2c7e1d00b83bf768fc92b450b3ce0\"&gt;https://preview.redd.it/vxwdsru4svef1.jpeg?width=1080&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=156359a57ea2c7e1d00b83bf768fc92b450b3ce0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yr1jg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753388469,
            "media_metadata": {
              "vxwdsru4svef1": {
                "status": "valid",
                "e": "Image",
                "m": "image/jpeg",
                "p": [
                  {
                    "y": 70,
                    "x": 108,
                    "u": "https://preview.redd.it/vxwdsru4svef1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7732b84657772667ad22b20c0625a098779f5b55"
                  },
                  {
                    "y": 140,
                    "x": 216,
                    "u": "https://preview.redd.it/vxwdsru4svef1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b0887cf541774b9bf0d6c5358ebb0deb7b1c65d8"
                  },
                  {
                    "y": 208,
                    "x": 320,
                    "u": "https://preview.redd.it/vxwdsru4svef1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3597f508434a9b1e955fd214d263d9c85b9cc3ca"
                  },
                  {
                    "y": 416,
                    "x": 640,
                    "u": "https://preview.redd.it/vxwdsru4svef1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1f97389ce42fde11bfba242d11483a9fae073795"
                  },
                  {
                    "y": 624,
                    "x": 960,
                    "u": "https://preview.redd.it/vxwdsru4svef1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7722de664bd573e457641dbbd246e610050e2b8f"
                  },
                  {
                    "y": 702,
                    "x": 1080,
                    "u": "https://preview.redd.it/vxwdsru4svef1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6bf8ccfd08068e610b51ababce53805176df6a7e"
                  }
                ],
                "s": {
                  "y": 702,
                  "x": 1080,
                  "u": "https://preview.redd.it/vxwdsru4svef1.jpeg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=156359a57ea2c7e1d00b83bf768fc92b450b3ce0"
                },
                "id": "vxwdsru4svef1"
              }
            },
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 16
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4xdp7s",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "wolfy-j",
            "can_mod_post": false,
            "created_utc": 1753374804,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 32,
            "author_fullname": "t2_g51so",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That’s ok, at least we got OpenAI model last Thursday! /s",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xdp7s",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That’s ok, at least we got OpenAI model last Thursday! /s&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": true,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xdp7s/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753374804,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 32
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4y0dyn",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "OmarBessa",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xx8qk",
                                "score": 41,
                                "author_fullname": "t2_guxix",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "from embarrassment yeh",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4y0dyn",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;from embarrassment yeh&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y0dyn/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753380932,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753380932,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 41
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xx8qk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "ShengrenR",
                      "can_mod_post": false,
                      "created_utc": 1753380050,
                      "send_replies": true,
                      "parent_id": "t1_n4xdbs0",
                      "score": 40,
                      "author_fullname": "t2_ji4n4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "needs more safety, duh",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xx8qk",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;needs more safety, duh&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xx8qk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753380050,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 40
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yftlc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Funny_Working_7490",
                      "can_mod_post": false,
                      "created_utc": 1753385335,
                      "send_replies": true,
                      "parent_id": "t1_n4xdbs0",
                      "score": 3,
                      "author_fullname": "t2_13mkyepwst",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "o3 is being shyy from Chinese now",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yftlc",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;o3 is being shyy from Chinese now&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yftlc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753385335,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xdbs0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Luston03",
            "can_mod_post": false,
            "created_utc": 1753374699,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 60,
            "author_fullname": "t2_n2kmftzjf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "OpenAI still doesn't wanna release o3 mini lmao",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xdbs0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OpenAI still doesn&amp;#39;t wanna release o3 mini lmao&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xdbs0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753374699,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 60
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "d2642412-d9ce-11ed-ae30-32b11309f5bd",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n565xkn",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Background-Ad-5398",
                      "can_mod_post": false,
                      "created_utc": 1753483366,
                      "send_replies": true,
                      "parent_id": "t1_n4zgcqk",
                      "score": 2,
                      "author_fullname": "t2_71b6nl31",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "thats something they leave out when talking about the golden horde. the mongols had gunpowder weapons they had from their captured chinese engineers, and europe and the middle east didnt",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n565xkn",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;thats something they leave out when talking about the golden horde. the mongols had gunpowder weapons they had from their captured chinese engineers, and europe and the middle east didnt&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n565xkn/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753483366,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4zgcqk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ortegaalfredo",
            "can_mod_post": false,
            "created_utc": 1753395948,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 14,
            "author_fullname": "t2_g177e",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Last time China mogged the west like this was when they invented gunpowder.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4zgcqk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Alpaca"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Last time China mogged the west like this was when they invented gunpowder.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zgcqk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753395948,
            "author_flair_text": "Alpaca",
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bd9e9e",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 14
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ef488598-491f-11ef-a847-9a3dd315819c",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4xa8ea",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "panchovix",
            "can_mod_post": false,
            "created_utc": 1753373848,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 25,
            "author_fullname": "t2_j1kqr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Waiting expectantly for that 355B A32B one.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xa8ea",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Llama 405B"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Waiting expectantly for that 355B A32B one.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xa8ea/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753373848,
            "author_flair_text": "Llama 405B",
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 25
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xt0y4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "-dysangel-",
                      "can_mod_post": false,
                      "created_utc": 1753378909,
                      "send_replies": true,
                      "parent_id": "t1_n4xg6k5",
                      "score": 17,
                      "author_fullname": "t2_12ggykute6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That sounds more like something for deep research modes. You can never be sure the model is not hallucinating. You cannot also be sure that a paper that is being referenced is actually correct without reading their methodology etc..",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xt0y4",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That sounds more like something for deep research modes. You can never be sure the model is not hallucinating. You cannot also be sure that a paper that is being referenced is actually correct without reading their methodology etc..&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xt0y4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753378909,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 17
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xrdci",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Agitated_Space_672",
                      "can_mod_post": false,
                      "created_utc": 1753378471,
                      "send_replies": true,
                      "parent_id": "t1_n4xg6k5",
                      "score": 20,
                      "author_fullname": "t2_uuk0cqoi",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Problem is they are out of date before they are released. A good code model can retrieve up to date answers.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xrdci",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Problem is they are out of date before they are released. A good code model can retrieve up to date answers.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xrdci/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753378471,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 20
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yf34b",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Caffdy",
                      "can_mod_post": false,
                      "created_utc": 1753385124,
                      "send_replies": true,
                      "parent_id": "t1_n4xg6k5",
                      "score": 3,
                      "author_fullname": "t2_ql2vu0wz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "coding in the training makes them smarter in other areas, that insight was posted before",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yf34b",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;coding in the training makes them smarter in other areas, that insight was posted before&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yf34b/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753385124,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n51tq6w",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "PurpleUpbeat2820",
                      "can_mod_post": false,
                      "created_utc": 1753430952,
                      "send_replies": true,
                      "parent_id": "t1_n4xg6k5",
                      "score": 2,
                      "author_fullname": "t2_7xnuxw8f",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; Imo there should be models that are less focused on coding and more focused on general knowledge with a focus on non-hallucinated answers. This would be really cool to see.\n\nI completely disagree. Neurons should be focused on comprehension and logic and not wasted on knowledge. Use RAG for knowledge.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n51tq6w",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Imo there should be models that are less focused on coding and more focused on general knowledge with a focus on non-hallucinated answers. This would be really cool to see.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I completely disagree. Neurons should be focused on comprehension and logic and not wasted on knowledge. Use RAG for knowledge.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51tq6w/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753430952,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yd0yz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AppearanceHeavy6724",
                      "can_mod_post": false,
                      "created_utc": 1753384538,
                      "send_replies": true,
                      "parent_id": "t1_n4xg6k5",
                      "score": 1,
                      "author_fullname": "t2_uz37qfx5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Mistral Small 3.2?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yd0yz",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mistral Small 3.2?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yd0yz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753384538,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yfzb4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "night0x63",
                      "can_mod_post": false,
                      "created_utc": 1753385381,
                      "send_replies": true,
                      "parent_id": "t1_n4xg6k5",
                      "score": 1,
                      "author_fullname": "t2_3h2irqtz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "No. Only coding. CEO demands we fire all human coders. Not sure who will run AI coders. But those are the orders from CEO. Maybe AI runs AI? /s",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yfzb4",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No. Only coding. CEO demands we fire all human coders. Not sure who will run AI coders. But those are the orders from CEO. Maybe AI runs AI? /s&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yfzb4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753385381,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yva0j",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Healthy-Nebula-3603",
                      "can_mod_post": false,
                      "created_utc": 1753389658,
                      "send_replies": true,
                      "parent_id": "t1_n4xg6k5",
                      "score": 1,
                      "author_fullname": "t2_ogjj6ebj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Link Wikipedia to the model ( even offline version ) if you want general knowledge....",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yva0j",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Link Wikipedia to the model ( even offline version ) if you want general knowledge....&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yva0j/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753389658,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xg6k5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "usernameplshere",
            "can_mod_post": false,
            "created_utc": 1753375495,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 35,
            "author_fullname": "t2_1zes6cdw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Imo there should be models that are less focused on coding and more focused on general knowledge with a focus on non-hallucinated answers. This would be really cool to see.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xg6k5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Imo there should be models that are less focused on coding and more focused on general knowledge with a focus on non-hallucinated answers. This would be really cool to see.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xg6k5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753375495,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 35
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4xm8ax",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Weary-Wing-6806",
            "can_mod_post": false,
            "created_utc": 1753377109,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 7,
            "author_fullname": "t2_1t2xvghrcr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I wonder how surrounding tooling (infra, UX, workflows, interfaces) keeps up as the pace of new LLMs accelerates. It’s one thing to launch a model but another to make it usable, integrable, and sticky in real-world products. Feels like a growing gap imo",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xm8ax",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I wonder how surrounding tooling (infra, UX, workflows, interfaces) keeps up as the pace of new LLMs accelerates. It’s one thing to launch a model but another to make it usable, integrable, and sticky in real-world products. Feels like a growing gap imo&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xm8ax/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753377109,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4ze2m6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "random-tomato",
                      "can_mod_post": false,
                      "created_utc": 1753395213,
                      "send_replies": true,
                      "parent_id": "t1_n4xfg7k",
                      "score": 13,
                      "author_fullname": "t2_fmd6oq5v6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "He's the guy behind AutoAWQ (https://casper-hansen.github.io/AutoAWQ/)\n\nSo I think when a new model is coming out soon the lab who releases it tries to make sure it works on inference engines like vllm, sglang, or llama.cpp, so they would probably be working with this guy to make it work with AWQ quantization. It's the same kind of deal with the Unsloth team; they get early access to Qwen/Mistral models (presumably) so that they can check the tokenizer/quantization stuff.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4ze2m6",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;He&amp;#39;s the guy behind AutoAWQ (&lt;a href=\"https://casper-hansen.github.io/AutoAWQ/\"&gt;https://casper-hansen.github.io/AutoAWQ/&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;So I think when a new model is coming out soon the lab who releases it tries to make sure it works on inference engines like vllm, sglang, or llama.cpp, so they would probably be working with this guy to make it work with AWQ quantization. It&amp;#39;s the same kind of deal with the Unsloth team; they get early access to Qwen/Mistral models (presumably) so that they can check the tokenizer/quantization stuff.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4ze2m6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753395213,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 13
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xwoi4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "JeffreySons_90",
                      "can_mod_post": false,
                      "created_utc": 1753379894,
                      "send_replies": true,
                      "parent_id": "t1_n4xfg7k",
                      "score": 7,
                      "author_fullname": "t2_vgnr5u5gg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "He is AI's Edward Snowden?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xwoi4",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;He is AI&amp;#39;s Edward Snowden?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xwoi4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753379894,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xfg7k",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ArtisticHamster",
            "can_mod_post": false,
            "created_utc": 1753375292,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 15,
            "author_fullname": "t2_2t2xbyfm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Who is this guy? Why does he has so much info?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xfg7k",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Who is this guy? Why does he has so much info?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xfg7k/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753375292,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4xanoi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "eggs-benedryl",
            "can_mod_post": false,
            "created_utc": 1753373965,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 15,
            "author_fullname": "t2_8nlxwtdi",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Me to this 100b model: You'll fit in my laptop Ram AND LIKE IT!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xanoi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Me to this 100b model: You&amp;#39;ll fit in my laptop Ram AND LIKE IT!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xanoi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753373965,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4y7lt0",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Godless_Phoenix",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xxcdm",
                                          "score": 7,
                                          "author_fullname": "t2_3381a2vc",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Same with Apple Silicon. MoE means fit the model = run the model",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4y7lt0",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Same with Apple Silicon. MoE means fit the model = run the model&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y7lt0/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753382991,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753382991,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 7
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n586d06",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Massive-Question-550",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4xxcdm",
                                          "score": 1,
                                          "author_fullname": "t2_72xxv3wb",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Kinda ironic since it also makes regular PC's more viable and thus harder to justify the high price of an AI max 395+.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n586d06",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Kinda ironic since it also makes regular PC&amp;#39;s more viable and thus harder to justify the high price of an AI max 395+.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n586d06/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753513373,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753513373,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xxcdm",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "JaredsBored",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xfrh5",
                                "score": 13,
                                "author_fullname": "t2_2egpkyt4",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Man MoE really has changed the viability of the AI Max 395+. That product looked like a dud when dense models were the meta, but with MoE, they're plenty viable",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xxcdm",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Man MoE really has changed the viability of the AI Max 395+. That product looked like a dud when dense models were the meta, but with MoE, they&amp;#39;re plenty viable&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xxcdm/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753380079,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753380079,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 13
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5295h8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "CoqueTornado",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xfrh5",
                                "score": 1,
                                "author_fullname": "t2_35jvqsfa",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "that AI Max 395+ 128GB means the model would not be necessary quantized!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5295h8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;that AI Max 395+ 128GB means the model would not be necessary quantized!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n5295h8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753439573,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753439573,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xfrh5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "eloquentemu",
                      "can_mod_post": false,
                      "created_utc": 1753375379,
                      "send_replies": true,
                      "parent_id": "t1_n4xb8wb",
                      "score": 48,
                      "author_fullname": "t2_lpdsy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The 106B isn't bad at all... Q4 comes in at ~60GB and with 12B active, I'd expect ~8 t/s on a normal dual channel DDR5-5600 desktop without a GPU at all.  Even a 8GB GPU would let you run probably ~15+t/s and let you offload enough to get away with 64GB system RAM.  And of course it's perfect for the AI Max 395+ 128GB boxes which would get ~20t/s and big context.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xfrh5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The 106B isn&amp;#39;t bad at all... Q4 comes in at ~60GB and with 12B active, I&amp;#39;d expect ~8 t/s on a normal dual channel DDR5-5600 desktop without a GPU at all.  Even a 8GB GPU would let you run probably ~15+t/s and let you offload enough to get away with 64GB system RAM.  And of course it&amp;#39;s perfect for the AI Max 395+ 128GB boxes which would get ~20t/s and big context.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xfrh5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753375379,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 48
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xhsi9",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "FunnyAsparagus1253",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xcdff",
                                "score": 3,
                                "author_fullname": "t2_i6c8tay3w",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The 106 should run pretty nicely on my 2xP40 setup. I’m actually looking forward to trying this one out 👀😅",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xhsi9",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The 106 should run pretty nicely on my 2xP40 setup. I’m actually looking forward to trying this one out 👀😅&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xhsi9/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753375934,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753375934,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n51heyi",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "dampflokfreund",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xcdff",
                                "score": 1,
                                "author_fullname": "t2_lis7z",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Most PCs have 32 GB in dual channel. ",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n51heyi",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Most PCs have 32 GB in dual channel. &lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51heyi/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753424155,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753424155,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xcdff",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "LevianMcBirdo",
                      "can_mod_post": false,
                      "created_utc": 1753374435,
                      "send_replies": true,
                      "parent_id": "t1_n4xb8wb",
                      "score": 14,
                      "author_fullname": "t2_cw9f6o0r",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I mean 106B at Q4 could run on a lot of consumer PCs. 64gb ddr5 RAM (quad channel if possible) and a GPU for the main language model (if it works like that) and you should have ok speeds.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xcdff",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I mean 106B at Q4 could run on a lot of consumer PCs. 64gb ddr5 RAM (quad channel if possible) and a GPU for the main language model (if it works like that) and you should have ok speeds.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xcdff/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753374435,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 14
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4y8onr",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Ulterior-Motive_",
                      "can_mod_post": false,
                      "created_utc": 1753383308,
                      "send_replies": true,
                      "parent_id": "t1_n4xb8wb",
                      "score": 3,
                      "author_fullname": "t2_127atw4awd",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "100B isn't even that bad, that's something you can run with 64GB of memory, which might be high for some people, but still reasonable compared to a 400B or even 200B model.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4y8onr",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;100B isn&amp;#39;t even that bad, that&amp;#39;s something you can run with 64GB of memory, which might be high for some people, but still reasonable compared to a 400B or even 200B model.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y8onr/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753383308,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xjfeh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "KrazyKirby99999",
                      "can_mod_post": false,
                      "created_utc": 1753376365,
                      "send_replies": true,
                      "parent_id": "t1_n4xb8wb",
                      "score": 7,
                      "author_fullname": "t2_1h5tfxy8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Large local models means cheap hosting from multiple providers",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xjfeh",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Large local models means cheap hosting from multiple providers&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xjfeh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753376365,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n52cm6j",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "po_stulate",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n521lu3",
                                          "score": 2,
                                          "author_fullname": "t2_86bhfy6r",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "It is meant to be a capable language model, not an average PC game. Use the right tool to do the job. btw, even the AAA games that don't run well on an average gaming PC aren't \"product of the moment\" I'm not sure what you're talking about.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n52cm6j",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is meant to be a capable language model, not an average PC game. Use the right tool to do the job. btw, even the AAA games that don&amp;#39;t run well on an average gaming PC aren&amp;#39;t &amp;quot;product of the moment&amp;quot; I&amp;#39;m not sure what you&amp;#39;re talking about.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n52cm6j/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753441217,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753441217,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n521lu3",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Slowhill369",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n509paa",
                                "score": 0,
                                "author_fullname": "t2_96zelxcg",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "If it can’t run on an average gaming PC, it’s worthless and will be seen as a product of the moment. ",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n521lu3",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If it can’t run on an average gaming PC, it’s worthless and will be seen as a product of the moment. &lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n521lu3/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753435504,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753435504,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n509paa",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "po_stulate",
                      "can_mod_post": false,
                      "created_utc": 1753405900,
                      "send_replies": true,
                      "parent_id": "t1_n4xb8wb",
                      "score": 2,
                      "author_fullname": "t2_86bhfy6r",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It's a 100b model, not a 1000b model dude.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n509paa",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a 100b model, not a 1000b model dude.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n509paa/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753405900,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xeb52",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "lordpuddingcup",
                      "can_mod_post": false,
                      "created_utc": 1753374974,
                      "send_replies": true,
                      "parent_id": "t1_n4xb8wb",
                      "score": 4,
                      "author_fullname": "t2_vc4z2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Lots of people run them ram isn’t expensive and gpu offload speeds it up for the moe",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xeb52",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Lots of people run them ram isn’t expensive and gpu offload speeds it up for the moe&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xeb52/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753374974,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yb2pz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "mxforest",
                      "can_mod_post": false,
                      "created_utc": 1753383987,
                      "send_replies": true,
                      "parent_id": "t1_n4xb8wb",
                      "score": 2,
                      "author_fullname": "t2_kenmq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "106B MoE is perfectly within RAM usage category. Also i am personally excited to run on my 128GB M4 Max.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yb2pz",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;106B MoE is perfectly within RAM usage category. Also i am personally excited to run on my 128GB M4 Max.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yb2pz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753383987,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4z5i2k",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Slowhill369",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4yiub8",
                                "score": 1,
                                "author_fullname": "t2_96zelxcg",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You’re a slave to a broken paradigm. How boring. ",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4z5i2k",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You’re a slave to a broken paradigm. How boring. &lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4z5i2k/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753392604,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753392604,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yiub8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "datbackup",
                      "can_mod_post": false,
                      "created_utc": 1753386192,
                      "send_replies": true,
                      "parent_id": "t1_n4xb8wb",
                      "score": -4,
                      "author_fullname": "t2_ielo6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Did you know there are more than 20 MILLION millionaires in the USA? How many do you think there might be globally?\n\nAnd you can join the local sota LLM club for $10k with a Mac m3 ultra 512GB, or perhaps significantly less than $10k with a previous gen multichannel RAM setup.\n\nMaybe your energy would be better spent in ways other than complaining",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yiub8",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Did you know there are more than 20 MILLION millionaires in the USA? How many do you think there might be globally?&lt;/p&gt;\n\n&lt;p&gt;And you can join the local sota LLM club for $10k with a Mac m3 ultra 512GB, or perhaps significantly less than $10k with a previous gen multichannel RAM setup.&lt;/p&gt;\n\n&lt;p&gt;Maybe your energy would be better spent in ways other than complaining&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yiub8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753386192,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xb8wb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Slowhill369",
            "can_mod_post": false,
            "created_utc": 1753374127,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 32,
            "author_fullname": "t2_96zelxcg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "And the whole 1000 people in existence running these large “local” models rejoiced! ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xb8wb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And the whole 1000 people in existence running these large “local” models rejoiced! &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xb8wb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753374127,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 32
          }
        },
        {
          "kind": "t1",
          "data": {
            "total_awards_received": 0,
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "ups": 3,
            "removal_reason": null,
            "link_id": "t3_1m88jdh",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4xm6s3",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Longjumping_Spot5843",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xlr7g",
                                "score": 0,
                                "author_fullname": "t2_oq9mqs8ip",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I'm not",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4xm6s3",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xm6s3/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753377098,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753377098,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xlr7g",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BoJackHorseMan53",
                      "can_mod_post": false,
                      "created_utc": 1753376984,
                      "send_replies": true,
                      "parent_id": "t1_n4xh6wg",
                      "score": 3,
                      "author_fullname": "t2_58t8ty6v",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Why are you anxious?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xlr7g",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why are you anxious?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xlr7g/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753376984,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xh6wg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "DELETED",
            "no_follow": true,
            "author": "[deleted]",
            "can_mod_post": false,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 3,
            "approved_by": null,
            "report_reasons": null,
            "all_awardings": [],
            "subreddit_id": "t5_81eyvm",
            "body": "[deleted]",
            "edited": false,
            "downs": 0,
            "author_flair_css_class": null,
            "collapsed": true,
            "is_submitter": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
            "gildings": {},
            "collapsed_reason": null,
            "associated_award": null,
            "stickied": false,
            "subreddit_type": "public",
            "can_gild": false,
            "top_awarded_type": null,
            "unrepliable_reason": null,
            "author_flair_text_color": "dark",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xh6wg/",
            "num_reports": null,
            "locked": false,
            "name": "t1_n4xh6wg",
            "created": 1753375771,
            "subreddit": "LocalLLaMA",
            "author_flair_text": null,
            "treatment_tags": [],
            "created_utc": 1753375771,
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "mod_note": null,
            "distinguished": null
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4z4vco",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "randomanoni",
                      "can_mod_post": false,
                      "created_utc": 1753392414,
                      "send_replies": true,
                      "parent_id": "t1_n4y0a0m",
                      "score": 2,
                      "author_fullname": "t2_tmyziykn",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "That's what &lt;censored&gt;.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4z4vco",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s what &amp;lt;censored&amp;gt;.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4z4vco/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753392414,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4y0a0m",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "OmarBessa",
            "can_mod_post": false,
            "created_utc": 1753380902,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 3,
            "author_fullname": "t2_guxix",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Excellent size though.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4y0a0m",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Excellent size though.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y0a0m/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753380902,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4y516b",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GabryIta",
            "can_mod_post": false,
            "created_utc": 1753382245,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 3,
            "author_fullname": "t2_pv1nb9469",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "GLM &lt;3",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4y516b",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GLM &amp;lt;3&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y516b/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753382245,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4yl2hq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Bakoro",
            "can_mod_post": false,
            "created_utc": 1753386812,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 3,
            "author_fullname": "t2_7fz62",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This has been a hell of a week.  \n   \nI feel for the people behind Kimi K2, they didn't even get a full week to have people hyped about their achievement, multiple groups have just been putting out banger after banger.   \n    \nThe pace of AI right now is like, damn, you really do only have 15 minutes of fame.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4yl2hq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This has been a hell of a week.  &lt;/p&gt;\n\n&lt;p&gt;I feel for the people behind Kimi K2, they didn&amp;#39;t even get a full week to have people hyped about their achievement, multiple groups have just been putting out banger after banger.   &lt;/p&gt;\n\n&lt;p&gt;The pace of AI right now is like, damn, you really do only have 15 minutes of fame.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yl2hq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753386812,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n4zxep3",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Aldarund",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n4zrqxo",
                                                              "score": 1,
                                                              "author_fullname": "t2_bu5xy",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Lol, are u OK? Are this benchmarks in the room with you now? Benchmarks show that no Chinese model is on higher than  top US model.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n4zxep3",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Lol, are u OK? Are this benchmarks in the room with you now? Benchmarks show that no Chinese model is on higher than  top US model.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m88jdh",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zxep3/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753401592,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753401592,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 1,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n4zrqxo",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "jinnyjuice",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4zqi3f",
                                                    "score": 5,
                                                    "author_fullname": "t2_4hrx8",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "I was talking about DeepSeek last year.\n\nYou can call it whatever you would like, but that's what the research and benchmarks show. It's not my opinion.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n4zrqxo",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was talking about DeepSeek last year.&lt;/p&gt;\n\n&lt;p&gt;You can call it whatever you would like, but that&amp;#39;s what the research and benchmarks show. It&amp;#39;s not my opinion.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zrqxo/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753399703,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753399703,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 5
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n50o3or",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "ELPascalito",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n4zqi3f",
                                                    "score": 3,
                                                    "author_fullname": "t2_6ox5x11a",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "[https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/GsHZfE\\_aUAEo64N.png](https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/GsHZfE_aUAEo64N.png)\n\nits a race to the bottom, who has the cheapest prices, the Asian LLMs are open source and have very comparable performance to price, while Gemini and Claude are still king, the gap is closing fast, they left OpenAI in the dust, the only good AI is gpt4.5 and that was so expensive they dropped it, while Kimi and Deepseek give you similar performance for cents o the dollar, and the current trends show that it wont take long for OpenAI to fall from grace, ngl you are coping because OpenAI is playing dirty and never released any open source materials since gpt2, while its peers are playing fair in the open source space and beating it at its own game",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n50o3or",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/GsHZfE_aUAEo64N.png\"&gt;https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/GsHZfE_aUAEo64N.png&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;its a race to the bottom, who has the cheapest prices, the Asian LLMs are open source and have very comparable performance to price, while Gemini and Claude are still king, the gap is closing fast, they left OpenAI in the dust, the only good AI is gpt4.5 and that was so expensive they dropped it, while Kimi and Deepseek give you similar performance for cents o the dollar, and the current trends show that it wont take long for OpenAI to fall from grace, ngl you are coping because OpenAI is playing dirty and never released any open source materials since gpt2, while its peers are playing fair in the open source space and beating it at its own game&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m88jdh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n50o3or/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753411163,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753411163,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4zqi3f",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Aldarund",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4zpbls",
                                          "score": 4,
                                          "author_fullname": "t2_bu5xy",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Thats some serious cope. While deepseek is so on is good its behind any current top model like o3, Gemini 2.5 pro etc .",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4zqi3f",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thats some serious cope. While deepseek is so on is good its behind any current top model like o3, Gemini 2.5 pro etc .&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m88jdh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zqi3f/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753399294,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753399294,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4zpbls",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "jinnyjuice",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4xwrfp",
                                "score": 10,
                                "author_fullname": "t2_4hrx8",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Claude is the only one that stands a chance due to its software development capabilties at the moment. There are no other US models that are better than Chinese flagships at the moment. Right below China, US capabilities would be more comparable to Korean models. Below that would probably be France, Japan, etc., but they have different aims, so it might not be right comparisons. For example, French Mistral aims for military uses.\n\nFor all other functions besides software development, US is definitely behind. Deepseek was when we all realised China had better software capabilities than the US, because US hardware was 1,5 generations ahead of China due to sanctions when it happened, but this was only with LLM-specific purpose hardware (i.e. Nvidia GPUs). China was already ahead of the US when it comes to HPCs (high performance computers) with a bit of a gap (Japan's Fugaku was #1 right before two Chinese HPCs took #1 and #2 spots) as they reached exascale (it goes mega, giga, tera, peta, then exa) first, for example.\n\nSo in terms of both software and hardware, US has been behind China on multiple fronts, though not all fronts. In terms of hardware, China has been ahead of US for many years except for the chipmaking processes, probably about a year gap. It's inevitable though, unless if US can get expand about 2x to 5x its talent immigration to match the Chinese skilled labour pool, especially from India. It obviously won't happen.",
                                "edited": 1753399253,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4zpbls",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Claude is the only one that stands a chance due to its software development capabilties at the moment. There are no other US models that are better than Chinese flagships at the moment. Right below China, US capabilities would be more comparable to Korean models. Below that would probably be France, Japan, etc., but they have different aims, so it might not be right comparisons. For example, French Mistral aims for military uses.&lt;/p&gt;\n\n&lt;p&gt;For all other functions besides software development, US is definitely behind. Deepseek was when we all realised China had better software capabilities than the US, because US hardware was 1,5 generations ahead of China due to sanctions when it happened, but this was only with LLM-specific purpose hardware (i.e. Nvidia GPUs). China was already ahead of the US when it comes to HPCs (high performance computers) with a bit of a gap (Japan&amp;#39;s Fugaku was #1 right before two Chinese HPCs took #1 and #2 spots) as they reached exascale (it goes mega, giga, tera, peta, then exa) first, for example.&lt;/p&gt;\n\n&lt;p&gt;So in terms of both software and hardware, US has been behind China on multiple fronts, though not all fronts. In terms of hardware, China has been ahead of US for many years except for the chipmaking processes, probably about a year gap. It&amp;#39;s inevitable though, unless if US can get expand about 2x to 5x its talent immigration to match the Chinese skilled labour pool, especially from India. It obviously won&amp;#39;t happen.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m88jdh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zpbls/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753398906,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753398906,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 10
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xwrfp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Aldarund",
                      "can_mod_post": false,
                      "created_utc": 1753379917,
                      "send_replies": true,
                      "parent_id": "t1_n4xkksv",
                      "score": 9,
                      "author_fullname": "t2_bu5xy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It's still top, isn't it? Or anyone can name a Chinese model that is better than top US models?",
                      "edited": 1753380798,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xwrfp",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s still top, isn&amp;#39;t it? Or anyone can name a Chinese model that is better than top US models?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xwrfp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753379917,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 9
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xkksv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "oodelay",
            "can_mod_post": false,
            "created_utc": 1753376668,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 12,
            "author_fullname": "t2_6q32j",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "American was top for a few years in a.i., which is nice but finished. Let the Asian a.i. and gpus glorious era begin! Countries needed a non-tariffing option lately, how convenient!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xkksv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;American was top for a few years in a.i., which is nice but finished. Let the Asian a.i. and gpus glorious era begin! Countries needed a non-tariffing option lately, how convenient!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xkksv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753376668,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 12
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4zj5ak",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "chinese__investor",
                      "can_mod_post": false,
                      "created_utc": 1753396869,
                      "send_replies": true,
                      "parent_id": "t1_n4ynv07",
                      "score": 4,
                      "author_fullname": "t2_78mu4w5q",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "yeah",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4zj5ak",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yeah&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zj5ak/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753396869,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4ynv07",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Famous_Ad_2709",
            "can_mod_post": false,
            "created_utc": 1753387587,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 6,
            "author_fullname": "t2_94v5vm94",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "i love china now",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4ynv07",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;i love china now&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4ynv07/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753387587,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n504mz2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "NunyaBuzor",
            "can_mod_post": false,
            "created_utc": 1753404128,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 2,
            "author_fullname": "t2_10pze1d3jf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "In the time it between OpenAI open-source announcement and its probable release date, China is about to release a third AI model.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n504mz2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In the time it between OpenAI open-source announcement and its probable release date, China is about to release a third AI model.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n504mz2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753404128,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n51t3kw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "PurpleUpbeat2820",
            "can_mod_post": false,
            "created_utc": 1753430593,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 2,
            "author_fullname": "t2_7xnuxw8f",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "* A12B is too few ⇒ will be stupid.\n* 355B is too many ⇒ $15k Mac Studio is the only consumer hardware capable of running it.\n\nI'd really like a 32-49B non-MoE non-reasoning coding model heavily trained on math, logic and coding. Basically just an updated qwen2.5-coder.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n51t3kw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;A12B is too few ⇒ will be stupid.&lt;/li&gt;\n&lt;li&gt;355B is too many ⇒ $15k Mac Studio is the only consumer hardware capable of running it.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;d really like a 32-49B non-MoE non-reasoning coding model heavily trained on math, logic and coding. Basically just an updated qwen2.5-coder.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51t3kw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753430593,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n53ugu1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "LetterFair6479",
            "can_mod_post": false,
            "created_utc": 1753458855,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 2,
            "author_fullname": "t2_8yw5802i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Aaaand what are we able to run locally ?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n53ugu1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Aaaand what are we able to run locally ?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n53ugu1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753458855,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n50v83h",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Loighic",
                      "can_mod_post": false,
                      "created_utc": 1753413942,
                      "send_replies": true,
                      "parent_id": "t1_n4xb7lp",
                      "score": 2,
                      "author_fullname": "t2_gem8t",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "exact same setup",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n50v83h",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;exact same setup&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n50v83h/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753413942,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xb7lp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "No_Conversation9561",
            "can_mod_post": false,
            "created_utc": 1753374117,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 7,
            "author_fullname": "t2_jqxb4pte",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hoping to run 106B at Q8 and 355B at Q4 on M3 ultra 256 GB",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xb7lp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hoping to run 106B at Q8 and 355B at Q4 on M3 ultra 256 GB&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xb7lp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753374117,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4xwcno",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Alarming-Ad8154",
                      "can_mod_post": false,
                      "created_utc": 1753379803,
                      "send_replies": true,
                      "parent_id": "t1_n4xunnj",
                      "score": 6,
                      "author_fullname": "t2_77kmf6kp",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "There are a lot of VERY capable 20-30b models by Qwen, mistral, google…",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4xwcno",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There are a lot of VERY capable 20-30b models by Qwen, mistral, google…&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xwcno/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753379803,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5088sj",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "po_stulate",
                      "can_mod_post": false,
                      "created_utc": 1753405387,
                      "send_replies": true,
                      "parent_id": "t1_n4xunnj",
                      "score": -1,
                      "author_fullname": "t2_86bhfy6r",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "No. We don't need more 30b toy models, there's too many already. Bring more 100b-200b models that is actually capable but don't need a server room to run.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5088sj",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No. We don&amp;#39;t need more 30b toy models, there&amp;#39;s too many already. Bring more 100b-200b models that is actually capable but don&amp;#39;t need a server room to run.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m88jdh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n5088sj/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753405387,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xunnj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Gold-Vehicle1428",
            "can_mod_post": false,
            "created_utc": 1753379346,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 2,
            "author_fullname": "t2_sx1ddsoy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "release some 20-30b models, very few can actually run 100b+ models.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xunnj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;release some 20-30b models, very few can actually run 100b+ models.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xunnj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753379346,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4xwe20",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "JeffreySons_90",
            "can_mod_post": false,
            "created_utc": 1753379814,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 2,
            "author_fullname": "t2_vgnr5u5gg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Why does his tweets always start with \"if you love kimi k2....\"?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xwe20",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why does his tweets always start with &amp;quot;if you love kimi k2....&amp;quot;?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xwe20/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753379814,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4xidtv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "fp4guru",
            "can_mod_post": false,
            "created_utc": 1753376091,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_1tp8zldw5g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "100b level Moe is pure awesomeness. Boosting my 24gb + 128gb to up to 16 tokens per second.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xidtv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;100b level Moe is pure awesomeness. Boosting my 24gb + 128gb to up to 16 tokens per second.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xidtv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753376091,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4xwi0h",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Different_Fix_2217",
            "can_mod_post": false,
            "created_utc": 1753379845,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_4dhrrvi6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I liked glm4, a big one sounds exciting.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xwi0h",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I liked glm4, a big one sounds exciting.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xwi0h/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753379845,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4y1ra7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "a_beautiful_rhind",
            "can_mod_post": false,
            "created_utc": 1753381317,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_h5utwre7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Sooo.. they show GLM-experimental in the screenshot?\n\nEver since I heard about the vllm commits, I went and chatted to that model. It replied really fast and would be the A12B, assumptively. \n\nI did enjoy their previous ~30b offerings. Let's just say, I'm looking forward to the A32B and leave it there.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4y1ra7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sooo.. they show GLM-experimental in the screenshot?&lt;/p&gt;\n\n&lt;p&gt;Ever since I heard about the vllm commits, I went and chatted to that model. It replied really fast and would be the A12B, assumptively. &lt;/p&gt;\n\n&lt;p&gt;I did enjoy their previous ~30b offerings. Let&amp;#39;s just say, I&amp;#39;m looking forward to the A32B and leave it there.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y1ra7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753381317,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4ydnjn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "neotorama",
            "can_mod_post": false,
            "created_utc": 1753384717,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_45wzf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "GLM CLI",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4ydnjn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GLM CLI&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4ydnjn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753384717,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4ygwno",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Afternoon_4260",
            "can_mod_post": false,
            "created_utc": 1753385646,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_cj9kap4bx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Who's that guy?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4ygwno",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Who&amp;#39;s that guy?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4ygwno/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753385646,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4z3rvs",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Turbulent_Pin7635",
            "can_mod_post": false,
            "created_utc": 1753392090,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_1hra1kibwa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Local O3-like?!? Yep! And the parameter are not that high. \n\nWhat is the best way to have something as efficient as the deep research and search?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4z3rvs",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Local O3-like?!? Yep! And the parameter are not that high. &lt;/p&gt;\n\n&lt;p&gt;What is the best way to have something as efficient as the deep research and search?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4z3rvs/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753392090,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4zhxg5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Danmoreng",
            "can_mod_post": false,
            "created_utc": 1753396464,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_7z26p",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So this at Q4 fits nicely into 64Gb RAM with a 12GB GPU. Awesome.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4zhxg5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So this at Q4 fits nicely into 64Gb RAM with a 12GB GPU. Awesome.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zhxg5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753396464,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4zw5ya",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "LA_rent_Aficionado",
            "can_mod_post": false,
            "created_utc": 1753401169,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_t8zbiflk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hopefully this archicture works on older llama.cpp builds because recent changes mid-month nerfed multi-GPU performance on my rig :(",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4zw5ya",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hopefully this archicture works on older llama.cpp builds because recent changes mid-month nerfed multi-GPU performance on my rig :(&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zw5ya/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753401169,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n506d2c",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "appakaradi",
            "can_mod_post": false,
            "created_utc": 1753404731,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_rp1qjux",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That is Qwen 3 thinking only.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n506d2c",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That is Qwen 3 thinking only.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n506d2c/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753404731,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n507id3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "mrfakename0",
            "can_mod_post": false,
            "created_utc": 1753405128,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_1f194h3luj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Confirmed that it is Zhipu AI",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n507id3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Confirmed that it is Zhipu AI&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n507id3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753405128,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n50tnby",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "extopico",
            "can_mod_post": false,
            "created_utc": 1753413311,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_14b2jf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Really need a strong open weights multimodal model... that will be more exciting",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n50tnby",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Really need a strong open weights multimodal model... that will be more exciting&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n50tnby/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753413311,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n51qw81",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Lesser-than",
            "can_mod_post": false,
            "created_utc": 1753429346,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_98d256k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "for real though these guys have been cooking as well!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n51qw81",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;for real though these guys have been cooking as well!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51qw81/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753429346,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n51sfpn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Trysem",
            "can_mod_post": false,
            "created_utc": 1753430220,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_9phou5uh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "China is slapping US continuously 🤣",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n51sfpn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;China is slapping US continuously 🤣&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51sfpn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753430220,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n51tgib",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Impressive_Half_2819",
            "can_mod_post": false,
            "created_utc": 1753430796,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_1fpbfjtnc5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This will be pretty good.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n51tgib",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This will be pretty good.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n51tgib/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753430796,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n55abov",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Equivalent-Word-7691",
            "can_mod_post": false,
            "created_utc": 1753473641,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 1,
            "author_fullname": "t2_30nt1tdo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Gosh is there any model expect Gemini that can go over 128k okens? As a creative writer it's Just FUCKING frustrating seeing this, because it would ne soo awesome and would lower Gemini 's price",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n55abov",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Gosh is there any model expect Gemini that can go over 128k okens? As a creative writer it&amp;#39;s Just FUCKING frustrating seeing this, because it would ne soo awesome and would lower Gemini &amp;#39;s price&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n55abov/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753473641,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4yhm8z",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Dundell",
            "can_mod_post": false,
            "created_utc": 1753385848,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 0,
            "author_fullname": "t2_3gl53gi6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I've just finished installing my 5th rtx 3060 12gb... Very interested in Q4 of whatever 108B this is since the Hunyuan 80B didn't really work out.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4yhm8z",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve just finished installing my 5th rtx 3060 12gb... Very interested in Q4 of whatever 108B this is since the Hunyuan 80B didn&amp;#39;t really work out.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4yhm8z/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753385848,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4zotuk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Rich_Artist_8327",
            "can_mod_post": false,
            "created_utc": 1753398743,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": 0,
            "author_fullname": "t2_1jk2ep8a52",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Zuck will blame Obama.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4zotuk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Zuck will blame Obama.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4zotuk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753398743,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4xgb4d",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Icy_Gas8807",
            "can_mod_post": false,
            "created_utc": 1753375530,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": -3,
            "author_fullname": "t2_u5scsvlj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Their web scraping/ reasoning is good. But once I signed up it is more professional. Anyone with similar experience?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xgb4d",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Their web scraping/ reasoning is good. But once I signed up it is more professional. Anyone with similar experience?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4xgb4d/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753375530,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4y7kki",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Friendly_Willingness",
            "can_mod_post": false,
            "created_utc": 1753382981,
            "send_replies": true,
            "parent_id": "t3_1m88jdh",
            "score": -2,
            "author_fullname": "t2_4763uud5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "We either need a multi-T parameter SOTA model or a hyper-optimized 7-32B one. I don't see the point of these half-assed mid-range models.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4y7kki",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We either need a multi-T parameter SOTA model or a hyper-optimized 7-32B one. I don&amp;#39;t see the point of these half-assed mid-range models.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m88jdh/ok_next_big_open_source_model_also_from_china/n4y7kki/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753382981,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m88jdh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -2
          }
        }
      ],
      "before": null
    }
  }
]