[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Testing Qwen2.5-VL-7B for pill/imprint text extraction.\n\nWondering if any of you would know of a vLLM that would work well for this use case.\n\nLooking for best options for pharmaceutical OCR (imprint codes, dosages) that are:\n- More accurate \n- Easier RunPod deployment\n- Better price/performance\n\nAny experience with LLaVA, CogVLM, or others for this use case?​​​​​​​​​​​​​​​​",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Best vLLM for pill imprint/textOCR?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1ma89au",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.33,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1iti0qaxaf",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753574706,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Testing Qwen2.5-VL-7B for pill/imprint text extraction.&lt;/p&gt;\n\n&lt;p&gt;Wondering if any of you would know of a vLLM that would work well for this use case.&lt;/p&gt;\n\n&lt;p&gt;Looking for best options for pharmaceutical OCR (imprint codes, dosages) that are:\n- More accurate \n- Easier RunPod deployment\n- Better price/performance&lt;/p&gt;\n\n&lt;p&gt;Any experience with LLaVA, CogVLM, or others for this use case?​​​​​​​​​​​​​​​​&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1ma89au",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Virtual_Attitude2025",
            "discussion_type": null,
            "num_comments": 8,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/",
            "subreddit_subscribers": 505616,
            "created_utc": 1753574706,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5hu2zv",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Virtual_Attitude2025",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5d0nc2",
                                          "score": 1,
                                          "author_fullname": "t2_1iti0qaxaf",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Pretty impressive and I really appreciate you taking the time. You are very knowledgeable. Dm me if ever you are interested in doing some consulting. Thanks for your help.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5hu2zv",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Pretty impressive and I really appreciate you taking the time. You are very knowledgeable. Dm me if ever you are interested in doing some consulting. Thanks for your help.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1ma89au",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/n5hu2zv/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753648697,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753648697,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5d0nc2",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Clear-Ad-9312",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5czl07",
                                "score": 2,
                                "author_fullname": "t2_13gn4f8kdq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "yeah sorry if it is a lot to read. There is a lot to work on for this kind of thing. your best bet is to find what works best for you. especially since image OCR is just something that doesn't have a one size fits all type of thing. \n\nI can find research papers as early as this year that still trying to make headway in what you want. specifically pill identification, which includes identifying the imprint on the pill. it isn't a solved game is what I am telling you. good luck",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5d0nc2",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yeah sorry if it is a lot to read. There is a lot to work on for this kind of thing. your best bet is to find what works best for you. especially since image OCR is just something that doesn&amp;#39;t have a one size fits all type of thing. &lt;/p&gt;\n\n&lt;p&gt;I can find research papers as early as this year that still trying to make headway in what you want. specifically pill identification, which includes identifying the imprint on the pill. it isn&amp;#39;t a solved game is what I am telling you. good luck&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1ma89au",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/n5d0nc2/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753579690,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753579690,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5czl07",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Virtual_Attitude2025",
                      "can_mod_post": false,
                      "created_utc": 1753579274,
                      "send_replies": true,
                      "parent_id": "t1_n5cx43y",
                      "score": 1,
                      "author_fullname": "t2_1iti0qaxaf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you! Appreciate your input!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5czl07",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you! Appreciate your input!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1ma89au",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/n5czl07/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753579274,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5cx43y",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Clear-Ad-9312",
            "can_mod_post": false,
            "created_utc": 1753578322,
            "send_replies": true,
            "parent_id": "t3_1ma89au",
            "score": 4,
            "author_fullname": "t2_13gn4f8kdq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "ah qwen is quite good at OCR. however, LLMs are not really meant for OCR, they are meant for explaining or describing by guessing/estimating what is in the image. that includes making guesses of text in the image.\n\nI think just getting an answer of what is \"best\" that someone else tested for pharmaceutical OCR is just not realistic way of handling this. concerning that pharma stuff is very important and need to handled with care. You should learn a bit more about what you are getting yourself into. This post, [Link](https://www.reddit.com/r/LocalLLaMA/comments/1hjfirl/how_are_some_llms_so_good_at_ocr_while_on_the/), is pretty good for reading up why it isn't recommended. Also, you can train a model to be more accurate with specific data, but at the same time I would be wary of its outputs(remember LLMs are estimating based on trained data). especially with doing it for imprints or handwritten/printed bottles. I firmly believe an LLM is just not going to bring the correct percentage of accuracy a pharmaceutical company would require.\n\nFor reliability, we have standards. Identifying QR codes or bar codes, or other types of standardized code can be done accurately without an LLM. The issue is making sure everyone is on board with using the same standard code. Until the risk is minimized(which I am thinking it would never happen anytime soon), you should stick with proper procedures and making sure the infrastructure/process is up to standards.\n\nat the end of the day, to get something done accurately without error, you really need to take a step back and look at what kind of data you are feeding a tool like an LLM and the risk you are taking if you don't standardize.\n\nIf you are looking for how to integrate an LLM to expand OCR, then you should make both tools complement each other by having the OCR and LLM corroborate the outputs until both can agree on the same thing. if a stalemate or a mistake occurs then you will have to step in.\n\nI think having the LLM supplement the process is the safest choice here.\n\non the other hand, if you still just want a recommendation, then a good general OCR is easy to search for here(notice the top level comment about paddleOCR, it is really good especially when supplemented with an LLM): [https://www.reddit.com/r/LocalLLaMA/comments/1jz80f1/i\\_benchmarked\\_7\\_ocr\\_solutions\\_on\\_a\\_complex/](https://www.reddit.com/r/LocalLLaMA/comments/1jz80f1/i_benchmarked_7_ocr_solutions_on_a_complex/)\n\nfine tune the one you like with data you expect to be feeding the LLM to improve accuracy, because there is likely not a lot of data on pill imprints or dosages from whatever your need to read from.",
            "edited": 1753578728,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5cx43y",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ah qwen is quite good at OCR. however, LLMs are not really meant for OCR, they are meant for explaining or describing by guessing/estimating what is in the image. that includes making guesses of text in the image.&lt;/p&gt;\n\n&lt;p&gt;I think just getting an answer of what is &amp;quot;best&amp;quot; that someone else tested for pharmaceutical OCR is just not realistic way of handling this. concerning that pharma stuff is very important and need to handled with care. You should learn a bit more about what you are getting yourself into. This post, &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1hjfirl/how_are_some_llms_so_good_at_ocr_while_on_the/\"&gt;Link&lt;/a&gt;, is pretty good for reading up why it isn&amp;#39;t recommended. Also, you can train a model to be more accurate with specific data, but at the same time I would be wary of its outputs(remember LLMs are estimating based on trained data). especially with doing it for imprints or handwritten/printed bottles. I firmly believe an LLM is just not going to bring the correct percentage of accuracy a pharmaceutical company would require.&lt;/p&gt;\n\n&lt;p&gt;For reliability, we have standards. Identifying QR codes or bar codes, or other types of standardized code can be done accurately without an LLM. The issue is making sure everyone is on board with using the same standard code. Until the risk is minimized(which I am thinking it would never happen anytime soon), you should stick with proper procedures and making sure the infrastructure/process is up to standards.&lt;/p&gt;\n\n&lt;p&gt;at the end of the day, to get something done accurately without error, you really need to take a step back and look at what kind of data you are feeding a tool like an LLM and the risk you are taking if you don&amp;#39;t standardize.&lt;/p&gt;\n\n&lt;p&gt;If you are looking for how to integrate an LLM to expand OCR, then you should make both tools complement each other by having the OCR and LLM corroborate the outputs until both can agree on the same thing. if a stalemate or a mistake occurs then you will have to step in.&lt;/p&gt;\n\n&lt;p&gt;I think having the LLM supplement the process is the safest choice here.&lt;/p&gt;\n\n&lt;p&gt;on the other hand, if you still just want a recommendation, then a good general OCR is easy to search for here(notice the top level comment about paddleOCR, it is really good especially when supplemented with an LLM): &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1jz80f1/i_benchmarked_7_ocr_solutions_on_a_complex/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1jz80f1/i_benchmarked_7_ocr_solutions_on_a_complex/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;fine tune the one you like with data you expect to be feeding the LLM to improve accuracy, because there is likely not a lot of data on pill imprints or dosages from whatever your need to read from.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/n5cx43y/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753578322,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma89au",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "total_awards_received": 0,
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "ups": 1,
                                "removal_reason": null,
                                "link_id": "t3_1ma89au",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5hyagr",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": "DELETED",
                                "no_follow": true,
                                "author": "[deleted]",
                                "can_mod_post": false,
                                "created_utc": 1753649983,
                                "send_replies": true,
                                "parent_id": "t1_n5hub8z",
                                "score": 1,
                                "approved_by": null,
                                "report_reasons": null,
                                "all_awardings": [],
                                "subreddit_id": "t5_81eyvm",
                                "body": "[deleted]",
                                "edited": 1753650245,
                                "author_flair_css_class": null,
                                "downs": 0,
                                "is_submitter": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "associated_award": null,
                                "stickied": false,
                                "subreddit_type": "public",
                                "can_gild": false,
                                "top_awarded_type": null,
                                "unrepliable_reason": null,
                                "author_flair_text_color": "dark",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/n5hyagr/",
                                "num_reports": null,
                                "locked": false,
                                "name": "t1_n5hyagr",
                                "created": 1753649983,
                                "subreddit": "LocalLLaMA",
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "collapsed": true,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "mod_note": null,
                                "distinguished": null
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5hzpgp",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "kironlau",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5hub8z",
                                "score": 1,
                                "author_fullname": "t2_tb0dz2ds",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "For GGUF, LM studio, for easiness, it support only CPU inference, choose \"CPU only llama.cpp\" as the inference engine\n\nyou could directly download the model from LM studio.",
                                "edited": 1753650833,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5hzpgp",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For GGUF, LM studio, for easiness, it support only CPU inference, choose &amp;quot;CPU only llama.cpp&amp;quot; as the inference engine&lt;/p&gt;\n\n&lt;p&gt;you could directly download the model from LM studio.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1ma89au",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/n5hzpgp/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753650422,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753650422,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5i03fo",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "kironlau",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5hub8z",
                                "score": 1,
                                "author_fullname": "t2_tb0dz2ds",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "for VLLM, if it supports Qwen2.5 VL, then it should support [allenai/olmOCR-7B-0725 · Hugging Face](https://huggingface.co/allenai/olmOCR-7B-0725)\n\nit's just a fintune of Qwen2.5 VL",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5i03fo",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;for VLLM, if it supports Qwen2.5 VL, then it should support &lt;a href=\"https://huggingface.co/allenai/olmOCR-7B-0725\"&gt;allenai/olmOCR-7B-0725 · Hugging Face&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;s just a fintune of Qwen2.5 VL&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1ma89au",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/n5i03fo/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753650542,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753650542,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5hub8z",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Virtual_Attitude2025",
                      "can_mod_post": false,
                      "created_utc": 1753648766,
                      "send_replies": true,
                      "parent_id": "t1_n5hhtbc",
                      "score": 1,
                      "author_fullname": "t2_1iti0qaxaf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks! What is easiest way to run it without a physical GPU?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5hub8z",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks! What is easiest way to run it without a physical GPU?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1ma89au",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/n5hub8z/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753648766,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5hhtbc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "kironlau",
            "can_mod_post": false,
            "created_utc": 1753644948,
            "send_replies": true,
            "parent_id": "t3_1ma89au",
            "score": 2,
            "author_fullname": "t2_tb0dz2ds",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "try this one:\n\n[mradermacher/olmOCR-7B-0725-GGUF · Hugging Face](https://huggingface.co/mradermacher/olmOCR-7B-0725-GGUF)\n\n[allenai/olmOCR-7B-0725 · Hugging Face](https://huggingface.co/allenai/olmOCR-7B-0725)\n\nit is a fintune model of Qwen/Qwen2.5-VL-7B-Instruct\n\nand I found it very good at handwriting ocr\n\nFYI, Allenai is very good at image recongization and ocr finetune.",
            "edited": 1753645151,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hhtbc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;try this one:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/mradermacher/olmOCR-7B-0725-GGUF\"&gt;mradermacher/olmOCR-7B-0725-GGUF · Hugging Face&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/allenai/olmOCR-7B-0725\"&gt;allenai/olmOCR-7B-0725 · Hugging Face&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;it is a fintune model of Qwen/Qwen2.5-VL-7B-Instruct&lt;/p&gt;\n\n&lt;p&gt;and I found it very good at handwriting ocr&lt;/p&gt;\n\n&lt;p&gt;FYI, Allenai is very good at image recongization and ocr finetune.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma89au/best_vllm_for_pill_imprinttextocr/n5hhtbc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753644948,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma89au",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]