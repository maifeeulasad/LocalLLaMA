[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Windows would be unusable for me without everything. I have over a hundred terabytes of data which I search in an instant using this tool everyday, across multiple nases, and I've yet found anything that can rival everything even on mac or linux.\n\nBut I just wish there was an llm implementation which can take this functionality to the next level, and while I've tried to vibe code something myself, it seems to me that the existing llms hallucinate too much, and it would require a purpose built llm. I don't have the resources or hardware to build/train an llm, nor the expertise to make a structured natural language process that works in every instance like an llm. \n\nLike you can interface with ex.exe which is the command line interface for everything, and I've successfully gotten a bit into being able to query for files of this type above x size. But llms simply lack the consistency and reliability for a proper search function that works time over time.\n\nI just can't believe this hasn't already been made. Being able to just ask, show me pictures above 10mb that I have from july 2025 or something like that and seeing results would be a godsend, instead of having to type in regex. \n\nNow this isn't rag, well I suppose it could be? All I'm thinking for llms in this case is just being an interpreter than takes natural language and converts into everything reg ex.\n\nI assume there is more that could be done, using regex as well, but that would be heavily based on the size of database in terms of the context size required.\n\nThis is kind of a newb question, but I'm just curious if there already is an solution out there.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Why isn't/Is there a natural language search interface for Everything from void tools?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m9mdtj",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.67,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_jchjkp4r1",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753511511,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Windows would be unusable for me without everything. I have over a hundred terabytes of data which I search in an instant using this tool everyday, across multiple nases, and I&amp;#39;ve yet found anything that can rival everything even on mac or linux.&lt;/p&gt;\n\n&lt;p&gt;But I just wish there was an llm implementation which can take this functionality to the next level, and while I&amp;#39;ve tried to vibe code something myself, it seems to me that the existing llms hallucinate too much, and it would require a purpose built llm. I don&amp;#39;t have the resources or hardware to build/train an llm, nor the expertise to make a structured natural language process that works in every instance like an llm. &lt;/p&gt;\n\n&lt;p&gt;Like you can interface with ex.exe which is the command line interface for everything, and I&amp;#39;ve successfully gotten a bit into being able to query for files of this type above x size. But llms simply lack the consistency and reliability for a proper search function that works time over time.&lt;/p&gt;\n\n&lt;p&gt;I just can&amp;#39;t believe this hasn&amp;#39;t already been made. Being able to just ask, show me pictures above 10mb that I have from july 2025 or something like that and seeing results would be a godsend, instead of having to type in regex. &lt;/p&gt;\n\n&lt;p&gt;Now this isn&amp;#39;t rag, well I suppose it could be? All I&amp;#39;m thinking for llms in this case is just being an interpreter than takes natural language and converts into everything reg ex.&lt;/p&gt;\n\n&lt;p&gt;I assume there is more that could be done, using regex as well, but that would be heavily based on the size of database in terms of the context size required.&lt;/p&gt;\n\n&lt;p&gt;This is kind of a newb question, but I&amp;#39;m just curious if there already is an solution out there.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m9mdtj",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "CystralSkye",
            "discussion_type": null,
            "num_comments": 1,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m9mdtj/why_isntis_there_a_natural_language_search/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m9mdtj/why_isntis_there_a_natural_language_search/",
            "subreddit_subscribers": 504692,
            "created_utc": 1753511511,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n587wma",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DorphinPack",
            "can_mod_post": false,
            "created_utc": 1753514244,
            "send_replies": true,
            "parent_id": "t3_1m9mdtj",
            "score": 1,
            "author_fullname": "t2_zebuyjw9s",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you have a robust indexing solution (or everything in a database rather than a filesystem) Iâ€™d imagine you could write a tool function or MCP server that the LLM can use to implement your natural language query.\n\nI believe there already are some tools like that out there. Getting them to work reliably is more a matter of model-usecase fit.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n587wma",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you have a robust indexing solution (or everything in a database rather than a filesystem) Iâ€™d imagine you could write a tool function or MCP server that the LLM can use to implement your natural language query.&lt;/p&gt;\n\n&lt;p&gt;I believe there already are some tools like that out there. Getting them to work reliably is more a matter of model-usecase fit.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9mdtj/why_isntis_there_a_natural_language_search/n587wma/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753514244,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9mdtj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]