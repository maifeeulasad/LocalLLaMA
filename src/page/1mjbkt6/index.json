[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "What’s the best full stack/most automated way to code with chosen model?\n\nI’ve heard of solutions like Augment Code, but don’t want to be locked on model choice or stuck in a browser like Z.ai web chat full stack mode. I’d like the option to use local models if I want.\n\nCurrently interested in trying GLM 4.5, what is the best “set and forget” way to have the model work on something like the browser chat of GLM 4.5? The browser chat for GLM has a “full stack” mode that’s supposed to work in loops until it’s both accomplished its goal and there are no errors preventing the project from running. I’d like to do this in something on my computer so that the model is actually checking for errors with my specific set up, and so that I could potentially have more control to swap out what tools it has available as new and better ones become available.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Best solution to use any model in full stack mode?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjbkt6",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.66,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1loou9xu",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754502670,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What’s the best full stack/most automated way to code with chosen model?&lt;/p&gt;\n\n&lt;p&gt;I’ve heard of solutions like Augment Code, but don’t want to be locked on model choice or stuck in a browser like Z.ai web chat full stack mode. I’d like the option to use local models if I want.&lt;/p&gt;\n\n&lt;p&gt;Currently interested in trying GLM 4.5, what is the best “set and forget” way to have the model work on something like the browser chat of GLM 4.5? The browser chat for GLM has a “full stack” mode that’s supposed to work in loops until it’s both accomplished its goal and there are no errors preventing the project from running. I’d like to do this in something on my computer so that the model is actually checking for errors with my specific set up, and so that I could potentially have more control to swap out what tools it has available as new and better ones become available.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mjbkt6",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Shadow-Amulet-Ambush",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mjbkt6/best_solution_to_use_any_model_in_full_stack_mode/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjbkt6/best_solution_to_use_any_model_in_full_stack_mode/",
            "subreddit_subscribers": 512426,
            "created_utc": 1754502670,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7a4v9e",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Shadow-Amulet-Ambush",
                      "can_mod_post": false,
                      "created_utc": 1754506378,
                      "send_replies": true,
                      "parent_id": "t1_n79zg2y",
                      "score": 1,
                      "author_fullname": "t2_1loou9xu",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "You’re wrong but ok",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7a4v9e",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You’re wrong but ok&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjbkt6",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjbkt6/best_solution_to_use_any_model_in_full_stack_mode/n7a4v9e/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754506378,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n79zg2y",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "laterbreh",
            "can_mod_post": false,
            "created_utc": 1754504833,
            "send_replies": true,
            "parent_id": "t3_1mjbkt6",
            "score": 1,
            "author_fullname": "t2_ev9y9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Rule 1 \n\n# Please search before asking\n\n* Before posting a question, please spend a reasonable amount of time searching for existing questions that may provide an answer.\n\nRule 3\n\n# Low Effort Posts\n\n* Asking questions is allowed, but follow Rule 1. Low effort posts may be removed.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n79zg2y",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Rule 1 &lt;/p&gt;\n\n&lt;h1&gt;Please search before asking&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Before posting a question, please spend a reasonable amount of time searching for existing questions that may provide an answer.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Rule 3&lt;/p&gt;\n\n&lt;h1&gt;Low Effort Posts&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Asking questions is allowed, but follow Rule 1. Low effort posts may be removed.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjbkt6/best_solution_to_use_any_model_in_full_stack_mode/n79zg2y/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754504833,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjbkt6",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]