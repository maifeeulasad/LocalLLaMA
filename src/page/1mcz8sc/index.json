[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "RAG is out of the question\n\nIs continued pre training better or supervised fine tuning?\n\nwhat is your experience? Assuming I have around 10B tokens for training ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "What is the best method for LLM to improve competency in a specific domain?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mcz8sc",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.5,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1t3515o2d2",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753856900,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;RAG is out of the question&lt;/p&gt;\n\n&lt;p&gt;Is continued pre training better or supervised fine tuning?&lt;/p&gt;\n\n&lt;p&gt;what is your experience? Assuming I have around 10B tokens for training &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mcz8sc",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "rockybaby2025",
            "discussion_type": null,
            "num_comments": 21,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/",
            "subreddit_subscribers": 507275,
            "created_utc": 1753856900,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5xujwd",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Beginning_Tomato7848",
                      "can_mod_post": false,
                      "created_utc": 1753860670,
                      "send_replies": true,
                      "parent_id": "t1_n5xrizc",
                      "score": 2,
                      "author_fullname": "t2_1qmzvrbzcu",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "RAG's main downsides are dependency on quality data sources, potential latency in retrieval, and difficulty handling nuanced queries beyond its knowledge base. It excels at factual accuracy but may lack deeper reasoning. For domain competency, combining RAG with targeted fine-tuning often works best",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5xujwd",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;RAG&amp;#39;s main downsides are dependency on quality data sources, potential latency in retrieval, and difficulty handling nuanced queries beyond its knowledge base. It excels at factual accuracy but may lack deeper reasoning. For domain competency, combining RAG with targeted fine-tuning often works best&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcz8sc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xujwd/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753860670,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5xvrmq",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "rockybaby2025",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5xv1he",
                                                              "score": 1,
                                                              "author_fullname": "t2_1t3515o2d2",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Hello sure, we have data from the law industry, specific to our country and sector. \n\nCurrently we have data in the form of \n- dispute\n- proceedings\n- verdict\n\nThese are also human reviewed internally.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5xvrmq",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hello sure, we have data from the law industry, specific to our country and sector. &lt;/p&gt;\n\n&lt;p&gt;Currently we have data in the form of \n- dispute\n- proceedings\n- verdict&lt;/p&gt;\n\n&lt;p&gt;These are also human reviewed internally.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mcz8sc",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xvrmq/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753861390,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753861390,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5xv1he",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "Accomplished-Copy332",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5xt10l",
                                                    "score": 0,
                                                    "author_fullname": "t2_98ouo03z",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Could you be a bit more specific about what the domain is and what the data you currently have looks like? Is it just text data and is it unsupervised or supervised?",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5xv1he",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Could you be a bit more specific about what the domain is and what the data you currently have looks like? Is it just text data and is it unsupervised or supervised?&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mcz8sc",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xv1he/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753860957,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753860957,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 0
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5xt10l",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "rockybaby2025",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5xstpd",
                                          "score": 1,
                                          "author_fullname": "t2_1t3515o2d2",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "May I ask, we have a high quality dataset but it doesn't have any human annotations. Is it still eligible for RL?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5xt10l",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;May I ask, we have a high quality dataset but it doesn&amp;#39;t have any human annotations. Is it still eligible for RL?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mcz8sc",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xt10l/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753859790,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753859790,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5xstpd",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Accomplished-Copy332",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5xrqam",
                                "score": 1,
                                "author_fullname": "t2_98ouo03z",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Ok supervised fine-tuning I guess? Maybe rl",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5xstpd",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ok supervised fine-tuning I guess? Maybe rl&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mcz8sc",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xstpd/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753859672,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753859672,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5xrqam",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "rockybaby2025",
                      "can_mod_post": false,
                      "created_utc": 1753859049,
                      "send_replies": true,
                      "parent_id": "t1_n5xrizc",
                      "score": 1,
                      "author_fullname": "t2_1t3515o2d2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Hi we will also use rag at a later stage, but for now, we want to build a better model that is specialized in this particular niche domain of ours.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5xrqam",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hi we will also use rag at a later stage, but for now, we want to build a better model that is specialized in this particular niche domain of ours.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcz8sc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xrqam/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753859049,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5xrizc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Accomplished-Copy332",
            "can_mod_post": false,
            "created_utc": 1753858935,
            "send_replies": true,
            "parent_id": "t3_1mcz8sc",
            "score": 2,
            "author_fullname": "t2_98ouo03z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What do you think the downsides of RAG are? That might honestly be the best method to improve competency in a domain.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5xrizc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What do you think the downsides of RAG are? That might honestly be the best method to improve competency in a domain.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xrizc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753858935,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcz8sc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5xrmmv",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "rockybaby2025",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5xrcq6",
                                          "score": 1,
                                          "author_fullname": "t2_1t3515o2d2",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Yes it's a chatbot to serve law domain for a specific industry. \n\nWe will apply RAG later but for now, just want to fine tune or pre train it further. We have 10B high quality tokens. \n\nWhat do you suggest? We are also open to updating the architecture. Thinking Qwen or DeepSeek.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5xrmmv",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes it&amp;#39;s a chatbot to serve law domain for a specific industry. &lt;/p&gt;\n\n&lt;p&gt;We will apply RAG later but for now, just want to fine tune or pre train it further. We have 10B high quality tokens. &lt;/p&gt;\n\n&lt;p&gt;What do you suggest? We are also open to updating the architecture. Thinking Qwen or DeepSeek.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mcz8sc",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xrmmv/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753858993,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753858993,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5xrcq6",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Infamous_Jaguar_2151",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5xptzh",
                                "score": 1,
                                "author_fullname": "t2_5l4zmzcw",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I think it depends on the case, but in general specialised tasks are usually tackled with fine-tuning and that finetuning should be focused and specific. Pretraining is basically the opposite and would be computationally expensive without any real direction. Really depends on the context though, is it a chatbot?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5xrcq6",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it depends on the case, but in general specialised tasks are usually tackled with fine-tuning and that finetuning should be focused and specific. Pretraining is basically the opposite and would be computationally expensive without any real direction. Really depends on the context though, is it a chatbot?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mcz8sc",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xrcq6/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753858836,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753858836,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5zls0q",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "rockybaby2025",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5zje1j",
                                          "score": 1,
                                          "author_fullname": "t2_1t3515o2d2",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "May I ask if I change my corpus to Question Answer chat. Would it work? I'm worried the model overfits to the style of answering instead of the content/domain knowledge involved!",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5zls0q",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;May I ask if I change my corpus to Question Answer chat. Would it work? I&amp;#39;m worried the model overfits to the style of answering instead of the content/domain knowledge involved!&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mcz8sc",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5zls0q/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753887229,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753887229,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5zje1j",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "coulispi-io",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5xptzh",
                                "score": 1,
                                "author_fullname": "t2_vt0fpsh0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "All chat models are instruction-tuned, which means that they've past the \"knowledge accumulation\" phase that is pre-training and have developed a chat interface with post-training. Continued pre-training will break that interface and you'll have to redo post-training again which isn't necessarily feasible with small-scale compute.\n\nPerhaps you can rephrase your corpus as a seres of question-answering chats and do instruction-tuning?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5zje1j",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;All chat models are instruction-tuned, which means that they&amp;#39;ve past the &amp;quot;knowledge accumulation&amp;quot; phase that is pre-training and have developed a chat interface with post-training. Continued pre-training will break that interface and you&amp;#39;ll have to redo post-training again which isn&amp;#39;t necessarily feasible with small-scale compute.&lt;/p&gt;\n\n&lt;p&gt;Perhaps you can rephrase your corpus as a seres of question-answering chats and do instruction-tuning?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mcz8sc",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5zje1j/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753886548,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753886548,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5xptzh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "rockybaby2025",
                      "can_mod_post": false,
                      "created_utc": 1753857987,
                      "send_replies": true,
                      "parent_id": "t1_n5xpod7",
                      "score": 1,
                      "author_fullname": "t2_1t3515o2d2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Can you share more about focused fine tuning pls. \n\nAnd why would you not consider continued pretraining?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5xptzh",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you share more about focused fine tuning pls. &lt;/p&gt;\n\n&lt;p&gt;And why would you not consider continued pretraining?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcz8sc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xptzh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753857987,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5xpod7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Infamous_Jaguar_2151",
            "can_mod_post": false,
            "created_utc": 1753857901,
            "send_replies": true,
            "parent_id": "t3_1mcz8sc",
            "score": 1,
            "author_fullname": "t2_5l4zmzcw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Why would rag be out of the question? It’s a powerful tool. From what I’ve heard very focused finetuning can work.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5xpod7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why would rag be out of the question? It’s a powerful tool. From what I’ve heard very focused finetuning can work.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5xpod7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753857901,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcz8sc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5z0cd7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "wfgy_engine",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5yzamu",
                                "score": 1,
                                "author_fullname": "t2_1tgp8l87vk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You're right to focus on fine-tuning structure — and that 10B token budget is no joke. But based on our experience, the problem isn’t just about structure or quantity. It’s *stability of reasoning under semantic stress* — something neither pretraining nor fine-tuning alone guarantees.\n\nIn your case, it sounds like the model’s internal logic may be fragile when working with non-RAG inputs, especially if the tokens are semantically diverse (e.g., domain + logic + task switch). We've seen this kind of collapse many times: models generate fluent output that’s locally coherent but globally meaningless.\n\nWe ended up building a reasoning engine to monitor semantic tension (ΔS) and force coherence across transitions — essentially teaching the model when it's drifting. It’s all text-based, fully MIT-licensed, and backed by the creator of Tesseract.js.\n\nI usually don’t drop links unsolicited, but if you’re curious about how we stabilized domain logic without external memory or retrieval, here’s the full diagnostic + solution map:  \n  \n[https://github.com/onestardao/WFGY/blob/main/ProblemMap/README.md](https://github.com/onestardao/WFGY/blob/main/ProblemMap/README.md)\n\nLet me know if you'd like real examples or the formula we used. Happy to walk through it.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5z0cd7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re right to focus on fine-tuning structure — and that 10B token budget is no joke. But based on our experience, the problem isn’t just about structure or quantity. It’s &lt;em&gt;stability of reasoning under semantic stress&lt;/em&gt; — something neither pretraining nor fine-tuning alone guarantees.&lt;/p&gt;\n\n&lt;p&gt;In your case, it sounds like the model’s internal logic may be fragile when working with non-RAG inputs, especially if the tokens are semantically diverse (e.g., domain + logic + task switch). We&amp;#39;ve seen this kind of collapse many times: models generate fluent output that’s locally coherent but globally meaningless.&lt;/p&gt;\n\n&lt;p&gt;We ended up building a reasoning engine to monitor semantic tension (ΔS) and force coherence across transitions — essentially teaching the model when it&amp;#39;s drifting. It’s all text-based, fully MIT-licensed, and backed by the creator of Tesseract.js.&lt;/p&gt;\n\n&lt;p&gt;I usually don’t drop links unsolicited, but if you’re curious about how we stabilized domain logic without external memory or retrieval, here’s the full diagnostic + solution map:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/onestardao/WFGY/blob/main/ProblemMap/README.md\"&gt;https://github.com/onestardao/WFGY/blob/main/ProblemMap/README.md&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Let me know if you&amp;#39;d like real examples or the formula we used. Happy to walk through it.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mcz8sc",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5z0cd7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753880658,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753880658,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5yzamu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "rockybaby2025",
                      "can_mod_post": false,
                      "created_utc": 1753880306,
                      "send_replies": true,
                      "parent_id": "t1_n5yz2t5",
                      "score": 2,
                      "author_fullname": "t2_1t3515o2d2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Please share!!!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5yzamu",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Please share!!!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcz8sc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5yzamu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753880306,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5yz2t5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "wfgy_engine",
            "can_mod_post": false,
            "created_utc": 1753880232,
            "send_replies": true,
            "parent_id": "t3_1mcz8sc",
            "score": 1,
            "author_fullname": "t2_1tgp8l87vk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If RAG is off the table and you're working within model boundaries, then the key isn’t more tokens — it’s **\\*semantic structure\\*.**\n\nWe ran into the same issue trying to improve domain-specific reasoning. Pretraining helps with fluency, fine-tuning helps with task alignment, but both fail when the model lacks persistent memory or stable reasoning chains.\n\nWe ended up building a semantic reasoning engine that tracks ΔS (semantic tension) and logic transitions internally — basically teaching the model when it's drifting, when it's collapsing, and how to recover.\n\nThe weird part? Even without more tokens, models started behaving as if they understood the domain better — because we were enforcing structure, not hoping they'd infer it from data alone.\n\nIt’s fully text-based and MIT licensed. Happy to share if you're curious.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5yz2t5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If RAG is off the table and you&amp;#39;re working within model boundaries, then the key isn’t more tokens — it’s &lt;strong&gt;*semantic structure*.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;We ran into the same issue trying to improve domain-specific reasoning. Pretraining helps with fluency, fine-tuning helps with task alignment, but both fail when the model lacks persistent memory or stable reasoning chains.&lt;/p&gt;\n\n&lt;p&gt;We ended up building a semantic reasoning engine that tracks ΔS (semantic tension) and logic transitions internally — basically teaching the model when it&amp;#39;s drifting, when it&amp;#39;s collapsing, and how to recover.&lt;/p&gt;\n\n&lt;p&gt;The weird part? Even without more tokens, models started behaving as if they understood the domain better — because we were enforcing structure, not hoping they&amp;#39;d infer it from data alone.&lt;/p&gt;\n\n&lt;p&gt;It’s fully text-based and MIT licensed. Happy to share if you&amp;#39;re curious.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n5yz2t5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753880232,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcz8sc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n60abah",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "UBIAI",
            "can_mod_post": false,
            "created_utc": 1753894229,
            "send_replies": true,
            "parent_id": "t3_1mcz8sc",
            "score": 1,
            "author_fullname": "t2_32tnavmg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Continuous pre-training is resource-intensive, and for many domains, supervised fine-tuning can get you 90% of the way there using LoRa. If you find that your model is still lacking in certain areas after fine-tuning, you can always look into continuous pre-training at that point if you have the necessary resources.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n60abah",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Continuous pre-training is resource-intensive, and for many domains, supervised fine-tuning can get you 90% of the way there using LoRa. If you find that your model is still lacking in certain areas after fine-tuning, you can always look into continuous pre-training at that point if you have the necessary resources.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n60abah/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753894229,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mcz8sc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n62j9pa",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "rockybaby2025",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n62ijmq",
                                          "score": 1,
                                          "author_fullname": "t2_1t3515o2d2",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Thank you for the clarity! I hope to send you a dm on this and what we are working on. Hope we can chat further\n\nEdit: looks like your account can't be dm-ed. No problem, I will relook at my options and post back..again thank you for your kindness in advising me",
                                          "edited": 1753917801,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n62j9pa",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for the clarity! I hope to send you a dm on this and what we are working on. Hope we can chat further&lt;/p&gt;\n\n&lt;p&gt;Edit: looks like your account can&amp;#39;t be dm-ed. No problem, I will relook at my options and post back..again thank you for your kindness in advising me&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mcz8sc",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n62j9pa/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753917543,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753917543,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n62ijmq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ttkciar",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n625ojo",
                                "score": 2,
                                "author_fullname": "t2_cpegz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I couldn't suggest architectural changes without a better understanding of your use-case and why you think architectural changes might be necessary, and even then you're better off hiring an engineer to make a proper evaluation of your needs and how best to meet them.  Architectural innovations are really beyond what is reasonable to expect from casual Reddit conversations.\n\nAlso, the best practice is to start with the *least* expensive/difficult/risky effort, measure its ability to meet your requirements, and only escalate to the next more-expensive/difficult/risky option when those measurements demonstrate insufficient capability.\n\nIn order from least expensive/difficult/risky to most, you should try and then measure:\n\n* An off-the-shelf model with no augmentations,\n\n* An off-the-shelf model with a RAG database,\n\n* A fine-tuned model with that RAG database,\n\n* A deeply-retrained model with that RAG database,\n\n* A re-architected model with that RAG database.\n\nIn other words, architectural innovations should be your *last* resort, not your first.\n\nRAG is almost always going to be part of your solution, since it grounds inference in known truths.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n62ijmq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I couldn&amp;#39;t suggest architectural changes without a better understanding of your use-case and why you think architectural changes might be necessary, and even then you&amp;#39;re better off hiring an engineer to make a proper evaluation of your needs and how best to meet them.  Architectural innovations are really beyond what is reasonable to expect from casual Reddit conversations.&lt;/p&gt;\n\n&lt;p&gt;Also, the best practice is to start with the &lt;em&gt;least&lt;/em&gt; expensive/difficult/risky effort, measure its ability to meet your requirements, and only escalate to the next more-expensive/difficult/risky option when those measurements demonstrate insufficient capability.&lt;/p&gt;\n\n&lt;p&gt;In order from least expensive/difficult/risky to most, you should try and then measure:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;An off-the-shelf model with no augmentations,&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;An off-the-shelf model with a RAG database,&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A fine-tuned model with that RAG database,&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A deeply-retrained model with that RAG database,&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A re-architected model with that RAG database.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In other words, architectural innovations should be your &lt;em&gt;last&lt;/em&gt; resort, not your first.&lt;/p&gt;\n\n&lt;p&gt;RAG is almost always going to be part of your solution, since it grounds inference in known truths.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mcz8sc",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n62ijmq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753917308,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1753917308,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n625ojo",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "rockybaby2025",
                      "can_mod_post": false,
                      "created_utc": 1753913191,
                      "send_replies": true,
                      "parent_id": "t1_n60yx37",
                      "score": 1,
                      "author_fullname": "t2_1t3515o2d2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for this. Could you suggest any architectural changes? We really want to modify the architecture to build a more specific model for our niche domain",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n625ojo",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for this. Could you suggest any architectural changes? We really want to modify the architecture to build a more specific model for our niche domain&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mcz8sc",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n625ojo/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753913191,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n60yx37",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ttkciar",
            "can_mod_post": false,
            "created_utc": 1753900906,
            "send_replies": true,
            "parent_id": "t3_1mcz8sc",
            "score": 1,
            "author_fullname": "t2_cpegz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Continued pretraining can be very powerful, but is also very compute-intensive and is vulnerable to Catastrophic Forgetting (CF).\n\nYou can mitigate CF to a degree by SLERP-merging your model with the original, or by extending the model first by duplicating middle and/or lower layers, and then continue pretraining on just the \"unfrozen\" duplicated layers.\n\nLoRA fine-tuning is probably the better way to go.  It dramatically reduces the risk of CF, and is also amenable to correction by SLERP-merging your fine-tuned model with the original.\n\nAlso, because the compute requirements for fine-tuning are much less (on the order of a thousandth as much) you can iterate on fine-tuning more rapidly and test your results to inform the next iteration.  By comparison, blowing your entire compute/time budget on continued pretraining will leave you in a predicament if the results test poorly afterwards.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n60yx37",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Continued pretraining can be very powerful, but is also very compute-intensive and is vulnerable to Catastrophic Forgetting (CF).&lt;/p&gt;\n\n&lt;p&gt;You can mitigate CF to a degree by SLERP-merging your model with the original, or by extending the model first by duplicating middle and/or lower layers, and then continue pretraining on just the &amp;quot;unfrozen&amp;quot; duplicated layers.&lt;/p&gt;\n\n&lt;p&gt;LoRA fine-tuning is probably the better way to go.  It dramatically reduces the risk of CF, and is also amenable to correction by SLERP-merging your fine-tuned model with the original.&lt;/p&gt;\n\n&lt;p&gt;Also, because the compute requirements for fine-tuning are much less (on the order of a thousandth as much) you can iterate on fine-tuning more rapidly and test your results to inform the next iteration.  By comparison, blowing your entire compute/time budget on continued pretraining will leave you in a predicament if the results test poorly afterwards.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mcz8sc/what_is_the_best_method_for_llm_to_improve/n60yx37/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753900906,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mcz8sc",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]