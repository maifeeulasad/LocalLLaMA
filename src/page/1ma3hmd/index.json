[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hello guys,  \nSo I have been developing a NL to SQL multi agent system using langgraph and llama 3:8b.  \nLately I read at some places and the official docs that 8b version is not capable of maitaining regular conversations with tool calling.  \nI need some suggestions on if I should use any other version of llama which supports tool calling. Tool calling is needed because I need some way to generate visuals/ answer very complex queries etc.  \nMaybe there is a hack or I am completely missing something.  \nThanks for the suggestions. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Tool calling support in Llama 3 8b",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1ma3hmd",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.5,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_kws1zhj",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753561832,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;br/&gt;\nSo I have been developing a NL to SQL multi agent system using langgraph and llama 3:8b.&lt;br/&gt;\nLately I read at some places and the official docs that 8b version is not capable of maitaining regular conversations with tool calling.&lt;br/&gt;\nI need some suggestions on if I should use any other version of llama which supports tool calling. Tool calling is needed because I need some way to generate visuals/ answer very complex queries etc.&lt;br/&gt;\nMaybe there is a hack or I am completely missing something.&lt;br/&gt;\nThanks for the suggestions. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1ma3hmd",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "codingpinscher",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1ma3hmd/tool_calling_support_in_llama_3_8b/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ma3hmd/tool_calling_support_in_llama_3_8b/",
            "subreddit_subscribers": 504973,
            "created_utc": 1753561832,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5bpa0u",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "croninsiglos",
            "can_mod_post": false,
            "created_utc": 1753562606,
            "send_replies": true,
            "parent_id": "t3_1ma3hmd",
            "score": 1,
            "author_fullname": "t2_v7qje",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Tool calling was introduced in 3.1 not 3.\n\nIt was also really temperamental. Most chat templates and system prompts would force it to use tools if you bound tools to the call so you needed separate llms (in the langchain sense) for invocations with potential tool calls, and then those for regular messages.\n\n  \nI'd recommend switching to Qwen3 models or maybe mistral.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5bpa0u",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Tool calling was introduced in 3.1 not 3.&lt;/p&gt;\n\n&lt;p&gt;It was also really temperamental. Most chat templates and system prompts would force it to use tools if you bound tools to the call so you needed separate llms (in the langchain sense) for invocations with potential tool calls, and then those for regular messages.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d recommend switching to Qwen3 models or maybe mistral.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma3hmd/tool_calling_support_in_llama_3_8b/n5bpa0u/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753562606,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma3hmd",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5bots4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1753562459,
            "send_replies": true,
            "parent_id": "t3_1ma3hmd",
            "score": 0,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You could try llama 3.1 8b or use a different model altogether. Phi 4 would be my recommendation.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5bots4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You could try llama 3.1 8b or use a different model altogether. Phi 4 would be my recommendation.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma3hmd/tool_calling_support_in_llama_3_8b/n5bots4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753562459,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma3hmd",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5c684i",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DinoAmino",
            "can_mod_post": false,
            "created_utc": 1753568329,
            "send_replies": true,
            "parent_id": "t3_1ma3hmd",
            "score": 0,
            "author_fullname": "t2_j1v7f",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Check the BFCL leaderboard for the best tool calling LLMs.\n\nhttps://gorilla.cs.berkeley.edu/leaderboard.html\n\nThere are two fine-tunes of Llama 8b in the top 10\n\n#4 - Salesforce/Llama-xLAM-2-8b-fc-r\n\nhttps://huggingface.co/Salesforce/Llama-xLAM-2-8b-fc-r\n\n#10 -Team-ACE/ToolACE-2-Llama-3.1-8B\n\nhttps://huggingface.co/Team-ACE/ToolACE-2-Llama-3.1-8B",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5c684i",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Check the BFCL leaderboard for the best tool calling LLMs.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://gorilla.cs.berkeley.edu/leaderboard.html\"&gt;https://gorilla.cs.berkeley.edu/leaderboard.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;There are two fine-tunes of Llama 8b in the top 10&lt;/p&gt;\n\n&lt;h1&gt;4 - Salesforce/Llama-xLAM-2-8b-fc-r&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/Salesforce/Llama-xLAM-2-8b-fc-r\"&gt;https://huggingface.co/Salesforce/Llama-xLAM-2-8b-fc-r&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;10 -Team-ACE/ToolACE-2-Llama-3.1-8B&lt;/h1&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/Team-ACE/ToolACE-2-Llama-3.1-8B\"&gt;https://huggingface.co/Team-ACE/ToolACE-2-Llama-3.1-8B&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma3hmd/tool_calling_support_in_llama_3_8b/n5c684i/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753568329,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma3hmd",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ch5gk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "jacek2023",
            "can_mod_post": false,
            "created_utc": 1753572272,
            "send_replies": true,
            "parent_id": "t3_1ma3hmd",
            "score": 0,
            "author_fullname": "t2_vqgbql9w",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You should not use llama 3.x, you should explore modern models, like qwen or mistral, I just googled there is a tool calling in granite 8b if you like IBM",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ch5gk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You should not use llama 3.x, you should explore modern models, like qwen or mistral, I just googled there is a tool calling in granite 8b if you like IBM&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma3hmd/tool_calling_support_in_llama_3_8b/n5ch5gk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753572272,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1ma3hmd",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]