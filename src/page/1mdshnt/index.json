[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I love efficiency. I’m always hoping to find a solution that allows me to automate basic coding tasks like “create some css that makes a menu that looks like this” to leave running while I go to work. Main problem with this currently is that AI will often stop and declare it’s done, and then you have to make fixes to whatever it spit out, which isn’t feasible when you’re not there! Hopefully soon you could have another model (maybe vision based?) babysitting the coding model and saying “a little to the left” over the 10 prompts it takes to get it while youre away.\n\nUntil that day comes, please share with me your favorite things that you’ve been able to automate with language models to make your life more efficient!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Best thing Youve automated?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mdshnt",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.75,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1loou9xu",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753937233,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I love efficiency. I’m always hoping to find a solution that allows me to automate basic coding tasks like “create some css that makes a menu that looks like this” to leave running while I go to work. Main problem with this currently is that AI will often stop and declare it’s done, and then you have to make fixes to whatever it spit out, which isn’t feasible when you’re not there! Hopefully soon you could have another model (maybe vision based?) babysitting the coding model and saying “a little to the left” over the 10 prompts it takes to get it while youre away.&lt;/p&gt;\n\n&lt;p&gt;Until that day comes, please share with me your favorite things that you’ve been able to automate with language models to make your life more efficient!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mdshnt",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Shadow-Amulet-Ambush",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mdshnt/best_thing_youve_automated/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdshnt/best_thing_youve_automated/",
            "subreddit_subscribers": 507575,
            "created_utc": 1753937233,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6473xr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "libregrape",
            "can_mod_post": false,
            "created_utc": 1753940569,
            "send_replies": true,
            "parent_id": "t3_1mdshnt",
            "score": 3,
            "author_fullname": "t2_100x0lil34",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I automate code review. Every time my makefile is run, a script is called that reviews each code file separately, and then writes all reports into a single markdown file, and opens it.\n\n\nAt first it needed some tinkering, as vode review isn't an easy task for LLMs. I have segmented the task in \"maintainablility\" and \"code logic\" reviews.\n\nAnd it has show itself to be quite useful, since it notices quite a bit of basic errors that would otherwise be missed, and that could be easily avoided.\n\nA big problem was that AI did not really understand the intention behind my code, or had other opinions on how it should be done. For example, I write my code with a more offensive approach, but AI constantly suggests defensive strategies for code. But at one moment, I realsed that whatever AI does not understand is... a perfect candidate for a comment! So that way instead of combatting the seemingly annoying habit of AI misunderstanding my code with prompting, I have eliminated the real problem - incomprehensible code.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6473xr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I automate code review. Every time my makefile is run, a script is called that reviews each code file separately, and then writes all reports into a single markdown file, and opens it.&lt;/p&gt;\n\n&lt;p&gt;At first it needed some tinkering, as vode review isn&amp;#39;t an easy task for LLMs. I have segmented the task in &amp;quot;maintainablility&amp;quot; and &amp;quot;code logic&amp;quot; reviews.&lt;/p&gt;\n\n&lt;p&gt;And it has show itself to be quite useful, since it notices quite a bit of basic errors that would otherwise be missed, and that could be easily avoided.&lt;/p&gt;\n\n&lt;p&gt;A big problem was that AI did not really understand the intention behind my code, or had other opinions on how it should be done. For example, I write my code with a more offensive approach, but AI constantly suggests defensive strategies for code. But at one moment, I realsed that whatever AI does not understand is... a perfect candidate for a comment! So that way instead of combatting the seemingly annoying habit of AI misunderstanding my code with prompting, I have eliminated the real problem - incomprehensible code.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdshnt/best_thing_youve_automated/n6473xr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753940569,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdshnt",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n64hymj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "kmouratidis",
            "can_mod_post": false,
            "created_utc": 1753946403,
            "send_replies": true,
            "parent_id": "t3_1mdshnt",
            "score": 0,
            "author_fullname": "t2_k6u7rfxb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "My yearly financial and tax reporting was a pain. I used local models (can't remember which) to generate &gt;70% of the code for a small project that reads and parses multiple data files, and uses jinja2 to generate a markdown report that then gets converted to html and PDF. This was the first year I sent it to my accountant. With Mistral 3.2, I'll be able to automate the last part of it too (reading payslips).\n\nI also created a n8n automation that reads the daily r/CVEWatch post, feeds it to my LLM to extract affected software, then it connects to my docker instance and reads the deployed stacks I have, and finally feeds both into the LLM and checks if any of them are vulnerable. Finally, it sends me a simple email with the results.\n\nI want to implement stock watch or similar, or some Reddit FAQ automation too. We'll see.\n\n\nEdit: btw, do you want to try [my Devstral-Vision rebase](https://huggingface.co/kmouratidis/Devstral-Small-2507-Rebased-Vision) for automated UI + dev work? You should be able to take screenshots and feed them to it.",
            "edited": 1753946636,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n64hymj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My yearly financial and tax reporting was a pain. I used local models (can&amp;#39;t remember which) to generate &amp;gt;70% of the code for a small project that reads and parses multiple data files, and uses jinja2 to generate a markdown report that then gets converted to html and PDF. This was the first year I sent it to my accountant. With Mistral 3.2, I&amp;#39;ll be able to automate the last part of it too (reading payslips).&lt;/p&gt;\n\n&lt;p&gt;I also created a n8n automation that reads the daily &lt;a href=\"/r/CVEWatch\"&gt;r/CVEWatch&lt;/a&gt; post, feeds it to my LLM to extract affected software, then it connects to my docker instance and reads the deployed stacks I have, and finally feeds both into the LLM and checks if any of them are vulnerable. Finally, it sends me a simple email with the results.&lt;/p&gt;\n\n&lt;p&gt;I want to implement stock watch or similar, or some Reddit FAQ automation too. We&amp;#39;ll see.&lt;/p&gt;\n\n&lt;p&gt;Edit: btw, do you want to try &lt;a href=\"https://huggingface.co/kmouratidis/Devstral-Small-2507-Rebased-Vision\"&gt;my Devstral-Vision rebase&lt;/a&gt; for automated UI + dev work? You should be able to take screenshots and feed them to it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdshnt/best_thing_youve_automated/n64hymj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753946403,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdshnt",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]