[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "This is probably a very uninspiring question for most people here, but I am looking to replace my current AMD RX 6600 (8GB) for both UWQHD gaming and experimentation with Local LLMs.\n\nI've been running various models in the 4-15GB range, so ocasionally VRAM only, sometimes VRAM+RAM (of which I also only have 32GB, DDR4, decent timings.) CPU is a 5800X3D on a MSI B550 Pro (so PCI 4.0)\n\nObviously, that's very meh, but my budget is quite constrained.\n\nI've mostly done text generation (creative writing, not RP; code). I am interest in pushing context windows and making more use of RAG). I want to also look into image and audio generation in the future. \n\nI'd also love to run some hobbyist expirements with *training* midi or score based composition networks (obviously being quite limited in ressources... this is more for my education/edification than getting any kind of competetive results).\n\nSo... what's the most generally useful kind of purchase I might be looking at?\n\nCurrently my research indicates the following candidates:   \n\n* Radeon RX 9060 XT 16GB ~380€ (gaming, price+, not CUDA is limiting for some things)  \n* RTX 5060 Ti 16GB, ~440€ (similar performance, for 60€ more, but maybe an NVIDIA bonus)\n* last generation used, 16GB, seem to be about 100€ cheaper?, so in the 300-360€ range (7600XT-4060Ti16)?\n* Arc A770, ~ 250-280€ (cheapest ? 16GB option that isn't incredibly old, I assume?)\n\n\nI haven't really looked into a dual setup or two generations old, so if I should do that (2xused RX 6800 or some such), chime up. I guess biggest downside of using two cards now is I can't just extend one of the above with a duplicate in the future.\n\nRadeon RX 7900 XT 20GB (680€) or XTX 24 GB (880€) seem like the cheapest options beyond 16GB and that's probably beyond what I should spend, as tempting as they seem.\n\nAs you all seem way more knowledgeable, I'd love some advice. Thanks in advance.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "lowish/midrange budget general purpose GPU",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m8dufz",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.67,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_k9k5w",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753385354,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is probably a very uninspiring question for most people here, but I am looking to replace my current AMD RX 6600 (8GB) for both UWQHD gaming and experimentation with Local LLMs.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been running various models in the 4-15GB range, so ocasionally VRAM only, sometimes VRAM+RAM (of which I also only have 32GB, DDR4, decent timings.) CPU is a 5800X3D on a MSI B550 Pro (so PCI 4.0)&lt;/p&gt;\n\n&lt;p&gt;Obviously, that&amp;#39;s very meh, but my budget is quite constrained.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve mostly done text generation (creative writing, not RP; code). I am interest in pushing context windows and making more use of RAG). I want to also look into image and audio generation in the future. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also love to run some hobbyist expirements with &lt;em&gt;training&lt;/em&gt; midi or score based composition networks (obviously being quite limited in ressources... this is more for my education/edification than getting any kind of competetive results).&lt;/p&gt;\n\n&lt;p&gt;So... what&amp;#39;s the most generally useful kind of purchase I might be looking at?&lt;/p&gt;\n\n&lt;p&gt;Currently my research indicates the following candidates:   &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Radeon RX 9060 XT 16GB ~380€ (gaming, price+, not CUDA is limiting for some things)&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;RTX 5060 Ti 16GB, ~440€ (similar performance, for 60€ more, but maybe an NVIDIA bonus)&lt;/li&gt;\n&lt;li&gt;last generation used, 16GB, seem to be about 100€ cheaper?, so in the 300-360€ range (7600XT-4060Ti16)?&lt;/li&gt;\n&lt;li&gt;Arc A770, ~ 250-280€ (cheapest ? 16GB option that isn&amp;#39;t incredibly old, I assume?)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I haven&amp;#39;t really looked into a dual setup or two generations old, so if I should do that (2xused RX 6800 or some such), chime up. I guess biggest downside of using two cards now is I can&amp;#39;t just extend one of the above with a duplicate in the future.&lt;/p&gt;\n\n&lt;p&gt;Radeon RX 7900 XT 20GB (680€) or XTX 24 GB (880€) seem like the cheapest options beyond 16GB and that&amp;#39;s probably beyond what I should spend, as tempting as they seem.&lt;/p&gt;\n\n&lt;p&gt;As you all seem way more knowledgeable, I&amp;#39;d love some advice. Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m8dufz",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "BrainOnLoan",
            "discussion_type": null,
            "num_comments": 9,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/",
            "subreddit_subscribers": 504023,
            "created_utc": 1753385354,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4z4lrk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ttkciar",
                      "can_mod_post": false,
                      "created_utc": 1753392335,
                      "send_replies": true,
                      "parent_id": "t1_n4yhjvz",
                      "score": 1,
                      "author_fullname": "t2_cpegz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "For what it's worth, this is the performance I'm getting for pure-CPU inference with llama.cpp on dual Xeon hardware eight-channel DDR4, and on i7-9750H dual-channel DDR4:\n\nhttp://ciar.org/h/performance.html\n\nAlso, you might want to consider purchasing an MI60 (32GB VRAM).  They're going for about $450 on eBay right now.  I'm pretty happy with mine.  Like you, I just want usable speeds from larger models, and I'm able to get 11 tps from Gemma3-27B (Q4_K_M) on my MI60 if I reduce the context limit to 4K (any more than that and it won't fit in 32GB).  Do get the add-on blower cooler, though, and tape it against cracking.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4z4lrk",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For what it&amp;#39;s worth, this is the performance I&amp;#39;m getting for pure-CPU inference with llama.cpp on dual Xeon hardware eight-channel DDR4, and on i7-9750H dual-channel DDR4:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://ciar.org/h/performance.html\"&gt;http://ciar.org/h/performance.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Also, you might want to consider purchasing an MI60 (32GB VRAM).  They&amp;#39;re going for about $450 on eBay right now.  I&amp;#39;m pretty happy with mine.  Like you, I just want usable speeds from larger models, and I&amp;#39;m able to get 11 tps from Gemma3-27B (Q4_K_M) on my MI60 if I reduce the context limit to 4K (any more than that and it won&amp;#39;t fit in 32GB).  Do get the add-on blower cooler, though, and tape it against cracking.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8dufz",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/n4z4lrk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753392335,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4yhjvz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "BrainOnLoan",
            "can_mod_post": false,
            "created_utc": 1753385830,
            "send_replies": true,
            "parent_id": "t3_1m8dufz",
            "score": 1,
            "author_fullname": "t2_k9k5w",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Some thought I got too late:  \n\nAs I don't really require top token/sec, just useable speeds, I guess another avenue would be looking into upgrading my RAM and leaning much more heavily into larger model sizes that way?\n\nThe only realistic upgrade option, I think, is just adding another 2x16GB RAM to get to 64GB total. That's reasonably in my budget range still, but I don't know whether a 4channel configuration with DDR4 is any use??\n\nThough if I remember correctly my CPU wouldn't exactly be the best starting point for such an andeavour?\n\n(And a GPU upgrade is required anyway for gaming on new monitor with more pixels that need pushing)\n\nAlso, obviously I can rent cheaper someplace outside of my home for many use cases, but I am tinkering and learning on purpose.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4yhjvz",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Some thought I got too late:  &lt;/p&gt;\n\n&lt;p&gt;As I don&amp;#39;t really require top token/sec, just useable speeds, I guess another avenue would be looking into upgrading my RAM and leaning much more heavily into larger model sizes that way?&lt;/p&gt;\n\n&lt;p&gt;The only realistic upgrade option, I think, is just adding another 2x16GB RAM to get to 64GB total. That&amp;#39;s reasonably in my budget range still, but I don&amp;#39;t know whether a 4channel configuration with DDR4 is any use??&lt;/p&gt;\n\n&lt;p&gt;Though if I remember correctly my CPU wouldn&amp;#39;t exactly be the best starting point for such an andeavour?&lt;/p&gt;\n\n&lt;p&gt;(And a GPU upgrade is required anyway for gaming on new monitor with more pixels that need pushing)&lt;/p&gt;\n\n&lt;p&gt;Also, obviously I can rent cheaper someplace outside of my home for many use cases, but I am tinkering and learning on purpose.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/n4yhjvz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753385830,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8dufz",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4znicr",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "BrainOnLoan",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4yy8zc",
                                          "score": 2,
                                          "author_fullname": "t2_k9k5w",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Thx, running linux for sth like that is fine, I frequently have dual-boot setups.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4znicr",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thx, running linux for sth like that is fine, I frequently have dual-boot setups.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m8dufz",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/n4znicr/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753398309,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753398309,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4yy8zc",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "triynizzles1",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4yn4az",
                                "score": 1,
                                "author_fullname": "t2_zr0g49ixt",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Network training meaning fine-tuning, or adjusting the weights of the model? \n\nYes, unless you run linux.\n\nRocm (amd’s version of cuda) isn’t supported by the windows version of pytorch. Pytorch is used to build and finetune language models.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4yy8zc",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Network training meaning fine-tuning, or adjusting the weights of the model? &lt;/p&gt;\n\n&lt;p&gt;Yes, unless you run linux.&lt;/p&gt;\n\n&lt;p&gt;Rocm (amd’s version of cuda) isn’t supported by the windows version of pytorch. Pytorch is used to build and finetune language models.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m8dufz",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/n4yy8zc/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753390486,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753390486,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yn4az",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BrainOnLoan",
                      "can_mod_post": false,
                      "created_utc": 1753387379,
                      "send_replies": true,
                      "parent_id": "t1_n4ylkca",
                      "score": 1,
                      "author_fullname": "t2_k9k5w",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "thx for chiming in\n\n&gt; and dont foresee needing CUDA (nvidia gpu) for your use cases\n\nI've ocassionally seen this here and there, so I was aware of it, but in detail I've no idea where I might need it.\n\nAs I said, I want to do some experimentation, including network training, so is that an area where it would be relevant?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yn4az",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;thx for chiming in&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;and dont foresee needing CUDA (nvidia gpu) for your use cases&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;ve ocassionally seen this here and there, so I was aware of it, but in detail I&amp;#39;ve no idea where I might need it.&lt;/p&gt;\n\n&lt;p&gt;As I said, I want to do some experimentation, including network training, so is that an area where it would be relevant?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8dufz",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/n4yn4az/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753387379,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n4yzu65",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "BrainOnLoan",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n4yye9f",
                                          "score": 1,
                                          "author_fullname": "t2_k9k5w",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I am seeing used versions for 650€ or so, but if I see several on first glance, some waiting and sniping might yield 600€ or so.\n\nI'll have to think about how flexible I am on spending that much, as it's the upper end of \"my\" affordable.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n4yzu65",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am seeing used versions for 650€ or so, but if I see several on first glance, some waiting and sniping might yield 600€ or so.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll have to think about how flexible I am on spending that much, as it&amp;#39;s the upper end of &amp;quot;my&amp;quot; affordable.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m8dufz",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/n4yzu65/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753390935,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753390935,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n4yye9f",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "triynizzles1",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4yx77e",
                                "score": 1,
                                "author_fullname": "t2_zr0g49ixt",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "3090 would be great if you can buy within budget!!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4yye9f",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3090 would be great if you can buy within budget!!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m8dufz",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/n4yye9f/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753390527,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753390527,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yx77e",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "BrainOnLoan",
                      "can_mod_post": false,
                      "created_utc": 1753390192,
                      "send_replies": true,
                      "parent_id": "t1_n4ylkca",
                      "score": 1,
                      "author_fullname": "t2_k9k5w",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "After further googling, a used 3090 might be a very tempting option, if I can just about squeeze it into my budget.\n\nProbably not as bang/buck excellent in gaming as for LLMs, it should be sufficient there too.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yx77e",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;After further googling, a used 3090 might be a very tempting option, if I can just about squeeze it into my budget.&lt;/p&gt;\n\n&lt;p&gt;Probably not as bang/buck excellent in gaming as for LLMs, it should be sufficient there too.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8dufz",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/n4yx77e/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753390192,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4ylkca",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1753386949,
            "send_replies": true,
            "parent_id": "t3_1m8dufz",
            "score": 1,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Imo if you are familiar with AMD and dont foresee needing CUDA (nvidia gpu) for your use cases, rx7600xt 16gb version would be a great choice. I’m not sure if you can buy them new still. Even secondhand its a great price for 16 GB.\n\n4060ti 16 gb version would also be a decent secondhand option.\n\nThe current gen cards you mentioned are faster but not huge leap forward.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4ylkca",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Imo if you are familiar with AMD and dont foresee needing CUDA (nvidia gpu) for your use cases, rx7600xt 16gb version would be a great choice. I’m not sure if you can buy them new still. Even secondhand its a great price for 16 GB.&lt;/p&gt;\n\n&lt;p&gt;4060ti 16 gb version would also be a decent secondhand option.&lt;/p&gt;\n\n&lt;p&gt;The current gen cards you mentioned are faster but not huge leap forward.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8dufz/lowishmidrange_budget_general_purpose_gpu/n4ylkca/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753386949,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8dufz",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]