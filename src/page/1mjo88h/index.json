[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Im very interested in hearing what the current state of the art is in finetuning hybrid reasoning models like GPT-OS: or even GLM-4.5-Air. \n\nUnless I’m mistaken , reasoning models would normally require hybrid fine-tuning to retain reasoning after the finetuning possess. Is it possible to shape their approach to reasoning during finetuning as well?\n\nThis seems to what most people were frustrated about with GPT-OSS, that it thinks a bit too much about unrelated or inappropriate concepts before answering. To be clear I’m not saying it should be made reckless, but I’m still interested in knowing whether all that needs to be done is add more streamlined reasoning examples?\n\nExcerpt on one way these models are trained:\n\n „Hybrid Fine-Tuning (HFT) as a cold start, followed by online reinforcement learning with the proposed Hybrid Group Policy Optimization (HGPO) to implicitly learn to select the appropriate thinking mode“. \n\n- Source: Reasonings-Finetuning Repurposes Latent Representations in Base Models. Jake Ward, Chuqiao Lin, Constantin Venhoff, Neel Nanda.\n\nI found this useful guide on hybrid finetuning which applies to qlora techniques too: https://atalupadhyay.wordpress.com/2025/05/07/fine-tuning-qwen-3-with-hybrid-reasoning-a-comprehensive-guide/\n\nHow would you go about finetuning it? What reasoning datasets could be best suited? Is lora or qlora gonna be sufficient, or would pretraining be required?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Fine-Tuning the New GPT-OSS",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjo88h",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.55,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_5l4zmzcw",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1754535509,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754533791,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im very interested in hearing what the current state of the art is in finetuning hybrid reasoning models like GPT-OS: or even GLM-4.5-Air. &lt;/p&gt;\n\n&lt;p&gt;Unless I’m mistaken , reasoning models would normally require hybrid fine-tuning to retain reasoning after the finetuning possess. Is it possible to shape their approach to reasoning during finetuning as well?&lt;/p&gt;\n\n&lt;p&gt;This seems to what most people were frustrated about with GPT-OSS, that it thinks a bit too much about unrelated or inappropriate concepts before answering. To be clear I’m not saying it should be made reckless, but I’m still interested in knowing whether all that needs to be done is add more streamlined reasoning examples?&lt;/p&gt;\n\n&lt;p&gt;Excerpt on one way these models are trained:&lt;/p&gt;\n\n&lt;p&gt;„Hybrid Fine-Tuning (HFT) as a cold start, followed by online reinforcement learning with the proposed Hybrid Group Policy Optimization (HGPO) to implicitly learn to select the appropriate thinking mode“. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Source: Reasonings-Finetuning Repurposes Latent Representations in Base Models. Jake Ward, Chuqiao Lin, Constantin Venhoff, Neel Nanda.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I found this useful guide on hybrid finetuning which applies to qlora techniques too: &lt;a href=\"https://atalupadhyay.wordpress.com/2025/05/07/fine-tuning-qwen-3-with-hybrid-reasoning-a-comprehensive-guide/\"&gt;https://atalupadhyay.wordpress.com/2025/05/07/fine-tuning-qwen-3-with-hybrid-reasoning-a-comprehensive-guide/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;How would you go about finetuning it? What reasoning datasets could be best suited? Is lora or qlora gonna be sufficient, or would pretraining be required?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/oTDGi28rWT9Prb4fKdNPYKjBtnQT_9Y1bd_ug2fGJaU.jpeg?auto=webp&amp;s=d2d2930818293da2932d147ec786d539e35d1bbe",
                    "width": 201,
                    "height": 201
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/oTDGi28rWT9Prb4fKdNPYKjBtnQT_9Y1bd_ug2fGJaU.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=09957d4d504bc996c65e6855e5de32d26bcf7c9b",
                      "width": 108,
                      "height": 108
                    }
                  ],
                  "variants": {},
                  "id": "oTDGi28rWT9Prb4fKdNPYKjBtnQT_9Y1bd_ug2fGJaU"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mjo88h",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Infamous_Jaguar_2151",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mjo88h/finetuning_the_new_gptoss/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjo88h/finetuning_the_new_gptoss/",
            "subreddit_subscribers": 512874,
            "created_utc": 1754533791,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7d0ifj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Accomplished_Ad9530",
            "can_mod_post": false,
            "created_utc": 1754540638,
            "send_replies": true,
            "parent_id": "t3_1mjo88h",
            "score": 5,
            "author_fullname": "t2_88fma001",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think these models have a lot of room for fine-tuning and adapting. Here are a few bits I'm starting with:\n\nOAI cookbook: [https://cookbook.openai.com/articles/gpt-oss/fine-tune-transfomers](https://cookbook.openai.com/articles/gpt-oss/fine-tune-transfomers)\n\nOAI red-teaming paper: [https://cdn.openai.com/pdf/231bf018-659a-494d-976c-2efdfc72b652/oai\\_gpt-oss\\_Model\\_Safety.pdf](https://cdn.openai.com/pdf/231bf018-659a-494d-976c-2efdfc72b652/oai_gpt-oss_Model_Safety.pdf)\n\nMXFP4 spec: [https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf](https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf)\n\nHF cookbook: [https://github.com/huggingface/gpt-oss-recipes/blob/main/sft.py](https://github.com/huggingface/gpt-oss-recipes/blob/main/sft.py)",
            "edited": 1754541828,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7d0ifj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think these models have a lot of room for fine-tuning and adapting. Here are a few bits I&amp;#39;m starting with:&lt;/p&gt;\n\n&lt;p&gt;OAI cookbook: &lt;a href=\"https://cookbook.openai.com/articles/gpt-oss/fine-tune-transfomers\"&gt;https://cookbook.openai.com/articles/gpt-oss/fine-tune-transfomers&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;OAI red-teaming paper: &lt;a href=\"https://cdn.openai.com/pdf/231bf018-659a-494d-976c-2efdfc72b652/oai_gpt-oss_Model_Safety.pdf\"&gt;https://cdn.openai.com/pdf/231bf018-659a-494d-976c-2efdfc72b652/oai_gpt-oss_Model_Safety.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;MXFP4 spec: &lt;a href=\"https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf\"&gt;https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;HF cookbook: &lt;a href=\"https://github.com/huggingface/gpt-oss-recipes/blob/main/sft.py\"&gt;https://github.com/huggingface/gpt-oss-recipes/blob/main/sft.py&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjo88h/finetuning_the_new_gptoss/n7d0ifj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754540638,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjo88h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7cki60",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "mrtime777",
            "can_mod_post": false,
            "created_utc": 1754534158,
            "send_replies": true,
            "parent_id": "t3_1mjo88h",
            "score": -4,
            "author_fullname": "t2_37pn0768",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I wouldn't waste my gpu time fine tuning this model. I'll try to fine tune 20b and see what happens, but it seems DOA to me",
            "edited": 1754535628,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7cki60",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I wouldn&amp;#39;t waste my gpu time fine tuning this model. I&amp;#39;ll try to fine tune 20b and see what happens, but it seems DOA to me&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjo88h/finetuning_the_new_gptoss/n7cki60/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754534158,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjo88h",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -4
          }
        }
      ],
      "before": null
    }
  }
]