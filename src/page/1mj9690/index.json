[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Which one is better?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "gpt-oss-20b vs magistral:24b?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mj9690",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.73,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 5,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_tqt1idp",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 5,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754497291,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Which one is better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mj9690",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "BillyTheMilli",
            "discussion_type": null,
            "num_comments": 11,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/",
            "subreddit_subscribers": 512426,
            "created_utc": 1754497291,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7a4s2n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ayylmaonade",
            "can_mod_post": false,
            "created_utc": 1754506353,
            "send_replies": true,
            "parent_id": "t3_1mj9690",
            "score": 5,
            "author_fullname": "t2_oqajf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It depends what you're doing. GPT-oss isn't a *great* model, but it's not as bad as people here make it out to be. Magistral is rarely spoken of here, but honestly, it kind of sucks to work with, at least locally. Magistral is just a fine-tune of Mistral Small 3.1 and hell, even requires a system prompt to get it to reason, which leads to inconsistency when the model decides its system prompt is no longer relevant. (It's hard to *keep* the model reasoning after 2-3 prompts.) Magistral also reasons far longer and tends to draft its entire response every time, which is kind of annoying. GPT-oss doesn't.\n\nAlthough, Magistral has the upper hand on GPT-oss by far in terms of world knowledge, and a much lower hallucination rate. If your task in any way relies on world knowledge, choose Magistral. GPT-oss would be better suited for pure reasoning tasks, like maths or other difficult problem solving. But I wouldn't even recommend it for coding as theres betters options. (Devstral, Qwen3-Coder-30B-A3B)\n\nMy recommendation would be; pick neither of them. If you want a model with good reasoning ability, pick Qwen-3-30B-A3B-Thinking-2507. Or if that's slightly too much system resources, Qwen 14B. If you don't mind a non-reasoning model, go with Mistral Small 3.2-Instruct-2506. Low hallucination rate, decent at coding, great for world knowledge, and same parameter count as Magistral.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7a4s2n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It depends what you&amp;#39;re doing. GPT-oss isn&amp;#39;t a &lt;em&gt;great&lt;/em&gt; model, but it&amp;#39;s not as bad as people here make it out to be. Magistral is rarely spoken of here, but honestly, it kind of sucks to work with, at least locally. Magistral is just a fine-tune of Mistral Small 3.1 and hell, even requires a system prompt to get it to reason, which leads to inconsistency when the model decides its system prompt is no longer relevant. (It&amp;#39;s hard to &lt;em&gt;keep&lt;/em&gt; the model reasoning after 2-3 prompts.) Magistral also reasons far longer and tends to draft its entire response every time, which is kind of annoying. GPT-oss doesn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;Although, Magistral has the upper hand on GPT-oss by far in terms of world knowledge, and a much lower hallucination rate. If your task in any way relies on world knowledge, choose Magistral. GPT-oss would be better suited for pure reasoning tasks, like maths or other difficult problem solving. But I wouldn&amp;#39;t even recommend it for coding as theres betters options. (Devstral, Qwen3-Coder-30B-A3B)&lt;/p&gt;\n\n&lt;p&gt;My recommendation would be; pick neither of them. If you want a model with good reasoning ability, pick Qwen-3-30B-A3B-Thinking-2507. Or if that&amp;#39;s slightly too much system resources, Qwen 14B. If you don&amp;#39;t mind a non-reasoning model, go with Mistral Small 3.2-Instruct-2506. Low hallucination rate, decent at coding, great for world knowledge, and same parameter count as Magistral.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n7a4s2n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754506353,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj9690",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n79ey47",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Aldarund",
                      "can_mod_post": false,
                      "created_utc": 1754499178,
                      "send_replies": true,
                      "parent_id": "t1_n79amde",
                      "score": 2,
                      "author_fullname": "t2_bu5xy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Gpt frequently goes into loop.too ( at least 120b version )",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n79ey47",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Gpt frequently goes into loop.too ( at least 120b version )&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj9690",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n79ey47/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754499178,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7a7qbx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Daniokenon",
                      "can_mod_post": false,
                      "created_utc": 1754507193,
                      "send_replies": true,
                      "parent_id": "t1_n79amde",
                      "score": 1,
                      "author_fullname": "t2_ugryjft4e",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Magistral (others too)I have found that Repetition Penalty 1.1 with Rep Pen Range 64 helps a lot with this and improves the quality of reasoning overall.\n\n  \nI also noticed that it's worth starting your own reasoning. For example, &lt;think&gt; Okay, before I answer, let me first analyze the last answer.\n\nYou can direct the model to what you need - this saves me time and in my opinion the results are better.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7a7qbx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Magistral (others too)I have found that Repetition Penalty 1.1 with Rep Pen Range 64 helps a lot with this and improves the quality of reasoning overall.&lt;/p&gt;\n\n&lt;p&gt;I also noticed that it&amp;#39;s worth starting your own reasoning. For example, &amp;lt;think&amp;gt; Okay, before I answer, let me first analyze the last answer.&lt;/p&gt;\n\n&lt;p&gt;You can direct the model to what you need - this saves me time and in my opinion the results are better.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj9690",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n7a7qbx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754507193,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n79ep60",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "No_Efficiency_1144",
                      "can_mod_post": false,
                      "created_utc": 1754499110,
                      "send_replies": true,
                      "parent_id": "t1_n79amde",
                      "score": -5,
                      "author_fullname": "t2_1nkj9l14b0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "OSS is censored for sure but I would expect it to be less benchmaxxed",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n79ep60",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OSS is censored for sure but I would expect it to be less benchmaxxed&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mj9690",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n79ep60/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754499110,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n79amde",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "kiselsa",
            "can_mod_post": false,
            "created_utc": 1754497958,
            "send_replies": true,
            "parent_id": "t3_1mj9690",
            "score": 5,
            "author_fullname": "t2_7vw78tdp",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "They both are bad.  \nGpt is benchmaxxxed, censored and fried.\n\nMagistral doesn't have brain damage like GPT, but it frequently goes into loops or its thinking isnt aligned with answers (no hate for mistral, only love, they are nice guys especially compared to evil that closedai is, but this model is just not very successful, so waiting for mistral to drop better models).\n\nQwen3 thikning models (especially new ones) are much better.",
            "edited": 1754498775,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n79amde",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They both are bad.&lt;br/&gt;\nGpt is benchmaxxxed, censored and fried.&lt;/p&gt;\n\n&lt;p&gt;Magistral doesn&amp;#39;t have brain damage like GPT, but it frequently goes into loops or its thinking isnt aligned with answers (no hate for mistral, only love, they are nice guys especially compared to evil that closedai is, but this model is just not very successful, so waiting for mistral to drop better models).&lt;/p&gt;\n\n&lt;p&gt;Qwen3 thikning models (especially new ones) are much better.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n79amde/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754497958,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj9690",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n79plyb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "entsnack",
            "can_mod_post": false,
            "created_utc": 1754502081,
            "send_replies": true,
            "parent_id": "t3_1mj9690",
            "score": 4,
            "author_fullname": "t2_1a48h7vf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "gpt-oss-20b by far, just look at the benchmarks and try them both. gpt-oss-20b is *blazing* fast, performance exceeds Kimi K2 and DeepSeek-r1 on some benchmarks (community-provided ones like SVGBench and FamilyBench, not ones that models typically benchmaxxx on).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n79plyb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "a": ":X:",
                "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                "e": "emoji"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;gpt-oss-20b by far, just look at the benchmarks and try them both. gpt-oss-20b is &lt;em&gt;blazing&lt;/em&gt; fast, performance exceeds Kimi K2 and DeepSeek-r1 on some benchmarks (community-provided ones like SVGBench and FamilyBench, not ones that models typically benchmaxxx on).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "dark",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n79plyb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754502081,
            "author_flair_text": ":X:",
            "treatment_tags": [],
            "link_id": "t3_1mj9690",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": "transparent",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n799i95",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Voxandr",
            "can_mod_post": false,
            "created_utc": 1754497640,
            "send_replies": true,
            "parent_id": "t3_1mj9690",
            "score": 1,
            "author_fullname": "t2_86dk0gye",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "We need to find out.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n799i95",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We need to find out.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n799i95/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754497640,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj9690",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7aiuds",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "robertotomas",
            "can_mod_post": false,
            "created_utc": 1754510371,
            "send_replies": true,
            "parent_id": "t3_1mj9690",
            "score": 1,
            "author_fullname": "t2_65zz9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "honestly my go to for agentic use more often then not is Gemma 3 (27b if needed, I've got 48GB, so sadly the 120b model is out of reach). I am not as impressed as I have seen others be about the recent batch (or even previous batch) of mistral local models. I tend to use Qwen 3 if the reasoning is the issue for Gemma, but find it flakey below 32b",
            "edited": 1754510583,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7aiuds",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;honestly my go to for agentic use more often then not is Gemma 3 (27b if needed, I&amp;#39;ve got 48GB, so sadly the 120b model is out of reach). I am not as impressed as I have seen others be about the recent batch (or even previous batch) of mistral local models. I tend to use Qwen 3 if the reasoning is the issue for Gemma, but find it flakey below 32b&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n7aiuds/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754510371,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj9690",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7befls",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "TSG-AYAN",
            "can_mod_post": false,
            "created_utc": 1754519747,
            "send_replies": true,
            "parent_id": "t3_1mj9690",
            "score": 1,
            "author_fullname": "t2_5ml0rsi7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "gpt oss is pretty bad, and you will feel like its working against you sometimes. but it's smarter, at least for maths and multi-turn chat. magistral's thinking feels more like a hack on instead of being integrated. Qwen is much, much better though.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7befls",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;gpt oss is pretty bad, and you will feel like its working against you sometimes. but it&amp;#39;s smarter, at least for maths and multi-turn chat. magistral&amp;#39;s thinking feels more like a hack on instead of being integrated. Qwen is much, much better though.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n7befls/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754519747,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mj9690",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7bm2ye",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "cristoper",
            "can_mod_post": false,
            "created_utc": 1754522288,
            "send_replies": true,
            "parent_id": "t3_1mj9690",
            "score": 1,
            "author_fullname": "t2_38xkk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think you'd really need to compile a few sample inputs for the tasks you have in mind and run them through both in order to find out which is better for your use cases.\n\nAnother model in the same class you could consider is qwen3-30b-a3b-thinking-2507 (and there are similar non-thinking models like gemma3-27b and qwen3-30b-a3b-instruct)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7bm2ye",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think you&amp;#39;d really need to compile a few sample inputs for the tasks you have in mind and run them through both in order to find out which is better for your use cases.&lt;/p&gt;\n\n&lt;p&gt;Another model in the same class you could consider is qwen3-30b-a3b-thinking-2507 (and there are similar non-thinking models like gemma3-27b and qwen3-30b-a3b-instruct)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n7bm2ye/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754522288,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj9690",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n799qz2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "sleepingsysadmin",
            "can_mod_post": false,
            "created_utc": 1754497709,
            "send_replies": true,
            "parent_id": "t3_1mj9690",
            "score": 1,
            "author_fullname": "t2_x73h4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "On benchmarks, which i agree with are legit.\n\n20b scores a 54 and Magistral small scores a 38. So fairly noticable difference. \n\nBut for me, I cant seem to find a good agentic tool that handles GPT 20b which is rather disqualifying.\n\nIn other news, roo code is the first tool that uses qwen3 coder 30b well.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n799qz2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;On benchmarks, which i agree with are legit.&lt;/p&gt;\n\n&lt;p&gt;20b scores a 54 and Magistral small scores a 38. So fairly noticable difference. &lt;/p&gt;\n\n&lt;p&gt;But for me, I cant seem to find a good agentic tool that handles GPT 20b which is rather disqualifying.&lt;/p&gt;\n\n&lt;p&gt;In other news, roo code is the first tool that uses qwen3 coder 30b well.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mj9690/gptoss20b_vs_magistral24b/n799qz2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754497709,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mj9690",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]