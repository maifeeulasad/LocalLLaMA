[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "so‚Ä¶ i've been building local RAG pipelines (ollama + pdfs + scanned docs + markdowns)Ôºå  \nand ocr is always that one piece that looks fine‚Ä¶ until it totally isn‚Äôt.\n\nlike:\n\n* retrieves wrong paragraph even though the chunk ‚Äúlooks right‚Äù\n* breaks sentence mid-way due to invisible newline\n* embeds headers or disclaimers that kill reasoning\n* or fails on first-call because vector store wasn't ready\n\neventually, i mapped out **16 common failure modes** across chunking, retrieval, ocr, and LLM reasoning.  \nand yeah, i gave up trying to fix them piecemeal ‚Äî so i just patched the whole pipeline.\n\n**üõ†Ô∏è it's all MIT licensed, no retraining, plug &amp; play with full diagnosis for each problem.**\n\neven got a ‚≠ê from the guy who made `tesseract.js`:  \n[https://github.com/bijection?tab=stars](https://github.com/bijection?tab=stars) ÔºàWFGY on topÔºâ\n\nüîí **i won‚Äôt drop the repo unless someone asks** , not being cryptic, just trying to respect the signal/noise balance here.\n\nif you‚Äôre dealing with these headaches, i‚Äôll gladly share the full fix stack + problem map.\n\ndon‚Äôt suffer alone. i already did.  \n(i'm also the creator of `wfgy_engine`, same as my reddit ID.)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "has anyone actually gotten RAG + OCR to work locally without silent bugs?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1memwlm",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.2,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1tgp8l87vk",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1754026027,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754021971,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so‚Ä¶ i&amp;#39;ve been building local RAG pipelines (ollama + pdfs + scanned docs + markdowns)Ôºå&lt;br/&gt;\nand ocr is always that one piece that looks fine‚Ä¶ until it totally isn‚Äôt.&lt;/p&gt;\n\n&lt;p&gt;like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;retrieves wrong paragraph even though the chunk ‚Äúlooks right‚Äù&lt;/li&gt;\n&lt;li&gt;breaks sentence mid-way due to invisible newline&lt;/li&gt;\n&lt;li&gt;embeds headers or disclaimers that kill reasoning&lt;/li&gt;\n&lt;li&gt;or fails on first-call because vector store wasn&amp;#39;t ready&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;eventually, i mapped out &lt;strong&gt;16 common failure modes&lt;/strong&gt; across chunking, retrieval, ocr, and LLM reasoning.&lt;br/&gt;\nand yeah, i gave up trying to fix them piecemeal ‚Äî so i just patched the whole pipeline.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;üõ†Ô∏è it&amp;#39;s all MIT licensed, no retraining, plug &amp;amp; play with full diagnosis for each problem.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;even got a ‚≠ê from the guy who made &lt;code&gt;tesseract.js&lt;/code&gt;:&lt;br/&gt;\n&lt;a href=\"https://github.com/bijection?tab=stars\"&gt;https://github.com/bijection?tab=stars&lt;/a&gt; ÔºàWFGY on topÔºâ&lt;/p&gt;\n\n&lt;p&gt;üîí &lt;strong&gt;i won‚Äôt drop the repo unless someone asks&lt;/strong&gt; , not being cryptic, just trying to respect the signal/noise balance here.&lt;/p&gt;\n\n&lt;p&gt;if you‚Äôre dealing with these headaches, i‚Äôll gladly share the full fix stack + problem map.&lt;/p&gt;\n\n&lt;p&gt;don‚Äôt suffer alone. i already did.&lt;br/&gt;\n(i&amp;#39;m also the creator of &lt;code&gt;wfgy_engine&lt;/code&gt;, same as my reddit ID.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1memwlm",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "wfgy_engine",
            "discussion_type": null,
            "num_comments": 13,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/",
            "subreddit_subscribers": 508191,
            "created_utc": 1754021971,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6atcuw",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "wfgy_engine",
                      "can_mod_post": false,
                      "created_utc": 1754025989,
                      "send_replies": true,
                      "parent_id": "t1_n6ap6az",
                      "score": 1,
                      "author_fullname": "t2_1tgp8l87vk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "haha fair point \n\nthe post does kick off with OCR, but yeah the bugs listed are more about what happens after OCR silently passes junk into the pipeline.\n\nhonestly i just needed a relatable entry point. OCR is the one thing that looks fine until it totally isn't.\n\nas for the emoji... guilty as charged......",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6atcuw",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;haha fair point &lt;/p&gt;\n\n&lt;p&gt;the post does kick off with OCR, but yeah the bugs listed are more about what happens after OCR silently passes junk into the pipeline.&lt;/p&gt;\n\n&lt;p&gt;honestly i just needed a relatable entry point. OCR is the one thing that looks fine until it totally isn&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;as for the emoji... guilty as charged......&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1memwlm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6atcuw/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754025989,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6ap6az",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "HistorianPotential48",
            "can_mod_post": false,
            "created_utc": 1754023964,
            "send_replies": true,
            "parent_id": "t3_1memwlm",
            "score": 3,
            "author_fullname": "t2_4dzthia7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "```\n...and ocr is always that one piece that looks fine‚Ä¶ until it totally isn‚Äôt.\nlike:\n    * retrieves wrong paragraph even though the chunk ‚Äúlooks right‚Äù\n    * breaks sentence mid-way due to invisible newline\n    * embeds headers or disclaimers that kill reasoning\n    * or fails on first-call because vector store wasn't ready\n```\n\ni like how 3 out of 4 examples ain't got nothing to do with ocr, and the usage of ‚Äî‚Äî and emojis in the totally human post",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ap6az",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;code&gt;\n...and ocr is always that one piece that looks fine‚Ä¶ until it totally isn‚Äôt.\nlike:\n    * retrieves wrong paragraph even though the chunk ‚Äúlooks right‚Äù\n    * breaks sentence mid-way due to invisible newline\n    * embeds headers or disclaimers that kill reasoning\n    * or fails on first-call because vector store wasn&amp;#39;t ready\n&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;i like how 3 out of 4 examples ain&amp;#39;t got nothing to do with ocr, and the usage of ‚Äî‚Äî and emojis in the totally human post&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6ap6az/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754023964,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1memwlm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6asn9y",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "wfgy_engine",
                      "can_mod_post": false,
                      "created_utc": 1754025637,
                      "send_replies": true,
                      "parent_id": "t1_n6an60e",
                      "score": 1,
                      "author_fullname": "t2_1tgp8l87vk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "yep, that‚Äôs one way to cope   \n  \ni tried that too... then realized the default settings were just the beginning of the pain.  \n  \nlike, page headers pretending to be body text? invisible breaks mid-sentence? hallucinated table ends?\n\ni gave up fixing piece by piece.  \njust‚Ä¶ nuked the pipeline &amp; built a new one.\n\nbut hey, if you're surviving with duct tape and hope ‚Äî you‚Äôre stronger than me ü´°",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6asn9y",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yep, that‚Äôs one way to cope   &lt;/p&gt;\n\n&lt;p&gt;i tried that too... then realized the default settings were just the beginning of the pain.  &lt;/p&gt;\n\n&lt;p&gt;like, page headers pretending to be body text? invisible breaks mid-sentence? hallucinated table ends?&lt;/p&gt;\n\n&lt;p&gt;i gave up fixing piece by piece.&lt;br/&gt;\njust‚Ä¶ nuked the pipeline &amp;amp; built a new one.&lt;/p&gt;\n\n&lt;p&gt;but hey, if you&amp;#39;re surviving with duct tape and hope ‚Äî you‚Äôre stronger than me ü´°&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1memwlm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6asn9y/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754025637,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6an60e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ExcuseAccomplished97",
            "can_mod_post": false,
            "created_utc": 1754023015,
            "send_replies": true,
            "parent_id": "t3_1memwlm",
            "score": 2,
            "author_fullname": "t2_73xg2fw4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "One possible solution is to reconstruct the text processed by the OCR. I found that Tesseract is often inconsistent with the default settings.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6an60e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;One possible solution is to reconstruct the text processed by the OCR. I found that Tesseract is often inconsistent with the default settings.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6an60e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754023015,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1memwlm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6auenr",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "wfgy_engine",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6atwf4",
                                          "score": 2,
                                          "author_fullname": "t2_1tgp8l87vk",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "yeah i feel that  i was stuck fiddling with --psm too, especially when layout heuristics made the model switch formats halfway through a doc.\n\nturns out a lot of what breaks isn‚Äôt the OCR per se, but the invisible shifts in logic when layout anchors drift across pages. like page 3 suddenly behaving like a table header from page 5.\n\nended up building a rule-based logic layer to detect and patch those. no need to guess psm anymore , the system just flags semantic discontinuities and injects fixes inline before the vector step.        if you‚Äôre interested, i mapped all 16+ of those layout collapse patterns and hard-coded patch logic for each. kinda overkill, but it finally stopped the silent fails.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6auenr",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yeah i feel that  i was stuck fiddling with --psm too, especially when layout heuristics made the model switch formats halfway through a doc.&lt;/p&gt;\n\n&lt;p&gt;turns out a lot of what breaks isn‚Äôt the OCR per se, but the invisible shifts in logic when layout anchors drift across pages. like page 3 suddenly behaving like a table header from page 5.&lt;/p&gt;\n\n&lt;p&gt;ended up building a rule-based logic layer to detect and patch those. no need to guess psm anymore , the system just flags semantic discontinuities and injects fixes inline before the vector step.        if you‚Äôre interested, i mapped all 16+ of those layout collapse patterns and hard-coded patch logic for each. kinda overkill, but it finally stopped the silent fails.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1memwlm",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6auenr/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754026515,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754026515,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6atwf4",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ttkciar",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6asx2g",
                                "score": 2,
                                "author_fullname": "t2_cpegz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "&gt; oh nice\n\nThanks :-)\n\n&gt; curious though !! how consistent is your setup when switching between languages or page formats?\n\nI have not used it for languages other than English, so cannot speak to that.\n\nFor page layouts, tesseract mostly does a good job of figuring it out (and the higher resolution PNG helps), but sometimes I have had to fiddle with the `--psm` parameter to coerce it into a different layout segmentation approach.\n\nRight now that is manual, but it should be possible in theory to detect inappropriate layout segmentation and use heuristics (or maybe LLM inference?) to guess at the better `--psm` option.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6atwf4",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;oh nice&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Thanks :-)&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;curious though !! how consistent is your setup when switching between languages or page formats?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I have not used it for languages other than English, so cannot speak to that.&lt;/p&gt;\n\n&lt;p&gt;For page layouts, tesseract mostly does a good job of figuring it out (and the higher resolution PNG helps), but sometimes I have had to fiddle with the &lt;code&gt;--psm&lt;/code&gt; parameter to coerce it into a different layout segmentation approach.&lt;/p&gt;\n\n&lt;p&gt;Right now that is manual, but it should be possible in theory to detect inappropriate layout segmentation and use heuristics (or maybe LLM inference?) to guess at the better &lt;code&gt;--psm&lt;/code&gt; option.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1memwlm",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6atwf4/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754026262,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754026262,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6asx2g",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "wfgy_engine",
                      "can_mod_post": false,
                      "created_utc": 1754025771,
                      "send_replies": true,
                      "parent_id": "t1_n6anuv5",
                      "score": 1,
                      "author_fullname": "t2_1tgp8l87vk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "oh nice   \nyou're one of the few people here who actually brute-forced the whole OCR hell with your own pipeline.\n\ni like that you're not relying on vision models   \n  \nfeels like everyone's forgotten how powerful plain preprocessing can be.\n\ni tried something similar back when i hit invisible newline bugs and floating headers. ended up mapping the logic failures more than the OCR glitches.\n\ncurious though !! how consistent is your setup when switching between languages or page formats?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6asx2g",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;oh nice&lt;br/&gt;\nyou&amp;#39;re one of the few people here who actually brute-forced the whole OCR hell with your own pipeline.&lt;/p&gt;\n\n&lt;p&gt;i like that you&amp;#39;re not relying on vision models   &lt;/p&gt;\n\n&lt;p&gt;feels like everyone&amp;#39;s forgotten how powerful plain preprocessing can be.&lt;/p&gt;\n\n&lt;p&gt;i tried something similar back when i hit invisible newline bugs and floating headers. ended up mapping the logic failures more than the OCR glitches.&lt;/p&gt;\n\n&lt;p&gt;curious though !! how consistent is your setup when switching between languages or page formats?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1memwlm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6asx2g/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754025771,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6anuv5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ttkciar",
            "can_mod_post": false,
            "created_utc": 1754023336,
            "send_replies": true,
            "parent_id": "t3_1memwlm",
            "score": 2,
            "author_fullname": "t2_cpegz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "FWIW, I'm not downvoting you.\n\nMy solution to OCR has been to use GOFAI solutions -- in my case pdftopng + tesseract.  Given a sufficiently high-resolution black-and-white PNG (my go-to is `-r 900`), tesseract does a damn fine job, better than any vision model I've tried.\n\nOnce I have text from tesseract, I can infer from it directly with text-to-text model, or preprocess it first by asking Gemma3-27B or Tulu3-70B to improve/edit the text and then infer on it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6anuv5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;FWIW, I&amp;#39;m not downvoting you.&lt;/p&gt;\n\n&lt;p&gt;My solution to OCR has been to use GOFAI solutions -- in my case pdftopng + tesseract.  Given a sufficiently high-resolution black-and-white PNG (my go-to is &lt;code&gt;-r 900&lt;/code&gt;), tesseract does a damn fine job, better than any vision model I&amp;#39;ve tried.&lt;/p&gt;\n\n&lt;p&gt;Once I have text from tesseract, I can infer from it directly with text-to-text model, or preprocess it first by asking Gemma3-27B or Tulu3-70B to improve/edit the text and then infer on it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6anuv5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754023336,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1memwlm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6as69m",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1754025401,
            "send_replies": true,
            "parent_id": "t3_1memwlm",
            "score": 2,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don‚Äôt really use rag. In the system I built it extracts text from PDFs, PowerPoint, csv, doc, etc. but not any charts or images within the files.\n\nIf you also need to extract data from graphs you could add to your script a screenshot mechanism and special tokens in the embeddings ex: &lt;image&gt; Name_of_screenshot.JPEG&lt;/image&gt; then have your script parse this from the response and append the image to be sent in the json payload.\n\nIf you‚Äôre still having issues, most AI models cannot have an infinite number of images per conversation and images fill up context window faster than text. Set it to 1 image per conversation or one rag request per conversation, so each follow up request is handled as a new conversation.\n\nAlso in your description, it sounds like you are searching the files before extracting the data and putting it into a vector database. The workflow should be extract data to vector database then query the DB with embedding model. The response is fed to the AI and does all of the thinking.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6as69m",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don‚Äôt really use rag. In the system I built it extracts text from PDFs, PowerPoint, csv, doc, etc. but not any charts or images within the files.&lt;/p&gt;\n\n&lt;p&gt;If you also need to extract data from graphs you could add to your script a screenshot mechanism and special tokens in the embeddings ex: &amp;lt;image&amp;gt; Name_of_screenshot.JPEG&amp;lt;/image&amp;gt; then have your script parse this from the response and append the image to be sent in the json payload.&lt;/p&gt;\n\n&lt;p&gt;If you‚Äôre still having issues, most AI models cannot have an infinite number of images per conversation and images fill up context window faster than text. Set it to 1 image per conversation or one rag request per conversation, so each follow up request is handled as a new conversation.&lt;/p&gt;\n\n&lt;p&gt;Also in your description, it sounds like you are searching the files before extracting the data and putting it into a vector database. The workflow should be extract data to vector database then query the DB with embedding model. The response is fed to the AI and does all of the thinking.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6as69m/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754025401,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1memwlm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "fe89e94a-13f2-11f0-a9de-6262c74956cf",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "fe89e94a-13f2-11f0-a9de-6262c74956cf",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6azh9v",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Asleep-Ratio7535",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6aw1ta",
                                "score": 2,
                                "author_fullname": "t2_1lfyddwf0c",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Ah, sorry I just checked your title and thought you had this common problem. Thanks for your insight.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6azh9v",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "Llama 4"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah, sorry I just checked your title and thought you had this common problem. Thanks for your insight.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1memwlm",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6azh9v/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754029149,
                                "author_flair_text": "Llama 4",
                                "treatment_tags": [],
                                "created_utc": 1754029149,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#b0ae9b",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6aw1ta",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "wfgy_engine",
                      "can_mod_post": false,
                      "created_utc": 1754027353,
                      "send_replies": true,
                      "parent_id": "t1_n6av150",
                      "score": 1,
                      "author_fullname": "t2_1tgp8l87vk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "yeah that‚Äôs a good instinct, but the silent failure i was referring to isn‚Äôt from OCR accuracy , it‚Äôs from semantic drift that happens *after* OCR, during vector ingestion or chunking logic.\n\nlike:\n\n* you do OCR correctly\n* the chunk looks perfect\n* but something like a missing header, or hidden newline, breaks the reasoning path\n\nand unless you track every transformation step, the model still answers \\~ just wrongly, and confidently.\n\ni‚Äôve seen a lot of people try to \"pre-check\" their OCR separately, but even then, their RAG output fails due to cross-step boundary issues.\n\nif you‚Äôve run into that kind of thing too, you‚Äôre definitely not alone",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6aw1ta",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yeah that‚Äôs a good instinct, but the silent failure i was referring to isn‚Äôt from OCR accuracy , it‚Äôs from semantic drift that happens &lt;em&gt;after&lt;/em&gt; OCR, during vector ingestion or chunking logic.&lt;/p&gt;\n\n&lt;p&gt;like:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;you do OCR correctly&lt;/li&gt;\n&lt;li&gt;the chunk looks perfect&lt;/li&gt;\n&lt;li&gt;but something like a missing header, or hidden newline, breaks the reasoning path&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;and unless you track every transformation step, the model still answers ~ just wrongly, and confidently.&lt;/p&gt;\n\n&lt;p&gt;i‚Äôve seen a lot of people try to &amp;quot;pre-check&amp;quot; their OCR separately, but even then, their RAG output fails due to cross-step boundary issues.&lt;/p&gt;\n\n&lt;p&gt;if you‚Äôve run into that kind of thing too, you‚Äôre definitely not alone&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1memwlm",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6aw1ta/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754027353,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6av150",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Asleep-Ratio7535",
            "can_mod_post": false,
            "created_utc": 1754026833,
            "send_replies": true,
            "parent_id": "t3_1memwlm",
            "score": 2,
            "author_fullname": "t2_1lfyddwf0c",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Why don't you separate OCR from your pipeline? You can chunk it after anyway. It costs similar times but you can check the quality and optimize it first.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6av150",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Llama 4"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why don&amp;#39;t you separate OCR from your pipeline? You can chunk it after anyway. It costs similar times but you can check the quality and optimize it first.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6av150/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754026833,
            "author_flair_text": "Llama 4",
            "treatment_tags": [],
            "link_id": "t3_1memwlm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#b0ae9b",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6b40ze",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Ok_Doughnut5075",
            "can_mod_post": false,
            "created_utc": 1754031626,
            "send_replies": true,
            "parent_id": "t3_1memwlm",
            "score": 1,
            "author_fullname": "t2_1gyxgr8g2t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "https://www.youtube.com/watch?v=anwy2MPT5RE",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6b40ze",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=anwy2MPT5RE\"&gt;https://www.youtube.com/watch?v=anwy2MPT5RE&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1memwlm/has_anyone_actually_gotten_rag_ocr_to_work/n6b40ze/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754031626,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1memwlm",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]