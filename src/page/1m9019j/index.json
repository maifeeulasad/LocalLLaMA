[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi all, \n\n\n\nI'm a solo dev and first-time open-source maintainer. I just released my first Python package: \\*\\*Arkhon Memory SDK\\*\\* – a lightweight, local-first memory module for autonomous LLM agents. This is part of my bigger project, but I thought this component could be useful for some of you.\n\n\\- **No vector DBs, no cloud, no LangChain**: clean, JSON-native memory with time decay, tagging, and session lifecycle hooks.\n\n\\- It’s fully pip installable: \\`pip install arkhon-memory\\`\n\n\\- Works with Python 3.8+ and pydantic 2.x.\n\n  \nYou can find it in:\n\n🔗 GitHub: [https://github.com/kissg96/arkhon\\_memory](https://github.com/kissg96/arkhon_memory)  \n\n🔗 PyPI: [https://pypi.org/project/arkhon-memory/](https://pypi.org/project/arkhon-memory/)\n\n\n\nIf you’re building LLM workflows, want persistence for agents, or just want a memory layer that \\*\\*never leaves your local machine\\*\\*, I’d love for you to try it.\n\n\n\nWould really appreciate feedback, stars, or suggestions!  \n\nFeel free to open issues or email me: [kissg@me.com](mailto:kissg@me.com)\n\n\n\nThanks for reading,  \n\nkissg96\n\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "[Release] Arkhon Memory SDK – Local, lightweight long-term memory for LLM agents (pip install arkhon-memory)",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m9019j",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.86,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 10,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_47eqehtw",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 10,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753452243,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a solo dev and first-time open-source maintainer. I just released my first Python package: **Arkhon Memory SDK** – a lightweight, local-first memory module for autonomous LLM agents. This is part of my bigger project, but I thought this component could be useful for some of you.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;No vector DBs, no cloud, no LangChain&lt;/strong&gt;: clean, JSON-native memory with time decay, tagging, and session lifecycle hooks.&lt;/p&gt;\n\n&lt;p&gt;- It’s fully pip installable: `pip install arkhon-memory`&lt;/p&gt;\n\n&lt;p&gt;- Works with Python 3.8+ and pydantic 2.x.&lt;/p&gt;\n\n&lt;p&gt;You can find it in:&lt;/p&gt;\n\n&lt;p&gt;🔗 GitHub: &lt;a href=\"https://github.com/kissg96/arkhon_memory\"&gt;https://github.com/kissg96/arkhon_memory&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;🔗 PyPI: &lt;a href=\"https://pypi.org/project/arkhon-memory/\"&gt;https://pypi.org/project/arkhon-memory/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you’re building LLM workflows, want persistence for agents, or just want a memory layer that **never leaves your local machine**, I’d love for you to try it.&lt;/p&gt;\n\n&lt;p&gt;Would really appreciate feedback, stars, or suggestions!  &lt;/p&gt;\n\n&lt;p&gt;Feel free to open issues or email me: [&lt;a href=\"mailto:kissg@me.com\"&gt;kissg@me.com&lt;/a&gt;](mailto:&lt;a href=\"mailto:kissg@me.com\"&gt;kissg@me.com&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading,  &lt;/p&gt;\n\n&lt;p&gt;kissg96&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/YGnv7M3dsPp97Dq77LwXuer94UoHKkGm7B7JRQJXITI.png?auto=webp&amp;s=3d6dbe3ba64c55f4a5b820d7b93c67e5e863a7c1",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/YGnv7M3dsPp97Dq77LwXuer94UoHKkGm7B7JRQJXITI.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7a209445a0ca39ec32cc43c3974f0c86515e04f3",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/YGnv7M3dsPp97Dq77LwXuer94UoHKkGm7B7JRQJXITI.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9bb430093762e9015e857ef6b4fe920adf08bdd4",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/YGnv7M3dsPp97Dq77LwXuer94UoHKkGm7B7JRQJXITI.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=48db854452639ae78e9c6f0926847bc1b64d167d",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/YGnv7M3dsPp97Dq77LwXuer94UoHKkGm7B7JRQJXITI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ecdd2622f584e6329d2bea611d6c3fe12d38f1b8",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/YGnv7M3dsPp97Dq77LwXuer94UoHKkGm7B7JRQJXITI.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8b13d3181d5a2ca5fed4e99539ad3d340ef806d8",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/YGnv7M3dsPp97Dq77LwXuer94UoHKkGm7B7JRQJXITI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b70f7aefa32c79066655cbc1eac72b62818bf406",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "YGnv7M3dsPp97Dq77LwXuer94UoHKkGm7B7JRQJXITI"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1m9019j",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "kissgeri96",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m9019j/release_arkhon_memory_sdk_local_lightweight/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m9019j/release_arkhon_memory_sdk_local_lightweight/",
            "subreddit_subscribers": 504487,
            "created_utc": 1753452243,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n55vxtf",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "kissgeri96",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n55txzv",
                                          "score": 1,
                                          "author_fullname": "t2_47eqehtw",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Wow, one of my first wins was getting Mixtral to recall a memory from a previous chat session—having real, local persistence felt like magic after all the “stateless” local llm chats I tried.\n\nI haven’t tried SQLite for vectors, but i think you could use it as a backend for embeddings if you want to keep things local.\n\nIf you do end up wiring it in or discover any pain points, please open an issue or just let me know what worked. Would love to see what you build!",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n55vxtf",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wow, one of my first wins was getting Mixtral to recall a memory from a previous chat session—having real, local persistence felt like magic after all the “stateless” local llm chats I tried.&lt;/p&gt;\n\n&lt;p&gt;I haven’t tried SQLite for vectors, but i think you could use it as a backend for embeddings if you want to keep things local.&lt;/p&gt;\n\n&lt;p&gt;If you do end up wiring it in or discover any pain points, please open an issue or just let me know what worked. Would love to see what you build!&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m9019j",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m9019j/release_arkhon_memory_sdk_local_lightweight/n55vxtf/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753480087,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753480087,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n55txzv",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Environmental-Metal9",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n55n6dj",
                                "score": 2,
                                "author_fullname": "t2_6x9o42az",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Right now, nothing much, but I tinkered a lot with SillyTavern’s memory plugin, and built a crude chat ui with various types of memories, but I never tackled persistence per se. I’m thinking about tacking chat memory but with persistence this time. I was thinking about using SQLite for vector db for the embeddings, so knowing I could plug that in makes this pretty cool!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n55txzv",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Right now, nothing much, but I tinkered a lot with SillyTavern’s memory plugin, and built a crude chat ui with various types of memories, but I never tackled persistence per se. I’m thinking about tacking chat memory but with persistence this time. I was thinking about using SQLite for vector db for the embeddings, so knowing I could plug that in makes this pretty cool!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9019j",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9019j/release_arkhon_memory_sdk_local_lightweight/n55txzv/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753479467,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753479467,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n55n6dj",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "kissgeri96",
                      "can_mod_post": false,
                      "created_utc": 1753477387,
                      "send_replies": true,
                      "parent_id": "t1_n558sz0",
                      "score": 1,
                      "author_fullname": "t2_47eqehtw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Great question! Right now in the SDK you do classic keyword/tag search and use relevance score (with time decay and reuse counts) - so recent or more frequently surfaced memories rank higher. \n\nFor similarity search you could wire in an embedding model and FAISS (which is how i use this in my own system for more advanced retrieval). The public SDK is intentionally kept light, but the architecture is ready for plug-and-play vector backends if you want to build on it.\n\nIf you’re interested in how to extend with vector search, I can share some general ideas or point you to open tools that could be used.\n\nThanks for asking, and let me know what you’re building!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n55n6dj",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great question! Right now in the SDK you do classic keyword/tag search and use relevance score (with time decay and reuse counts) - so recent or more frequently surfaced memories rank higher. &lt;/p&gt;\n\n&lt;p&gt;For similarity search you could wire in an embedding model and FAISS (which is how i use this in my own system for more advanced retrieval). The public SDK is intentionally kept light, but the architecture is ready for plug-and-play vector backends if you want to build on it.&lt;/p&gt;\n\n&lt;p&gt;If you’re interested in how to extend with vector search, I can share some general ideas or point you to open tools that could be used.&lt;/p&gt;\n\n&lt;p&gt;Thanks for asking, and let me know what you’re building!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9019j",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9019j/release_arkhon_memory_sdk_local_lightweight/n55n6dj/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753477387,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n558sz0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Environmental-Metal9",
            "can_mod_post": false,
            "created_utc": 1753473195,
            "send_replies": true,
            "parent_id": "t3_1m9019j",
            "score": 2,
            "author_fullname": "t2_6x9o42az",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Before I go dive in the code, do you have a similarity search, or cosine search way of finding relevant memories, or how are you solving for accurate retrieval?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n558sz0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Before I go dive in the code, do you have a similarity search, or cosine search way of finding relevant memories, or how are you solving for accurate retrieval?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9019j/release_arkhon_memory_sdk_local_lightweight/n558sz0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753473195,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9019j",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]