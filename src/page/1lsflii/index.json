[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I’m doing self-funded AI research and recently got access to 2× NVIDIA A100 SXM4 GPUs. I want to build a quiet, stable node at home to run local models and training workloads — no cloud.\n\nHas anyone here actually built a DIY system with A100 SXM4s (not PCIe)? If so:\n What HGX carrier board or server chassis did you use?\n How did you handle power + cooling safely at home?\n Any tips on finding used baseboards or reference systems?\n\nI’m not working for any company — just serious about doing advanced AI work locally and learning by building. Happy to share progress once it’s working.\n\nThanks in advance — would love any help or photos from others doing the same.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Anyone built a home 2× A100 SXM4 node?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1lsflii",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.83,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 8,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_rysc7jpo",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 8,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1751737534,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m doing self-funded AI research and recently got access to 2× NVIDIA A100 SXM4 GPUs. I want to build a quiet, stable node at home to run local models and training workloads — no cloud.&lt;/p&gt;\n\n&lt;p&gt;Has anyone here actually built a DIY system with A100 SXM4s (not PCIe)? If so:\n What HGX carrier board or server chassis did you use?\n How did you handle power + cooling safely at home?\n Any tips on finding used baseboards or reference systems?&lt;/p&gt;\n\n&lt;p&gt;I’m not working for any company — just serious about doing advanced AI work locally and learning by building. Happy to share progress once it’s working.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance — would love any help or photos from others doing the same.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1lsflii",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Fun_Nefariousness228",
            "discussion_type": null,
            "num_comments": 11,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/",
            "subreddit_subscribers": 494897,
            "created_utc": 1751737534,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n1iqhl6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "a_beautiful_rhind",
            "can_mod_post": false,
            "created_utc": 1751744504,
            "send_replies": true,
            "parent_id": "t3_1lsflii",
            "score": 9,
            "author_fullname": "t2_h5utwre7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you search on here, there is someone who bought a lot of them at auction and then used SXM-&gt;PCIE adapters to use them.\n\nMight be cheaper than SXM chassis.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1iqhl6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you search on here, there is someone who bought a lot of them at auction and then used SXM-&amp;gt;PCIE adapters to use them.&lt;/p&gt;\n\n&lt;p&gt;Might be cheaper than SXM chassis.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1iqhl6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751744504,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lsflii",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1iq7wq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "aquarius-tech",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1iod12",
                                "score": 2,
                                "author_fullname": "t2_pf6j9vti8",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "My setup is quite stable, it’s silent. I decided to go for P40 since RTX are too expensive \n\nThat motherboard is fantastic, I did almost nothing in the BIOS, just checked for 4G decoding enabled and so it was \n\nNvidia driver is number 570 and tensor is 12.8\n\nI posted some benchmarks I did with ollama and models going up to 72b 5Tks/s, 30b models 25Tks/s \n\nThe only updates I did a couple of days ago were \n\nI bought another NVMe 3.8 TB and changed the Dynatron for Noctua CPU cooler",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1iq7wq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My setup is quite stable, it’s silent. I decided to go for P40 since RTX are too expensive &lt;/p&gt;\n\n&lt;p&gt;That motherboard is fantastic, I did almost nothing in the BIOS, just checked for 4G decoding enabled and so it was &lt;/p&gt;\n\n&lt;p&gt;Nvidia driver is number 570 and tensor is 12.8&lt;/p&gt;\n\n&lt;p&gt;I posted some benchmarks I did with ollama and models going up to 72b 5Tks/s, 30b models 25Tks/s &lt;/p&gt;\n\n&lt;p&gt;The only updates I did a couple of days ago were &lt;/p&gt;\n\n&lt;p&gt;I bought another NVMe 3.8 TB and changed the Dynatron for Noctua CPU cooler&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lsflii",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1iq7wq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751744414,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751744414,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1iod12",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Fun_Nefariousness228",
                      "can_mod_post": false,
                      "created_utc": 1751743785,
                      "send_replies": true,
                      "parent_id": "t1_n1in37n",
                      "score": 1,
                      "author_fullname": "t2_rysc7jpo",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Just checked out your post — that’s a really clean setup. Love how you pulled it off with the P40s and kept things quiet on a budget.\n\nI’m working on a 2× A100 SXM4 build at home right now, which has its own fun mix of power, cooling, and compatibility headaches.\n\nCurious how stable your setup’s been under full load — and whether you ran into any issues with BIOS settings or GPU tuning.\n\nAppreciate you sharing — not many folks are documenting this kind of DIY work, and it’s super helpful.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1iod12",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just checked out your post — that’s a really clean setup. Love how you pulled it off with the P40s and kept things quiet on a budget.&lt;/p&gt;\n\n&lt;p&gt;I’m working on a 2× A100 SXM4 build at home right now, which has its own fun mix of power, cooling, and compatibility headaches.&lt;/p&gt;\n\n&lt;p&gt;Curious how stable your setup’s been under full load — and whether you ran into any issues with BIOS settings or GPU tuning.&lt;/p&gt;\n\n&lt;p&gt;Appreciate you sharing — not many folks are documenting this kind of DIY work, and it’s super helpful.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lsflii",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1iod12/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751743785,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1in37n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "aquarius-tech",
            "can_mod_post": false,
            "created_utc": 1751743356,
            "send_replies": true,
            "parent_id": "t3_1lsflii",
            "score": 2,
            "author_fullname": "t2_pf6j9vti8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Not A100 but P40 take a look at my profile, I posted my setup\n\nStill performing tests and building a RAG",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1in37n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not A100 but P40 take a look at my profile, I posted my setup&lt;/p&gt;\n\n&lt;p&gt;Still performing tests and building a RAG&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1in37n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751743356,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lsflii",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n1k75br",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Fun_Nefariousness228",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1j52hy",
                                "score": 1,
                                "author_fullname": "t2_rysc7jpo",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "@Conscious_Cut_6144 agree 100% on watercooling — that eBay link could be a solid starting point if it seats well. I might look into mounting proper cold plates or adapting datacenter blocks. Appreciate the heads up.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1k75br",
                                "is_submitter": true,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;@Conscious_Cut_6144 agree 100% on watercooling — that eBay link could be a solid starting point if it seats well. I might look into mounting proper cold plates or adapting datacenter blocks. Appreciate the heads up.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lsflii",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1k75br/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751763146,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751763146,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1j52hy",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Conscious_Cut_6144",
                      "can_mod_post": false,
                      "created_utc": 1751749300,
                      "send_replies": true,
                      "parent_id": "t1_n1it4lu",
                      "score": 2,
                      "author_fullname": "t2_9hl4ymvj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "If I was running those at home I would find a way to watercool them.\n\nSomething like this could be a starting point: (wish they had real pics...)  \n[https://www.ebay.com/itm/364949248725](https://www.ebay.com/itm/364949248725)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1j52hy",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If I was running those at home I would find a way to watercool them.&lt;/p&gt;\n\n&lt;p&gt;Something like this could be a starting point: (wish they had real pics...)&lt;br/&gt;\n&lt;a href=\"https://www.ebay.com/itm/364949248725\"&gt;https://www.ebay.com/itm/364949248725&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lsflii",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1j52hy/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751749300,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n1khn4j",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "aquarius-tech",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n1k71nm",
                                          "score": 1,
                                          "author_fullname": "t2_pf6j9vti8",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Yes I did, please check this comment \n\nhttps://www.reddit.com/r/HomeServer/s/AEpoBqhzzp",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n1khn4j",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes I did, please check this comment &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/HomeServer/s/AEpoBqhzzp\"&gt;https://www.reddit.com/r/HomeServer/s/AEpoBqhzzp&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1lsflii",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1khn4j/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1751767419,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1751767419,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n1k71nm",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Fun_Nefariousness228",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n1jcixi",
                                "score": 1,
                                "author_fullname": "t2_rysc7jpo",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "@aquarius-tech that’s super helpful — I hadn’t realized Ollama could split 70B across all cards that cleanly. Did you have to tweak anything beyond systemd to get that working smoothly (e.g. model quant config or CUDA_VISIBLE_DEVICES)? Curious what made the biggest difference in stability vs speed.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n1k71nm",
                                "is_submitter": true,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;@aquarius-tech that’s super helpful — I hadn’t realized Ollama could split 70B across all cards that cleanly. Did you have to tweak anything beyond systemd to get that working smoothly (e.g. model quant config or CUDA_VISIBLE_DEVICES)? Curious what made the biggest difference in stability vs speed.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1lsflii",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1k71nm/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1751763105,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1751763105,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n1jcixi",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "aquarius-tech",
                      "can_mod_post": false,
                      "created_utc": 1751751840,
                      "send_replies": true,
                      "parent_id": "t1_n1it4lu",
                      "score": 2,
                      "author_fullname": "t2_pf6j9vti8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Ollama is capable of two things once you configure ollama systemd\n\nPreload the model evenly in the 4 graphics \n\nChoose one for thinking and answering making it very fast\n\nThat’s for 30b models MoE \n\n70b-72b models ollama uses the four graphics at the same time",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n1jcixi",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ollama is capable of two things once you configure ollama systemd&lt;/p&gt;\n\n&lt;p&gt;Preload the model evenly in the 4 graphics &lt;/p&gt;\n\n&lt;p&gt;Choose one for thinking and answering making it very fast&lt;/p&gt;\n\n&lt;p&gt;That’s for 30b models MoE &lt;/p&gt;\n\n&lt;p&gt;70b-72b models ollama uses the four graphics at the same time&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1lsflii",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1jcixi/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1751751840,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n1it4lu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Fun_Nefariousness228",
            "can_mod_post": false,
            "created_utc": 1751745385,
            "send_replies": true,
            "parent_id": "t3_1lsflii",
            "score": 2,
            "author_fullname": "t2_rysc7jpo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Thanks both of you — this is exactly the kind of insight I was hoping for.\n\n@aquarius-tech — really clean build, and those benchmarks surprised me. Curious: when you’re running something like a 30B model at 25 T/s, are you seeing all four GPUs get evenly loaded? Or does Ollama tend to prefer just one or two cards unless manually configured? Would love to hear how you got that performance dialed in — especially on older cards.\n\n@a_beautiful_rhind — I hadn’t seriously looked at SXM-to-PCIe adapters until now. Any idea if those setups actually allow full thermal dissipation and HBM2 speed, or if they tend to throttle without proper cooling from the original baseboard?\n\nStill leaning toward a proper 2× A100 SXM4 setup long term, but might test some interim paths first. Appreciate the help!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n1it4lu",
            "is_submitter": true,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks both of you — this is exactly the kind of insight I was hoping for.&lt;/p&gt;\n\n&lt;p&gt;@aquarius-tech — really clean build, and those benchmarks surprised me. Curious: when you’re running something like a 30B model at 25 T/s, are you seeing all four GPUs get evenly loaded? Or does Ollama tend to prefer just one or two cards unless manually configured? Would love to hear how you got that performance dialed in — especially on older cards.&lt;/p&gt;\n\n&lt;p&gt;@a_beautiful_rhind — I hadn’t seriously looked at SXM-to-PCIe adapters until now. Any idea if those setups actually allow full thermal dissipation and HBM2 speed, or if they tend to throttle without proper cooling from the original baseboard?&lt;/p&gt;\n\n&lt;p&gt;Still leaning toward a proper 2× A100 SXM4 setup long term, but might test some interim paths first. Appreciate the help!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1lsflii/anyone_built_a_home_2_a100_sxm4_node/n1it4lu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1751745385,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1lsflii",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]