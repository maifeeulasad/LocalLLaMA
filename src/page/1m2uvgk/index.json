[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "So I've got this computer from 2012-2015. It's just sitting around, free real estate, but in looking at what I could do with it, the general advice is to \"upgrade xyz\" in order to use it to do something, which kinda defeats the point - if I'm going to spend even $500 to upgrade this computer I might as well just put that money towards improving my more modern computers.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "What can I do with an old computer?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 78,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m2uvgk",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.56,
            "author_flair_background_color": null,
            "ups": 3,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_jkslu7in5",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 3,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/0H9YJwooDQnZBYCkDLhGUlC1Zk4l-8mrUW4lhyFy7ag.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1752819719,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve got this computer from 2012-2015. It&amp;#39;s just sitting around, free real estate, but in looking at what I could do with it, the general advice is to &amp;quot;upgrade xyz&amp;quot; in order to use it to do something, which kinda defeats the point - if I&amp;#39;m going to spend even $500 to upgrade this computer I might as well just put that money towards improving my more modern computers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/r33tmk8yskdf1.jpeg",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/r33tmk8yskdf1.jpeg?auto=webp&amp;s=5dfe1106506c83f6c2a2c975d7d47e6dd4155cf2",
                    "width": 4000,
                    "height": 2252
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/r33tmk8yskdf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9d05f2199a28e50fda4fcc796609d3dc35f2db2",
                      "width": 108,
                      "height": 60
                    },
                    {
                      "url": "https://preview.redd.it/r33tmk8yskdf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=308e61171715b4d269410cf9738255935b56c212",
                      "width": 216,
                      "height": 121
                    },
                    {
                      "url": "https://preview.redd.it/r33tmk8yskdf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=481bed375132b8513382e86932a81c208d44d706",
                      "width": 320,
                      "height": 180
                    },
                    {
                      "url": "https://preview.redd.it/r33tmk8yskdf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=91843b3f1aa8fe7dfffdd7e2310dca2214f8bec6",
                      "width": 640,
                      "height": 360
                    },
                    {
                      "url": "https://preview.redd.it/r33tmk8yskdf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=623eaeea70ffeee289b9f78509eec6ef979f80a6",
                      "width": 960,
                      "height": 540
                    },
                    {
                      "url": "https://preview.redd.it/r33tmk8yskdf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9cb335ce1e0c7da6f15d9945e2e2c7aa9d22aaa5",
                      "width": 1080,
                      "height": 608
                    }
                  ],
                  "variants": {},
                  "id": "ER0CDmHWLyyKDWMiyHigg6Yscgc6JEyeaii7tcDuYkQ"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m2uvgk",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "KingofRheinwg",
            "discussion_type": null,
            "num_comments": 34,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/",
            "stickied": false,
            "url": "https://i.redd.it/r33tmk8yskdf1.jpeg",
            "subreddit_subscribers": 501103,
            "created_utc": 1752819719,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n3ui8qr",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "AppearanceHeavy6724",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n3ug8l5",
                                          "score": 1,
                                          "author_fullname": "t2_uz37qfx5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "&gt; DDR3 1333 single channel is 10GBps but let's say reality is closer to 6GBps. So on a bandwidth calculation that's about 10t/s.\n\n30b-A3B is pretty heavy on attention computation, it never worked fully according to the formula bw/modelsize, and very quickly degrades with growth of context.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n3ui8qr",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;DDR3 1333 single channel is 10GBps but let&amp;#39;s say reality is closer to 6GBps. So on a bandwidth calculation that&amp;#39;s about 10t/s.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;30b-A3B is pretty heavy on attention computation, it never worked fully according to the formula bw/modelsize, and very quickly degrades with growth of context.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m2uvgk",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3ui8qr/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1752857866,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1752857866,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n3ug8l5",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "eloquentemu",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n3sap2j",
                                "score": 2,
                                "author_fullname": "t2_lpdsy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "They have 2 channels of memory, it's just unbalanced.  I don't know how those particular CPUs handle unbalanced memory, but it's common to interleave the common sizes (2x8GB) into dual channel accesses and leave only the unbalanced portion as single channel.  Or maybe it'll just access both sticks channels independently, IDK, regardless I _did_ say it would be slow.\n\nBut let's get some maths in here!  Let's say you run Qwen3-30B-A3B at IQ4_XS.  That has 758MB of common weights and 128 * 120MB experts so you can put ~40% of the experts on GPU (depending on context size).  [If you're clever that's basically enough to run the model 90+% on GPU](https://x.com/kalomaze/status/1918238263330148487) but let's assume it is balanced.  That means you'll need 4.8avg experts from the CPU per token, so 576MB.  DDR3 1333 single channel is 10GBps but let's say reality is closer to 6GBps.  So on a bandwidth calculation that's about 10t/s.  Seems okay to me (I was/am actually more worried about the CPU).\n\nKimi K2 was a half-joke, but PCIe3x4 is 4GBps and so not far off single channel DDR3 :).  Note that you wouldn't need to de-rate that like I did for the RAM... RAM needs to handle read-write during inference which hurts bandwidth while the NVMe would be read only.  Though, the way llama.cpp swaps I only see about 2GB/s even on PCIe4 (maximal NVMe performance requires some tuning).  I _think_ one of the tiny quants can fit non-experts on an 8GB GPU (Q4_K_M needs ~12GB).  But back to the CPU, running those quants can add a lot of CPU overhead and IDK how supported a AVX1 chip is...",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n3ug8l5",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They have 2 channels of memory, it&amp;#39;s just unbalanced.  I don&amp;#39;t know how those particular CPUs handle unbalanced memory, but it&amp;#39;s common to interleave the common sizes (2x8GB) into dual channel accesses and leave only the unbalanced portion as single channel.  Or maybe it&amp;#39;ll just access both sticks channels independently, IDK, regardless I &lt;em&gt;did&lt;/em&gt; say it would be slow.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s get some maths in here!  Let&amp;#39;s say you run Qwen3-30B-A3B at IQ4_XS.  That has 758MB of common weights and 128 * 120MB experts so you can put ~40% of the experts on GPU (depending on context size).  &lt;a href=\"https://x.com/kalomaze/status/1918238263330148487\"&gt;If you&amp;#39;re clever that&amp;#39;s basically enough to run the model 90+% on GPU&lt;/a&gt; but let&amp;#39;s assume it is balanced.  That means you&amp;#39;ll need 4.8avg experts from the CPU per token, so 576MB.  DDR3 1333 single channel is 10GBps but let&amp;#39;s say reality is closer to 6GBps.  So on a bandwidth calculation that&amp;#39;s about 10t/s.  Seems okay to me (I was/am actually more worried about the CPU).&lt;/p&gt;\n\n&lt;p&gt;Kimi K2 was a half-joke, but PCIe3x4 is 4GBps and so not far off single channel DDR3 :).  Note that you wouldn&amp;#39;t need to de-rate that like I did for the RAM... RAM needs to handle read-write during inference which hurts bandwidth while the NVMe would be read only.  Though, the way llama.cpp swaps I only see about 2GB/s even on PCIe4 (maximal NVMe performance requires some tuning).  I &lt;em&gt;think&lt;/em&gt; one of the tiny quants can fit non-experts on an 8GB GPU (Q4_K_M needs ~12GB).  But back to the CPU, running those quants can add a lot of CPU overhead and IDK how supported a AVX1 chip is...&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m2uvgk",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3ug8l5/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752857317,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752857317,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n3sap2j",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AppearanceHeavy6724",
                      "can_mod_post": false,
                      "created_utc": 1752830012,
                      "send_replies": true,
                      "parent_id": "t1_n3rtqkp",
                      "score": 2,
                      "author_fullname": "t2_uz37qfx5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The op has single channel ddr3. No cpu inference is feasible on this config.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n3sap2j",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The op has single channel ddr3. No cpu inference is feasible on this config.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m2uvgk",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3sap2j/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752830012,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n3xkwc6",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "eloquentemu",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n3xe6k2",
                                "score": 2,
                                "author_fullname": "t2_lpdsy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thanks.  I don't run it much myself, but would lean towards Q4_K_M because that fits on a 24GB GPU and runs hilariously fast.  I think if you're using CPU you could evaluate Q6 or Q8 because it's a smaller model so it might matter and 3B active at Q8 is still not bad.  Above Q4, though, you see diminishing returns in terms of small quality improvements for large performance losses.\n\nFor OP?  I think they might need to try a few... still probably Q4\\_K\\_M though, but Q4\\_0 might be worth a shot too since I _think_ I remember hearing the K quants can perform poorly on older hardware, but that might not be true (or just true for GPUs and not CPUs). On my machine (Zen4 Epyc) running 4 cores (i.e. CPU limited) the Q4_K_M is 25% faster and should be higher quality.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n3xkwc6",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks.  I don&amp;#39;t run it much myself, but would lean towards Q4_K_M because that fits on a 24GB GPU and runs hilariously fast.  I think if you&amp;#39;re using CPU you could evaluate Q6 or Q8 because it&amp;#39;s a smaller model so it might matter and 3B active at Q8 is still not bad.  Above Q4, though, you see diminishing returns in terms of small quality improvements for large performance losses.&lt;/p&gt;\n\n&lt;p&gt;For OP?  I think they might need to try a few... still probably Q4_K_M though, but Q4_0 might be worth a shot too since I &lt;em&gt;think&lt;/em&gt; I remember hearing the K quants can perform poorly on older hardware, but that might not be true (or just true for GPUs and not CPUs). On my machine (Zen4 Epyc) running 4 cores (i.e. CPU limited) the Q4_K_M is 25% faster and should be higher quality.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m2uvgk",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3xkwc6/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752893865,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752893865,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n3xe6k2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Lost-Blanket",
                      "can_mod_post": false,
                      "created_utc": 1752891190,
                      "send_replies": true,
                      "parent_id": "t1_n3rtqkp",
                      "score": 1,
                      "author_fullname": "t2_1tqgmtk251",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Such a good response! What quantisation do you recommend for the Qwen3-30B-A3B?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n3xe6k2",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Such a good response! What quantisation do you recommend for the Qwen3-30B-A3B?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m2uvgk",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3xe6k2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752891190,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n3rtqkp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "eloquentemu",
            "can_mod_post": false,
            "created_utc": 1752820513,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 10,
            "author_fullname": "t2_lpdsy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "- Run a small model (&lt;~10B) tolerably fast on the 1070\n- Run a small model slowly on the CPU with a bit of GPU support (Qwen3-30B-A3B would probably be the one)\n- Run [Kimi K2](https://docs.unsloth.ai/basics/kimi-k2-how-to-run-locally#run-kimi-k2-tutorials) hilariously slowly on the CPU + SSD (supposing it's a PCIe3 NVMe; SATA would be impossibly slow)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3rtqkp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;Run a small model (&amp;lt;~10B) tolerably fast on the 1070&lt;/li&gt;\n&lt;li&gt;Run a small model slowly on the CPU with a bit of GPU support (Qwen3-30B-A3B would probably be the one)&lt;/li&gt;\n&lt;li&gt;Run &lt;a href=\"https://docs.unsloth.ai/basics/kimi-k2-how-to-run-locally#run-kimi-k2-tutorials\"&gt;Kimi K2&lt;/a&gt; hilariously slowly on the CPU + SSD (supposing it&amp;#39;s a PCIe3 NVMe; SATA would be impossibly slow)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rtqkp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752820513,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3s1dm2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Longjumpingfish0403",
            "can_mod_post": false,
            "created_utc": 1752824702,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 7,
            "author_fullname": "t2_jarttha4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Think about turning it into a media server for streaming music, movies, or sharing files over your home network using Plex or Kodi. It's a cost-effective way to repurpose older hardware without major upgrades.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3s1dm2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Think about turning it into a media server for streaming music, movies, or sharing files over your home network using Plex or Kodi. It&amp;#39;s a cost-effective way to repurpose older hardware without major upgrades.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3s1dm2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752824702,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3rt4t6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Routine_Author961",
            "can_mod_post": false,
            "created_utc": 1752820191,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 8,
            "author_fullname": "t2_e6v0plyv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have a similar computer, you can run some 7B models",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3rt4t6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have a similar computer, you can run some 7B models&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rt4t6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752820191,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n3s3poq",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "AppearanceHeavy6724",
                      "can_mod_post": false,
                      "created_utc": 1752826009,
                      "send_replies": true,
                      "parent_id": "t1_n3s2q8z",
                      "score": 1,
                      "author_fullname": "t2_uz37qfx5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; With 32 GB total memory you can run a lot of things I think. Hardware is still supported by llama.cpp no problem. And with Qwen3 A3B the speed would be acceptable as well. \n\nSingle channel (he has 24 GiB, which means at least some of it is singlechannel, as there is no 12 GiB DDR3 in existence) DDR3 is way too slow, 12 GB/sec for any LLM. You'll get 1-2 t/s even with 7b models.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n3s3poq",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;With 32 GB total memory you can run a lot of things I think. Hardware is still supported by llama.cpp no problem. And with Qwen3 A3B the speed would be acceptable as well. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Single channel (he has 24 GiB, which means at least some of it is singlechannel, as there is no 12 GiB DDR3 in existence) DDR3 is way too slow, 12 GB/sec for any LLM. You&amp;#39;ll get 1-2 t/s even with 7b models.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m2uvgk",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3s3poq/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752826009,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n3s2q8z",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "OutlandishnessIll466",
            "can_mod_post": false,
            "created_utc": 1752825453,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 3,
            "author_fullname": "t2_e4ru5ouw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "With 32 GB total memory you can run a lot of things I think. Hardware is still supported by llama.cpp no problem. And with Qwen3 A3B the speed would be acceptable as well. Could be a perfectly fine, always on, AI server if you ask me. Especially for running background tasks. Just try it out I'd say",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3s2q8z",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;With 32 GB total memory you can run a lot of things I think. Hardware is still supported by llama.cpp no problem. And with Qwen3 A3B the speed would be acceptable as well. Could be a perfectly fine, always on, AI server if you ask me. Especially for running background tasks. Just try it out I&amp;#39;d say&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3s2q8z/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752825453,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3ruo7w",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "rinaldo23",
            "can_mod_post": false,
            "created_utc": 1752821009,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 3,
            "author_fullname": "t2_12axr3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have a laptop with a 1060 and it can run a small Gemma3 just fine.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3ruo7w",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have a laptop with a 1060 and it can run a small Gemma3 just fine.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3ruo7w/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752821009,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3ry4kz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "sathi006",
            "can_mod_post": false,
            "created_utc": 1752822870,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 3,
            "author_fullname": "t2_cwisfl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Automate things with Hevolve.Ai and make it use your computer to do agent actions or use it as a burner machine",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3ry4kz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Automate things with Hevolve.Ai and make it use your computer to do agent actions or use it as a burner machine&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3ry4kz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752822870,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3rtkvi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "simadik",
            "can_mod_post": false,
            "created_utc": 1752820429,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 2,
            "author_fullname": "t2_4776ill7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So without upgrading it you could run some quantized models up to 8B-12B with some little context window, but 8GB of VRAM is not much to work with. You could also run some SDXL models with ComfyUI, but it may be pretty slow (like my guess is 20-30s for 1024x1024 image with 20 steps).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3rtkvi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So without upgrading it you could run some quantized models up to 8B-12B with some little context window, but 8GB of VRAM is not much to work with. You could also run some SDXL models with ComfyUI, but it may be pretty slow (like my guess is 20-30s for 1024x1024 image with 20 steps).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rtkvi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752820429,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3rwj49",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "patrakov",
            "can_mod_post": false,
            "created_utc": 1752821998,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 2,
            "author_fullname": "t2_1bgl3e06",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is good enough for running 4-bit quantized 13B models on the CPU, slowly. 30B models might also work, but it will be very slow.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3rwj49",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is good enough for running 4-bit quantized 13B models on the CPU, slowly. 30B models might also work, but it will be very slow.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rwj49/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752821998,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3ry7gp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "SkyNetLive",
            "can_mod_post": false,
            "created_utc": 1752822914,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 2,
            "author_fullname": "t2_657d4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yours is about the same as my development machine. I can use it for inferencing like Ollama. LMStudio ( I havent used but plan to ) and similar local model UI. You could do some image generation as well. I have even used it to train small text models in Fp32/FP16 mode just fine since CPU is not all the important, so if I an train models then you can certainly runa  few models. Your gpu is decent. \n\nLooks for model that have file sizes &lt;= 7GB , which will fit comfortable in your GPU VRAM.   \nGo for the highest parameter you can fit in that file size. 11B &gt; 10B &gt; 7b &gt; 3b all the way to 0.5B is possible. \n\nYou are saving the planet",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3ry7gp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yours is about the same as my development machine. I can use it for inferencing like Ollama. LMStudio ( I havent used but plan to ) and similar local model UI. You could do some image generation as well. I have even used it to train small text models in Fp32/FP16 mode just fine since CPU is not all the important, so if I an train models then you can certainly runa  few models. Your gpu is decent. &lt;/p&gt;\n\n&lt;p&gt;Looks for model that have file sizes &amp;lt;= 7GB , which will fit comfortable in your GPU VRAM.&lt;br/&gt;\nGo for the highest parameter you can fit in that file size. 11B &amp;gt; 10B &amp;gt; 7b &amp;gt; 3b all the way to 0.5B is possible. &lt;/p&gt;\n\n&lt;p&gt;You are saving the planet&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3ry7gp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752822914,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3tc6fe",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "maz_net_au",
            "can_mod_post": false,
            "created_utc": 1752845811,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 2,
            "author_fullname": "t2_ejn46",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Use it as a boat anchor",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3tc6fe",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Use it as a boat anchor&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3tc6fe/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752845811,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3xezft",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "starphish",
            "can_mod_post": false,
            "created_utc": 1752891501,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 2,
            "author_fullname": "t2_9659",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm able to run SmolLLM2:1.7b on a mid range smartphone. It's relatively quick. You could also run Qwen 2.5:3b, and gemma3n:e2b without much issue.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3xezft",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m able to run SmolLLM2:1.7b on a mid range smartphone. It&amp;#39;s relatively quick. You could also run Qwen 2.5:3b, and gemma3n:e2b without much issue.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3xezft/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752891501,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n3v3wqs",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Corporate_Drone31",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n3saex2",
                                          "score": 1,
                                          "author_fullname": "t2_32o8hu91",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I have no illusions about running a dense model on this setup. Both R1 and Kimi are MoE, which is the only reason they run nearly fast enough. The lack of AVX2 is a pain too, not least because I have to compile a custom build of llama.cpp. All those trade-offs are why it's so cheap to buy such a machine for cheap.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n3v3wqs",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have no illusions about running a dense model on this setup. Both R1 and Kimi are MoE, which is the only reason they run nearly fast enough. The lack of AVX2 is a pain too, not least because I have to compile a custom build of llama.cpp. All those trade-offs are why it&amp;#39;s so cheap to buy such a machine for cheap.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m2uvgk",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3v3wqs/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1752864009,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1752864009,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n3saex2",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "AppearanceHeavy6724",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n3s8wdg",
                                "score": 3,
                                "author_fullname": "t2_uz37qfx5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yes if you have gazillion of channels like on EPIC and run a MoE. Not a dense model on a single channel ddr3 and ancient 3570 with no AVX2.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n3saex2",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes if you have gazillion of channels like on EPIC and run a MoE. Not a dense model on a single channel ddr3 and ancient 3570 with no AVX2.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m2uvgk",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3saex2/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752829848,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752829848,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n3s8wdg",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Corporate_Drone31",
                      "can_mod_post": false,
                      "created_utc": 1752828972,
                      "send_replies": true,
                      "parent_id": "t1_n3rt5u0",
                      "score": 0,
                      "author_fullname": "t2_32o8hu91",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; It is unsuable for cpu inference as it is DDR3.\n\n[Citation needed]. Full R1 671B user here, soon upgrading to Kimi K2 after I max out my RAM. DDR3 is cheap and cheerful, through slow.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n3s8wdg",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It is unsuable for cpu inference as it is DDR3.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;[Citation needed]. Full R1 671B user here, soon upgrading to Kimi K2 after I max out my RAM. DDR3 is cheap and cheerful, through slow.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m2uvgk",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3s8wdg/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752828972,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n3rt5u0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AppearanceHeavy6724",
            "can_mod_post": false,
            "created_utc": 1752820207,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 4,
            "author_fullname": "t2_uz37qfx5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Not much, unless you are willing to upgrade videocard. It is unsuable for cpu inference as it is DDR3.\n\nAdd a used p104-100 for $25 (cutdown 1070 analog) and use your rig for lighter LLMs. \n\nYou still can run 12b models such as Mistral Nemo or Gemma 3 12b. 12b is the size where models become fully coherent.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3rt5u0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not much, unless you are willing to upgrade videocard. It is unsuable for cpu inference as it is DDR3.&lt;/p&gt;\n\n&lt;p&gt;Add a used p104-100 for $25 (cutdown 1070 analog) and use your rig for lighter LLMs. &lt;/p&gt;\n\n&lt;p&gt;You still can run 12b models such as Mistral Nemo or Gemma 3 12b. 12b is the size where models become fully coherent.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rt5u0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752820207,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3slm0f",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Agreeable-Prompt-666",
            "can_mod_post": false,
            "created_utc": 1752835846,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 1,
            "author_fullname": "t2_1l3z4stvkq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Give away to family/son and play supreme commander with them",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3slm0f",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Give away to family/son and play supreme commander with them&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3slm0f/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752835846,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3srvy5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "RouterThuruare",
            "can_mod_post": false,
            "created_utc": 1752838635,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 1,
            "author_fullname": "t2_44nzkyfqa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You can give it to me. I'll definitely take it off your hands",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3srvy5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can give it to me. I&amp;#39;ll definitely take it off your hands&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3srvy5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752838635,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3sse3z",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "admajic",
            "can_mod_post": false,
            "created_utc": 1752838844,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 1,
            "author_fullname": "t2_60b9farf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Give it away to some one who can't afford a PC so they can learn on it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3sse3z",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Give it away to some one who can&amp;#39;t afford a PC so they can learn on it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3sse3z/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752838844,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3swko1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Klutzy-Snow8016",
            "can_mod_post": false,
            "created_utc": 1752840504,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 1,
            "author_fullname": "t2_1d5l610jz3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "There's lots of stuff you can do with a system like this, as others have mentioned. Other ideas include hosting STT / TTS endpoints, hosting MCPs, or using it as a storage server.\n\nIf you want even more options, this platform is so old that you could upgrade to 32GB dual channel ram or a 4c8t CPU for probably less than $20, and that would make it a competent last-gen gaming machine.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3swko1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s lots of stuff you can do with a system like this, as others have mentioned. Other ideas include hosting STT / TTS endpoints, hosting MCPs, or using it as a storage server.&lt;/p&gt;\n\n&lt;p&gt;If you want even more options, this platform is so old that you could upgrade to 32GB dual channel ram or a 4c8t CPU for probably less than $20, and that would make it a competent last-gen gaming machine.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3swko1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752840504,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3u90s4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Visotoniki",
            "can_mod_post": false,
            "created_utc": 1752855246,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 1,
            "author_fullname": "t2_12w10k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Honestly nothing worth doing. Your better of just using deepseek either on the web or over api.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3u90s4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Honestly nothing worth doing. Your better of just using deepseek either on the web or over api.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3u90s4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752855246,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3xdysr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Ok-Internal9317",
            "can_mod_post": false,
            "created_utc": 1752891107,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 1,
            "author_fullname": "t2_77yd9w74",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "First I wanted to comment that 3570K is not a weak processor, then I noticed it's posted in r/LocalLLaMA",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3xdysr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;First I wanted to comment that 3570K is not a weak processor, then I noticed it&amp;#39;s posted in &lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3xdysr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752891107,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3rxc3a",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Robert__Sinclair",
            "can_mod_post": false,
            "created_utc": 1752822437,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 1,
            "author_fullname": "t2_120m02qa8a",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "3B/7B q8\\_0 or q4K quantized models. or use any big model via API :D",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3rxc3a",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3B/7B q8_0 or q4K quantized models. or use any big model via API :D&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rxc3a/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752822437,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3rxs2o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "JackStrawWitchita",
            "can_mod_post": false,
            "created_utc": 1752822682,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 1,
            "author_fullname": "t2_w7utwoz3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You can run ollama - many, many LLMs to choose from. 7B - 8B models no problem. Just a bit slowly.\n\nYou can run Chatterbox, speech to text, text to speech, and all sorts of things - albeit slowly. \n\nThere's nothing wrong with that computer.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3rxs2o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can run ollama - many, many LLMs to choose from. 7B - 8B models no problem. Just a bit slowly.&lt;/p&gt;\n\n&lt;p&gt;You can run Chatterbox, speech to text, text to speech, and all sorts of things - albeit slowly. &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s nothing wrong with that computer.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rxs2o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752822682,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n3rtp01",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "GPTrack_ai",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n3rt4hz",
                                "score": 1,
                                "author_fullname": "t2_1tpuoj72sa",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "yes, you can make some kid happy.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n3rtp01",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yes, you can make some kid happy.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m2uvgk",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rtp01/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1752820490,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1752820490,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n3rt4hz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "KingofRheinwg",
                      "can_mod_post": false,
                      "created_utc": 1752820187,
                      "send_replies": true,
                      "parent_id": "t1_n3rsxf0",
                      "score": 0,
                      "author_fullname": "t2_jkslu7in5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Lol no one is buying something like this. But yeah, just give it away to needy kids or something?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n3rt4hz",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Lol no one is buying something like this. But yeah, just give it away to needy kids or something?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m2uvgk",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rt4hz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1752820187,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n3rsxf0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GPTrack_ai",
            "can_mod_post": false,
            "created_utc": 1752820082,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 0,
            "author_fullname": "t2_1tpuoj72sa",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Sell it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3rsxf0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sell it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rsxf0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752820082,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3rv3oy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Clajmate",
            "can_mod_post": false,
            "created_utc": 1752821237,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 0,
            "author_fullname": "t2_jvu48yh3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "sell it.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3rv3oy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;sell it.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3rv3oy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752821237,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3s6i38",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "pravbk100",
            "can_mod_post": false,
            "created_utc": 1752827603,
            "send_replies": true,
            "parent_id": "t3_1m2uvgk",
            "score": 0,
            "author_fullname": "t2_3z8nadicr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Only difference in yours and mine is 3770k and 3090. I am full sdxl fine tuning and flux lora. Works all fine. I do have another 3090 so i am gonna try 32b q8 model but my z77x mobo doesnt have space to fit 2 3090, so waiting for pcie raiser cable.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3s6i38",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Only difference in yours and mine is 3770k and 3090. I am full sdxl fine tuning and flux lora. Works all fine. I do have another 3090 so i am gonna try 32b q8 model but my z77x mobo doesnt have space to fit 2 3090, so waiting for pcie raiser cable.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m2uvgk/what_can_i_do_with_an_old_computer/n3s6i38/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752827603,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m2uvgk",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]