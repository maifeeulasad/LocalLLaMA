[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "**Goal:**  \nI'm building a local AI assistant — like a voice-based Alfred — that runs entirely on my machine. I've already downloaded and installed **LLaMA 2 13B Q5 Chat** for this purpose. However, I've noticed that the chat model includes certain **filters** or restrictions that limit the assistant’s responses.\n\nIn my research, I came across **SillyTavern**, which is known for providing more flexibility and customization when interacting with local LLMs — including better control over prompt behavior and fewer filtering constraints.\n\nMy plan is to **integrate SillyTavern as the conversational layer** within my custom **Alfred interface**, using it as the chat system that powers the assistant's personality, memory, and dialogue — while handling voice input/output through local tools and ElevenLabs. Is this possible can someone guide? What exactly is SillyTavern",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Hey everyone I'm pretty new at this. I'm a designer please help me. Stupid Question",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mdln75",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.67,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_a4m5uj5t",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753917291,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt;&lt;br/&gt;\nI&amp;#39;m building a local AI assistant — like a voice-based Alfred — that runs entirely on my machine. I&amp;#39;ve already downloaded and installed &lt;strong&gt;LLaMA 2 13B Q5 Chat&lt;/strong&gt; for this purpose. However, I&amp;#39;ve noticed that the chat model includes certain &lt;strong&gt;filters&lt;/strong&gt; or restrictions that limit the assistant’s responses.&lt;/p&gt;\n\n&lt;p&gt;In my research, I came across &lt;strong&gt;SillyTavern&lt;/strong&gt;, which is known for providing more flexibility and customization when interacting with local LLMs — including better control over prompt behavior and fewer filtering constraints.&lt;/p&gt;\n\n&lt;p&gt;My plan is to &lt;strong&gt;integrate SillyTavern as the conversational layer&lt;/strong&gt; within my custom &lt;strong&gt;Alfred interface&lt;/strong&gt;, using it as the chat system that powers the assistant&amp;#39;s personality, memory, and dialogue — while handling voice input/output through local tools and ElevenLabs. Is this possible can someone guide? What exactly is SillyTavern&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mdln75",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Iamtheguyyy",
            "discussion_type": null,
            "num_comments": 10,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/",
            "subreddit_subscribers": 507574,
            "created_utc": 1753917291,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n65eo6a",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Iamtheguyyy",
                      "can_mod_post": false,
                      "created_utc": 1753963173,
                      "send_replies": true,
                      "parent_id": "t1_n62nbun",
                      "score": 1,
                      "author_fullname": "t2_a4m5uj5t",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Let ne check it out and change the model. How censored is it?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n65eo6a",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Let ne check it out and change the model. How censored is it?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdln75",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n65eo6a/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753963173,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n62nbun",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Lissanro",
            "can_mod_post": false,
            "created_utc": 1753918863,
            "send_replies": true,
            "parent_id": "t3_1mdln75",
            "score": 2,
            "author_fullname": "t2_fpfao9g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Llama 2 is extremely outdated. Recent release of Qwen3 30B-A3B is much better and many times faster too due to being MoE, compared to a dense 13B model. There are smaller and bigger models in Qwen3 series too, that you may choose depending on your memory limitations.\n\nSillyTavern is just UI where you can use character cards as system prompt templates, and has many advanced functions. The best way to learn is to clone its git repo and search for commits that added certain features related to areas you are interested in - you will get some clues what you need to change to add your own features.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n62nbun",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Llama 2 is extremely outdated. Recent release of Qwen3 30B-A3B is much better and many times faster too due to being MoE, compared to a dense 13B model. There are smaller and bigger models in Qwen3 series too, that you may choose depending on your memory limitations.&lt;/p&gt;\n\n&lt;p&gt;SillyTavern is just UI where you can use character cards as system prompt templates, and has many advanced functions. The best way to learn is to clone its git repo and search for commits that added certain features related to areas you are interested in - you will get some clues what you need to change to add your own features.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n62nbun/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753918863,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdln75",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n65he0z",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Iamtheguyyy",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n65f7x5",
                                          "score": 1,
                                          "author_fullname": "t2_a4m5uj5t",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Mac m3 pro",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n65he0z",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mac m3 pro&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mdln75",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n65he0z/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753964188,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753964188,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n65j68w",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Iamtheguyyy",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n65f7x5",
                                          "score": 1,
                                          "author_fullname": "t2_a4m5uj5t",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I dont mind them being a bit slower but they should have context and smart",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n65j68w",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I dont mind them being a bit slower but they should have context and smart&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mdln75",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n65j68w/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753964824,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753964824,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n65f7x5",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DepthHour1669",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n65em3v",
                                "score": 1,
                                "author_fullname": "t2_t6glzswk",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Try both and see what you prefer. \n\nMistral should be a bit faster.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n65f7x5",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Try both and see what you prefer. &lt;/p&gt;\n\n&lt;p&gt;Mistral should be a bit faster.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mdln75",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n65f7x5/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753963383,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753963383,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n65em3v",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Iamtheguyyy",
                      "can_mod_post": false,
                      "created_utc": 1753963152,
                      "send_replies": true,
                      "parent_id": "t1_n62w0i6",
                      "score": 1,
                      "author_fullname": "t2_a4m5uj5t",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah I installed LM but am confused about the models. Mistral is better or Qwen? I want it to be really smart.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n65em3v",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah I installed LM but am confused about the models. Mistral is better or Qwen? I want it to be really smart.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdln75",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n65em3v/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753963152,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n62w0i6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DepthHour1669",
            "can_mod_post": false,
            "created_utc": 1753921825,
            "send_replies": true,
            "parent_id": "t3_1mdln75",
            "score": 2,
            "author_fullname": "t2_t6glzswk",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Are you on a windows computer or mac? \n\nSillyTavern is just a frontend app that loads any model. You can use any app to load a model. \n\nIf you want an uncensored model, I recommend *Mistral Small 3.2 24B Q4*. https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506\n\nHere is a rankings list of uncensored models: https://huggingface.co/spaces/DontPlanToEnd/UGI-Leaderboard  \nNote that you probably can't run anything over 32B params on your machine, so ignore anything bigger than 32 in the #P column in this table.\n\nThere are plenty of other apps that can load any of these models. LM Studio is probably the easiest to use app on a Mac.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n62w0i6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Are you on a windows computer or mac? &lt;/p&gt;\n\n&lt;p&gt;SillyTavern is just a frontend app that loads any model. You can use any app to load a model. &lt;/p&gt;\n\n&lt;p&gt;If you want an uncensored model, I recommend &lt;em&gt;Mistral Small 3.2 24B Q4&lt;/em&gt;. &lt;a href=\"https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506\"&gt;https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is a rankings list of uncensored models: &lt;a href=\"https://huggingface.co/spaces/DontPlanToEnd/UGI-Leaderboard\"&gt;https://huggingface.co/spaces/DontPlanToEnd/UGI-Leaderboard&lt;/a&gt;&lt;br/&gt;\nNote that you probably can&amp;#39;t run anything over 32B params on your machine, so ignore anything bigger than 32 in the #P column in this table.&lt;/p&gt;\n\n&lt;p&gt;There are plenty of other apps that can load any of these models. LM Studio is probably the easiest to use app on a Mac.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n62w0i6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753921825,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdln75",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n62ly18",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "fp4guru",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n62kbg8",
                                "score": 1,
                                "author_fullname": "t2_1tp8zldw5g",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "\nAsk Claude this: \n\n&gt; You are a senior AI engineer. I want to build a fully local voice assistant that works on my MacBook using open-source tools only, no cloud APIs. The assistant should:\n\n1. Continuously listen via microphone\n\n\n2. Convert speech to text\n\n\n3. Pass that text to a local LLM (e.g. llama.cpp, ExLlamaV3, Mistral, etc.)\n\n\n4. Convert the response text to speech\n\n\n5. Output voice via speakers\n\n\n\nPlease:\n\nRecommend the best open-source libraries for each step (STT, LLM, TTS)\n\nShow how to wire them together in Python\n\nOptimize for low-latency and low resource usage\n\nEnsure it works offline on macOS (Apple Silicon or Intel)\n\nBonus: support hotword activation like \"Hey Assistant\"\n\n\nI have Python, Homebrew, ffmpeg, and local models downloaded already.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n62ly18",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ask Claude this: &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;You are a senior AI engineer. I want to build a fully local voice assistant that works on my MacBook using open-source tools only, no cloud APIs. The assistant should:&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Continuously listen via microphone&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Convert speech to text&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Pass that text to a local LLM (e.g. llama.cpp, ExLlamaV3, Mistral, etc.)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Convert the response text to speech&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Output voice via speakers&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Please:&lt;/p&gt;\n\n&lt;p&gt;Recommend the best open-source libraries for each step (STT, LLM, TTS)&lt;/p&gt;\n\n&lt;p&gt;Show how to wire them together in Python&lt;/p&gt;\n\n&lt;p&gt;Optimize for low-latency and low resource usage&lt;/p&gt;\n\n&lt;p&gt;Ensure it works offline on macOS (Apple Silicon or Intel)&lt;/p&gt;\n\n&lt;p&gt;Bonus: support hotword activation like &amp;quot;Hey Assistant&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;I have Python, Homebrew, ffmpeg, and local models downloaded already.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mdln75",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n62ly18/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753918411,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753918411,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n62kbg8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Iamtheguyyy",
                      "can_mod_post": false,
                      "created_utc": 1753917885,
                      "send_replies": true,
                      "parent_id": "t1_n62joz4",
                      "score": -1,
                      "author_fullname": "t2_a4m5uj5t",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Like? Google? I want the best one. Which can run on my macbook pro. Google will have too much censorship?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n62kbg8",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Like? Google? I want the best one. Which can run on my macbook pro. Google will have too much censorship?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdln75",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n62kbg8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753917885,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n62joz4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "fp4guru",
            "can_mod_post": false,
            "created_utc": 1753917680,
            "send_replies": true,
            "parent_id": "t3_1mdln75",
            "score": 1,
            "author_fullname": "t2_1tp8zldw5g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You can probably build this in a few hours by asking chatgpt or Claude. Llama2 is outdated , switch to a modern one.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n62joz4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can probably build this in a few hours by asking chatgpt or Claude. Llama2 is outdated , switch to a modern one.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdln75/hey_everyone_im_pretty_new_at_this_im_a_designer/n62joz4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753917680,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdln75",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]