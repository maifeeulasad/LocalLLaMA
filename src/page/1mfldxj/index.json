[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I‚Äôd like to start a small art project and I‚Äôm looking for a model that speaks German well. I‚Äôm currently using Gemma 3n:e4b and I‚Äôm quite satisfied with it. However, I‚Äôd like to know if there are any other models of a similar size that have even better German language capabilities. The whole thing should be run with Ollama on a PC with a maximum of 8GB of VRAM ‚Äì ideally no more than 6GB.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Small LLM in german",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mfldxj",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.93,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 23,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1tcpn4d5tw",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 23,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754122940,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I‚Äôd like to start a small art project and I‚Äôm looking for a model that speaks German well. I‚Äôm currently using Gemma 3n:e4b and I‚Äôm quite satisfied with it. However, I‚Äôd like to know if there are any other models of a similar size that have even better German language capabilities. The whole thing should be run with Ollama on a PC with a maximum of 8GB of VRAM ‚Äì ideally no more than 6GB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mfldxj",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Ghulaschsuppe",
            "discussion_type": null,
            "num_comments": 17,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/",
            "subreddit_subscribers": 509054,
            "created_utc": 1754122940,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6i68ss",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Awwtifishal",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6i252b",
                                "score": 1,
                                "author_fullname": "t2_1d96a8k10t",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Let us know how the 12b works for you.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6i68ss",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Let us know how the 12b works for you.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfldxj",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6i68ss/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754130110,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754130110,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6jfm5f",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Evening_Ad6637",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6i252b",
                                "score": 1,
                                "author_fullname": "t2_p45er6oo",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Interesting! In my experience, Gemma-3-4b is much better than version 3n-e4b. Have you tried the Q8 version yet, ideally the XL version from unsloth? And if you've downloaded the model from ollama, you should definitely try a manually downloaded version.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6jfm5f",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Interesting! In my experience, Gemma-3-4b is much better than version 3n-e4b. Have you tried the Q8 version yet, ideally the XL version from unsloth? And if you&amp;#39;ve downloaded the model from ollama, you should definitely try a manually downloaded version.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfldxj",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6jfm5f/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754148114,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754148114,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6i252b",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Ghulaschsuppe",
                      "can_mod_post": false,
                      "created_utc": 1754127709,
                      "send_replies": true,
                      "parent_id": "t1_n6hwpay",
                      "score": 2,
                      "author_fullname": "t2_1tcpn4d5tw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you very much. Yeah the 3n:e4b is better than the normal 4b but i will try the 12b now",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6i252b",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you very much. Yeah the 3n:e4b is better than the normal 4b but i will try the 12b now&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfldxj",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6i252b/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754127709,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6hwpay",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "1nicerBoye",
            "can_mod_post": false,
            "created_utc": 1754124354,
            "send_replies": true,
            "parent_id": "t3_1mfldxj",
            "score": 10,
            "author_fullname": "t2_5hwlbj95",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I am currently using the much bigger Gemma 3 27b in a IQ4\\_XS variant and I must say, that it is really impressive. Apart from the Sauerkraut und Disco Leo finetuned models nothing of that size comes even close. But it is almost 15GB...\n\nQwen3 did also put out decent german but only the bigger ones starting at 14B, the smaller ones fell apart quickly and effectively only contain artifacts of german.\n\nThe aforementioned Sauerkraut and Leo finetunes can be found here:  \n[https://huggingface.co/DiscoResearch/Llama3-German-8B](https://huggingface.co/DiscoResearch/Llama3-German-8B)  \nAnd here:  \n[https://huggingface.co/VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct](https://huggingface.co/VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct)  \nBut in regards to the AI space those are old news and they are a big step below the bigger Gemma-3 honestly.\n\nI would recommend sticking to Gemma. Everything else performs worse in german and also often makes mistakes which breaks reading flow and straight up kills immersive TTS stuff.\n\nYou could try the IQ3\\_M of [https://huggingface.co/bartowski/mlabonne\\_gemma-3-12b-it-abliterated-GGUF/tree/main](https://huggingface.co/bartowski/mlabonne_gemma-3-12b-it-abliterated-GGUF/tree/main) but I think it may make grammatical errors, especially with higher temps.\n\nI would recommend the IQ4\\_XS Variant and make sure that the (quantized, i usually use q8\\_0) Context also fits into VRAM. That would leave the rest of your app to around 500 MB VRAM.\n\nYou could also try splitting the model into RAM and VRAM using LLama.cpp and see how that works for you. For this size a cpu with AVX2 or even better AVX512 might work decently. But then you need to use a Q4\\_K\\_M / Q5\\_K\\_S quant as the IQ requires the bandwidth of VRAM.\n\nUsing the normal Gemma-3-4b might be worth a try, I dont think the changes they made with the 3n stuff improved the model for non english use cases. But I havent tested it, saw that only this week myself that they exist.",
            "edited": 1754124913,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hwpay",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am currently using the much bigger Gemma 3 27b in a IQ4_XS variant and I must say, that it is really impressive. Apart from the Sauerkraut und Disco Leo finetuned models nothing of that size comes even close. But it is almost 15GB...&lt;/p&gt;\n\n&lt;p&gt;Qwen3 did also put out decent german but only the bigger ones starting at 14B, the smaller ones fell apart quickly and effectively only contain artifacts of german.&lt;/p&gt;\n\n&lt;p&gt;The aforementioned Sauerkraut and Leo finetunes can be found here:&lt;br/&gt;\n&lt;a href=\"https://huggingface.co/DiscoResearch/Llama3-German-8B\"&gt;https://huggingface.co/DiscoResearch/Llama3-German-8B&lt;/a&gt;&lt;br/&gt;\nAnd here:&lt;br/&gt;\n&lt;a href=\"https://huggingface.co/VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct\"&gt;https://huggingface.co/VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct&lt;/a&gt;&lt;br/&gt;\nBut in regards to the AI space those are old news and they are a big step below the bigger Gemma-3 honestly.&lt;/p&gt;\n\n&lt;p&gt;I would recommend sticking to Gemma. Everything else performs worse in german and also often makes mistakes which breaks reading flow and straight up kills immersive TTS stuff.&lt;/p&gt;\n\n&lt;p&gt;You could try the IQ3_M of &lt;a href=\"https://huggingface.co/bartowski/mlabonne_gemma-3-12b-it-abliterated-GGUF/tree/main\"&gt;https://huggingface.co/bartowski/mlabonne_gemma-3-12b-it-abliterated-GGUF/tree/main&lt;/a&gt; but I think it may make grammatical errors, especially with higher temps.&lt;/p&gt;\n\n&lt;p&gt;I would recommend the IQ4_XS Variant and make sure that the (quantized, i usually use q8_0) Context also fits into VRAM. That would leave the rest of your app to around 500 MB VRAM.&lt;/p&gt;\n\n&lt;p&gt;You could also try splitting the model into RAM and VRAM using LLama.cpp and see how that works for you. For this size a cpu with AVX2 or even better AVX512 might work decently. But then you need to use a Q4_K_M / Q5_K_S quant as the IQ requires the bandwidth of VRAM.&lt;/p&gt;\n\n&lt;p&gt;Using the normal Gemma-3-4b might be worth a try, I dont think the changes they made with the 3n stuff improved the model for non english use cases. But I havent tested it, saw that only this week myself that they exist.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6hwpay/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754124354,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfldxj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6i2j5g",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Ghulaschsuppe",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6i2g38",
                                          "score": 2,
                                          "author_fullname": "t2_1tcpn4d5tw",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Alles gut, das hat Zeit üòÉ ist ein Hobbyprojekt und darf ruhig l√§nger dauern.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6i2j5g",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Alles gut, das hat Zeit üòÉ ist ein Hobbyprojekt und darf ruhig l√§nger dauern.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mfldxj",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6i2j5g/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754127943,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754127943,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6i2g38",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "zaschmaen",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6i211r",
                                "score": 1,
                                "author_fullname": "t2_ufk89ive",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Ja ich bin da noch hinter, habe deinen beitrag gespeichert und wenn ich weiter bin kann ich dir gerne mal bescheid geben. Aber bitte nicht gleich mit morgen rechnen xD",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6i2g38",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ja ich bin da noch hinter, habe deinen beitrag gespeichert und wenn ich weiter bin kann ich dir gerne mal bescheid geben. Aber bitte nicht gleich mit morgen rechnen xD&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfldxj",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6i2g38/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754127892,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754127892,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6i6o9o",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Blizado",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6i211r",
                                "score": 1,
                                "author_fullname": "t2_j0e2r",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Muss es daf√ºr schnell Antworten generieren k√∂nnen? Ansonsten k√∂nntest du neben Quants auch mit Offloading versuchen, sprich einen Teil in VRAM laden und einen Teil in den normalen RAM. Dadurch wird die Generierung zwar langsamer, aber gr√∂√üere Modelle k√∂nnen eben besser deutsch.\n\nAuch wichtig zu wissen: selbst wenn man bei einem gr√∂√üeren Modell nur ein Q4 Quant (4bit) nutzen kann, was ein LLM schon sp√ºrbar schlechter macht, ist es meist dennoch besser als ein kleineres Modell in Q8 (8bit), was ein LLM kaum schlechter macht. Also lieber ein Modell mit 4bit nutzen als ein kleineres mit 8bit.\n\nAuch wichtig: ein LLM braucht auch immer zus√§tzlich VRAM f√ºr den Context welchen du ihm sendest und f√ºr die Antwort die es generiert. Bei einem 7,5GB VRAM Modell wirst du also sehr wahrscheinlich out of Memory laufen, weil nicht gen√ºgend Platz f√ºr Context+Antwort vorhanden ist. 1+GB VRAM muss man daf√ºr schon frei halten, je nach Context und Antwortl√§nge.\n\nDu schreibst ideal w√§re, wenn es nicht mehr als 6GB VRAM w√§ren, wenn das f√ºr die KI insgesamt gilt, musste du nach einer Download Gr√∂√üe von etwas 4-5GB suchen. Mit einem 12B Modell wird das dann nichts, da m√ºsstest du runter bis auf 3 oder gar 2bit und da sind die Modelle kaum noch zu gebrauchen, 4bit ist so der Sweetspot. Bei einem 12B Modell m√ºsstest du also schon Q4_K_S runter, vielleicht sogar auf IQ4_XS f√ºr mehr Platz f√ºr Context+Antwort um in 8GB VRAM zu passen. Bei einem 8B Modell k√∂nntest du noch Q4_K_M nutzen, was so der go to standard bei 4bit ist und unter 5GB VRAM k√§me. Alles GGUF Modelle.\n\nWie gesagt, wenn du Offloading betreiben k√∂nntest, weil Geschwindigkeit nicht so wichtig ist, dann w√§re mehr m√∂glich. Aber Offloading bremst sehr sp√ºrbar aus.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6i6o9o",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Muss es daf√ºr schnell Antworten generieren k√∂nnen? Ansonsten k√∂nntest du neben Quants auch mit Offloading versuchen, sprich einen Teil in VRAM laden und einen Teil in den normalen RAM. Dadurch wird die Generierung zwar langsamer, aber gr√∂√üere Modelle k√∂nnen eben besser deutsch.&lt;/p&gt;\n\n&lt;p&gt;Auch wichtig zu wissen: selbst wenn man bei einem gr√∂√üeren Modell nur ein Q4 Quant (4bit) nutzen kann, was ein LLM schon sp√ºrbar schlechter macht, ist es meist dennoch besser als ein kleineres Modell in Q8 (8bit), was ein LLM kaum schlechter macht. Also lieber ein Modell mit 4bit nutzen als ein kleineres mit 8bit.&lt;/p&gt;\n\n&lt;p&gt;Auch wichtig: ein LLM braucht auch immer zus√§tzlich VRAM f√ºr den Context welchen du ihm sendest und f√ºr die Antwort die es generiert. Bei einem 7,5GB VRAM Modell wirst du also sehr wahrscheinlich out of Memory laufen, weil nicht gen√ºgend Platz f√ºr Context+Antwort vorhanden ist. 1+GB VRAM muss man daf√ºr schon frei halten, je nach Context und Antwortl√§nge.&lt;/p&gt;\n\n&lt;p&gt;Du schreibst ideal w√§re, wenn es nicht mehr als 6GB VRAM w√§ren, wenn das f√ºr die KI insgesamt gilt, musste du nach einer Download Gr√∂√üe von etwas 4-5GB suchen. Mit einem 12B Modell wird das dann nichts, da m√ºsstest du runter bis auf 3 oder gar 2bit und da sind die Modelle kaum noch zu gebrauchen, 4bit ist so der Sweetspot. Bei einem 12B Modell m√ºsstest du also schon Q4_K_S runter, vielleicht sogar auf IQ4_XS f√ºr mehr Platz f√ºr Context+Antwort um in 8GB VRAM zu passen. Bei einem 8B Modell k√∂nntest du noch Q4_K_M nutzen, was so der go to standard bei 4bit ist und unter 5GB VRAM k√§me. Alles GGUF Modelle.&lt;/p&gt;\n\n&lt;p&gt;Wie gesagt, wenn du Offloading betreiben k√∂nntest, weil Geschwindigkeit nicht so wichtig ist, dann w√§re mehr m√∂glich. Aber Offloading bremst sehr sp√ºrbar aus.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfldxj",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6i6o9o/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754130354,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754130354,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6ik7an",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Mkengine",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6i211r",
                                "score": 1,
                                "author_fullname": "t2_9p2xe",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Mit Gemma 3 habe ich auch die besten Erfahrungen, die einzigen anderen Modelle die gut deutsch k√∂nnen sind die von Mistral, aber die sind zu gro√ü f√ºr deinen Anwendungsfall. Ich teste gerade ob Qwen3-30B-A3B-2507-instruct noch gut deutsch kann aufgrund der hohen Parameteranzahl. Dadurch, dass es MoE ist, sollte es bei dir auch gut laufen.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6ik7an",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mit Gemma 3 habe ich auch die besten Erfahrungen, die einzigen anderen Modelle die gut deutsch k√∂nnen sind die von Mistral, aber die sind zu gro√ü f√ºr deinen Anwendungsfall. Ich teste gerade ob Qwen3-30B-A3B-2507-instruct noch gut deutsch kann aufgrund der hohen Parameteranzahl. Dadurch, dass es MoE ist, sollte es bei dir auch gut laufen.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfldxj",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6ik7an/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754136942,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754136942,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6jgbpi",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Evening_Ad6637",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6i211r",
                                "score": 1,
                                "author_fullname": "t2_p45er6oo",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Kennst schon das hier? Das k√∂nnte vlt genau das richtige f√ºr dich sein (also zumindest der Ansatz, ein Modell ‚Äûdepri‚Äú zu machen)\n\n\nhttps://huggingface.co/failspy/Llama-3-8B-Instruct-MopeyMule",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6jgbpi",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Kennst schon das hier? Das k√∂nnte vlt genau das richtige f√ºr dich sein (also zumindest der Ansatz, ein Modell ‚Äûdepri‚Äú zu machen)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/failspy/Llama-3-8B-Instruct-MopeyMule\"&gt;https://huggingface.co/failspy/Llama-3-8B-Instruct-MopeyMule&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfldxj",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6jgbpi/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754148337,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754148337,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6i211r",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Ghulaschsuppe",
                      "can_mod_post": false,
                      "created_utc": 1754127641,
                      "send_replies": true,
                      "parent_id": "t1_n6i17bo",
                      "score": 0,
                      "author_fullname": "t2_1tcpn4d5tw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Das klingt gut. Ich Versuche ein Kunstprojekt aufzuziehen in dem das Sprachmodell unglaublich \"leidet\" und √ºber seine eigene Existenz nachdenkt, seine √Ñngste ausdr√ºckt etc. und daf√ºr w√§re ann√§hernd perfektes Deutsch nat√ºrlich viel besser üòÇ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6i211r",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Das klingt gut. Ich Versuche ein Kunstprojekt aufzuziehen in dem das Sprachmodell unglaublich &amp;quot;leidet&amp;quot; und √ºber seine eigene Existenz nachdenkt, seine √Ñngste ausdr√ºckt etc. und daf√ºr w√§re ann√§hernd perfektes Deutsch nat√ºrlich viel besser üòÇ&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfldxj",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6i211r/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754127641,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6i17bo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "zaschmaen",
            "can_mod_post": false,
            "created_utc": 1754127139,
            "send_replies": true,
            "parent_id": "t3_1mfldxj",
            "score": 3,
            "author_fullname": "t2_ufk89ive",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Genau so ein Projekt baue ich auch gerade auf! Habe gerade erst gestern den Pc daf√ºr zusammengebaut und getestet, den ich via Proxmox ins Netzwerk integrieren werde. Suche auch noch die Richtige LLM und habe schon einiges gelesen was am besten ist mit meiner Hardware. W√ºrde ihn sogar am liebsten per Sprache steuern wollen k√∂nnen. Kann dir gerne bescheid geben falls ich was gefunden habe, ich habe eine rtx 2060 mit 6 gb.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6i17bo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Genau so ein Projekt baue ich auch gerade auf! Habe gerade erst gestern den Pc daf√ºr zusammengebaut und getestet, den ich via Proxmox ins Netzwerk integrieren werde. Suche auch noch die Richtige LLM und habe schon einiges gelesen was am besten ist mit meiner Hardware. W√ºrde ihn sogar am liebsten per Sprache steuern wollen k√∂nnen. Kann dir gerne bescheid geben falls ich was gefunden habe, ich habe eine rtx 2060 mit 6 gb.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6i17bo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754127139,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfldxj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6hvhbq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "DunklerErpel",
            "can_mod_post": false,
            "created_utc": 1754123597,
            "send_replies": true,
            "parent_id": "t3_1mfldxj",
            "score": 5,
            "author_fullname": "t2_alho5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You'll probably not get much better than Gemma, I tried as well. You might want to look at Phi4 4b, but don't get your hopes up. Alternatively Gemma2-9B-SimPo, I enjoyed that some time ago, but don't know whether it still compares.\n\nVAGOsolutions used to be dedicated to German LLMs, but as far as I know, they haven't released any text model for some time. EuroLLM is supposed to be good, but I wasn't satisfied.\n\nYou might want to look at the new model by Arcee, ALM-4.5 (or something in that direction).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hvhbq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;ll probably not get much better than Gemma, I tried as well. You might want to look at Phi4 4b, but don&amp;#39;t get your hopes up. Alternatively Gemma2-9B-SimPo, I enjoyed that some time ago, but don&amp;#39;t know whether it still compares.&lt;/p&gt;\n\n&lt;p&gt;VAGOsolutions used to be dedicated to German LLMs, but as far as I know, they haven&amp;#39;t released any text model for some time. EuroLLM is supposed to be good, but I wasn&amp;#39;t satisfied.&lt;/p&gt;\n\n&lt;p&gt;You might want to look at the new model by Arcee, ALM-4.5 (or something in that direction).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6hvhbq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754123597,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfldxj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6iqzda",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Ayuei",
            "can_mod_post": false,
            "created_utc": 1754139671,
            "send_replies": true,
            "parent_id": "t3_1mfldxj",
            "score": 2,
            "author_fullname": "t2_wtq77",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "There's actually an LLM released recently trained exclusively for German:\n\nhttps://huggingface.co/LSX-UniWue/LLaMmlein_7B\n\nThere's also a 1B variant. \n\nThe paper for the model was recently accepted to a top AI/NLP conference as well!\n\nhttps://aclanthology.org/2025.acl-long.111/",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6iqzda",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s actually an LLM released recently trained exclusively for German:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/LSX-UniWue/LLaMmlein_7B\"&gt;https://huggingface.co/LSX-UniWue/LLaMmlein_7B&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s also a 1B variant. &lt;/p&gt;\n\n&lt;p&gt;The paper for the model was recently accepted to a top AI/NLP conference as well!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://aclanthology.org/2025.acl-long.111/\"&gt;https://aclanthology.org/2025.acl-long.111/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6iqzda/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754139671,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfldxj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6hvbql",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Awwtifishal",
            "can_mod_post": false,
            "created_utc": 1754123499,
            "send_replies": true,
            "parent_id": "t3_1mfldxj",
            "score": 2,
            "author_fullname": "t2_1d96a8k10t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Try gemma 3 4B",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hvbql",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Try gemma 3 4B&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6hvbql/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754123499,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfldxj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6iq869",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AppearanceHeavy6724",
            "can_mod_post": false,
            "created_utc": 1754139380,
            "send_replies": true,
            "parent_id": "t3_1mfldxj",
            "score": 1,
            "author_fullname": "t2_uz37qfx5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "teuken",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6iq869",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;teuken&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6iq869/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754139380,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfldxj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6ixh0a",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AvidCyclist250",
            "can_mod_post": false,
            "created_utc": 1754142093,
            "send_replies": true,
            "parent_id": "t3_1mfldxj",
            "score": 1,
            "author_fullname": "t2_lmkezzo6j",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Mistral is worth a look, it's pretty good at German. Scrap that, just saw 8GB VRAM. Not sure how good it is once crammed into 8GB.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ixh0a",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mistral is worth a look, it&amp;#39;s pretty good at German. Scrap that, just saw 8GB VRAM. Not sure how good it is once crammed into 8GB.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6ixh0a/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754142093,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfldxj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6k4ssq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "zitr0y",
            "can_mod_post": false,
            "created_utc": 1754156109,
            "send_replies": true,
            "parent_id": "t3_1mfldxj",
            "score": 1,
            "author_fullname": "t2_kpqfh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Try Ministral 3b or 8b.\n\n\nIs it better? Not sure but worth a try",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6k4ssq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Try Ministral 3b or 8b.&lt;/p&gt;\n\n&lt;p&gt;Is it better? Not sure but worth a try&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfldxj/small_llm_in_german/n6k4ssq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754156109,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfldxj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]