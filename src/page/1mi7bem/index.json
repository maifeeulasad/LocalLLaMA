[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "No more need for super-complex regular expression in the -ot option! Just do `--cpu-moe` or `--n-cpu-moe #` and reduce the number until the model no longer fits on the GPU.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "New llama.cpp options make MoE offloading trivial: `--n-cpu-moe`",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Tutorial | Guide"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 70,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mi7bem",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.97,
            "author_flair_background_color": null,
            "ups": 291,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_5b972ieo",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Tutorial | Guide",
            "can_mod_post": false,
            "score": 291,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/z9bB4lcxUZhZHvTMdXPfCmtA3BVsCM9FB8umPl48qlU.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=a6683566ea3a2ab3f10144b97e4072ab0639db68",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "link",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754395457,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "github.com",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;No more need for super-complex regular expression in the -ot option! Just do &lt;code&gt;--cpu-moe&lt;/code&gt; or &lt;code&gt;--n-cpu-moe #&lt;/code&gt; and reduce the number until the model no longer fits on the GPU.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://github.com/ggml-org/llama.cpp/pull/15077",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/z9bB4lcxUZhZHvTMdXPfCmtA3BVsCM9FB8umPl48qlU.png?auto=webp&amp;s=6d449514411bd16575e7077a57c169d46f49d2e5",
                    "width": 1200,
                    "height": 600
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/z9bB4lcxUZhZHvTMdXPfCmtA3BVsCM9FB8umPl48qlU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ad9e8961b664b6710eb58c6fa604f119639c53e1",
                      "width": 108,
                      "height": 54
                    },
                    {
                      "url": "https://external-preview.redd.it/z9bB4lcxUZhZHvTMdXPfCmtA3BVsCM9FB8umPl48qlU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=734713090c897be69c4245b0a525571c45526c1e",
                      "width": 216,
                      "height": 108
                    },
                    {
                      "url": "https://external-preview.redd.it/z9bB4lcxUZhZHvTMdXPfCmtA3BVsCM9FB8umPl48qlU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=03bee70399e29da7291f5a8bd625456274a76ec6",
                      "width": 320,
                      "height": 160
                    },
                    {
                      "url": "https://external-preview.redd.it/z9bB4lcxUZhZHvTMdXPfCmtA3BVsCM9FB8umPl48qlU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fc3c355c6e5a0c2867654d9ea9c2e7c8ed9c618b",
                      "width": 640,
                      "height": 320
                    },
                    {
                      "url": "https://external-preview.redd.it/z9bB4lcxUZhZHvTMdXPfCmtA3BVsCM9FB8umPl48qlU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4e77bcd6622924abcac1fa3acd0c374064d0fda",
                      "width": 960,
                      "height": 480
                    },
                    {
                      "url": "https://external-preview.redd.it/z9bB4lcxUZhZHvTMdXPfCmtA3BVsCM9FB8umPl48qlU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=bc470b6cb695b2d267be6deae5c3dd1b77f91432",
                      "width": 1080,
                      "height": 540
                    }
                  ],
                  "variants": {},
                  "id": "z9bB4lcxUZhZHvTMdXPfCmtA3BVsCM9FB8umPl48qlU"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "449b05a6-bf8e-11ed-b4bd-66961e47bd50",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#0079d3",
            "id": "1mi7bem",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "Pristine-Woodpecker",
            "discussion_type": null,
            "num_comments": 75,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/",
            "stickied": false,
            "url": "https://github.com/ggml-org/llama.cpp/pull/15077",
            "subreddit_subscribers": 511885,
            "created_utc": 1754395457,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n72xlby",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "Green-Ad-3964",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n71yolh",
                                                              "score": 2,
                                                              "author_fullname": "t2_sfb08i7a",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "I guess we'll have huge advantages with ddr6 and socamm models, but they are still far away ",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n72xlby",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I guess we&amp;#39;ll have huge advantages with ddr6 and socamm models, but they are still far away &lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72xlby/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754412362,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754412362,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n71yolh",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "jacek2023",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n71wnnh",
                                                    "score": 3,
                                                    "author_fullname": "t2_vqgbql9w",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "But the question was about speed on two 3090s. It depends on your CPU/RAM speed if you offload big part of the model.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n71yolh",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "e": "text",
                                                        "t": "llama.cpp"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But the question was about speed on two 3090s. It depends on your CPU/RAM speed if you offload big part of the model.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi7bem",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "light",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71yolh/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754402307,
                                                    "author_flair_text": "llama.cpp",
                                                    "collapsed": false,
                                                    "created_utc": 1754402307,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "#bbbdbf",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n71wnnh",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Paradigmind",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n71mauj",
                                          "score": 17,
                                          "author_fullname": "t2_6ste18zta",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I would personally prefer a higher quant an lower speeds.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n71wnnh",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would personally prefer a higher quant an lower speeds.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mi7bem",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71wnnh/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754401660,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754401660,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 17
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "richtext",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "text",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": null,
                                                                                            "likes": null,
                                                                                            "replies": "",
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n74bgfe",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": false,
                                                                                            "author": "McSendo",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1754428884,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n7495h2",
                                                                                            "score": 2,
                                                                                            "author_fullname": "t2_2544z5xm",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "Some more stats 16k context:  \nprompt eval time =  161683.19 ms / 16568 tokens (    9.76 ms per token,   102.47 tokens per second)\n\neval time =  104397.18 ms /  1553 tokens (   67.22 ms per token,    14.88 tokens per second)\n\ntotal time =  266080.38 ms / 18121 tokens\n\nIt's usable if you can wait i guess",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n74bgfe",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Some more stats 16k context:&lt;br/&gt;\nprompt eval time =  161683.19 ms / 16568 tokens (    9.76 ms per token,   102.47 tokens per second)&lt;/p&gt;\n\n&lt;p&gt;eval time =  104397.18 ms /  1553 tokens (   67.22 ms per token,    14.88 tokens per second)&lt;/p&gt;\n\n&lt;p&gt;total time =  266080.38 ms / 18121 tokens&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s usable if you can wait i guess&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": null,
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n74bgfe/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1754428884,
                                                                                            "author_flair_text": null,
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1mi7bem",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": null,
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 2
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n7495h2",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": false,
                                                                                  "author": "McSendo",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754428143,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n72713d",
                                                                                  "score": 3,
                                                                                  "author_fullname": "t2_2544z5xm",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "I can also confirm this, 20 tok/s 2x3090, 64gb ddr4 3600  on ancient AM4 X370 chipset.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n7495h2",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can also confirm this, 20 tok/s 2x3090, 64gb ddr4 3600  on ancient AM4 X370 chipset.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mi7bem",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n7495h2/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754428143,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 3
                                                                                }
                                                                              },
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "richtext",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                                                            "likes": null,
                                                                                            "replies": "",
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n728bei",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": false,
                                                                                            "author": "jacek2023",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1754405176,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n727at5",
                                                                                            "score": 5,
                                                                                            "author_fullname": "t2_vqgbql9w",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "If you can't fit model into your GPUs try experimenting with -ts option",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n728bei",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [
                                                                                              {
                                                                                                "e": "text",
                                                                                                "t": "llama.cpp"
                                                                                              }
                                                                                            ],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you can&amp;#39;t fit model into your GPUs try experimenting with -ts option&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": "light",
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n728bei/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1754405176,
                                                                                            "author_flair_text": "llama.cpp",
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1mi7bem",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": "#bbbdbf",
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 5
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n727at5",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": false,
                                                                                  "author": "TacGibs",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754404882,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n72713d",
                                                                                  "score": 2,
                                                                                  "author_fullname": "t2_8w0y7ezw",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "Pretty good speed ! Thanks a lot for your time 👍",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n727at5",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Pretty good speed ! Thanks a lot for your time 👍&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mi7bem",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n727at5/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754404882,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 2
                                                                                }
                                                                              },
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "richtext",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                                                            "likes": null,
                                                                                            "replies": {
                                                                                              "kind": "Listing",
                                                                                              "data": {
                                                                                                "after": null,
                                                                                                "dist": null,
                                                                                                "modhash": "",
                                                                                                "geo_filter": "",
                                                                                                "children": [
                                                                                                  {
                                                                                                    "kind": "t1",
                                                                                                    "data": {
                                                                                                      "subreddit_id": "t5_81eyvm",
                                                                                                      "approved_at_utc": null,
                                                                                                      "author_is_blocked": false,
                                                                                                      "comment_type": null,
                                                                                                      "awarders": [],
                                                                                                      "mod_reason_by": null,
                                                                                                      "banned_by": null,
                                                                                                      "author_flair_type": "text",
                                                                                                      "total_awards_received": 0,
                                                                                                      "subreddit": "LocalLLaMA",
                                                                                                      "author_flair_template_id": null,
                                                                                                      "likes": null,
                                                                                                      "replies": {
                                                                                                        "kind": "Listing",
                                                                                                        "data": {
                                                                                                          "after": null,
                                                                                                          "dist": null,
                                                                                                          "modhash": "",
                                                                                                          "geo_filter": "",
                                                                                                          "children": [
                                                                                                            {
                                                                                                              "kind": "more",
                                                                                                              "data": {
                                                                                                                "count": 0,
                                                                                                                "name": "t1__",
                                                                                                                "id": "_",
                                                                                                                "parent_id": "t1_n72rq2u",
                                                                                                                "depth": 10,
                                                                                                                "children": []
                                                                                                              }
                                                                                                            }
                                                                                                          ],
                                                                                                          "before": null
                                                                                                        }
                                                                                                      },
                                                                                                      "user_reports": [],
                                                                                                      "saved": false,
                                                                                                      "id": "n72rq2u",
                                                                                                      "banned_at_utc": null,
                                                                                                      "mod_reason_title": null,
                                                                                                      "gilded": 0,
                                                                                                      "archived": false,
                                                                                                      "collapsed_reason_code": null,
                                                                                                      "no_follow": false,
                                                                                                      "author": "gofiend",
                                                                                                      "can_mod_post": false,
                                                                                                      "created_utc": 1754410658,
                                                                                                      "send_replies": true,
                                                                                                      "parent_id": "t1_n72prig",
                                                                                                      "score": 1,
                                                                                                      "author_fullname": "t2_2roqrw5l",
                                                                                                      "approved_by": null,
                                                                                                      "mod_note": null,
                                                                                                      "all_awardings": [],
                                                                                                      "collapsed": false,
                                                                                                      "body": "Gotcha I've been debating 4x4 splitting PCI with an AM5 vs. picking up an older threadripper setup. What you have is probably a lot easier to setup and keep running ...",
                                                                                                      "edited": false,
                                                                                                      "top_awarded_type": null,
                                                                                                      "author_flair_css_class": null,
                                                                                                      "name": "t1_n72rq2u",
                                                                                                      "is_submitter": false,
                                                                                                      "downs": 0,
                                                                                                      "author_flair_richtext": [],
                                                                                                      "author_patreon_flair": false,
                                                                                                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Gotcha I&amp;#39;ve been debating 4x4 splitting PCI with an AM5 vs. picking up an older threadripper setup. What you have is probably a lot easier to setup and keep running ...&lt;/p&gt;\n&lt;/div&gt;",
                                                                                                      "removal_reason": null,
                                                                                                      "collapsed_reason": null,
                                                                                                      "distinguished": null,
                                                                                                      "associated_award": null,
                                                                                                      "stickied": false,
                                                                                                      "author_premium": false,
                                                                                                      "can_gild": false,
                                                                                                      "gildings": {},
                                                                                                      "unrepliable_reason": null,
                                                                                                      "author_flair_text_color": null,
                                                                                                      "score_hidden": false,
                                                                                                      "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72rq2u/",
                                                                                                      "subreddit_type": "public",
                                                                                                      "locked": false,
                                                                                                      "report_reasons": null,
                                                                                                      "created": 1754410658,
                                                                                                      "author_flair_text": null,
                                                                                                      "treatment_tags": [],
                                                                                                      "link_id": "t3_1mi7bem",
                                                                                                      "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                                      "controversiality": 0,
                                                                                                      "depth": 9,
                                                                                                      "author_flair_background_color": null,
                                                                                                      "collapsed_because_crowd_control": null,
                                                                                                      "mod_reports": [],
                                                                                                      "num_reports": null,
                                                                                                      "ups": 1
                                                                                                    }
                                                                                                  }
                                                                                                ],
                                                                                                "before": null
                                                                                              }
                                                                                            },
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n72prig",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": false,
                                                                                            "author": "jacek2023",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1754410108,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n72oynt",
                                                                                            "score": 2,
                                                                                            "author_fullname": "t2_vqgbql9w",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "The reason I use the x399 is its 4 PCIe slots and open frame (I replaced a single 3090 with a single 5070 on my i7-13700 DDR5 desktop)\n\nRAM on x399 is much slower, so I am trying not to use too many CPU tensors (and that may be a reason for fourth 3090 in the future)",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n72prig",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [
                                                                                              {
                                                                                                "e": "text",
                                                                                                "t": "llama.cpp"
                                                                                              }
                                                                                            ],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The reason I use the x399 is its 4 PCIe slots and open frame (I replaced a single 3090 with a single 5070 on my i7-13700 DDR5 desktop)&lt;/p&gt;\n\n&lt;p&gt;RAM on x399 is much slower, so I am trying not to use too many CPU tensors (and that may be a reason for fourth 3090 in the future)&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": "light",
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72prig/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1754410108,
                                                                                            "author_flair_text": "llama.cpp",
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1mi7bem",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": "#bbbdbf",
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 2
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n72oynt",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": false,
                                                                                  "author": "gofiend",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754409883,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n72713d",
                                                                                  "score": 2,
                                                                                  "author_fullname": "t2_2roqrw5l",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "Am I right in thinking that your (CPU offload) performance would be no better with a typical desktop DDR5 motherboard? Quad channel DDR4 @ 3200 Mt/s vs dual channel DDR5 @ 6400 Mt/s?",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n72oynt",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Am I right in thinking that your (CPU offload) performance would be no better with a typical desktop DDR5 motherboard? Quad channel DDR4 @ 3200 Mt/s vs dual channel DDR5 @ 6400 Mt/s?&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mi7bem",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72oynt/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754409883,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 2
                                                                                }
                                                                              },
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": "",
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n72tubr",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": false,
                                                                                  "author": "csixtay",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754411256,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n72713d",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_6kjia",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "Wow this is fantastic news.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n72tubr",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wow this is fantastic news.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mi7bem",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72tubr/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754411256,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              },
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": "",
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n76cpbx",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": false,
                                                                                  "author": "RedKnightRG",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754454671,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n72713d",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_tlq31",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "Thanks for this man, nice to see some setups from other folks.    With max ctx-size, flash-attention, and q8 KV cache quantization I have to keep 27 layers on CPU:\n\n\\--ctx-size 131072 \\\\\n\n\\--flash-attn \\\\\n\n\\--n-gpu-layers 99 \\\\\n\n\\--tensor-split 32,14 \\\\\n\n\\--n-cpu-moe 27 \\\\\n\n\\--cache-type-k q8\\_0 \\\\\n\n\\--cache-type-v q8\\_0 \\\\\n\n\\--jinja\n\nI'm seeing about 8 t/s with the above setup on a machine with a Ryzen 9950x and 128GB of DDR5 running at 6000mt/s.   I'm guessing you're seeing similar scaling if you turn up the context?",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n76cpbx",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for this man, nice to see some setups from other folks.    With max ctx-size, flash-attention, and q8 KV cache quantization I have to keep 27 layers on CPU:&lt;/p&gt;\n\n&lt;p&gt;--ctx-size 131072 \\&lt;/p&gt;\n\n&lt;p&gt;--flash-attn \\&lt;/p&gt;\n\n&lt;p&gt;--n-gpu-layers 99 \\&lt;/p&gt;\n\n&lt;p&gt;--tensor-split 32,14 \\&lt;/p&gt;\n\n&lt;p&gt;--n-cpu-moe 27 \\&lt;/p&gt;\n\n&lt;p&gt;--cache-type-k q8_0 \\&lt;/p&gt;\n\n&lt;p&gt;--cache-type-v q8_0 \\&lt;/p&gt;\n\n&lt;p&gt;--jinja&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m seeing about 8 t/s with the above setup on a machine with a Ryzen 9950x and 128GB of DDR5 running at 6000mt/s.   I&amp;#39;m guessing you&amp;#39;re seeing similar scaling if you turn up the context?&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mi7bem",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n76cpbx/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754454671,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n72713d",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": false,
                                                                        "author": "jacek2023",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n7248op",
                                                                        "score": 7,
                                                                        "author_fullname": "t2_vqgbql9w",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "for two 3090s, the magic command is:\n\n`CUDA_VISIBLE_DEVICES=0,1 llama-server -ts 15/8 -ngl 99 -m ~/models/GLM-4.5-Air-UD-Q4_K_XL-00001-of-00002.gguf --n-cpu-moe 18 --jinja --host` [`0.0.0.0`](http://0.0.0.0)\n\nthe memory looks like that:\n\n`load_tensors: offloaded 48/48 layers to GPU`\n\n`load_tensors: CUDA0 model buffer size = 21625.63 MiB`\n\n`load_tensors: CUDA1 model buffer size = 21586.17 MiB`\n\n`load_tensors: CPU_Mapped model buffer size = 25527.93 MiB`\n\n`llama_context: CUDA_Host output buffer size = 0.58 MiB`\n\n`llama_kv_cache_unified: CUDA0 KV buffer size = 512.00 MiB`\n\n`llama_kv_cache_unified: CUDA1 KV buffer size = 224.00 MiB`\n\n`llama_kv_cache_unified: size = 736.00 MiB ( 4096 cells, 46 layers, 1/1 seqs), K (f16): 368.00 MiB, V (f16): 368.00 MiB`\n\n`llama_context: CUDA0 compute buffer size = 862.76 MiB`\n\n`llama_context: CUDA1 compute buffer size = 852.01 MiB`\n\n`llama_context: CUDA_Host compute buffer size = 20.01 MiB`\n\nand the speed is over **20 t/s**\n\n  \nmy setup is:\n\n`jacek@AI-SuperComputer:~$ inxi -CMm`\n\n`Machine:`\n\n  `Type: Desktop Mobo: ASRock model: X399 Taichi serial: &lt;superuser required&gt;`\n\n`UEFI-[Legacy]: American Megatrends v: P4.03 date: 01/18/2024`\n\n`Memory:`\n\n  `System RAM: total: 128 GiB available: 121.43 GiB used: 3.09 GiB (2.5%)`\n\n  `Message: For most reliable report, use superuser + dmidecode.`\n\n  `Array-1: capacity: 512 GiB slots: 8 modules: 4 EC: None`\n\n  `Device-1: Channel-A DIMM 0 type: no module installed`\n\n  `Device-2: Channel-A DIMM 1 type: DDR4 size: 32 GiB speed: 3200 MT/s`\n\n  `Device-3: Channel-B DIMM 0 type: no module installed`\n\n  `Device-4: Channel-B DIMM 1 type: DDR4 size: 32 GiB speed: 3200 MT/s`\n\n  `Device-5: Channel-C DIMM 0 type: no module installed`\n\n  `Device-6: Channel-C DIMM 1 type: DDR4 size: 32 GiB speed: 3200 MT/s`\n\n  `Device-7: Channel-D DIMM 0 type: no module installed`\n\n  `Device-8: Channel-D DIMM 1 type: DDR4 size: 32 GiB speed: 3200 MT/s`\n\n`CPU:`\n\n  `Info: 12-core model: AMD Ryzen Threadripper 1920X bits: 64 type: MT MCP cache: L2: 6 MiB`\n\n  `Speed (MHz): avg: 2208 min/max: 2200/3500 cores: 1: 2208 2: 2208 3: 2208 4: 2208 5: 2208`\n\n`6: 2208 7: 2208 8: 2208 9: 2208 10: 2208 11: 2208 12: 2208 13: 2208 14: 2208 15: 2208 16: 2208`\n\n`17: 2208 18: 2208 19: 2208 20: 2208 21: 2208 22: 2208 23: 2208 24: 2208`\n\n  \nhope that helps",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n72713d",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [
                                                                          {
                                                                            "e": "text",
                                                                            "t": "llama.cpp"
                                                                          }
                                                                        ],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;for two 3090s, the magic command is:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;CUDA_VISIBLE_DEVICES=0,1 llama-server -ts 15/8 -ngl 99 -m ~/models/GLM-4.5-Air-UD-Q4_K_XL-00001-of-00002.gguf --n-cpu-moe 18 --jinja --host&lt;/code&gt; &lt;a href=\"http://0.0.0.0\"&gt;&lt;code&gt;0.0.0.0&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;the memory looks like that:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;load_tensors: offloaded 48/48 layers to GPU&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;load_tensors: CUDA0 model buffer size = 21625.63 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;load_tensors: CUDA1 model buffer size = 21586.17 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;load_tensors: CPU_Mapped model buffer size = 25527.93 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;llama_context: CUDA_Host output buffer size = 0.58 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;llama_kv_cache_unified: CUDA0 KV buffer size = 512.00 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;llama_kv_cache_unified: CUDA1 KV buffer size = 224.00 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;llama_kv_cache_unified: size = 736.00 MiB ( 4096 cells, 46 layers, 1/1 seqs), K (f16): 368.00 MiB, V (f16): 368.00 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;llama_context: CUDA0 compute buffer size = 862.76 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;llama_context: CUDA1 compute buffer size = 852.01 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;llama_context: CUDA_Host compute buffer size = 20.01 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;and the speed is over &lt;strong&gt;20 t/s&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;my setup is:&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;jacek@AI-SuperComputer:~$ inxi -CMm&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Machine:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Type: Desktop Mobo: ASRock model: X399 Taichi serial: &amp;lt;superuser required&amp;gt;&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;UEFI-[Legacy]: American Megatrends v: P4.03 date: 01/18/2024&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Memory:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;System RAM: total: 128 GiB available: 121.43 GiB used: 3.09 GiB (2.5%)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Message: For most reliable report, use superuser + dmidecode.&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Array-1: capacity: 512 GiB slots: 8 modules: 4 EC: None&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Device-1: Channel-A DIMM 0 type: no module installed&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Device-2: Channel-A DIMM 1 type: DDR4 size: 32 GiB speed: 3200 MT/s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Device-3: Channel-B DIMM 0 type: no module installed&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Device-4: Channel-B DIMM 1 type: DDR4 size: 32 GiB speed: 3200 MT/s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Device-5: Channel-C DIMM 0 type: no module installed&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Device-6: Channel-C DIMM 1 type: DDR4 size: 32 GiB speed: 3200 MT/s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Device-7: Channel-D DIMM 0 type: no module installed&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Device-8: Channel-D DIMM 1 type: DDR4 size: 32 GiB speed: 3200 MT/s&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;CPU:&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Info: 12-core model: AMD Ryzen Threadripper 1920X bits: 64 type: MT MCP cache: L2: 6 MiB&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;Speed (MHz): avg: 2208 min/max: 2200/3500 cores: 1: 2208 2: 2208 3: 2208 4: 2208 5: 2208&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;6: 2208 7: 2208 8: 2208 9: 2208 10: 2208 11: 2208 12: 2208 13: 2208 14: 2208 15: 2208 16: 2208&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;17: 2208 18: 2208 19: 2208 20: 2208 21: 2208 22: 2208 23: 2208 24: 2208&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;hope that helps&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mi7bem",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": "light",
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72713d/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754404805,
                                                                        "author_flair_text": "llama.cpp",
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754404805,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": "#bbbdbf",
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 7
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n7248op",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "TacGibs",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n72224w",
                                                              "score": 4,
                                                              "author_fullname": "t2_8w0y7ezw",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Please do it !\n\nI think a lot of people got 2 3090 with DDR4 :)",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n7248op",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Please do it !&lt;/p&gt;\n\n&lt;p&gt;I think a lot of people got 2 3090 with DDR4 :)&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n7248op/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754403982,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754403982,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 4
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n72224w",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "jacek2023",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n721m1o",
                                                    "score": 2,
                                                    "author_fullname": "t2_vqgbql9w",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "As you can see in this discussion another person has an opposite opinion :)\n\nI can test 2x3090 speed for you but as I said, it will be affected by my slow DDR4 RAM on x399",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n72224w",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "e": "text",
                                                        "t": "llama.cpp"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;As you can see in this discussion another person has an opposite opinion :)&lt;/p&gt;\n\n&lt;p&gt;I can test 2x3090 speed for you but as I said, it will be affected by my slow DDR4 RAM on x399&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi7bem",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "light",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72224w/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754403335,
                                                    "author_flair_text": "llama.cpp",
                                                    "collapsed": false,
                                                    "created_utc": 1754403335,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "#bbbdbf",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n721m1o",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "TacGibs",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n71mauj",
                                          "score": 5,
                                          "author_fullname": "t2_8w0y7ezw",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I'm not talking about a lower quant, just what kind of performance you can get using a Q4 with 2 3090 :)\n\nGoing lower than Q4 with only 12B active parameters isn't something goof quality wise !",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n721m1o",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not talking about a lower quant, just what kind of performance you can get using a Q4 with 2 3090 :)&lt;/p&gt;\n\n&lt;p&gt;Going lower than Q4 with only 12B active parameters isn&amp;#39;t something goof quality wise !&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mi7bem",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n721m1o/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754403201,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754403201,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 5
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n71mauj",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "jacek2023",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n71l008",
                                "score": 7,
                                "author_fullname": "t2_vqgbql9w",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It's easy: you just need to use a lower quant (smaller file).  \nfor the same file, you’d need to offload the difference to the CPU, so you need fast CPU/RAM",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n71mauj",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s easy: you just need to use a lower quant (smaller file).&lt;br/&gt;\nfor the same file, you’d need to offload the difference to the CPU, so you need fast CPU/RAM&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi7bem",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71mauj/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754398221,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754398221,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 7
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n71l008",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "TacGibs",
                      "can_mod_post": false,
                      "created_utc": 1754397765,
                      "send_replies": true,
                      "parent_id": "t1_n71htev",
                      "score": 12,
                      "author_fullname": "t2_8w0y7ezw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Would love to know how much t/s you can get on 2 3090 !",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n71l008",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Would love to know how much t/s you can get on 2 3090 !&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi7bem",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71l008/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754397765,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 12
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "total_awards_received": 0,
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "ups": 2,
                      "removal_reason": null,
                      "link_id": "t3_1mi7bem",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "total_awards_received": 0,
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "ups": 1,
                                          "removal_reason": null,
                                          "link_id": "t3_1mi7bem",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n72n2mu",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "Tx3hc78",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n72h23z",
                                                              "score": 1,
                                                              "author_fullname": "t2_5t6qmknj",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Turns out I'm smooth brained. Removed comments to avoid causing more confusion.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n72n2mu",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Turns out I&amp;#39;m smooth brained. Removed comments to avoid causing more confusion.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72n2mu/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754409357,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754409357,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n72h23z",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "jacek2023",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n72covu",
                                                    "score": 1,
                                                    "author_fullname": "t2_vqgbql9w",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "I don't really understand why you are comparing 10 with 30, please explain, maybe I am missing something (GLM has 47 layers)",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n72h23z",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "e": "text",
                                                        "t": "llama.cpp"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t really understand why you are comparing 10 with 30, please explain, maybe I am missing something (GLM has 47 layers)&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi7bem",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "light",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72h23z/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754407680,
                                                    "author_flair_text": "llama.cpp",
                                                    "collapsed": false,
                                                    "created_utc": 1754407680,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "#bbbdbf",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n72covu",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": "DELETED",
                                          "no_follow": false,
                                          "author": "[deleted]",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n72baqx",
                                          "score": 1,
                                          "approved_by": null,
                                          "report_reasons": null,
                                          "all_awardings": [],
                                          "subreddit_id": "t5_81eyvm",
                                          "body": "[deleted]",
                                          "edited": 1754406625,
                                          "downs": 0,
                                          "author_flair_css_class": null,
                                          "collapsed": true,
                                          "is_submitter": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "subreddit_type": "public",
                                          "can_gild": false,
                                          "top_awarded_type": null,
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "dark",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72covu/",
                                          "num_reports": null,
                                          "locked": false,
                                          "name": "t1_n72covu",
                                          "created": 1754406434,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754406434,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "mod_note": null,
                                          "distinguished": null
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n72baqx",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "jacek2023",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n72b22e",
                                "score": 1,
                                "author_fullname": "t2_vqgbql9w",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "could you test both cases?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n72baqx",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;could you test both cases?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi7bem",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72baqx/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754406032,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754406032,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n72b22e",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "DELETED",
                      "no_follow": false,
                      "author": "[deleted]",
                      "can_mod_post": false,
                      "send_replies": true,
                      "parent_id": "t1_n71htev",
                      "score": 2,
                      "approved_by": null,
                      "report_reasons": null,
                      "all_awardings": [],
                      "subreddit_id": "t5_81eyvm",
                      "body": "[deleted]",
                      "edited": 1754406646,
                      "author_flair_css_class": null,
                      "collapsed": true,
                      "downs": 0,
                      "is_submitter": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "associated_award": null,
                      "stickied": false,
                      "subreddit_type": "public",
                      "can_gild": false,
                      "top_awarded_type": null,
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72b22e/",
                      "num_reports": null,
                      "locked": false,
                      "name": "t1_n72b22e",
                      "created": 1754405964,
                      "subreddit": "LocalLLaMA",
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "created_utc": 1754405964,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "mod_note": null,
                      "distinguished": null
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "richtext",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "richtext",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                                                                            "likes": null,
                                                                                            "replies": "",
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n720tsz",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": false,
                                                                                            "author": "jacek2023",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1754402966,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n71zg4c",
                                                                                            "score": 1,
                                                                                            "author_fullname": "t2_vqgbql9w",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "I read paper from Nvidia that small models are enough for agents, by small they mean like 4-12B. That's another topic I need to explore - to run a swarm of models on my computer :)",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n720tsz",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [
                                                                                              {
                                                                                                "e": "text",
                                                                                                "t": "llama.cpp"
                                                                                              }
                                                                                            ],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I read paper from Nvidia that small models are enough for agents, by small they mean like 4-12B. That&amp;#39;s another topic I need to explore - to run a swarm of models on my computer :)&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": "light",
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n720tsz/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1754402966,
                                                                                            "author_flair_text": "llama.cpp",
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1mi7bem",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": "#bbbdbf",
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 1
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n71zg4c",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": false,
                                                                                  "author": "LagOps91",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754402546,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n71yaql",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_3wi6j7vwh",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "different models have different strengths, that's true. I am also curious if mistral will also release MoE models in the future.\n\nas for perplexity, it's a decent enough proxy for quality, at least if the perplexity drop is very low. for R1 in particular i have heard that even the Q2 quants offer high quality in practice and are sometimes even preferred as they run faster due to the smaller memory footprint (and thus smaller reads).\n\ni can't confirm any of that tho, since i can't run the model on my setup. but as i said, Q4 was perfectly fine for me when using dense 32b models. it makes the most out of my hardware as smaller models at a higher quant are typically worse.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n71zg4c",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;different models have different strengths, that&amp;#39;s true. I am also curious if mistral will also release MoE models in the future.&lt;/p&gt;\n\n&lt;p&gt;as for perplexity, it&amp;#39;s a decent enough proxy for quality, at least if the perplexity drop is very low. for R1 in particular i have heard that even the Q2 quants offer high quality in practice and are sometimes even preferred as they run faster due to the smaller memory footprint (and thus smaller reads).&lt;/p&gt;\n\n&lt;p&gt;i can&amp;#39;t confirm any of that tho, since i can&amp;#39;t run the model on my setup. but as i said, Q4 was perfectly fine for me when using dense 32b models. it makes the most out of my hardware as smaller models at a higher quant are typically worse.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mi7bem",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71zg4c/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754402546,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n71yaql",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": false,
                                                                        "author": "jacek2023",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n71wo6e",
                                                                        "score": 2,
                                                                        "author_fullname": "t2_vqgbql9w",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "Thanks for reminding me that I must explore perplexity more :)\n\nAs for differences you can find that a very unpopular llama scout is better than qwen 32B because qwen has no as much knowledge about western culture and maybe you need that in your prompt. That's why I would like to see Mistral MoE. But maybe the OpenAI model will be released soon?\n\nLargest model I run is 235B and I use Q3",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n71yaql",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [
                                                                          {
                                                                            "e": "text",
                                                                            "t": "llama.cpp"
                                                                          }
                                                                        ],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for reminding me that I must explore perplexity more :)&lt;/p&gt;\n\n&lt;p&gt;As for differences you can find that a very unpopular llama scout is better than qwen 32B because qwen has no as much knowledge about western culture and maybe you need that in your prompt. That&amp;#39;s why I would like to see Mistral MoE. But maybe the OpenAI model will be released soon?&lt;/p&gt;\n\n&lt;p&gt;Largest model I run is 235B and I use Q3&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mi7bem",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": "light",
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71yaql/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754402186,
                                                                        "author_flair_text": "llama.cpp",
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754402186,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": "#bbbdbf",
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 2
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n71wo6e",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "LagOps91",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n71sxrg",
                                                              "score": 1,
                                                              "author_fullname": "t2_3wi6j7vwh",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "yes. the most testing has been done for the large qwen moe and particularly r1. here are some results: [https://www.reddit.com/r/LocalLLaMA/comments/1lz1s8x/some\\_small\\_ppl\\_benchmarks\\_on\\_deepseek\\_r1\\_0528/](https://www.reddit.com/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/)\n\nas you can see, Q4 quants are just barely (0.5%-1.5%) worse than the Q8 quant. there really is no point at all in sacreficing speed to get a tiny bit of quality (unless you do coding, i did hear it makes a difference for that, but don't have any benchmark numbers on it).\n\nnow, GLM-4.5 air is a smaller model and it's not yet known how the quant quality looks like, but i am personally running dense 32b models are Q4 and that is already entirely fine. i can't imagine it being any worse for GLM-4.5 air.",
                                                              "edited": 1754402228,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n71wo6e",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yes. the most testing has been done for the large qwen moe and particularly r1. here are some results: &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/\"&gt;https://www.reddit.com/r/LocalLLaMA/comments/1lz1s8x/some_small_ppl_benchmarks_on_deepseek_r1_0528/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;as you can see, Q4 quants are just barely (0.5%-1.5%) worse than the Q8 quant. there really is no point at all in sacreficing speed to get a tiny bit of quality (unless you do coding, i did hear it makes a difference for that, but don&amp;#39;t have any benchmark numbers on it).&lt;/p&gt;\n\n&lt;p&gt;now, GLM-4.5 air is a smaller model and it&amp;#39;s not yet known how the quant quality looks like, but i am personally running dense 32b models are Q4 and that is already entirely fine. i can&amp;#39;t imagine it being any worse for GLM-4.5 air.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71wo6e/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754401665,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754401665,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n71sxrg",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "jacek2023",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n71sfrk",
                                                    "score": 6,
                                                    "author_fullname": "t2_vqgbql9w",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Do you have some specific test results explaining why there is no big difference between Q4 and Q6 for bigger models?",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n71sxrg",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "e": "text",
                                                        "t": "llama.cpp"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you have some specific test results explaining why there is no big difference between Q4 and Q6 for bigger models?&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi7bem",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "light",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71sxrg/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754400446,
                                                    "author_flair_text": "llama.cpp",
                                                    "collapsed": false,
                                                    "created_utc": 1754400446,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "#bbbdbf",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 6
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n71xr3p",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "LagOps91",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n71w33h",
                                                              "score": 1,
                                                              "author_fullname": "t2_3wi6j7vwh",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "that's true - but in this case Q5 and Q6 don't help either. And in the post we are talking to going from Q4 XL to Q4 M... there really hardly is any difference there. i see no reason not to do it if it helps me avoid offloading to ram.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n71xr3p",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;that&amp;#39;s true - but in this case Q5 and Q6 don&amp;#39;t help either. And in the post we are talking to going from Q4 XL to Q4 M... there really hardly is any difference there. i see no reason not to do it if it helps me avoid offloading to ram.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71xr3p/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754402012,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754402012,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          },
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n72jark",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "skrshawk",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n71w33h",
                                                              "score": 1,
                                                              "author_fullname": "t2_36e47",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "In the case of Qwen 235B using Unsloth Q3 I find sufficient since the gates that need higher quants to avoid quality degradation are already there.\n\nAlso if for general/writing purposes I find using 8-bit KV cache to be fine but I would not want to do that for code for the same reason, syntax will break.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n72jark",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In the case of Qwen 235B using Unsloth Q3 I find sufficient since the gates that need higher quants to avoid quality degradation are already there.&lt;/p&gt;\n\n&lt;p&gt;Also if for general/writing purposes I find using 8-bit KV cache to be fine but I would not want to do that for code for the same reason, syntax will break.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72jark/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754408313,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754408313,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          },
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n722elo",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "CheatCodesOfLife",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n71w33h",
                                                              "score": 1,
                                                              "author_fullname": "t2_32el727b",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Weirdly, I disagree with this. Code gen seems less affected than creative writing. It's more subtle but the prose is significantly worse with smaller quants.\n\nI also noticed you get a much larger speed boost coding vs writing (more acceptance from the draft model).\n\nNote: This is with R1 and Comamnd-A, I haven't compared glm4.5 or Qwen3 yet.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n722elo",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Weirdly, I disagree with this. Code gen seems less affected than creative writing. It&amp;#39;s more subtle but the prose is significantly worse with smaller quants.&lt;/p&gt;\n\n&lt;p&gt;I also noticed you get a much larger speed boost coding vs writing (more acceptance from the draft model).&lt;/p&gt;\n\n&lt;p&gt;Note: This is with R1 and Comamnd-A, I haven&amp;#39;t compared glm4.5 or Qwen3 yet.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n722elo/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754403438,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754403438,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n71w33h",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "Whatforit1",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n71sfrk",
                                                    "score": 3,
                                                    "author_fullname": "t2_14nrn5",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Depends on the use case IMO. For creative writing/general chat, Q4 is typically fine. If you're using it for code gen, the loss of precision can lead to malformed/invalid syntax. The typical suggesting for code is Q8",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n71w33h",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Depends on the use case IMO. For creative writing/general chat, Q4 is typically fine. If you&amp;#39;re using it for code gen, the loss of precision can lead to malformed/invalid syntax. The typical suggesting for code is Q8&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi7bem",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71w33h/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754401474,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754401474,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": {
                                                                                    "kind": "Listing",
                                                                                    "data": {
                                                                                      "after": null,
                                                                                      "dist": null,
                                                                                      "modhash": "",
                                                                                      "geo_filter": "",
                                                                                      "children": [
                                                                                        {
                                                                                          "kind": "t1",
                                                                                          "data": {
                                                                                            "subreddit_id": "t5_81eyvm",
                                                                                            "approved_at_utc": null,
                                                                                            "author_is_blocked": false,
                                                                                            "comment_type": null,
                                                                                            "awarders": [],
                                                                                            "mod_reason_by": null,
                                                                                            "banned_by": null,
                                                                                            "author_flair_type": "text",
                                                                                            "total_awards_received": 0,
                                                                                            "subreddit": "LocalLLaMA",
                                                                                            "author_flair_template_id": null,
                                                                                            "likes": null,
                                                                                            "replies": "",
                                                                                            "user_reports": [],
                                                                                            "saved": false,
                                                                                            "id": "n72b2g7",
                                                                                            "banned_at_utc": null,
                                                                                            "mod_reason_title": null,
                                                                                            "gilded": 0,
                                                                                            "archived": false,
                                                                                            "collapsed_reason_code": null,
                                                                                            "no_follow": false,
                                                                                            "author": "Paradigmind",
                                                                                            "can_mod_post": false,
                                                                                            "created_utc": 1754405967,
                                                                                            "send_replies": true,
                                                                                            "parent_id": "t1_n722u2e",
                                                                                            "score": 1,
                                                                                            "author_fullname": "t2_6ste18zta",
                                                                                            "approved_by": null,
                                                                                            "mod_note": null,
                                                                                            "all_awardings": [],
                                                                                            "body": "Ah okay thanks for clarifying.",
                                                                                            "edited": false,
                                                                                            "gildings": {},
                                                                                            "downs": 0,
                                                                                            "author_flair_css_class": null,
                                                                                            "name": "t1_n72b2g7",
                                                                                            "is_submitter": false,
                                                                                            "collapsed": false,
                                                                                            "author_flair_richtext": [],
                                                                                            "author_patreon_flair": false,
                                                                                            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah okay thanks for clarifying.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                            "removal_reason": null,
                                                                                            "collapsed_reason": null,
                                                                                            "distinguished": null,
                                                                                            "associated_award": null,
                                                                                            "stickied": false,
                                                                                            "author_premium": false,
                                                                                            "can_gild": false,
                                                                                            "top_awarded_type": null,
                                                                                            "unrepliable_reason": null,
                                                                                            "author_flair_text_color": null,
                                                                                            "score_hidden": false,
                                                                                            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72b2g7/",
                                                                                            "subreddit_type": "public",
                                                                                            "locked": false,
                                                                                            "report_reasons": null,
                                                                                            "created": 1754405967,
                                                                                            "author_flair_text": null,
                                                                                            "treatment_tags": [],
                                                                                            "link_id": "t3_1mi7bem",
                                                                                            "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                            "controversiality": 0,
                                                                                            "depth": 8,
                                                                                            "author_flair_background_color": null,
                                                                                            "collapsed_because_crowd_control": null,
                                                                                            "mod_reports": [],
                                                                                            "num_reports": null,
                                                                                            "ups": 1
                                                                                          }
                                                                                        }
                                                                                      ],
                                                                                      "before": null
                                                                                    }
                                                                                  },
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n722u2e",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": false,
                                                                                  "author": "CheatCodesOfLife",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754403565,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n71y03k",
                                                                                  "score": 6,
                                                                                  "author_fullname": "t2_32el727b",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "You didn't mix it up. People *were* saying this. But from what I could tell, it was an assumption (eg. Mixtral being degraded as much as a 7b model vs llama-2-70b).\n\nIt doesn't seem to hold up though.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n722u2e",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You didn&amp;#39;t mix it up. People &lt;em&gt;were&lt;/em&gt; saying this. But from what I could tell, it was an assumption (eg. Mixtral being degraded as much as a 7b model vs llama-2-70b).&lt;/p&gt;\n\n&lt;p&gt;It doesn&amp;#39;t seem to hold up though.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mi7bem",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n722u2e/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754403565,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 6
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n71y03k",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": false,
                                                                        "author": "Paradigmind",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n71xjqs",
                                                                        "score": 2,
                                                                        "author_fullname": "t2_6ste18zta",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "Maybe I mixed something up.",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n71y03k",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe I mixed something up.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mi7bem",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71y03k/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754402093,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754402093,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 2
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n71xjqs",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "LagOps91",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n71wyjc",
                                                              "score": 2,
                                                              "author_fullname": "t2_3wi6j7vwh",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "really? the data doesn't seem to support this. especially for models with shared experts you can simply quant those at higher bits while lowering overall size.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n71xjqs",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;really? the data doesn&amp;#39;t seem to support this. especially for models with shared experts you can simply quant those at higher bits while lowering overall size.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71xjqs/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754401947,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754401947,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n71wyjc",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "Paradigmind",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n71sfrk",
                                                    "score": 1,
                                                    "author_fullname": "t2_6ste18zta",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "People were saying that MoE is more prone to degradation from lower quants.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n71wyjc",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;People were saying that MoE is more prone to degradation from lower quants.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi7bem",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71wyjc/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754401758,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754401758,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n71sfrk",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": "LOW_SCORE",
                                          "no_follow": false,
                                          "author": "LagOps91",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n71rv5n",
                                          "score": -8,
                                          "author_fullname": "t2_3wi6j7vwh",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": true,
                                          "body": "you could just use Q4\\_K\\_M or something, hardly any different. you don't need to drop to Q3.\n\nQ5/Q6 for a model of this size should hardly make a difference.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n71sfrk",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;you could just use Q4_K_M or something, hardly any different. you don&amp;#39;t need to drop to Q3.&lt;/p&gt;\n\n&lt;p&gt;Q5/Q6 for a model of this size should hardly make a difference.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": "comment score below threshold",
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mi7bem",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71sfrk/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754400282,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754400282,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -8
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n71rv5n",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "jacek2023",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n71r2ug",
                                "score": 18,
                                "author_fullname": "t2_vqgbql9w",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Because smaller quant means worse quality.\n\nMy result shows that I should use Q5 or Q6, but because files are huge it takes both time and disk space, so I must explore slowly.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n71rv5n",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Because smaller quant means worse quality.&lt;/p&gt;\n\n&lt;p&gt;My result shows that I should use Q5 or Q6, but because files are huge it takes both time and disk space, so I must explore slowly.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi7bem",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71rv5n/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754400093,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1754400093,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 18
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n71r2ug",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "LagOps91",
                      "can_mod_post": false,
                      "created_utc": 1754399832,
                      "send_replies": true,
                      "parent_id": "t1_n71htev",
                      "score": -2,
                      "author_fullname": "t2_3wi6j7vwh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "why not have a slightly smaller quant and offload nothing to cpu?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n71r2ug",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;why not have a slightly smaller quant and offload nothing to cpu?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi7bem",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71r2ug/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754399832,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n71htev",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "jacek2023",
            "can_mod_post": false,
            "created_utc": 1754396603,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 76,
            "author_fullname": "t2_vqgbql9w",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "My name was mentioned ;) so I tested it today in the morning with GLM\n\n`llama-server -ts 18/17/18 -ngl 99 -m ~/models/GLM-4.5-Air-UD-Q4_K_XL-00001-of-00002.gguf --n-cpu-moe 2 --jinja --host` [`0.0.0.0`](http://0.0.0.0)\n\n  \nI am getting over 45 t/s on 3x3090",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n71htev",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My name was mentioned ;) so I tested it today in the morning with GLM&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;llama-server -ts 18/17/18 -ngl 99 -m ~/models/GLM-4.5-Air-UD-Q4_K_XL-00001-of-00002.gguf --n-cpu-moe 2 --jinja --host&lt;/code&gt; &lt;a href=\"http://0.0.0.0\"&gt;&lt;code&gt;0.0.0.0&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I am getting over 45 t/s on 3x3090&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71htev/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754396603,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 76
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n71fctg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Muted-Celebration-47",
            "can_mod_post": false,
            "created_utc": 1754395681,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 19,
            "author_fullname": "t2_q2qi86l3f",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yeah, I found this way is easier than find the best -ot by yourself. This --n-cpu-moe option is perfect fit with GLM4.5-Air gguf case.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n71fctg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, I found this way is easier than find the best -ot by yourself. This --n-cpu-moe option is perfect fit with GLM4.5-Air gguf case.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71fctg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754395681,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 19
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n71qy16",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "LagOps91",
            "can_mod_post": false,
            "created_utc": 1754399788,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 14,
            "author_fullname": "t2_3wi6j7vwh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "it's so simple to implement... man... and here i was reading up on tensor offloading. thanks for adding this!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n71qy16",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it&amp;#39;s so simple to implement... man... and here i was reading up on tensor offloading. thanks for adding this!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71qy16/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754399788,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 14
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": {
                                                                          "kind": "Listing",
                                                                          "data": {
                                                                            "after": null,
                                                                            "dist": null,
                                                                            "modhash": "",
                                                                            "geo_filter": "",
                                                                            "children": [
                                                                              {
                                                                                "kind": "t1",
                                                                                "data": {
                                                                                  "subreddit_id": "t5_81eyvm",
                                                                                  "approved_at_utc": null,
                                                                                  "author_is_blocked": false,
                                                                                  "comment_type": null,
                                                                                  "awarders": [],
                                                                                  "mod_reason_by": null,
                                                                                  "banned_by": null,
                                                                                  "author_flair_type": "text",
                                                                                  "total_awards_received": 0,
                                                                                  "subreddit": "LocalLLaMA",
                                                                                  "author_flair_template_id": null,
                                                                                  "distinguished": null,
                                                                                  "likes": null,
                                                                                  "replies": "",
                                                                                  "user_reports": [],
                                                                                  "saved": false,
                                                                                  "id": "n77uxnq",
                                                                                  "banned_at_utc": null,
                                                                                  "mod_reason_title": null,
                                                                                  "gilded": 0,
                                                                                  "archived": false,
                                                                                  "collapsed_reason_code": null,
                                                                                  "no_follow": false,
                                                                                  "author": "DistanceSolar1449",
                                                                                  "can_mod_post": false,
                                                                                  "created_utc": 1754482213,
                                                                                  "send_replies": true,
                                                                                  "parent_id": "t1_n77l6rq",
                                                                                  "score": 1,
                                                                                  "author_fullname": "t2_1utnp17o3h",
                                                                                  "approved_by": null,
                                                                                  "mod_note": null,
                                                                                  "all_awardings": [],
                                                                                  "body": "&gt; Nope, you can use --tensor-split and the -ot regex to keep the KV cache on box1, fill the GPUs on box2 with expert tensors and avoid sending the kv cache over the network.\n\nThat’s… not how it works.\n\nFirst off, llama.cpp automatically stores the kv cache with the compute. So for layers in gpu, the kv cache is in gpu. For layers on cpu, kv cache is in system ram. kv_cache_init() always allocates K &amp; V on the same backend as the layer’s attention weights, so layers on RPC back-ends keep their KV on that remote GPU; layers on the host keep KV in system RAM.\n\n\nSecondly, there is a kv cache for each layer. KV_cache = (Key + Value) = 2 × num_heads × head_dim × dtype_size. \nSo for something like Qwen3 235b, you get 73.7KB per layer per token. The transformer architecture literally demands you do matmuls to multiply the kv cache for that layer with the attention weights of that layer, so you can’t win- if they’re stored on different devices, then either you transfer the kv cache over, or you transfer the weights over.",
                                                                                  "edited": false,
                                                                                  "gildings": {},
                                                                                  "author_flair_css_class": null,
                                                                                  "name": "t1_n77uxnq",
                                                                                  "is_submitter": false,
                                                                                  "downs": 0,
                                                                                  "author_flair_richtext": [],
                                                                                  "author_patreon_flair": false,
                                                                                  "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt; Nope, you can use --tensor-split and the -ot regex to keep the KV cache on box1, fill the GPUs on box2 with expert tensors and avoid sending the kv cache over the network.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;That’s… not how it works.&lt;/p&gt;\n\n&lt;p&gt;First off, llama.cpp automatically stores the kv cache with the compute. So for layers in gpu, the kv cache is in gpu. For layers on cpu, kv cache is in system ram. kv_cache_init() always allocates K &amp;amp; V on the same backend as the layer’s attention weights, so layers on RPC back-ends keep their KV on that remote GPU; layers on the host keep KV in system RAM.&lt;/p&gt;\n\n&lt;p&gt;Secondly, there is a kv cache for each layer. KV_cache = (Key + Value) = 2 × num_heads × head_dim × dtype_size. \nSo for something like Qwen3 235b, you get 73.7KB per layer per token. The transformer architecture literally demands you do matmuls to multiply the kv cache for that layer with the attention weights of that layer, so you can’t win- if they’re stored on different devices, then either you transfer the kv cache over, or you transfer the weights over.&lt;/p&gt;\n&lt;/div&gt;",
                                                                                  "removal_reason": null,
                                                                                  "collapsed_reason": null,
                                                                                  "link_id": "t3_1mi7bem",
                                                                                  "associated_award": null,
                                                                                  "stickied": false,
                                                                                  "author_premium": false,
                                                                                  "can_gild": false,
                                                                                  "top_awarded_type": null,
                                                                                  "unrepliable_reason": null,
                                                                                  "author_flair_text_color": null,
                                                                                  "score_hidden": false,
                                                                                  "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n77uxnq/",
                                                                                  "subreddit_type": "public",
                                                                                  "locked": false,
                                                                                  "report_reasons": null,
                                                                                  "created": 1754482213,
                                                                                  "author_flair_text": null,
                                                                                  "treatment_tags": [],
                                                                                  "collapsed": false,
                                                                                  "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                                  "controversiality": 0,
                                                                                  "depth": 7,
                                                                                  "author_flair_background_color": null,
                                                                                  "collapsed_because_crowd_control": null,
                                                                                  "mod_reports": [],
                                                                                  "num_reports": null,
                                                                                  "ups": 1
                                                                                }
                                                                              }
                                                                            ],
                                                                            "before": null
                                                                          }
                                                                        },
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n77l6rq",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": false,
                                                                        "author": "CheatCodesOfLife",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n77i6a2",
                                                                        "score": 1,
                                                                        "author_fullname": "t2_32el727b",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "&gt; It’s not optimizable.\n\nIt is; running box1[4x3090] box2[2x3090] with vllm, is very fast with either -tp 2 -pp 3, or just -pp 6. Almost no loss in speed compared with box1[6x3090]\n\n&gt;  Prompt processing has to be machine 1 process layers 1-30, network transfer the kv cache, machine 2 processes layers 31-60, transfers the modified kvcache back, rinse repeat.\n\nNope, you can use --tensor-split and the -ot regex to keep the KV cache on box1, fill the GPUs on box2 with expert tensors and avoid sending the kv cache over the network.\n\n&gt; This is a limitation of the transformers architecture. You can’t fix this.\n\nI can't fix this because I'm not smart enough, but it can be done, big labs setup multiple nodes of 8xH100 to serve 1 model.\n\nEdit: I've also been able to train large models across nvidia GPUs over the network.",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n77l6rq",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It’s not optimizable.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It is; running box1[4x3090] box2[2x3090] with vllm, is very fast with either -tp 2 -pp 3, or just -pp 6. Almost no loss in speed compared with box1[6x3090]&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Prompt processing has to be machine 1 process layers 1-30, network transfer the kv cache, machine 2 processes layers 31-60, transfers the modified kvcache back, rinse repeat.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Nope, you can use --tensor-split and the -ot regex to keep the KV cache on box1, fill the GPUs on box2 with expert tensors and avoid sending the kv cache over the network.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;This is a limitation of the transformers architecture. You can’t fix this.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I can&amp;#39;t fix this because I&amp;#39;m not smart enough, but it can be done, big labs setup multiple nodes of 8xH100 to serve 1 model.&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;ve also been able to train large models across nvidia GPUs over the network.&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mi7bem",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n77l6rq/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754478174,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754478174,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 1
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n77i6a2",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "DistanceSolar1449",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n723e7o",
                                                              "score": 1,
                                                              "author_fullname": "t2_1utnp17o3h",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "It’s not optimizable. You cant transfer data in parallel.\n\nPrompt processing **has to be** machine 1 process layers 1-30, network transfer the kv cache, machine 2 processes layers 31-60, transfers the modified kvcache back, rinse repeat.\n\nNotice this means the network is idle while the GPUs are running, and the GPUs are idle while the network is transferring.\n\nThis is a limitation of the transformers architecture. You can’t fix this.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n77i6a2",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It’s not optimizable. You cant transfer data in parallel.&lt;/p&gt;\n\n&lt;p&gt;Prompt processing &lt;strong&gt;has to be&lt;/strong&gt; machine 1 process layers 1-30, network transfer the kv cache, machine 2 processes layers 31-60, transfers the modified kvcache back, rinse repeat.&lt;/p&gt;\n\n&lt;p&gt;Notice this means the network is idle while the GPUs are running, and the GPUs are idle while the network is transferring.&lt;/p&gt;\n\n&lt;p&gt;This is a limitation of the transformers architecture. You can’t fix this.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n77i6a2/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754476757,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754476757,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n723e7o",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "CheatCodesOfLife",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n71ye4d",
                                                    "score": 3,
                                                    "author_fullname": "t2_32el727b",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Latency specifically. I was using this to fully offload R1 to GPUs,  and found my prompt processing was capped at about 12t/s. Ended up faster to use the CPU + local GPUs.\n\nBut network traffic was nowhere near the 2.5gbit link limit.\n\nI hope they optimize this in the future as vllm is fast when running across multiple machines (meaning there's room for optimization).",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n723e7o",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Latency specifically. I was using this to fully offload R1 to GPUs,  and found my prompt processing was capped at about 12t/s. Ended up faster to use the CPU + local GPUs.&lt;/p&gt;\n\n&lt;p&gt;But network traffic was nowhere near the 2.5gbit link limit.&lt;/p&gt;\n\n&lt;p&gt;I hope they optimize this in the future as vllm is fast when running across multiple machines (meaning there&amp;#39;s room for optimization).&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi7bem",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n723e7o/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754403732,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754403732,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n71ye4d",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "segmond",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n71rc3o",
                                          "score": 1,
                                          "author_fullname": "t2_ah13x",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "it makes it possible to run models you won't be able to run, but network bandwidth/latency is a thing!  it's the difference between 0tk/sec and 3tk/sec.  Pick one.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n71ye4d",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "e": "text",
                                              "t": "llama.cpp"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it makes it possible to run models you won&amp;#39;t be able to run, but network bandwidth/latency is a thing!  it&amp;#39;s the difference between 0tk/sec and 3tk/sec.  Pick one.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mi7bem",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "light",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71ye4d/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754402215,
                                          "author_flair_text": "llama.cpp",
                                          "treatment_tags": [],
                                          "created_utc": 1754402215,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "#bbbdbf",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n71rc3o",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "johnerp",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n71jgqd",
                                "score": 2,
                                "author_fullname": "t2_100h8g",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Oh interesting, didn’t know this was a thing I assume network bandwidth / latency would prevent this. Does it work due to different requirements when handing off been components of an LLM architecture?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n71rc3o",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh interesting, didn’t know this was a thing I assume network bandwidth / latency would prevent this. Does it work due to different requirements when handing off been components of an LLM architecture?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi7bem",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71rc3o/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754399916,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754399916,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n71jgqd",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Zyguard7777777",
                      "can_mod_post": false,
                      "created_utc": 1754397210,
                      "send_replies": true,
                      "parent_id": "t1_n71hl3x",
                      "score": 5,
                      "author_fullname": "t2_zo1h5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "You can use llama.cpp's RPC feature, https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n71jgqd",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can use llama.cpp&amp;#39;s RPC feature, &lt;a href=\"https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc%C2%A0\"&gt;https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc &lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi7bem",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71jgqd/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754397210,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n71hl3x",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "thenomadexplorerlife",
            "can_mod_post": false,
            "created_utc": 1754396518,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 9,
            "author_fullname": "t2_ftxyqwjr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This seems a good enhancement! Just curious and may be a bit off-topic, is there a way to do something similar using two machines? For example, I have a Mac mini 64GB RAM and another linux laptop with 32GB RAM. It would be nice if I can run some layers in Mac GPU and remaining layers in linux laptop. This will allow me to run larger models by combining the RAM of two machines to load the model. New models are becoming bigger and buying a new machine with more RAM is out of budget for me.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n71hl3x",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This seems a good enhancement! Just curious and may be a bit off-topic, is there a way to do something similar using two machines? For example, I have a Mac mini 64GB RAM and another linux laptop with 32GB RAM. It would be nice if I can run some layers in Mac GPU and remaining layers in linux laptop. This will allow me to run larger models by combining the RAM of two machines to load the model. New models are becoming bigger and buying a new machine with more RAM is out of budget for me.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71hl3x/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754396518,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "a8acc9bc-4792-11ee-b77d-c61a47557e59",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "a8acc9bc-4792-11ee-b77d-c61a47557e59",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n76lm3k",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "arousedsquirel",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n74z67s",
                                          "score": -1,
                                          "author_fullname": "t2_509a63kb",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "If your group thinks so, yet it is about llama.cpp, not promoting a derivate.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n76lm3k",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If your group thinks so, yet it is about llama.cpp, not promoting a derivate.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mi7bem",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n76lm3k/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754458932,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754458932,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n74z67s",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "henk717",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7457ku",
                                "score": 9,
                                "author_fullname": "t2_bx8b9",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I'm not allowed to tell users that we will be implementing this when we are based on llamacpp?\n\n\n2 people asked me about it today, so I figured i'd let people know what our plans are as far as this PR go since KoboldCpp is based on llamacpp but its not a given that projects implement this feature.\n\n\nTo me its an on topic comment since it relates to this PR and people have been asking. So I don't see why giving official confirmation we will implement this command (and by which command line argument we will be adding it) is a bad thing.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n74z67s",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "KoboldAI"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not allowed to tell users that we will be implementing this when we are based on llamacpp?&lt;/p&gt;\n\n&lt;p&gt;2 people asked me about it today, so I figured i&amp;#39;d let people know what our plans are as far as this PR go since KoboldCpp is based on llamacpp but its not a given that projects implement this feature.&lt;/p&gt;\n\n&lt;p&gt;To me its an on topic comment since it relates to this PR and people have been asking. So I don&amp;#39;t see why giving official confirmation we will implement this command (and by which command line argument we will be adding it) is a bad thing.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi7bem",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n74z67s/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754436684,
                                "author_flair_text": "KoboldAI",
                                "treatment_tags": [],
                                "created_utc": 1754436684,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#5a74cc",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 9
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7457ku",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": false,
                      "author": "arousedsquirel",
                      "can_mod_post": false,
                      "created_utc": 1754426892,
                      "send_replies": true,
                      "parent_id": "t1_n73w4oe",
                      "score": -7,
                      "author_fullname": "t2_509a63kb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It's about llama.ccp not kobold promotion dude. So what about llama.ccp?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7457ku",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s about llama.ccp not kobold promotion dude. So what about llama.ccp?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi7bem",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n7457ku/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754426892,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n73w4oe",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "henk717",
            "can_mod_post": false,
            "created_utc": 1754423991,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 9,
            "author_fullname": "t2_bx8b9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "In the next KoboldCpp we will have --moecpu which is a remake of that PR (Since the launcher for koboldcpp is different).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n73w4oe",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "KoboldAI"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In the next KoboldCpp we will have --moecpu which is a remake of that PR (Since the launcher for koboldcpp is different).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n73w4oe/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754423991,
            "author_flair_text": "KoboldAI",
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#5a74cc",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n72t33e",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Colecoman1982",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n72eua7",
                                "score": 3,
                                "author_fullname": "t2_4arc0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I'm not OP, but I'm guessing that LCP is llama.cpp and LMS is LM Studio.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n72t33e",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not OP, but I&amp;#39;m guessing that LCP is llama.cpp and LMS is LM Studio.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi7bem",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72t33e/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754411043,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754411043,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n72eua7",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "muxxington",
                      "can_mod_post": false,
                      "created_utc": 1754407056,
                      "send_replies": true,
                      "parent_id": "t1_n71ipfe",
                      "score": 1,
                      "author_fullname": "t2_1ktdmsvo",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "What is LCP and what is LMS?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n72eua7",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What is LCP and what is LMS?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi7bem",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72eua7/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754407056,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n71ipfe",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Secure_Reflection409",
            "can_mod_post": false,
            "created_utc": 1754396930,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 8,
            "author_fullname": "t2_by77ogdhr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Excellenté!\n\n\nReally impressed with LCP's web interface, too.\n\n\nIf it had a context estimator like LMS it would prolly be perfect.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n71ipfe",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Excellenté!&lt;/p&gt;\n\n&lt;p&gt;Really impressed with LCP&amp;#39;s web interface, too.&lt;/p&gt;\n\n&lt;p&gt;If it had a context estimator like LMS it would prolly be perfect.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71ipfe/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754396930,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "richtext",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": "2b12e2b8-fdc0-11ee-9a03-6e2f48afd456",
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n74i104",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "Former-Ad-5757",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n7440fe",
                                                              "score": 3,
                                                              "author_fullname": "t2_ihsdiwk6k",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Actually in theory it should not be that hard I would guess, if you account for enough ram to hold all the tensors (Ram is usually not the problem, vram is) and load all tensors to ram then everything is at least in the slowest place. And then you could copy a tensor to gpu, after that is done just change the router which says where everything is located.\n\nWorst case scenario is that it isn't in vram but you will know it is in ram as a fallback.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n74i104",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [
                                                                {
                                                                  "e": "text",
                                                                  "t": "Llama 3"
                                                                }
                                                              ],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Actually in theory it should not be that hard I would guess, if you account for enough ram to hold all the tensors (Ram is usually not the problem, vram is) and load all tensors to ram then everything is at least in the slowest place. And then you could copy a tensor to gpu, after that is done just change the router which says where everything is located.&lt;/p&gt;\n\n&lt;p&gt;Worst case scenario is that it isn&amp;#39;t in vram but you will know it is in ram as a fallback.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mi7bem",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": "light",
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n74i104/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754430998,
                                                              "author_flair_text": "Llama 3",
                                                              "treatment_tags": [],
                                                              "created_utc": 1754430998,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": "#c7b594",
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 3
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7440fe",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "TheTerrasque",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n73v71w",
                                                    "score": 2,
                                                    "author_fullname": "t2_9uv8v",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Could just be as simple as keeping a table of each layer and a counter for when it's activated, and now and then rearrange layers based on the count. It would be a new feature, yes.\n\nEdit: \"Simple\" is maybe not the right word, now that I'm thinking about it :D I doubt llama.cpp has logic to move around layers after the load. So I guess statistics and generated regex is a better approach.\n\nAlso, I wouldn't be surprised if we saw the Pareto principle in action when it comes to activated layers.",
                                                    "edited": 1754427092,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7440fe",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Could just be as simple as keeping a table of each layer and a counter for when it&amp;#39;s activated, and now and then rearrange layers based on the count. It would be a new feature, yes.&lt;/p&gt;\n\n&lt;p&gt;Edit: &amp;quot;Simple&amp;quot; is maybe not the right word, now that I&amp;#39;m thinking about it :D I doubt llama.cpp has logic to move around layers after the load. So I guess statistics and generated regex is a better approach.&lt;/p&gt;\n\n&lt;p&gt;Also, I wouldn&amp;#39;t be surprised if we saw the Pareto principle in action when it comes to activated layers.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi7bem",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n7440fe/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754426513,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754426513,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n73v71w",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Former-Ad-5757",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n73mzn6",
                                          "score": 2,
                                          "author_fullname": "t2_ihsdiwk6k",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I would guess which experts are hot or not would be a combination of training, model and question. So it would be userspecific. Perhaps it could be a feature request or pr to keep a log of activated layers/expert in a run. And then a simple recalculation tool which could read the log and generate the perfect regex for your situation but it would be a totally new feature",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n73v71w",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "e": "text",
                                              "t": "Llama 3"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would guess which experts are hot or not would be a combination of training, model and question. So it would be userspecific. Perhaps it could be a feature request or pr to keep a log of activated layers/expert in a run. And then a simple recalculation tool which could read the log and generate the perfect regex for your situation but it would be a totally new feature&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mi7bem",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "light",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n73v71w/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754423678,
                                          "author_flair_text": "Llama 3",
                                          "treatment_tags": [],
                                          "created_utc": 1754423678,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "#c7b594",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n73mzn6",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "TheTerrasque",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n72bugb",
                                "score": 2,
                                "author_fullname": "t2_9uv8v",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I'm guessing some of the experts are \"hotter\" than others, and moving those to gpu would help more than moving random ones. \n\nBasically it could keep track of which layers saw the most activation and move them to the gpu. If the distribution is uniform or near uniform, this of course isn't a viable thing to do.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n73mzn6",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m guessing some of the experts are &amp;quot;hotter&amp;quot; than others, and moving those to gpu would help more than moving random ones. &lt;/p&gt;\n\n&lt;p&gt;Basically it could keep track of which layers saw the most activation and move them to the gpu. If the distribution is uniform or near uniform, this of course isn&amp;#39;t a viable thing to do.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi7bem",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n73mzn6/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754420852,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754420852,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n72bugb",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Marksta",
                      "can_mod_post": false,
                      "created_utc": 1754406191,
                      "send_replies": true,
                      "parent_id": "t1_n71vpi2",
                      "score": 4,
                      "author_fullname": "t2_559a1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "A little silly talk. There is dense layers and then there is the moe sparse layers, or the 'experts' layers. With this option or the older way of handling it via -ot, the dense layers are already accounted for via setting -ngl 99. So all dense layers (usually 1-3 of them) all go to GPU and sparse layers to CPU, and then if you can fit it add some of the sparse layers to GPU too instead of CPU.\n\nThere is some more inner logic to consider of keeping experts 'together', not sure how this handles it here or any real performance implications. But most people regex'ed experts as units to keep them together so this new arg probably does too.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n72bugb",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A little silly talk. There is dense layers and then there is the moe sparse layers, or the &amp;#39;experts&amp;#39; layers. With this option or the older way of handling it via -ot, the dense layers are already accounted for via setting -ngl 99. So all dense layers (usually 1-3 of them) all go to GPU and sparse layers to CPU, and then if you can fit it add some of the sparse layers to GPU too instead of CPU.&lt;/p&gt;\n\n&lt;p&gt;There is some more inner logic to consider of keeping experts &amp;#39;together&amp;#39;, not sure how this handles it here or any real performance implications. But most people regex&amp;#39;ed experts as units to keep them together so this new arg probably does too.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi7bem",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72bugb/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754406191,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n71vpi2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "silenceimpaired",
            "can_mod_post": false,
            "created_utc": 1754401353,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 7,
            "author_fullname": "t2_dissgzyl",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hopefully future revisions will intelligently offload. I assume some parts of the model are better on GPU. Would be nice if this considered this on a per model basis - perhaps all future models added could have these parts marked and existing ones could be patched in when this was added. Or maybe I’m talking silly talk.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n71vpi2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hopefully future revisions will intelligently offload. I assume some parts of the model are better on GPU. Would be nice if this considered this on a per model basis - perhaps all future models added could have these parts marked and existing ones could be patched in when this was added. Or maybe I’m talking silly talk.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71vpi2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754401353,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n76tqdp",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "Wooden-Potential2226",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n73xsp9",
                                                    "score": 2,
                                                    "author_fullname": "t2_9mo23y823",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Hugely informative thx!",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n76tqdp",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hugely informative thx!&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mi7bem",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n76tqdp/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754463256,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754463256,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n73xsp9",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Marksta",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n737uag",
                                          "score": 3,
                                          "author_fullname": "t2_559a1",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "So to be more clear, the new flags are nothing new you couldn't have done before. (But very happy they added them and hope ik_llama.cpp mimics it soon too for the simplicity it adds) So wouldn't really focus on it.\n\nSo for your setup, take note you're pretty close to running almost all in VRAM for even big MoE models depending on what model we're talking about like the brand new 120B from openAI can all get in there. So also think about vLLM and tp=2, using both your RTX 6000s at 'full speed' in parallel instead of sequentially. But that's a whole different beast of setup and documentation to flip through.\n\nFor ik_llama.cpp vs. llama.cpp argument, 1000% EPYC CPU and going to off load to CPU, it's no question, **you want to be on ik_llama.cpp** for that. The speed up is 2-3x on token generation. Flip through Ubergarm's model list and compare it to Unsloth's releases. They're seriously packing Q8 intelligence into Q4, which with the method they're using currently only runs on ik_llama.cpp not main line. While with your beast setup you could really fit the Q8, it matters even more since with the [IQ4_KS_R4 368GiB R1](https://huggingface.co/ubergarm/DeepSeek-R1-0528-GGUF) vs. the ~666GiB Q8, you can get that fancy Q4 at least 30+% of the weights into your GPUs too. The speed up there will be massive. For most of us, we just have enough GPU VRAM to barely fit in the KV cache, the dense layers, and maybe 1 set of experts and we get 10 tokens/second TG. You, you're going to get like bunch of the experts if you go with these compact quants. I'm thinking you see maybe 20 tokens/second TG on R1, maybe even higher.\n\n&gt; only the “active” parameters need to be in VRAM for max speed\n\nThe architecture is very usable and good to run like this, but it's still more ideal if you had 1TB of VRAM. That's what the big business datacenters are doing and how they provide their huge models at blazing 50-100 tokens/second for you on their services. It's just we're very happy at 5-10 t/s at all with our $ optimized setup putting the dense layers and cache to GPU. The experts are 'active' too, but not for every pass of the model. So the always active (dense) layers in GPU is definitely key (-ngl 99) and then the CPU taking on the extra alternating use of randomly selected experts gets us up and running.\n\n&gt;Any practical advice for getting the best balance of performance and reliability here?\n\nReliability as far as the setup running isn't really problematic once you dial something in that works. You can use llama-sweep-bench on ik_llama.cpp to test and I don't usually use it for production use, but when dialing settings in set --no-mmap if you're testing at out-of-memory's edge. This will fail your test run way quicker. Mmap is good for a start up speed-up, but it also allows you to go 'over' your limit and then your performance drops hard or go out of memory later on. But yeah, once you figure out how many experts can go into your GPU RAM and run for a few minutes of llama-sweep-bench, there's no more variables that'll change and mess things up. Setup should be rock solid and you can bring those settings over to llama-server and use it for work or whatever.\n\nAlso play with your -t and -tb to set the threads for your specific CPU setup, based on weirdness of how you max out memory bandwidth with LLMs and CPUs being sectioned off into CCDs, there is a sweet spot for how many threads can make full use of the bandwidth before they start fighting each other and going slower actually.\n\nSo just go download ik_llama.cpp from the github, build it, and learn from Ubergarm's model cards recommended commands to run to get started and he comments on here too. Great guy, he's working on GLM 4.5 right now too. But you can get started with an Unsloth release, they're great too but just focused on llama.cpp main line compatible quants.",
                                          "edited": 1754425026,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n73xsp9",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So to be more clear, the new flags are nothing new you couldn&amp;#39;t have done before. (But very happy they added them and hope ik_llama.cpp mimics it soon too for the simplicity it adds) So wouldn&amp;#39;t really focus on it.&lt;/p&gt;\n\n&lt;p&gt;So for your setup, take note you&amp;#39;re pretty close to running almost all in VRAM for even big MoE models depending on what model we&amp;#39;re talking about like the brand new 120B from openAI can all get in there. So also think about vLLM and tp=2, using both your RTX 6000s at &amp;#39;full speed&amp;#39; in parallel instead of sequentially. But that&amp;#39;s a whole different beast of setup and documentation to flip through.&lt;/p&gt;\n\n&lt;p&gt;For ik_llama.cpp vs. llama.cpp argument, 1000% EPYC CPU and going to off load to CPU, it&amp;#39;s no question, &lt;strong&gt;you want to be on ik_llama.cpp&lt;/strong&gt; for that. The speed up is 2-3x on token generation. Flip through Ubergarm&amp;#39;s model list and compare it to Unsloth&amp;#39;s releases. They&amp;#39;re seriously packing Q8 intelligence into Q4, which with the method they&amp;#39;re using currently only runs on ik_llama.cpp not main line. While with your beast setup you could really fit the Q8, it matters even more since with the &lt;a href=\"https://huggingface.co/ubergarm/DeepSeek-R1-0528-GGUF\"&gt;IQ4_KS_R4 368GiB R1&lt;/a&gt; vs. the ~666GiB Q8, you can get that fancy Q4 at least 30+% of the weights into your GPUs too. The speed up there will be massive. For most of us, we just have enough GPU VRAM to barely fit in the KV cache, the dense layers, and maybe 1 set of experts and we get 10 tokens/second TG. You, you&amp;#39;re going to get like bunch of the experts if you go with these compact quants. I&amp;#39;m thinking you see maybe 20 tokens/second TG on R1, maybe even higher.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;only the “active” parameters need to be in VRAM for max speed&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The architecture is very usable and good to run like this, but it&amp;#39;s still more ideal if you had 1TB of VRAM. That&amp;#39;s what the big business datacenters are doing and how they provide their huge models at blazing 50-100 tokens/second for you on their services. It&amp;#39;s just we&amp;#39;re very happy at 5-10 t/s at all with our $ optimized setup putting the dense layers and cache to GPU. The experts are &amp;#39;active&amp;#39; too, but not for every pass of the model. So the always active (dense) layers in GPU is definitely key (-ngl 99) and then the CPU taking on the extra alternating use of randomly selected experts gets us up and running.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Any practical advice for getting the best balance of performance and reliability here?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Reliability as far as the setup running isn&amp;#39;t really problematic once you dial something in that works. You can use llama-sweep-bench on ik_llama.cpp to test and I don&amp;#39;t usually use it for production use, but when dialing settings in set --no-mmap if you&amp;#39;re testing at out-of-memory&amp;#39;s edge. This will fail your test run way quicker. Mmap is good for a start up speed-up, but it also allows you to go &amp;#39;over&amp;#39; your limit and then your performance drops hard or go out of memory later on. But yeah, once you figure out how many experts can go into your GPU RAM and run for a few minutes of llama-sweep-bench, there&amp;#39;s no more variables that&amp;#39;ll change and mess things up. Setup should be rock solid and you can bring those settings over to llama-server and use it for work or whatever.&lt;/p&gt;\n\n&lt;p&gt;Also play with your -t and -tb to set the threads for your specific CPU setup, based on weirdness of how you max out memory bandwidth with LLMs and CPUs being sectioned off into CCDs, there is a sweet spot for how many threads can make full use of the bandwidth before they start fighting each other and going slower actually.&lt;/p&gt;\n\n&lt;p&gt;So just go download ik_llama.cpp from the github, build it, and learn from Ubergarm&amp;#39;s model cards recommended commands to run to get started and he comments on here too. Great guy, he&amp;#39;s working on GLM 4.5 right now too. But you can get started with an Unsloth release, they&amp;#39;re great too but just focused on llama.cpp main line compatible quants.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mi7bem",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n73xsp9/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754424532,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754424532,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 3
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n737uag",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Infamous_Jaguar_2151",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n72hu44",
                                "score": 1,
                                "author_fullname": "t2_5l4zmzcw",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Hey, thanks for the clarification! Just to make sure I’m understanding this right, here’s my situation:\n\n- I’ve got a workstation with 2×96 GB RTX 6000 GPUs (192 GB VRAM total) and 768 GB RAM (on an EPYC CPU).\n\n- My plan is to run huge MoE models like DeepSeek R1 or GLM 4.5 locally, aiming for high accuracy and long context windows.\n\n- My understanding is that for these models, only the “active” parameters (i.e., the selected experts per inference step—maybe 30–40B params) need to be in VRAM for max speed, and the rest can be offloaded to RAM/CPU.\n\nMy question is:\nGiven my hardware and goals, do you think mainline llama.cpp (with the new --cpu-moe or --n-cpu-moe flags) is now just as effective as ik_llama.cpp for this hybrid setup? Or does ik_llama.cpp still give me a real advantage for handling massive MoE models with heavy CPU offload?\n\nAny practical advice for getting the best balance of performance and reliability here?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n737uag",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hey, thanks for the clarification! Just to make sure I’m understanding this right, here’s my situation:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;I’ve got a workstation with 2×96 GB RTX 6000 GPUs (192 GB VRAM total) and 768 GB RAM (on an EPYC CPU).&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;My plan is to run huge MoE models like DeepSeek R1 or GLM 4.5 locally, aiming for high accuracy and long context windows.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;My understanding is that for these models, only the “active” parameters (i.e., the selected experts per inference step—maybe 30–40B params) need to be in VRAM for max speed, and the rest can be offloaded to RAM/CPU.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My question is:\nGiven my hardware and goals, do you think mainline llama.cpp (with the new --cpu-moe or --n-cpu-moe flags) is now just as effective as ik_llama.cpp for this hybrid setup? Or does ik_llama.cpp still give me a real advantage for handling massive MoE models with heavy CPU offload?&lt;/p&gt;\n\n&lt;p&gt;Any practical advice for getting the best balance of performance and reliability here?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mi7bem",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n737uag/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754415595,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754415595,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n72hu44",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Marksta",
                      "can_mod_post": false,
                      "created_utc": 1754407897,
                      "send_replies": true,
                      "parent_id": "t1_n729dd0",
                      "score": 6,
                      "author_fullname": "t2_559a1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt;So the main difference between this and ik-llama is integer quantisation?\n\nNo, this is just a quality of life option they added to llama.cpp. It doesn't impact how you run MoE models besides you write and edit less lines of ot regex patterns.\n\n&gt;Does it still make sense to use ik-llama?\n\nYes, you should probably still use ik_llama.cpp if you want to use SOTA quants and get better CPU performance. Use either if you're all in GPU but if you're dumping 200gb+ of moe experts onto CPU, 100% use ik. Also those quants are really amazing, ~Q4s that are on par with Q8. Literally need half the half hardware to run.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n72hu44",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;So the main difference between this and ik-llama is integer quantisation?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No, this is just a quality of life option they added to llama.cpp. It doesn&amp;#39;t impact how you run MoE models besides you write and edit less lines of ot regex patterns.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Does it still make sense to use ik-llama?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yes, you should probably still use ik_llama.cpp if you want to use SOTA quants and get better CPU performance. Use either if you&amp;#39;re all in GPU but if you&amp;#39;re dumping 200gb+ of moe experts onto CPU, 100% use ik. Also those quants are really amazing, ~Q4s that are on par with Q8. Literally need half the half hardware to run.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mi7bem",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n72hu44/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754407897,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n729dd0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Infamous_Jaguar_2151",
            "can_mod_post": false,
            "created_utc": 1754405478,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 3,
            "author_fullname": "t2_5l4zmzcw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So the main difference between this and ik-llama is integer quantisation? Slightly better performances ik-llama especially at longer contexts? Does it still make sense to use ik-llama?",
            "edited": 1754406269,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n729dd0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So the main difference between this and ik-llama is integer quantisation? Slightly better performances ik-llama especially at longer contexts? Does it still make sense to use ik-llama?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n729dd0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754405478,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n71klsx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ForsookComparison",
            "can_mod_post": false,
            "created_utc": 1754397627,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 4,
            "author_fullname": "t2_on5es7pe3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "THANK YOU",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n71klsx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;THANK YOU&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n71klsx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754397627,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n728eu3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "a_beautiful_rhind",
            "can_mod_post": false,
            "created_utc": 1754405204,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 1,
            "author_fullname": "t2_h5utwre7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Going to have to try it in verbose and see what it does. Some layers are bigger than others and it's better to skip them.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n728eu3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Going to have to try it in verbose and see what it does. Some layers are bigger than others and it&amp;#39;s better to skip them.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n728eu3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754405204,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n76g8ke",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "relmny",
            "can_mod_post": false,
            "created_utc": 1754456295,
            "send_replies": true,
            "parent_id": "t3_1mi7bem",
            "score": 1,
            "author_fullname": "t2_joxwuyje",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Will that work with things like:\n\n\"\\\\.(4|5|6|7|8|9|\\[0-9\\]\\[0-9\\]|\\[0-9\\]\\[0-9\\]\\[0-9\\]).ffn\\_(gate|up|down)\\_exps.=CPU\"\n\nor is that too specific?\n\n  \n(edit: I'm only asking whether is possible or not, not how to do it)",
            "edited": 1754456801,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n76g8ke",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Will that work with things like:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;\\.(4|5|6|7|8|9|[0-9][0-9]|[0-9][0-9][0-9]).ffn_(gate|up|down)_exps.=CPU&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;or is that too specific?&lt;/p&gt;\n\n&lt;p&gt;(edit: I&amp;#39;m only asking whether is possible or not, not how to do it)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mi7bem/new_llamacpp_options_make_moe_offloading_trivial/n76g8ke/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754456295,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mi7bem",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]