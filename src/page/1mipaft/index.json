[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Alright, OpenAI finally released their long-awaited open-weight model. And, by their own admission, this model matches or surpasses GPT-o3 and o4-mini and is highly customizable. All good and dandy.\n\nBut here's the twist.\n\nWhile they encourage **local customization and autonomy** right out of the gate, they had to bake in **guardrails** (aka telemetry). Some of them, like Biological, Chemical and Cyber capabilities, are understandable. But they also included \"No AI Self-Improvement\" (see below image). WTF is that all about? Are they afraid some local loonies will spark AI sentience in their garage?\n\n[gpt-oss-120b &amp; gpt-oss-20b Model Card \\(https:\\/\\/openai.com\\/index\\/gpt-oss-model-card\\/?utm\\_source=chatgpt.com\\)](https://preview.redd.it/oh9o1124dahf1.png?width=760&amp;format=png&amp;auto=webp&amp;s=20a2e0c6acffb86bbca9508963f460ac39f220a0)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "OpenAI Releases gpt-oss-120b with This Warning: No AI Self-Improvement (Like What??)",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 64,
            "top_awarded_type": null,
            "hide_score": true,
            "media_metadata": {
              "oh9o1124dahf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 50,
                    "x": 108,
                    "u": "https://preview.redd.it/oh9o1124dahf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e7144afa2fd7f9e49d9fbfb18a83ffa94273c1e4"
                  },
                  {
                    "y": 100,
                    "x": 216,
                    "u": "https://preview.redd.it/oh9o1124dahf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=015c7d97ffbb0d722cd13538f0c4438b553e3a87"
                  },
                  {
                    "y": 148,
                    "x": 320,
                    "u": "https://preview.redd.it/oh9o1124dahf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f2189301a9da21c386f2c11f82d1f39c8fdf919"
                  },
                  {
                    "y": 296,
                    "x": 640,
                    "u": "https://preview.redd.it/oh9o1124dahf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6beca9fdafa01ab6e390fdfaf53a73a20a90123e"
                  }
                ],
                "s": {
                  "y": 352,
                  "x": 760,
                  "u": "https://preview.redd.it/oh9o1124dahf1.png?width=760&amp;format=png&amp;auto=webp&amp;s=20a2e0c6acffb86bbca9508963f460ac39f220a0"
                },
                "id": "oh9o1124dahf1"
              }
            },
            "name": "t3_1mipaft",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.55,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_cna812e",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/FAqhmYjy7P9wFDjBnzVIDWLwelMou0qj66AJNyTGUZU.jpg",
            "edited": 1754437719,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754437534,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Alright, OpenAI finally released their long-awaited open-weight model. And, by their own admission, this model matches or surpasses GPT-o3 and o4-mini and is highly customizable. All good and dandy.&lt;/p&gt;\n\n&lt;p&gt;But here&amp;#39;s the twist.&lt;/p&gt;\n\n&lt;p&gt;While they encourage &lt;strong&gt;local customization and autonomy&lt;/strong&gt; right out of the gate, they had to bake in &lt;strong&gt;guardrails&lt;/strong&gt; (aka telemetry). Some of them, like Biological, Chemical and Cyber capabilities, are understandable. But they also included &amp;quot;No AI Self-Improvement&amp;quot; (see below image). WTF is that all about? Are they afraid some local loonies will spark AI sentience in their garage?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/oh9o1124dahf1.png?width=760&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=20a2e0c6acffb86bbca9508963f460ac39f220a0\"&gt;gpt-oss-120b &amp;amp; gpt-oss-20b Model Card (https://openai.com/index/gpt-oss-model-card/?utm_source=chatgpt.com)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1mipaft",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "sourdub",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mipaft/openai_releases_gptoss120b_with_this_warning_no/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mipaft/openai_releases_gptoss120b_with_this_warning_no/",
            "subreddit_subscribers": 511363,
            "created_utc": 1754437534,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n75a1bb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "abnormal_human",
            "can_mod_post": false,
            "created_utc": 1754440353,
            "send_replies": true,
            "parent_id": "t3_1mipaft",
            "score": 2,
            "author_fullname": "t2_5y02z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If the model achieved \"High capability\" in those categories it would likely be exposed to regulations in some location that would complicate the open release. They are just documenting their compliance process to cover their ass. There is no telemetry and this text does not restrict what you can do with the model, it just says that they did some kind of test on it and determined that it isn't powerful enough to do \"AI Self-Improvement\", whatever that means. \n\nBasically all models published by large established entities are going to have some alignment in place. I don't think that's really a point for or against them. Qwen, LLaMA, Deepseek, etc are all aligned to some definition of \"safety\".",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75a1bb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If the model achieved &amp;quot;High capability&amp;quot; in those categories it would likely be exposed to regulations in some location that would complicate the open release. They are just documenting their compliance process to cover their ass. There is no telemetry and this text does not restrict what you can do with the model, it just says that they did some kind of test on it and determined that it isn&amp;#39;t powerful enough to do &amp;quot;AI Self-Improvement&amp;quot;, whatever that means. &lt;/p&gt;\n\n&lt;p&gt;Basically all models published by large established entities are going to have some alignment in place. I don&amp;#39;t think that&amp;#39;s really a point for or against them. Qwen, LLaMA, Deepseek, etc are all aligned to some definition of &amp;quot;safety&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mipaft/openai_releases_gptoss120b_with_this_warning_no/n75a1bb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754440353,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mipaft",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n75dkny",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GlowiesEatShitAndDie",
            "can_mod_post": false,
            "created_utc": 1754441571,
            "send_replies": true,
            "parent_id": "t3_1mipaft",
            "score": 1,
            "author_fullname": "t2_1f8trxud0p",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Guardrails and telemetry are two different things.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75dkny",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Guardrails and telemetry are two different things.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mipaft/openai_releases_gptoss120b_with_this_warning_no/n75dkny/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754441571,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mipaft",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]