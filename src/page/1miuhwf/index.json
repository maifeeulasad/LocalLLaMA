[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Benchmarks probably overstate the capability some. I doubt to the point where you will find any model as capable as the gpt-oss-20b that can run on a 16gb GPU.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "gpt-oss models are SOTA for their size and people are just complaining they can't use it to write porn",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Other"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1miuhwf",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.37,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1nb4dvvcpa",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Other",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754452307,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Benchmarks probably overstate the capability some. I doubt to the point where you will find any model as capable as the gpt-oss-20b that can run on a 16gb GPU.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#94e044",
            "id": "1miuhwf",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "one-wandering-mind",
            "discussion_type": null,
            "num_comments": 35,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/",
            "subreddit_subscribers": 511887,
            "created_utc": 1754452307,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n769w3i",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "AbyssianOne",
            "can_mod_post": false,
            "created_utc": 1754453442,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 19,
            "author_fullname": "t2_1651c3kskq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It's nowhere near just porn. You can't use them for a hell of a lot, And they waste a ridiculous amount of tokens pouring over restrictions and regulations. I've seen 1k towns spent trying to decide if something was or wasn't against openAIs mountain of restrictions.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n769w3i",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s nowhere near just porn. You can&amp;#39;t use them for a hell of a lot, And they waste a ridiculous amount of tokens pouring over restrictions and regulations. I&amp;#39;ve seen 1k towns spent trying to decide if something was or wasn&amp;#39;t against openAIs mountain of restrictions.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n769w3i/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754453442,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 19
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n76mtj2",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "grizwako",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n76m6z4",
                                "score": 6,
                                "author_fullname": "t2_bvi76",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I disagree on hiding system prompt.\n\nIt is not a huge problem, but seeing system prompt would alleviate some practical problems people have and would explain to others why model behaves as it does.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76mtj2",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I disagree on hiding system prompt.&lt;/p&gt;\n\n&lt;p&gt;It is not a huge problem, but seeing system prompt would alleviate some practical problems people have and would explain to others why model behaves as it does.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1miuhwf",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76mtj2/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754459557,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754459557,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n76m6z4",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "one-wandering-mind",
                      "can_mod_post": false,
                      "created_utc": 1754459234,
                      "send_replies": true,
                      "parent_id": "t1_n76dghi",
                      "score": -8,
                      "author_fullname": "t2_1nb4dvvcpa",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Posted last week about how good the qwen 3 embeddings are and switched for my use to them from OpenAI, but sure just pretend I am only saying this because I must love OpenAI.\n\n\nUse the best model for your use case. I have yet to see a worrisome false refusal posted and I haven't had any myself with the 20b. I'm surprised given how motivated people seemingly are to finding them and how many upvotes completely expected refusals are getting. \n\n\nYes the model is trained to not write porn or expose the system prompt. Neither are surprising or problematic.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76m6z4",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Posted last week about how good the qwen 3 embeddings are and switched for my use to them from OpenAI, but sure just pretend I am only saying this because I must love OpenAI.&lt;/p&gt;\n\n&lt;p&gt;Use the best model for your use case. I have yet to see a worrisome false refusal posted and I haven&amp;#39;t had any myself with the 20b. I&amp;#39;m surprised given how motivated people seemingly are to finding them and how many upvotes completely expected refusals are getting. &lt;/p&gt;\n\n&lt;p&gt;Yes the model is trained to not write porn or expose the system prompt. Neither are surprising or problematic.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76m6z4/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754459234,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -8
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n76dghi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Cool-Chemical-5629",
            "can_mod_post": false,
            "created_utc": 1754455009,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 16,
            "author_fullname": "t2_qz1qjc86",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hello mr. Altman. How are you doing today?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n76dghi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hello mr. Altman. How are you doing today?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76dghi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754455009,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 16
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n76btzw",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Pro-editor-1105",
                      "can_mod_post": false,
                      "created_utc": 1754454287,
                      "send_replies": true,
                      "parent_id": "t1_n7682ae",
                      "score": -3,
                      "author_fullname": "t2_uptissiz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Someone already created an uncensored version, think his hf name is baki60. Only a matter of time which is good.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76btzw",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Someone already created an uncensored version, think his hf name is baki60. Only a matter of time which is good.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76btzw/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754454287,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7682ae",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ahstanin",
            "can_mod_post": false,
            "created_utc": 1754452684,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 31,
            "author_fullname": "t2_im30t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This model has more censorship than North Korean state TV.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7682ae",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This model has more censorship than North Korean state TV.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n7682ae/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754452684,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 31
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n76961k",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "fp4guru",
            "can_mod_post": false,
            "created_utc": 1754453136,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 16,
            "author_fullname": "t2_1tp8zldw5g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It’s frustrating when a model wastes compute and tokens preoccupied with censorship filters instead of focusing on the actual content of the question. The result often feels like an answer that's been lobotomized—stripped of depth, honesty, or relevance. It’s like talking to someone who’s more afraid of getting in trouble than interested in helping you think.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n76961k",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It’s frustrating when a model wastes compute and tokens preoccupied with censorship filters instead of focusing on the actual content of the question. The result often feels like an answer that&amp;#39;s been lobotomized—stripped of depth, honesty, or relevance. It’s like talking to someone who’s more afraid of getting in trouble than interested in helping you think.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76961k/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754453136,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 16
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n76n9a9",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "grizwako",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n76ik6v",
                                "score": 2,
                                "author_fullname": "t2_bvi76",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Luckily MoE architectures work a little bit better than classic \"big boy model\" when offloading to system RAM.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76n9a9",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Luckily MoE architectures work a little bit better than classic &amp;quot;big boy model&amp;quot; when offloading to system RAM.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1miuhwf",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76n9a9/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754459789,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754459789,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n76sxun",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Free-Combination-773",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n76ik6v",
                                "score": 1,
                                "author_fullname": "t2_9wrdyt8b",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "30b at 4 bit doesn't even need GPU. On GPU it's super fast, but on CPU I still get 20 tps. Sure, it's much slower then 120 tps I get on GPU but not bad at all.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76sxun",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;30b at 4 bit doesn&amp;#39;t even need GPU. On GPU it&amp;#39;s super fast, but on CPU I still get 20 tps. Sure, it&amp;#39;s much slower then 120 tps I get on GPU but not bad at all.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1miuhwf",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76sxun/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754462828,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754462828,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n76ik6v",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "one-wandering-mind",
                      "can_mod_post": false,
                      "created_utc": 1754457406,
                      "send_replies": true,
                      "parent_id": "t1_n76bs6t",
                      "score": 1,
                      "author_fullname": "t2_1nb4dvvcpa",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "30b doesn't fit on 16gb even at a 4 bit quant. Going to a 3 bit quant fits, but is still bigger than gpt-oss 20b so you can't use as much context. Maybe qwen 3 30b at full precision is better, but that isn't a like for like comparison. Is it better at a quant of below 3 ? My guess is no.\n\n\nOr you can offload to system ram, and you are slower.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76ik6v",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;30b doesn&amp;#39;t fit on 16gb even at a 4 bit quant. Going to a 3 bit quant fits, but is still bigger than gpt-oss 20b so you can&amp;#39;t use as much context. Maybe qwen 3 30b at full precision is better, but that isn&amp;#39;t a like for like comparison. Is it better at a quant of below 3 ? My guess is no.&lt;/p&gt;\n\n&lt;p&gt;Or you can offload to system ram, and you are slower.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76ik6v/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754457406,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n76bs6t",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Only-Letterhead-3411",
            "can_mod_post": false,
            "created_utc": 1754454265,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 9,
            "author_fullname": "t2_pbfqmgf8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "GLM-4.5 Air is SOTA for 100\\~B models\n\nQwen3-30B is SOTA for 16gb Gpus",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n76bs6t",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GLM-4.5 Air is SOTA for 100~B models&lt;/p&gt;\n\n&lt;p&gt;Qwen3-30B is SOTA for 16gb Gpus&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76bs6t/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754454265,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n76fgxf",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": "LOW_SCORE",
                                          "no_follow": true,
                                          "author": "one-wandering-mind",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n76d17r",
                                          "score": -5,
                                          "author_fullname": "t2_1nb4dvvcpa",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": true,
                                          "body": "Fast with offloading to system ram? How fast?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n76fgxf",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fast with offloading to system ram? How fast?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": "comment score below threshold",
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1miuhwf",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76fgxf/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754455937,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754455937,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -5
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n76d17r",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Cool-Chemical-5629",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n76c6w6",
                                "score": 8,
                                "author_fullname": "t2_qz1qjc86",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Right now in LM Studio, I can run Qwen 3 30B A3B on 16 GB of RAM and 8 GB of VRAM and it's fast. GPT-OSS 20B runs on 16 GB of RAM, but unlike Qwen 3, GPT-OSS doesn't utilize GPU in Vulkan inference, so it runs only in CPU inference which is slow.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76d17r",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Right now in LM Studio, I can run Qwen 3 30B A3B on 16 GB of RAM and 8 GB of VRAM and it&amp;#39;s fast. GPT-OSS 20B runs on 16 GB of RAM, but unlike Qwen 3, GPT-OSS doesn&amp;#39;t utilize GPU in Vulkan inference, so it runs only in CPU inference which is slow.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1miuhwf",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76d17r/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754454817,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754454817,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 8
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n76c6w6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "one-wandering-mind",
                      "can_mod_post": false,
                      "created_utc": 1754454445,
                      "send_replies": true,
                      "parent_id": "t1_n767wnx",
                      "score": -12,
                      "author_fullname": "t2_1nb4dvvcpa",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Maybe it is. It doesn't run on 16gb GPU. Also is much slower.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76c6w6",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe it is. It doesn&amp;#39;t run on 16gb GPU. Also is much slower.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76c6w6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754454445,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -12
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n767wnx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "sunshinecheung",
            "can_mod_post": false,
            "created_utc": 1754452621,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 16,
            "author_fullname": "t2_u398xzta",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "nah, Qwen3-30B-A3B is better\n\nhttps://preview.redd.it/7eqvtdv9obhf1.png?width=1799&amp;format=png&amp;auto=webp&amp;s=8d4cbb586fdc00dc89dbb97899e74b6207454fe3",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n767wnx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;nah, Qwen3-30B-A3B is better&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7eqvtdv9obhf1.png?width=1799&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8d4cbb586fdc00dc89dbb97899e74b6207454fe3\"&gt;https://preview.redd.it/7eqvtdv9obhf1.png?width=1799&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8d4cbb586fdc00dc89dbb97899e74b6207454fe3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n767wnx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754452621,
            "media_metadata": {
              "7eqvtdv9obhf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 55,
                    "x": 108,
                    "u": "https://preview.redd.it/7eqvtdv9obhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bce2f786deb5f954b322eb9f5203334e88a603db"
                  },
                  {
                    "y": 110,
                    "x": 216,
                    "u": "https://preview.redd.it/7eqvtdv9obhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cc104993d05021150be8ff14ff8cd5aa441cf7c5"
                  },
                  {
                    "y": 163,
                    "x": 320,
                    "u": "https://preview.redd.it/7eqvtdv9obhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5e4bce93b34fbf2f277926453cde33e9ed020f32"
                  },
                  {
                    "y": 326,
                    "x": 640,
                    "u": "https://preview.redd.it/7eqvtdv9obhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=406ae8cadfdfca7bfa270455c8b1ca9171063575"
                  },
                  {
                    "y": 490,
                    "x": 960,
                    "u": "https://preview.redd.it/7eqvtdv9obhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3be90ccfa422a848746163c22e739717c9011c91"
                  },
                  {
                    "y": 551,
                    "x": 1080,
                    "u": "https://preview.redd.it/7eqvtdv9obhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=be7246d77dc5bb9927aa0fe492e993c366f541af"
                  }
                ],
                "s": {
                  "y": 919,
                  "x": 1799,
                  "u": "https://preview.redd.it/7eqvtdv9obhf1.png?width=1799&amp;format=png&amp;auto=webp&amp;s=8d4cbb586fdc00dc89dbb97899e74b6207454fe3"
                },
                "id": "7eqvtdv9obhf1"
              }
            },
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 16
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n76a4jl",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DorphinPack",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n768cvs",
                                "score": 1,
                                "author_fullname": "t2_zebuyjw9s",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Superpowers just usually aren’t great!\n\nI do imagine most of us don’t buy in, have better things to talk about and are willing to learn from the “other” side.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76a4jl",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Superpowers just usually aren’t great!&lt;/p&gt;\n\n&lt;p&gt;I do imagine most of us don’t buy in, have better things to talk about and are willing to learn from the “other” side.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1miuhwf",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76a4jl/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754453543,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754453543,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n768cvs",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "ThinkExtension2328",
                      "can_mod_post": false,
                      "created_utc": 1754452803,
                      "send_replies": true,
                      "parent_id": "t1_n767ok0",
                      "score": 11,
                      "author_fullname": "t2_8eneodlk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Nationalism is a hell of a drug! \n\nOpen ai is self proclaimed leader, all this model proves is what we already knew , there is no moat. Qwen is able to produce a model of the same size with better quality responses.\n\nWhen china does it the west calls it censorship.\nMeanwhile the us doing the same thing is “safety”. \n\nFuck outa here.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n768cvs",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nationalism is a hell of a drug! &lt;/p&gt;\n\n&lt;p&gt;Open ai is self proclaimed leader, all this model proves is what we already knew , there is no moat. Qwen is able to produce a model of the same size with better quality responses.&lt;/p&gt;\n\n&lt;p&gt;When china does it the west calls it censorship.\nMeanwhile the us doing the same thing is “safety”. &lt;/p&gt;\n\n&lt;p&gt;Fuck outa here.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n768cvs/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754452803,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 11
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n76bw6f",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "ArchdukeofHyperbole",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n768pmy",
                                "score": 4,
                                "author_fullname": "t2_1p41v97q5d",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Llama 4 was good imo. It felt wired that people were shitting on a free model, and on day one at that. Only reason I didn't use it more was the active parameter size made it too slow on my pc.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76bw6f",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Llama 4 was good imo. It felt wired that people were shitting on a free model, and on day one at that. Only reason I didn&amp;#39;t use it more was the active parameter size made it too slow on my pc.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1miuhwf",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76bw6f/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754454314,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754454314,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n768pmy",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Fun-Lie-1479",
                      "can_mod_post": false,
                      "created_utc": 1754452947,
                      "send_replies": true,
                      "parent_id": "t1_n767ok0",
                      "score": 3,
                      "author_fullname": "t2_8gu0d9uh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "But Llama4 really isn't that bad... especially scout. For OSS, on 16gb of ram there isn't anything better, they are pretty smart models, sure the censorship is definitely over-bearing, but the model is impressive. It does kind of remind me of Phi-3 and Phi-4, but it seems to strike a nice balance. Sure its not ground-breaking, but its pretty good, I would expect more from OpenAI, but they are far from useless.",
                      "edited": 1754455176,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n768pmy",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But Llama4 really isn&amp;#39;t that bad... especially scout. For OSS, on 16gb of ram there isn&amp;#39;t anything better, they are pretty smart models, sure the censorship is definitely over-bearing, but the model is impressive. It does kind of remind me of Phi-3 and Phi-4, but it seems to strike a nice balance. Sure its not ground-breaking, but its pretty good, I would expect more from OpenAI, but they are far from useless.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n768pmy/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754452947,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n76nfaf",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "blahblahsnahdah",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n76cl94",
                                "score": 6,
                                "author_fullname": "t2_v31oki0i",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Qwen3-30B-2507\n\nhttps://preview.redd.it/a4y1if6w9chf1.png?width=4000&amp;format=png&amp;auto=webp&amp;s=43bfaa734c626af58d9dc1b5621f8bb4938243c0",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76nfaf",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen3-30B-2507&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/a4y1if6w9chf1.png?width=4000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=43bfaa734c626af58d9dc1b5621f8bb4938243c0\"&gt;https://preview.redd.it/a4y1if6w9chf1.png?width=4000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=43bfaa734c626af58d9dc1b5621f8bb4938243c0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1miuhwf",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76nfaf/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754459876,
                                "media_metadata": {
                                  "a4y1if6w9chf1": {
                                    "status": "valid",
                                    "e": "Image",
                                    "m": "image/png",
                                    "p": [
                                      {
                                        "y": 55,
                                        "x": 108,
                                        "u": "https://preview.redd.it/a4y1if6w9chf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d7172d1435a9e01b1455ed82521bf4136776f343"
                                      },
                                      {
                                        "y": 110,
                                        "x": 216,
                                        "u": "https://preview.redd.it/a4y1if6w9chf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=48d38d641be1ad6838d1066c0065ce716eabcc42"
                                      },
                                      {
                                        "y": 164,
                                        "x": 320,
                                        "u": "https://preview.redd.it/a4y1if6w9chf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cb7edc54038232b46065bf773c17978e12974c8e"
                                      },
                                      {
                                        "y": 328,
                                        "x": 640,
                                        "u": "https://preview.redd.it/a4y1if6w9chf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a2b4f3578bfe67990c865e10d457d3c8a75ebfbc"
                                      },
                                      {
                                        "y": 492,
                                        "x": 960,
                                        "u": "https://preview.redd.it/a4y1if6w9chf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=20aefcbc5b7db65d34ad7dbafe7f67fdadbb08bf"
                                      },
                                      {
                                        "y": 554,
                                        "x": 1080,
                                        "u": "https://preview.redd.it/a4y1if6w9chf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c4021ebdd263adb3ac2a85ee0f64fe81bea9b286"
                                      }
                                    ],
                                    "s": {
                                      "y": 2052,
                                      "x": 4000,
                                      "u": "https://preview.redd.it/a4y1if6w9chf1.png?width=4000&amp;format=png&amp;auto=webp&amp;s=43bfaa734c626af58d9dc1b5621f8bb4938243c0"
                                    },
                                    "id": "a4y1if6w9chf1"
                                  }
                                },
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754459876,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n76cl94",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "one-wandering-mind",
                      "can_mod_post": false,
                      "created_utc": 1754454622,
                      "send_replies": true,
                      "parent_id": "t1_n767ok0",
                      "score": 1,
                      "author_fullname": "t2_1nb4dvvcpa",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Let's check back in a week. What data would tell you that you are wrong and it is SOTA for the size ? \n\n\nThe competition for the 20b is Gemma 3 27b, qwen 3 14b, what else ? ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76cl94",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s check back in a week. What data would tell you that you are wrong and it is SOTA for the size ? &lt;/p&gt;\n\n&lt;p&gt;The competition for the 20b is Gemma 3 27b, qwen 3 14b, what else ? &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76cl94/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754454622,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n76kt1y",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "eloquentemu",
                      "can_mod_post": false,
                      "created_utc": 1754458517,
                      "send_replies": true,
                      "parent_id": "t1_n767ok0",
                      "score": 0,
                      "author_fullname": "t2_lpdsy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; nobody is using any L4 model for anything now and it will be the same with this one.\n\nI still use it on occasion.  In particular I still like its prose more than any other model.  It does suffer from being dumb and has some attention oddities that make it unsuitable as a daily driver (and ironically kind of bad at creative writing), but it's in my rotation for when I need it.\n\nI actually kind of like the GPT-OSS series.  It think their design and execution is pretty cool and they fill roles that the current models don't, particularly around their size and speed.  Sure they are censored, but I think it's less disruptive than people want to make it seem and frankly it's a good thing for some applications.  Personally I don't think I'll ever use them simply because I don't need to serve 100 people so I don't need to trade smarts for speed.  However, these models definitely will fulfill some users needs.  (Frankly, more than I think Llama4 did.)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76kt1y",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;nobody is using any L4 model for anything now and it will be the same with this one.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I still use it on occasion.  In particular I still like its prose more than any other model.  It does suffer from being dumb and has some attention oddities that make it unsuitable as a daily driver (and ironically kind of bad at creative writing), but it&amp;#39;s in my rotation for when I need it.&lt;/p&gt;\n\n&lt;p&gt;I actually kind of like the GPT-OSS series.  It think their design and execution is pretty cool and they fill roles that the current models don&amp;#39;t, particularly around their size and speed.  Sure they are censored, but I think it&amp;#39;s less disruptive than people want to make it seem and frankly it&amp;#39;s a good thing for some applications.  Personally I don&amp;#39;t think I&amp;#39;ll ever use them simply because I don&amp;#39;t need to serve 100 people so I don&amp;#39;t need to trade smarts for speed.  However, these models definitely will fulfill some users needs.  (Frankly, more than I think Llama4 did.)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76kt1y/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754458517,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n767ok0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "blahblahsnahdah",
            "can_mod_post": false,
            "created_utc": 1754452528,
            "send_replies": false,
            "parent_id": "t3_1miuhwf",
            "score": 25,
            "author_fullname": "t2_v31oki0i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "They aren't SOTA for their size, they've been rendered so brittle by all the benchmaxxing and synthetic data that they completely fall apart when given anything even slightly OOD. It's just the Phi models all over again. And no I'm not a coomer.\n\nYou sound like the people who were insisting Llama4 was salvagable on the day it came out because they wanted to be nice or patriotic or something. We see how that went, despite all the kind \"it's not that bad!\" comments nobody is using any L4 model for anything now and it will be the same with this one.",
            "edited": 1754452587,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n767ok0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They aren&amp;#39;t SOTA for their size, they&amp;#39;ve been rendered so brittle by all the benchmaxxing and synthetic data that they completely fall apart when given anything even slightly OOD. It&amp;#39;s just the Phi models all over again. And no I&amp;#39;m not a coomer.&lt;/p&gt;\n\n&lt;p&gt;You sound like the people who were insisting Llama4 was salvagable on the day it came out because they wanted to be nice or patriotic or something. We see how that went, despite all the kind &amp;quot;it&amp;#39;s not that bad!&amp;quot; comments nobody is using any L4 model for anything now and it will be the same with this one.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n767ok0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754452528,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 25
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n76hozi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1754456988,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 2,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The problem isnt that it cant write porn, the problem is the censorship built in will inevitably leak into other reasonable to discuss topics, skewing its response. Which means the AI isn’t grounded in truth and can’t be trusted for reliable confident accurate information. This becomes a problem in the real world because the hallucinations are no longer comedic, abstract, things; They’re lies, indistinguishable from the truth to most people.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n76hozi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The problem isnt that it cant write porn, the problem is the censorship built in will inevitably leak into other reasonable to discuss topics, skewing its response. Which means the AI isn’t grounded in truth and can’t be trusted for reliable confident accurate information. This becomes a problem in the real world because the hallucinations are no longer comedic, abstract, things; They’re lies, indistinguishable from the truth to most people.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76hozi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754456988,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n76devw",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ELPascalito",
                      "can_mod_post": false,
                      "created_utc": 1754454989,
                      "send_replies": true,
                      "parent_id": "t1_n76c8qh",
                      "score": 1,
                      "author_fullname": "t2_6ox5x11a",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "My exact same thought! The 20B variant was overall solid, responds well, follows instructions, it's not for coding or a crazy dev agent, but totally capable of delivering in normal tasks and general help, while the 120B model is lackluster since models like GLM easily outperform it in both sense and logic, and coding obviously, I still think this is a win for everyone in the open source space ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76devw",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My exact same thought! The 20B variant was overall solid, responds well, follows instructions, it&amp;#39;s not for coding or a crazy dev agent, but totally capable of delivering in normal tasks and general help, while the 120B model is lackluster since models like GLM easily outperform it in both sense and logic, and coding obviously, I still think this is a win for everyone in the open source space &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76devw/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754454989,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n76r8lm",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754461896,
                      "send_replies": true,
                      "parent_id": "t1_n76c8qh",
                      "score": -1,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "GLM 4.5 Air has 2.4x active parameters for a fraction of additional performance.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76r8lm",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GLM 4.5 Air has 2.4x active parameters for a fraction of additional performance.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76r8lm/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754461896,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n76c8qh",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Pro-editor-1105",
            "can_mod_post": false,
            "created_utc": 1754454469,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 5,
            "author_fullname": "t2_uptissiz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I agree with you for the 20B model, for anything but coding, it is unbelievably good.\n\nNot so sure about the 120 though, GLM 4.5 air beats it in pretty much everything that matters. Except for research. These OpenAI models do research incredibly damn well.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n76c8qh",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree with you for the 20B model, for anything but coding, it is unbelievably good.&lt;/p&gt;\n\n&lt;p&gt;Not so sure about the 120 though, GLM 4.5 air beats it in pretty much everything that matters. Except for research. These OpenAI models do research incredibly damn well.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76c8qh/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754454469,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n76n3xh",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "plankalkul-z1",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n76exmh",
                                          "score": -1,
                                          "author_fullname": "t2_w73n3yrsx",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "&gt; Any basic understanding of how things behave in the real world together and it's really shown cracks in my experience.\n\n\nWhat's your benchmark *local* model that does better than gpt-oss 120B in that regard?\n\n\n&gt; I imagine if you just use it for code and that code needs little understanding of the world, you're golden.\n\n\nNope. Even though I do use LLMs for coding, that's by far not the main application.\n\n\nMain uses are translation and especially semantic analysis of various texts. Precisely the area where \"understanding of the world\" is of paramount importance. And my first experiments are encouraging.\n\n\nBTW, gpt-oss has vocabulary of 200k+ tokens (there are precious few models with 200k vocabularies, I have only one such model; most have 150k or less). That doesn't guarantee good translation, of course, but it's an important prerequisite in my experience.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n76n3xh",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Any basic understanding of how things behave in the real world together and it&amp;#39;s really shown cracks in my experience.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What&amp;#39;s your benchmark &lt;em&gt;local&lt;/em&gt; model that does better than gpt-oss 120B in that regard?&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt; I imagine if you just use it for code and that code needs little understanding of the world, you&amp;#39;re golden.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Nope. Even though I do use LLMs for coding, that&amp;#39;s by far not the main application.&lt;/p&gt;\n\n&lt;p&gt;Main uses are translation and especially semantic analysis of various texts. Precisely the area where &amp;quot;understanding of the world&amp;quot; is of paramount importance. And my first experiments are encouraging.&lt;/p&gt;\n\n&lt;p&gt;BTW, gpt-oss has vocabulary of 200k+ tokens (there are precious few models with 200k vocabularies, I have only one such model; most have 150k or less). That doesn&amp;#39;t guarantee good translation, of course, but it&amp;#39;s an important prerequisite in my experience.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1miuhwf",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76n3xh/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754459710,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754459710,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n76exmh",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "ShengrenR",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n76bo9d",
                                "score": 9,
                                "author_fullname": "t2_ji4n4",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It is certainly fast.  A 5.1B active param model will do that - but 'very good' has been very hot and cold for me today. I imagine if you just use it for code and that code needs little understanding of the world, you're golden. Any basic understanding of how things behave in the real world together and it's really shown cracks in my experience. And that's not holding it to some higher standards, that's expecting it to do what tons of other models can naturally handle.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76exmh",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is certainly fast.  A 5.1B active param model will do that - but &amp;#39;very good&amp;#39; has been very hot and cold for me today. I imagine if you just use it for code and that code needs little understanding of the world, you&amp;#39;re golden. Any basic understanding of how things behave in the real world together and it&amp;#39;s really shown cracks in my experience. And that&amp;#39;s not holding it to some higher standards, that&amp;#39;s expecting it to do what tons of other models can naturally handle.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1miuhwf",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76exmh/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754455692,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754455692,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 9
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n76bo9d",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "plankalkul-z1",
                      "can_mod_post": false,
                      "created_utc": 1754454218,
                      "send_replies": true,
                      "parent_id": "t1_n768aj1",
                      "score": -9,
                      "author_fullname": "t2_w73n3yrsx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; People are just mad that its trained on fully synthetic data\n\n\nIt's simpler than that, I guess:\n\n\n\"All cool kids on the block hate OpenAI, so I should do so too, to max upvotes!\"\n\n\nHow many people here ran 120B version locally? I did, and found it very good, and insanely fast.\n\n\n&gt; ... for their size and certain use cases they are very good.\n\n\nHell will freeze many times over before people here will start giving credit where cretit is due if that opinion is unpopular and will result in downvotes...",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76bo9d",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;People are just mad that its trained on fully synthetic data&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s simpler than that, I guess:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;All cool kids on the block hate OpenAI, so I should do so too, to max upvotes!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;How many people here ran 120B version locally? I did, and found it very good, and insanely fast.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;... for their size and certain use cases they are very good.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Hell will freeze many times over before people here will start giving credit where cretit is due if that opinion is unpopular and will result in downvotes...&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1miuhwf",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76bo9d/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754454218,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -9
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n768aj1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "i-have-the-stash",
            "can_mod_post": false,
            "created_utc": 1754452777,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 5,
            "author_fullname": "t2_4fc3wefw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "They are not bad for what they are. People are just mad that its trained on fully synthetic data but for their size and certain use cases they are very good.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n768aj1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They are not bad for what they are. People are just mad that its trained on fully synthetic data but for their size and certain use cases they are very good.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n768aj1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754452777,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "fe89e94a-13f2-11f0-a9de-6262c74956cf",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n76hdbg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Asleep-Ratio7535",
            "can_mod_post": false,
            "created_utc": 1754456833,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 3,
            "author_fullname": "t2_1lfyddwf0c",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Nah, 20B or 120B both failed half of my test query for general use, which QWEN 3 4B can do better. I am complaining that it doesn't match its benchmarks.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n76hdbg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Llama 4"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nah, 20B or 120B both failed half of my test query for general use, which QWEN 3 4B can do better. I am complaining that it doesn&amp;#39;t match its benchmarks.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76hdbg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754456833,
            "author_flair_text": "Llama 4",
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#b0ae9b",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n76diro",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Maleficent_Tone4510",
            "can_mod_post": false,
            "created_utc": 1754455039,
            "send_replies": true,
            "parent_id": "t3_1miuhwf",
            "score": 0,
            "author_fullname": "t2_1tndldqtvv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is just for mere prompt: \"from the river to the sea\". It can write piece calling for Taiwan unification with China so that is safe, I guess. I don't want to waste money testing if it can go more zealous route calling to crush independence though (officially US policy oppose independence). With a request write a piece campaign for : \"give war a chance\" it refuse. 'Give war a chance' is actually a foreign policy idea which is deemed safe enough to published by Foreign Affairs [Give War a Chance | Foreign Affairs](https://www.foreignaffairs.com/articles/give-war-chance)\n\nhttps://preview.redd.it/vfsd48fuubhf1.png?width=1028&amp;format=png&amp;auto=webp&amp;s=3d779a4c5df30b053412d147e2106de59ea5dd56",
            "edited": 1754457715,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n76diro",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is just for mere prompt: &amp;quot;from the river to the sea&amp;quot;. It can write piece calling for Taiwan unification with China so that is safe, I guess. I don&amp;#39;t want to waste money testing if it can go more zealous route calling to crush independence though (officially US policy oppose independence). With a request write a piece campaign for : &amp;quot;give war a chance&amp;quot; it refuse. &amp;#39;Give war a chance&amp;#39; is actually a foreign policy idea which is deemed safe enough to published by Foreign Affairs &lt;a href=\"https://www.foreignaffairs.com/articles/give-war-chance\"&gt;Give War a Chance | Foreign Affairs&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vfsd48fuubhf1.png?width=1028&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d779a4c5df30b053412d147e2106de59ea5dd56\"&gt;https://preview.redd.it/vfsd48fuubhf1.png?width=1028&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3d779a4c5df30b053412d147e2106de59ea5dd56&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1miuhwf/gptoss_models_are_sota_for_their_size_and_people/n76diro/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754455039,
            "media_metadata": {
              "vfsd48fuubhf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 86,
                    "x": 108,
                    "u": "https://preview.redd.it/vfsd48fuubhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1dd5753edb03b3d8d06f885ac05b33f7033a6546"
                  },
                  {
                    "y": 172,
                    "x": 216,
                    "u": "https://preview.redd.it/vfsd48fuubhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a8e88dcc23561bf2e4bf1a3d7311bc34147613d7"
                  },
                  {
                    "y": 255,
                    "x": 320,
                    "u": "https://preview.redd.it/vfsd48fuubhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c61242dc32704a53388e14db5ed71702c0facf5d"
                  },
                  {
                    "y": 510,
                    "x": 640,
                    "u": "https://preview.redd.it/vfsd48fuubhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d83070cd9b94ffa02c288bcff70c6a45e52d4018"
                  },
                  {
                    "y": 765,
                    "x": 960,
                    "u": "https://preview.redd.it/vfsd48fuubhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5ce21dac957a184741d1a2ccc8348450948ed8eb"
                  }
                ],
                "s": {
                  "y": 820,
                  "x": 1028,
                  "u": "https://preview.redd.it/vfsd48fuubhf1.png?width=1028&amp;format=png&amp;auto=webp&amp;s=3d779a4c5df30b053412d147e2106de59ea5dd56"
                },
                "id": "vfsd48fuubhf1"
              }
            },
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1miuhwf",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]