[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I’m looking to get started at self hosting an LLM but have no experience with this. \n\nWhat I am looking for is:\n\nAn LLM that I can explore with code, ideally if I can link it in with some folders on my MacBook Pro M4, and then also on a server, the servers will be getting GPUs mounted soon. \n\nI ideally want to be able to send it a defined file of what code styles and principles to follow, and I would love to know what self hosted options we can look at helping with PR reviews. \n\nI don’t want AI to replace or cut the corners of my team but to help us out and become more consistent. \n\nSo ideally, self hosted options (Docker etc), if it could be integrated into PRs with a self hosted GitLab if needed?\n\nI’ve read a bit about Qwen3 but not sure where to even get started to explore and try it out. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "How to get started",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m9antc",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.33,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_fpgzf",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753476933,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m looking to get started at self hosting an LLM but have no experience with this. &lt;/p&gt;\n\n&lt;p&gt;What I am looking for is:&lt;/p&gt;\n\n&lt;p&gt;An LLM that I can explore with code, ideally if I can link it in with some folders on my MacBook Pro M4, and then also on a server, the servers will be getting GPUs mounted soon. &lt;/p&gt;\n\n&lt;p&gt;I ideally want to be able to send it a defined file of what code styles and principles to follow, and I would love to know what self hosted options we can look at helping with PR reviews. &lt;/p&gt;\n\n&lt;p&gt;I don’t want AI to replace or cut the corners of my team but to help us out and become more consistent. &lt;/p&gt;\n\n&lt;p&gt;So ideally, self hosted options (Docker etc), if it could be integrated into PRs with a self hosted GitLab if needed?&lt;/p&gt;\n\n&lt;p&gt;I’ve read a bit about Qwen3 but not sure where to even get started to explore and try it out. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m9antc",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "theonethatownz",
            "discussion_type": null,
            "num_comments": 0,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m9antc/how_to_get_started/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m9antc/how_to_get_started/",
            "subreddit_subscribers": 504487,
            "created_utc": 1753476933,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [],
      "before": null
    }
  }
]