[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I would like to perform some STS tasks on my MacBook Pro (M4 Pro chip). Based on the leaderboard at [https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard), it seems that Qwen 3 is the leader, so I wanted to set it up. However, I problem with the  `SentenceTransformer(\"mlx-community/Qwen3-Embedding-4B-4bit-DWQ\")`\n\nI received the following error:  \n\n    File ~/miniconda3/envs/ds/lib/python3.11/site-packages/transformers/quantizers/auto.py:244, in AutoHfQuantizer.supports_quant_method(quantization_config_dict)\n        242     quant_method = QuantizationMethod.BITS_AND_BYTES + suffix\n        243 elif quant_method is None:\n    --&gt; 244     raise ValueError(\n        245         \"The model's quantization config from the arguments has no `quant_method` attribute. Make sure that the model has been correctly quantized\"\n        246     )\n        248 if quant_method not in AUTO_QUANTIZATION_CONFIG_MAPPING:\n        249     logger.warning(\n        250         f\"Unknown quantization type, got {quant_method} - supported types are:\"\n        251         f\" {list(AUTO_QUANTIZER_MAPPING.keys())}. Hence, we will skip the quantization. \"\n        252         \"To remove the warning, you can delete the quantization_config attribute in config.json\"\n        253     )\n    \n    **ValueError:** The model's quantization config from the arguments has no `quant_method` attribute. Make sure that the model has been correctly quantized.  \n\n\n\nDoes anyone have any ideas on how to set this up (fix the error or create a quantized version that works).\n\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Semantic Textual Similarity on Apple Silicon",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mkby4r",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.75,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_82klp24i5",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754600478,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to perform some STS tasks on my MacBook Pro (M4 Pro chip). Based on the leaderboard at &lt;a href=\"https://huggingface.co/spaces/mteb/leaderboard\"&gt;https://huggingface.co/spaces/mteb/leaderboard&lt;/a&gt;, it seems that Qwen 3 is the leader, so I wanted to set it up. However, I problem with the  &lt;code&gt;SentenceTransformer(&amp;quot;mlx-community/Qwen3-Embedding-4B-4bit-DWQ&amp;quot;)&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;I received the following error:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;File ~/miniconda3/envs/ds/lib/python3.11/site-packages/transformers/quantizers/auto.py:244, in AutoHfQuantizer.supports_quant_method(quantization_config_dict)\n    242     quant_method = QuantizationMethod.BITS_AND_BYTES + suffix\n    243 elif quant_method is None:\n--&amp;gt; 244     raise ValueError(\n    245         &amp;quot;The model&amp;#39;s quantization config from the arguments has no `quant_method` attribute. Make sure that the model has been correctly quantized&amp;quot;\n    246     )\n    248 if quant_method not in AUTO_QUANTIZATION_CONFIG_MAPPING:\n    249     logger.warning(\n    250         f&amp;quot;Unknown quantization type, got {quant_method} - supported types are:&amp;quot;\n    251         f&amp;quot; {list(AUTO_QUANTIZER_MAPPING.keys())}. Hence, we will skip the quantization. &amp;quot;\n    252         &amp;quot;To remove the warning, you can delete the quantization_config attribute in config.json&amp;quot;\n    253     )\n\n**ValueError:** The model&amp;#39;s quantization config from the arguments has no `quant_method` attribute. Make sure that the model has been correctly quantized.  \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Does anyone have any ideas on how to set this up (fix the error or create a quantized version that works).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?auto=webp&amp;s=2c5b27b819fcf9d302ea9223ff63779967c158ee",
                    "width": 1200,
                    "height": 648
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bca5092323f107110de703666d0987ca51bedba1",
                      "width": 108,
                      "height": 58
                    },
                    {
                      "url": "https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=358d7917ee14c30039ae1797ffd0ca1d9fe68d82",
                      "width": 216,
                      "height": 116
                    },
                    {
                      "url": "https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3c373fac417435224291450b1bfdd231978005f7",
                      "width": 320,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9c4fb1a0d407644b871f4c6fd852f1d65ac7b457",
                      "width": 640,
                      "height": 345
                    },
                    {
                      "url": "https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=09ef247e453733c039205a9236d582047820cf4c",
                      "width": 960,
                      "height": 518
                    },
                    {
                      "url": "https://external-preview.redd.it/hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb5439e321758db220736b4ddd80f3cdab962692",
                      "width": 1080,
                      "height": 583
                    }
                  ],
                  "variants": {},
                  "id": "hINCyazmugT5nd39NF13gjbN1S3l4nlzHPyy65fQcLI"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mkby4r",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "holdvacs",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mkby4r/semantic_textual_similarity_on_apple_silicon/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mkby4r/semantic_textual_similarity_on_apple_silicon/",
            "subreddit_subscribers": 513813,
            "created_utc": 1754600478,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7iekl7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "thecstep",
            "can_mod_post": false,
            "created_utc": 1754610234,
            "send_replies": true,
            "parent_id": "t3_1mkby4r",
            "score": 1,
            "author_fullname": "t2_5bva3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Ask AI to fix the AI. That said Qwen models were dogshit slow for me. MXBAI were fantastic.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7iekl7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ask AI to fix the AI. That said Qwen models were dogshit slow for me. MXBAI were fantastic.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkby4r/semantic_textual_similarity_on_apple_silicon/n7iekl7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754610234,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkby4r",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7itmp2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "OriginalTerran",
            "can_mod_post": false,
            "created_utc": 1754615552,
            "send_replies": true,
            "parent_id": "t3_1mkby4r",
            "score": 1,
            "author_fullname": "t2_1kqhi8ngtm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If u want to use it with sentence transformers, the model needs extra adaptations. I know the reranker has one \n\nhttps://huggingface.co/tomaarsen/Qwen3-Reranker-0.6B-seq-cls\nBut I’m not sure if someone converted the embedding model.\nThe one u have is an mlx model and it only works using the mlx framework.",
            "edited": 1754615823,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7itmp2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If u want to use it with sentence transformers, the model needs extra adaptations. I know the reranker has one &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/tomaarsen/Qwen3-Reranker-0.6B-seq-cls\"&gt;https://huggingface.co/tomaarsen/Qwen3-Reranker-0.6B-seq-cls&lt;/a&gt;\nBut I’m not sure if someone converted the embedding model.\nThe one u have is an mlx model and it only works using the mlx framework.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mkby4r/semantic_textual_similarity_on_apple_silicon/n7itmp2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754615552,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mkby4r",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]