[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "First of all, the webui of llama.cpp has improved - thank you to all the web wizards doing this!\n\nHowever, there are a few annoyances I want to change. For example, the chat windows has a limited width, meaning long generated code is wrapped and hard to read. Ok, I found in index.scss:\n\n    .chat-screen {\n      max-width: 900px;\n    }\n\n...this can be thrown out or changed.\n\nBut now I have to rebuild index.html with some Typescript setup (which I havn't figured out yet) and then repatch this on every version upgrade.\n\nAnother, more complex improvement would be to replace the \"llama.cpp\" top banner and window title \"llama.cpp\" of the webbrowser with the name of the model being run. As I have usually 3+ different instances running, this would make keeping track of the different models and browser windows much easier. I havn't figured out how to patch this, yet.\n\nTL;DR: When you patch webui of llama.cpp, what's your strategy to do this efficiently?\n\n\nIf all fails, any recommendations for a \"lean\" webui that connects to llama-server? (lean = less white space waste, less rounded corners, no always-shown conversations bar, maybe make easier to ask same question to multiple models on different llama-server instances, ...)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Strategy for patching llama.cpp webui - and keeping it patched?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1ma3yps",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 1,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 9,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_neruppu",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 9,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753563038,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all, the webui of llama.cpp has improved - thank you to all the web wizards doing this!&lt;/p&gt;\n\n&lt;p&gt;However, there are a few annoyances I want to change. For example, the chat windows has a limited width, meaning long generated code is wrapped and hard to read. Ok, I found in index.scss:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;.chat-screen {\n  max-width: 900px;\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;...this can be thrown out or changed.&lt;/p&gt;\n\n&lt;p&gt;But now I have to rebuild index.html with some Typescript setup (which I havn&amp;#39;t figured out yet) and then repatch this on every version upgrade.&lt;/p&gt;\n\n&lt;p&gt;Another, more complex improvement would be to replace the &amp;quot;llama.cpp&amp;quot; top banner and window title &amp;quot;llama.cpp&amp;quot; of the webbrowser with the name of the model being run. As I have usually 3+ different instances running, this would make keeping track of the different models and browser windows much easier. I havn&amp;#39;t figured out how to patch this, yet.&lt;/p&gt;\n\n&lt;p&gt;TL;DR: When you patch webui of llama.cpp, what&amp;#39;s your strategy to do this efficiently?&lt;/p&gt;\n\n&lt;p&gt;If all fails, any recommendations for a &amp;quot;lean&amp;quot; webui that connects to llama-server? (lean = less white space waste, less rounded corners, no always-shown conversations bar, maybe make easier to ask same question to multiple models on different llama-server instances, ...)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1ma3yps",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "a_postgres_situation",
            "discussion_type": null,
            "num_comments": 3,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1ma3yps/strategy_for_patching_llamacpp_webui_and_keeping/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ma3yps/strategy_for_patching_llamacpp_webui_and_keeping/",
            "subreddit_subscribers": 505616,
            "created_utc": 1753563038,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5bt8ok",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "dinerburgeryum",
            "can_mod_post": false,
            "created_utc": 1753563907,
            "send_replies": true,
            "parent_id": "t3_1ma3yps",
            "score": 8,
            "author_fullname": "t2_1j53p3yv3e",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Using git I’d make a fork, branch it, and rebase on upstream/main before rebuilds. Easy. I’ll concede this requires a functional knowledge of git but maybe even the GitHub application would get this done for you. ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5bt8ok",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Using git I’d make a fork, branch it, and rebase on upstream/main before rebuilds. Easy. I’ll concede this requires a functional knowledge of git but maybe even the GitHub application would get this done for you. &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma3yps/strategy_for_patching_llamacpp_webui_and_keeping/n5bt8ok/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753563907,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma3yps",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 8
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5cwe5s",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "DeProgrammer99",
            "can_mod_post": false,
            "created_utc": 1753578047,
            "send_replies": true,
            "parent_id": "t3_1ma3yps",
            "score": 7,
            "author_fullname": "t2_w4j8t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I just use Tampermonkey (or Greasemonkey for Firefox). I added a \"count prompt tokens\" button at some point. (Though it doesn't work with large pasted text now that it no longer shows up in the textbox.)\n\n    // ==UserScript==\n    // @name         Llama Server Token Count Button\n    // @namespace    http://tampermonkey.net/\n    // @version      2024-12-09\n    // @description  try to take over the world!\n    // @author       You\n    // @match        http://127.0.0.1:7861/\n    // @icon         https://www.google.com/s2/favicons?sz=64&amp;domain=0.1\n    // @grant        none\n    // ==/UserScript==\n    \n    (function() {\n        'use strict';\n    \n        // Your code here...\n        document.querySelector(\".btn-primary\").insertAdjacentHTML(\"afterend\", \"&lt;button class='btn btn-secondary' onclick='countTokens()'&gt;Count Tokens&lt;/button&gt;\");\n        window.countTokens = function() {\n            fetch(\"/tokenize\", {\n                method: 'POST',\n                body: JSON.stringify({content: document.querySelector(\"#msg-input\").value}),\n            }).then(p =&gt; p.json()).then(p =&gt;\n                document.querySelector(\".btn-secondary\").textContent = p.tokens.length\n            );\n        }\n    })();",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5cwe5s",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I just use Tampermonkey (or Greasemonkey for Firefox). I added a &amp;quot;count prompt tokens&amp;quot; button at some point. (Though it doesn&amp;#39;t work with large pasted text now that it no longer shows up in the textbox.)&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;// ==UserScript==\n// @name         Llama Server Token Count Button\n// @namespace    http://tampermonkey.net/\n// @version      2024-12-09\n// @description  try to take over the world!\n// @author       You\n// @match        http://127.0.0.1:7861/\n// @icon         https://www.google.com/s2/favicons?sz=64&amp;amp;domain=0.1\n// @grant        none\n// ==/UserScript==\n\n(function() {\n    &amp;#39;use strict&amp;#39;;\n\n    // Your code here...\n    document.querySelector(&amp;quot;.btn-primary&amp;quot;).insertAdjacentHTML(&amp;quot;afterend&amp;quot;, &amp;quot;&amp;lt;button class=&amp;#39;btn btn-secondary&amp;#39; onclick=&amp;#39;countTokens()&amp;#39;&amp;gt;Count Tokens&amp;lt;/button&amp;gt;&amp;quot;);\n    window.countTokens = function() {\n        fetch(&amp;quot;/tokenize&amp;quot;, {\n            method: &amp;#39;POST&amp;#39;,\n            body: JSON.stringify({content: document.querySelector(&amp;quot;#msg-input&amp;quot;).value}),\n        }).then(p =&amp;gt; p.json()).then(p =&amp;gt;\n            document.querySelector(&amp;quot;.btn-secondary&amp;quot;).textContent = p.tokens.length\n        );\n    }\n})();\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma3yps/strategy_for_patching_llamacpp_webui_and_keeping/n5cwe5s/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753578047,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma3yps",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5byhkp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "DorphinPack",
            "can_mod_post": false,
            "created_utc": 1753565659,
            "send_replies": true,
            "parent_id": "t3_1ma3yps",
            "score": 4,
            "author_fullname": "t2_zebuyjw9s",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "+1 on the idea of having a fork of the git repo and building from source. I was surprised at how easy the building part is.\n\nThe git part is ALWAYS a headache the first time but just know there are senior developers who blush when you ask them any kind of real git question. You’ll be fine as long as you’re brave and being careful.\n\nBasically your fork is a parallel version of the main repo that knows the main repo is “upstream”. You have a branch (“username/custom-ui” or similar) in your repo. When new updates are available in the main repo’s main branch you can pull them into your repo’s main branch and then integrate those changes (rebasing is probably the right move) into your work branch and rebuild. Idk if it sounds overcomplicated but it is &lt;5 commands once you’re set up. The alternatives are PAINFUL.\n\nThe great news is you’re keeping your changes manually already so you can blow it up and start from scratch without losing anything. Eventually you’ll be all-in but to start it might be as simple as cloning the main repo and manually reapplying your changes every time you pull.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5byhkp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;+1 on the idea of having a fork of the git repo and building from source. I was surprised at how easy the building part is.&lt;/p&gt;\n\n&lt;p&gt;The git part is ALWAYS a headache the first time but just know there are senior developers who blush when you ask them any kind of real git question. You’ll be fine as long as you’re brave and being careful.&lt;/p&gt;\n\n&lt;p&gt;Basically your fork is a parallel version of the main repo that knows the main repo is “upstream”. You have a branch (“username/custom-ui” or similar) in your repo. When new updates are available in the main repo’s main branch you can pull them into your repo’s main branch and then integrate those changes (rebasing is probably the right move) into your work branch and rebuild. Idk if it sounds overcomplicated but it is &amp;lt;5 commands once you’re set up. The alternatives are PAINFUL.&lt;/p&gt;\n\n&lt;p&gt;The great news is you’re keeping your changes manually already so you can blow it up and start from scratch without losing anything. Eventually you’ll be all-in but to start it might be as simple as cloning the main repo and manually reapplying your changes every time you pull.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma3yps/strategy_for_patching_llamacpp_webui_and_keeping/n5byhkp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753565659,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma3yps",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        }
      ],
      "before": null
    }
  }
]