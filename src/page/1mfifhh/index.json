[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I wanna use this model for DMing a dnd game as well as using it to write stories. I‚Äôd like it to be abliterated if possible.\n\nI‚Äôve been looking at using Gemma 3 27B, and I do like its writing style, but I‚Äôm concerned about its ability to handle long context lengths.\n\nSo far I haven‚Äôt had that problem but that‚Äôs only because I‚Äôve been running it with low context lengths, since I‚Äôm using it on my gaming pc right now.\n\nI‚Äôm in the middle of building a budget local AI pc right now, 2 MI50 32gbs with 64gb of ddr4 ram on am4. With 64gb of vram combined, I want to see if there are better options available to me.\n\nThanks in advance ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Best creative writing + long context model?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mfifhh",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 1,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 9,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_rn6co7q5m",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 9,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754111899,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanna use this model for DMing a dnd game as well as using it to write stories. I‚Äôd like it to be abliterated if possible.&lt;/p&gt;\n\n&lt;p&gt;I‚Äôve been looking at using Gemma 3 27B, and I do like its writing style, but I‚Äôm concerned about its ability to handle long context lengths.&lt;/p&gt;\n\n&lt;p&gt;So far I haven‚Äôt had that problem but that‚Äôs only because I‚Äôve been running it with low context lengths, since I‚Äôm using it on my gaming pc right now.&lt;/p&gt;\n\n&lt;p&gt;I‚Äôm in the middle of building a budget local AI pc right now, 2 MI50 32gbs with 64gb of ddr4 ram on am4. With 64gb of vram combined, I want to see if there are better options available to me.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mfifhh",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "opoot_",
            "discussion_type": null,
            "num_comments": 5,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mfifhh/best_creative_writing_long_context_model/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mfifhh/best_creative_writing_long_context_model/",
            "subreddit_subscribers": 509054,
            "created_utc": 1754111899,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6hky4j",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ttkciar",
            "can_mod_post": false,
            "created_utc": 1754117463,
            "send_replies": true,
            "parent_id": "t3_1mfifhh",
            "score": 6,
            "author_fullname": "t2_cpegz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "For D&amp;D, you should use the Gemma3-27B fine-tune Big-Tiger-Gemma-27B-v3.  I have been using it for science fiction writing, and it is **brutal** (in a good way).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hky4j",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For D&amp;amp;D, you should use the Gemma3-27B fine-tune Big-Tiger-Gemma-27B-v3.  I have been using it for science fiction writing, and it is &lt;strong&gt;brutal&lt;/strong&gt; (in a good way).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfifhh/best_creative_writing_long_context_model/n6hky4j/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754117463,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mfifhh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6lkszy",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Ok_Exchange_8504",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6kpo5f",
                                "score": 1,
                                "author_fullname": "t2_p7nqw2dg",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "¬°Gracias por el inter√©s!\n\nNo uso memoria externa ni herramientas avanzadas. Todo lo controlo directamente desde el prompt, estructurado para mantener personalidad y contexto dentro de una √∫nica sesi√≥n.\n\n‚ö†Ô∏è Cada personaje tiene un bloque inicial que define su comportamiento.  \nüîÑA eso le a√±ado interacciones previas como si fueran entradas de diario o conversaci√≥n.  \n‚ùåNo uso RAG, ni embeddings, ni nada adicional. Solo texto, llama.cpp, y algo de bash.\n\nAqu√≠ tienes un ejemplo de estructura usada en tareas de revisi√≥n literaria, que muestra c√≥mo mantengo el rol estable sin necesidad de memoria externa: [https://gist.github.com/BiblioGalactic/24ab06c3dd744283c120b239a4af0d5f](https://gist.github.com/BiblioGalactic/24ab06c3dd744283c120b239a4af0d5f)\n\nSi te interesa algo m√°s espec√≠fico, dime qu√© modelo usas y te oriento con gusto.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6lkszy",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;¬°Gracias por el inter√©s!&lt;/p&gt;\n\n&lt;p&gt;No uso memoria externa ni herramientas avanzadas. Todo lo controlo directamente desde el prompt, estructurado para mantener personalidad y contexto dentro de una √∫nica sesi√≥n.&lt;/p&gt;\n\n&lt;p&gt;‚ö†Ô∏è Cada personaje tiene un bloque inicial que define su comportamiento.&lt;br/&gt;\nüîÑA eso le a√±ado interacciones previas como si fueran entradas de diario o conversaci√≥n.&lt;br/&gt;\n‚ùåNo uso RAG, ni embeddings, ni nada adicional. Solo texto, llama.cpp, y algo de bash.&lt;/p&gt;\n\n&lt;p&gt;Aqu√≠ tienes un ejemplo de estructura usada en tareas de revisi√≥n literaria, que muestra c√≥mo mantengo el rol estable sin necesidad de memoria externa: &lt;a href=\"https://gist.github.com/BiblioGalactic/24ab06c3dd744283c120b239a4af0d5f\"&gt;https://gist.github.com/BiblioGalactic/24ab06c3dd744283c120b239a4af0d5f&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Si te interesa algo m√°s espec√≠fico, dime qu√© modelo usas y te oriento con gusto.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mfifhh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mfifhh/best_creative_writing_long_context_model/n6lkszy/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754173361,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754173361,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6kpo5f",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "dlsnet",
                      "can_mod_post": false,
                      "created_utc": 1754162932,
                      "send_replies": true,
                      "parent_id": "t1_n6hcecv",
                      "score": 1,
                      "author_fullname": "t2_del3zk4v",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I would appreciate it if you shared the structure. I'm not able to get any good consistent results",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6kpo5f",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would appreciate it if you shared the structure. I&amp;#39;m not able to get any good consistent results&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mfifhh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mfifhh/best_creative_writing_long_context_model/n6kpo5f/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754162932,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6hcecv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Ok_Exchange_8504",
            "can_mod_post": false,
            "created_utc": 1754112808,
            "send_replies": true,
            "parent_id": "t3_1mfifhh",
            "score": 2,
            "author_fullname": "t2_p7nqw2dg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hey, cool use case ‚Äî I‚Äôve been testing something similar: running local models with fixed narrative roles entirely via prompt, no RAG or fine-tune.\n\nIf your goal is long-form consistency (for D&amp;D or story writing), it‚Äôs not just about context size ‚Äî it‚Äôs about structuring the prompt to simulate memory through tone and behavior.\n\nI‚Äôve had surprisingly good results with smaller models (13B Q6\\_K) using only llama.cpp and bash ‚Äî no server, no frontend.\n\nHappy to share the structure I‚Äôm using if it helps. Your 2x MI50 setup sounds perfect for this kind of controlled simulation. ü§Ø",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hcecv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hey, cool use case ‚Äî I‚Äôve been testing something similar: running local models with fixed narrative roles entirely via prompt, no RAG or fine-tune.&lt;/p&gt;\n\n&lt;p&gt;If your goal is long-form consistency (for D&amp;amp;D or story writing), it‚Äôs not just about context size ‚Äî it‚Äôs about structuring the prompt to simulate memory through tone and behavior.&lt;/p&gt;\n\n&lt;p&gt;I‚Äôve had surprisingly good results with smaller models (13B Q6_K) using only llama.cpp and bash ‚Äî no server, no frontend.&lt;/p&gt;\n\n&lt;p&gt;Happy to share the structure I‚Äôm using if it helps. Your 2x MI50 setup sounds perfect for this kind of controlled simulation. ü§Ø&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfifhh/best_creative_writing_long_context_model/n6hcecv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754112808,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfifhh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6ieuve",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AppearanceHeavy6724",
            "can_mod_post": false,
            "created_utc": 1754134582,
            "send_replies": true,
            "parent_id": "t3_1mfifhh",
            "score": 1,
            "author_fullname": "t2_uz37qfx5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Sadly none of my favorite 3 creative writing models, Gemma 3, GLM-4 and Mistral Nemo have good long context.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ieuve",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sadly none of my favorite 3 creative writing models, Gemma 3, GLM-4 and Mistral Nemo have good long context.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mfifhh/best_creative_writing_long_context_model/n6ieuve/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754134582,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mfifhh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]