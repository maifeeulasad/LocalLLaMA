[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Qwen has introduced a new technique calledÂ **GSPO**Â (Group Sequence Policy Optimization)\n\nPut simply:\n\n* It's a new method for training large language models\n* Instead of focusing on individual words like older methods, it optimizes entire sentences or passages as a whole â€” which is more logical and leads to better performance\n* This approach makes training moreÂ **stable**Â and less prone to crashes or errors, especially when used with large, modular models likeÂ **MoE (Mixture of Experts)**\n* The training process isÂ **simpler**Â and doesnâ€™t rely on complex tricks used in the past, making it cleaner and easier to manage\n* The more compute you throw at it, the better the model becomes â€” itÂ **scales efficiently**.\n* The latestÂ **Qwen3 models**Â (like those that can code or follow instructions) were trained using this method\n* Compared to the olderÂ **GRPO**Â method, GSPO leads toÂ **faster convergence**Â (the model learns faster) and usesÂ **fewer resources**\n\nPaper:Â [https://huggingface.co/papers/2507.18071](https://huggingface.co/papers/2507.18071)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Qwen GSPO (Group Sequence Policy Optimization)",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Other"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1man0hu",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.95,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 61,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1heeqeidfc",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Other",
            "can_mod_post": false,
            "score": 61,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753624825,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Qwen has introduced a new technique calledÂ &lt;strong&gt;GSPO&lt;/strong&gt;Â (Group Sequence Policy Optimization)&lt;/p&gt;\n\n&lt;p&gt;Put simply:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s a new method for training large language models&lt;/li&gt;\n&lt;li&gt;Instead of focusing on individual words like older methods, it optimizes entire sentences or passages as a whole â€” which is more logical and leads to better performance&lt;/li&gt;\n&lt;li&gt;This approach makes training moreÂ &lt;strong&gt;stable&lt;/strong&gt;Â and less prone to crashes or errors, especially when used with large, modular models likeÂ &lt;strong&gt;MoE (Mixture of Experts)&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;The training process isÂ &lt;strong&gt;simpler&lt;/strong&gt;Â and doesnâ€™t rely on complex tricks used in the past, making it cleaner and easier to manage&lt;/li&gt;\n&lt;li&gt;The more compute you throw at it, the better the model becomes â€” itÂ &lt;strong&gt;scales efficiently&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;The latestÂ &lt;strong&gt;Qwen3 models&lt;/strong&gt;Â (like those that can code or follow instructions) were trained using this method&lt;/li&gt;\n&lt;li&gt;Compared to the olderÂ &lt;strong&gt;GRPO&lt;/strong&gt;Â method, GSPO leads toÂ &lt;strong&gt;faster convergence&lt;/strong&gt;Â (the model learns faster) and usesÂ &lt;strong&gt;fewer resources&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Paper:Â &lt;a href=\"https://huggingface.co/papers/2507.18071\"&gt;https://huggingface.co/papers/2507.18071&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/kpkVEAiwNd6D_mfl3tEdDni1cD692QYRZ9sC2FzlBz4.png?auto=webp&amp;s=b7678a8af1d1d28f96c34fbaeb2656718573d56c",
                    "width": 1200,
                    "height": 648
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/kpkVEAiwNd6D_mfl3tEdDni1cD692QYRZ9sC2FzlBz4.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=204816acf3c4a486bb403207785321d33214adc7",
                      "width": 108,
                      "height": 58
                    },
                    {
                      "url": "https://external-preview.redd.it/kpkVEAiwNd6D_mfl3tEdDni1cD692QYRZ9sC2FzlBz4.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=81cb7197b22ed427b6c24ae43d3f69dc4cb2730d",
                      "width": 216,
                      "height": 116
                    },
                    {
                      "url": "https://external-preview.redd.it/kpkVEAiwNd6D_mfl3tEdDni1cD692QYRZ9sC2FzlBz4.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=329be156f229f90b7be0f62070e92a848fedc1f2",
                      "width": 320,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/kpkVEAiwNd6D_mfl3tEdDni1cD692QYRZ9sC2FzlBz4.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=82297d64dd06513853c691039970c2747e099d87",
                      "width": 640,
                      "height": 345
                    },
                    {
                      "url": "https://external-preview.redd.it/kpkVEAiwNd6D_mfl3tEdDni1cD692QYRZ9sC2FzlBz4.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=03df11e5919855e527dbf686542a55fb52fd228c",
                      "width": 960,
                      "height": 518
                    },
                    {
                      "url": "https://external-preview.redd.it/kpkVEAiwNd6D_mfl3tEdDni1cD692QYRZ9sC2FzlBz4.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2d08b01c22320c544d58ffd0a85b1d12a04e7402",
                      "width": 1080,
                      "height": 583
                    }
                  ],
                  "variants": {},
                  "id": "kpkVEAiwNd6D_mfl3tEdDni1cD692QYRZ9sC2FzlBz4"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "7a7848d2-bf8e-11ed-8c2f-765d15199f78",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#94e044",
            "id": "1man0hu",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "koc_Z3",
            "discussion_type": null,
            "num_comments": 5,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1man0hu/qwen_gspo_group_sequence_policy_optimization/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1man0hu/qwen_gspo_group_sequence_policy_optimization/",
            "subreddit_subscribers": 506191,
            "created_utc": 1753624825,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5fwrar",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "bihungba1101",
            "can_mod_post": false,
            "created_utc": 1753628012,
            "send_replies": true,
            "parent_id": "t3_1man0hu",
            "score": 10,
            "author_fullname": "t2_5krbhd7o",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is the advancements that we need!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5fwrar",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is the advancements that we need!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1man0hu/qwen_gspo_group_sequence_policy_optimization/n5fwrar/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753628012,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1man0hu",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 10
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5hjv9s",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Affectionate-Cap-600",
            "can_mod_post": false,
            "created_utc": 1753645577,
            "send_replies": true,
            "parent_id": "t3_1man0hu",
            "score": 2,
            "author_fullname": "t2_5oltmr5b",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "isn't that similar to CISPO used for minimax? (I mean, the aspect of not focusing on specific words)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hjv9s",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;isn&amp;#39;t that similar to CISPO used for minimax? (I mean, the aspect of not focusing on specific words)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1man0hu/qwen_gspo_group_sequence_policy_optimization/n5hjv9s/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753645577,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1man0hu",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5jt9w7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "joninco",
            "can_mod_post": false,
            "created_utc": 1753674218,
            "send_replies": true,
            "parent_id": "t3_1man0hu",
            "score": 2,
            "author_fullname": "t2_8e8y0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Qwen just keeping it coming",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5jt9w7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen just keeping it coming&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1man0hu/qwen_gspo_group_sequence_policy_optimization/n5jt9w7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753674218,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1man0hu",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5hg0c8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Double_Cause4609",
            "can_mod_post": false,
            "created_utc": 1753644391,
            "send_replies": true,
            "parent_id": "t3_1man0hu",
            "score": 2,
            "author_fullname": "t2_1kubzxt2ww",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Is this not analogous to methods talked about in RLOO and Cohere's \"Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs\"?\n\nI know they applied them to GRPO so it's new and shiny, but my suspicion is the techniques are roughly equivalent to what was used there.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5hg0c8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is this not analogous to methods talked about in RLOO and Cohere&amp;#39;s &amp;quot;Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;I know they applied them to GRPO so it&amp;#39;s new and shiny, but my suspicion is the techniques are roughly equivalent to what was used there.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1man0hu/qwen_gspo_group_sequence_policy_optimization/n5hg0c8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753644391,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1man0hu",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5kqavq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "terminoid_",
            "can_mod_post": false,
            "created_utc": 1753691640,
            "send_replies": true,
            "parent_id": "t3_1man0hu",
            "score": 1,
            "author_fullname": "t2_1iu07dnz2i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "ðŸ¦¥ðŸ””",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5kqavq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ðŸ¦¥ðŸ””&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1man0hu/qwen_gspo_group_sequence_policy_optimization/n5kqavq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753691640,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1man0hu",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]