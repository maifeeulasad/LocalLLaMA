[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Right now, open source models aren’t that far off in terms of capabilities compared to proprietary models and models like DeepSeek, Kimi, and Qwen are beating out Claude, Gemini, GPT, etc. in many domains and categories when you look at various benchmarks.\n\nThat said, do you think open source models will continue to remain competitive across their proprietary counterparts? If not, what do you think the turning point will be when proprietary models just completely dominate open source?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Do you think open source models continue to keep pace with proprietary models or will the gap widen?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m7wx5z",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.54,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1gpe2ygava",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753338395,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Right now, open source models aren’t that far off in terms of capabilities compared to proprietary models and models like DeepSeek, Kimi, and Qwen are beating out Claude, Gemini, GPT, etc. in many domains and categories when you look at various benchmarks.&lt;/p&gt;\n\n&lt;p&gt;That said, do you think open source models will continue to remain competitive across their proprietary counterparts? If not, what do you think the turning point will be when proprietary models just completely dominate open source?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1m7wx5z",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Smart-Confection1435",
            "discussion_type": null,
            "num_comments": 18,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/",
            "subreddit_subscribers": 503759,
            "created_utc": 1753338395,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4vh6h8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Due-Competition4564",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4vdo9g",
                                "score": 4,
                                "author_fullname": "t2_p168o2pu",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Man it is getting so easy to detect AI slop these days.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4vh6h8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Man it is getting so easy to detect AI slop these days.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7wx5z",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vh6h8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753352121,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753352121,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4vmnk1",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Stetto",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4vdo9g",
                                "score": 2,
                                "author_fullname": "t2_cqodq",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "And what prevents proprietary models to learn from open-source models as well and include those learnings into their architecture?\n\nSure, everyone loves transparency. But there is not much benefit to being transparent yourself besides idealism.\n\nLLMs aren't linux. LLMs don't need cooperation from more developers.\n\nMaybe try to formulate your own thoughts instead of just making an LLM think for you?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4vmnk1",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And what prevents proprietary models to learn from open-source models as well and include those learnings into their architecture?&lt;/p&gt;\n\n&lt;p&gt;Sure, everyone loves transparency. But there is not much benefit to being transparent yourself besides idealism.&lt;/p&gt;\n\n&lt;p&gt;LLMs aren&amp;#39;t linux. LLMs don&amp;#39;t need cooperation from more developers.&lt;/p&gt;\n\n&lt;p&gt;Maybe try to formulate your own thoughts instead of just making an LLM think for you?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7wx5z",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vmnk1/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753354788,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753354788,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4vdo9g",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "skyblue_Mr",
                      "can_mod_post": false,
                      "created_utc": 1753350263,
                      "send_replies": true,
                      "parent_id": "t1_n4uzrmc",
                      "score": -4,
                      "author_fullname": "t2_8ohz4gw6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yo, let's cut through the BS: Yeah, data quality matters for training, but if your model's core architecture is trash? You're burning cash on insane compute costs while getting garbage outputs.  \n\nHere’s the kicker—closed-source models keep their architectures locked down like Fort Knox (seriously, WTF is under the hood?). Meanwhile, DeepSeek and Qwen are out here open-sourcing their whole playbook: model designs, training tricks, the works.  \n\nThat transparency is game-changing. Projects like Kimi K2 are already baking their innovations into new models. That's how you accelerate the open-source ecosystem. Data's fuel, but architecture's the damn engine.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4vdo9g",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yo, let&amp;#39;s cut through the BS: Yeah, data quality matters for training, but if your model&amp;#39;s core architecture is trash? You&amp;#39;re burning cash on insane compute costs while getting garbage outputs.  &lt;/p&gt;\n\n&lt;p&gt;Here’s the kicker—closed-source models keep their architectures locked down like Fort Knox (seriously, WTF is under the hood?). Meanwhile, DeepSeek and Qwen are out here open-sourcing their whole playbook: model designs, training tricks, the works.  &lt;/p&gt;\n\n&lt;p&gt;That transparency is game-changing. Projects like Kimi K2 are already baking their innovations into new models. That&amp;#39;s how you accelerate the open-source ecosystem. Data&amp;#39;s fuel, but architecture&amp;#39;s the damn engine.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7wx5z",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vdo9g/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753350263,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uzrmc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Stetto",
            "can_mod_post": false,
            "created_utc": 1753342337,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 6,
            "author_fullname": "t2_cqodq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think it's a reasonable assumption, that Qwen and Deepseek are using output from proprietary models for training. \n\nThis fallback will always be possible and allow open-source models to keep pace.\n\nBut open-source doesn't have any innate advantage over proprietary models. In the contrary, for training infrastructure, you just need a huge boatload of money that you can burn for long time.\n\nAny company like Alibaba or Deepseek can decide at any moment, that this cost should be better hidden behind a paywall.\n\nSo, I'd say, we won't know. I see good reasons for both.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uzrmc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it&amp;#39;s a reasonable assumption, that Qwen and Deepseek are using output from proprietary models for training. &lt;/p&gt;\n\n&lt;p&gt;This fallback will always be possible and allow open-source models to keep pace.&lt;/p&gt;\n\n&lt;p&gt;But open-source doesn&amp;#39;t have any innate advantage over proprietary models. In the contrary, for training infrastructure, you just need a huge boatload of money that you can burn for long time.&lt;/p&gt;\n\n&lt;p&gt;Any company like Alibaba or Deepseek can decide at any moment, that this cost should be better hidden behind a paywall.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;d say, we won&amp;#39;t know. I see good reasons for both.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uzrmc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753342337,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4v6l9n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "zoupishness7",
            "can_mod_post": false,
            "created_utc": 1753346240,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 4,
            "author_fullname": "t2_disot",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I think the gap will remain relatively stable, for several years, but maybe not many. It was said at DeepMind, a couple years ago, \"We have no moat, and neither does OpenAI\".  This holds in lot of ways, but not in all. SOTA models are being offered as a service, but that access allows open and closed source interests to distill them. The distillations may not be more powerful, but the successful ones, the ones that tend to be widely adopted, are more efficient, in terms of hardware and energy cost.\n\nAt the same time, there isn't yet a distributed method of training a model, from scratch, that is more cost effective than cramming a bunch of brand new expensive hardware, into a relatively compact location, with top of the line energy and cooling infrastructure.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v6l9n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the gap will remain relatively stable, for several years, but maybe not many. It was said at DeepMind, a couple years ago, &amp;quot;We have no moat, and neither does OpenAI&amp;quot;.  This holds in lot of ways, but not in all. SOTA models are being offered as a service, but that access allows open and closed source interests to distill them. The distillations may not be more powerful, but the successful ones, the ones that tend to be widely adopted, are more efficient, in terms of hardware and energy cost.&lt;/p&gt;\n\n&lt;p&gt;At the same time, there isn&amp;#39;t yet a distributed method of training a model, from scratch, that is more cost effective than cramming a bunch of brand new expensive hardware, into a relatively compact location, with top of the line energy and cooling infrastructure.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v6l9n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753346240,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4v0afi",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "NNN_Throwaway2",
            "can_mod_post": false,
            "created_utc": 1753342637,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 3,
            "author_fullname": "t2_8rrihts9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It'll only widen if closed source makes a breakthrough in tech. Right now everyone is milking the same cow.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v0afi",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;ll only widen if closed source makes a breakthrough in tech. Right now everyone is milking the same cow.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v0afi/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753342637,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4v9tqu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "dark-light92",
            "can_mod_post": false,
            "created_utc": 1753348080,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 3,
            "author_fullname": "t2_3lvoq8zw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "There are very few open source models. What we have is open weight. Similar to freeware. \n\nEven if a lab publishes all their data and training recipes, training a SOTA model requires ungodly amount of compute.  \n\nSo, the question you should be asking is till when companies like deepseek, qwen and mistral will continue to release the weights of the models under open licenses because the moment they stop, the gap will widen. There is no truly open source player in SOTA race.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v9tqu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There are very few open source models. What we have is open weight. Similar to freeware. &lt;/p&gt;\n\n&lt;p&gt;Even if a lab publishes all their data and training recipes, training a SOTA model requires ungodly amount of compute.  &lt;/p&gt;\n\n&lt;p&gt;So, the question you should be asking is till when companies like deepseek, qwen and mistral will continue to release the weights of the models under open licenses because the moment they stop, the gap will widen. There is no truly open source player in SOTA race.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v9tqu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753348080,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n4uyhfw",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "custodiam99",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n4uxn0x",
                                "score": 1,
                                "author_fullname": "t2_nqnhgqqf5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It depends on how they will solve the \"common sense\" problem. Even Yann LeCun said it is a surprisingly hard problem.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n4uyhfw",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It depends on how they will solve the &amp;quot;common sense&amp;quot; problem. Even Yann LeCun said it is a surprisingly hard problem.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m7wx5z",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uyhfw/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753341607,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753341607,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n4uxn0x",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No_Efficiency_1144",
                      "can_mod_post": false,
                      "created_utc": 1753341142,
                      "send_replies": true,
                      "parent_id": "t1_n4uty60",
                      "score": 3,
                      "author_fullname": "t2_1nkj9l14b0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Causal encoding is way more efficient so we might be lucky",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4uxn0x",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Causal encoding is way more efficient so we might be lucky&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7wx5z",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uxn0x/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753341142,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uty60",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "custodiam99",
            "can_mod_post": false,
            "created_utc": 1753339147,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 2,
            "author_fullname": "t2_nqnhgqqf5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It will widen only if spatial-temporal and causal world models won't run on local PCs.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uty60",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It will widen only if spatial-temporal and causal world models won&amp;#39;t run on local PCs.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uty60/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753339147,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4uvcqj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Psionikus",
            "can_mod_post": false,
            "created_utc": 1753339904,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 2,
            "author_fullname": "t2_8vhsch4i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The equilibrium depends on a lot of factors.  A very telling question is if there are advantages to having open IP.  This usually occurs around standards and integration points.\n\nDownstream programs will want to integrate with MCP and A2A etc.  Local models are the only thing that can be trusted to gate interactions with remote models long term.  That's a lot of financial interest that does not care what happens to OpenAI and the rest.\n\nIn general, diversity breaks down walled gardens because it increases the value delivered by integration.  As long as there are a lot of players, you can expect that the demand to integrate downstream will pump a lot of economy into thicker open IP foundations with thinner closed IP products built on top and plugging into the foundatin.\n\nIMO we're just waiting on architecture compression to leave us in a situation with massively overbuilt compute and most of the models any human can ever want will be local.  Supercomputers will run more traditional simulations while taking input from models to walk strange gradients that can't be done with explicitly programmed numerical methods.  Basically CFD + AI and molecular modeling + AI etc will eat up the spare compute capacity.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uvcqj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The equilibrium depends on a lot of factors.  A very telling question is if there are advantages to having open IP.  This usually occurs around standards and integration points.&lt;/p&gt;\n\n&lt;p&gt;Downstream programs will want to integrate with MCP and A2A etc.  Local models are the only thing that can be trusted to gate interactions with remote models long term.  That&amp;#39;s a lot of financial interest that does not care what happens to OpenAI and the rest.&lt;/p&gt;\n\n&lt;p&gt;In general, diversity breaks down walled gardens because it increases the value delivered by integration.  As long as there are a lot of players, you can expect that the demand to integrate downstream will pump a lot of economy into thicker open IP foundations with thinner closed IP products built on top and plugging into the foundatin.&lt;/p&gt;\n\n&lt;p&gt;IMO we&amp;#39;re just waiting on architecture compression to leave us in a situation with massively overbuilt compute and most of the models any human can ever want will be local.  Supercomputers will run more traditional simulations while taking input from models to walk strange gradients that can&amp;#39;t be done with explicitly programmed numerical methods.  Basically CFD + AI and molecular modeling + AI etc will eat up the spare compute capacity.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uvcqj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753339904,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4v30gy",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ethertype",
            "can_mod_post": false,
            "created_utc": 1753344172,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 2,
            "author_fullname": "t2_3nfev4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Proprietary models will end up having to throw in more hardware to stay ahead of *other* proprietary models, making them unsuitable for local use. And such is the modern business anyway, sell whatever as a service for that sweet, sweet recurring revenue. A lot of VC money is burned every day to come into position, and it is way too early to predict winners. \n\nSo maybe the question should be: can open and *local* models and affordable hardware remain *or* become *good enough* to matter vs whatever remains standing among proprietary models when VC-money finally dries out?\n\nI am convinced the answer to that is 'yes'. \n\nThis is just another iteration of the process described in Clayton M. Christensen's \"The Innovator's Dilemma\". \n\n\n*However:*\nThere are certain aspects of \"access to technology\" which can shape the development a bit. As of 2025, there are:\n- memory manufacturers (Samsung, Hynix and Micron). \n- compute hardware (IP, tech, competence), which is a slightly more crowded field: (Nvidia, Intel, AMD, ARM and quite a few more.)\n- semiconductor *manufacturing* side, which in the top end is rather limited (TSMC, SMIC, Global Foundries, Samsung)\n- semiconductor manufacturing *machinery* (of which ASML is of major importance)\n\nYou need the whole stack, and the number of players at each rung of the ladder is so limited that it approaches a vulnerability.\n\nReplacing or even competing with any one of these companies is approaching a nation state level effort, requiring wast amounts of talent, cash, energy and water. And time. Lots of time.\n\nUnless, of course, someone comes up with a really bright idea *again*. Innovation never stops. :-)",
            "edited": 1753344931,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4v30gy",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Proprietary models will end up having to throw in more hardware to stay ahead of &lt;em&gt;other&lt;/em&gt; proprietary models, making them unsuitable for local use. And such is the modern business anyway, sell whatever as a service for that sweet, sweet recurring revenue. A lot of VC money is burned every day to come into position, and it is way too early to predict winners. &lt;/p&gt;\n\n&lt;p&gt;So maybe the question should be: can open and &lt;em&gt;local&lt;/em&gt; models and affordable hardware remain &lt;em&gt;or&lt;/em&gt; become &lt;em&gt;good enough&lt;/em&gt; to matter vs whatever remains standing among proprietary models when VC-money finally dries out?&lt;/p&gt;\n\n&lt;p&gt;I am convinced the answer to that is &amp;#39;yes&amp;#39;. &lt;/p&gt;\n\n&lt;p&gt;This is just another iteration of the process described in Clayton M. Christensen&amp;#39;s &amp;quot;The Innovator&amp;#39;s Dilemma&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;However:&lt;/em&gt;\nThere are certain aspects of &amp;quot;access to technology&amp;quot; which can shape the development a bit. As of 2025, there are:\n- memory manufacturers (Samsung, Hynix and Micron). \n- compute hardware (IP, tech, competence), which is a slightly more crowded field: (Nvidia, Intel, AMD, ARM and quite a few more.)\n- semiconductor &lt;em&gt;manufacturing&lt;/em&gt; side, which in the top end is rather limited (TSMC, SMIC, Global Foundries, Samsung)\n- semiconductor manufacturing &lt;em&gt;machinery&lt;/em&gt; (of which ASML is of major importance)&lt;/p&gt;\n\n&lt;p&gt;You need the whole stack, and the number of players at each rung of the ladder is so limited that it approaches a vulnerability.&lt;/p&gt;\n\n&lt;p&gt;Replacing or even competing with any one of these companies is approaching a nation state level effort, requiring wast amounts of talent, cash, energy and water. And time. Lots of time.&lt;/p&gt;\n\n&lt;p&gt;Unless, of course, someone comes up with a really bright idea &lt;em&gt;again&lt;/em&gt;. Innovation never stops. :-)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v30gy/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753344172,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4v05tx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Stetto",
                      "can_mod_post": false,
                      "created_utc": 1753342565,
                      "send_replies": true,
                      "parent_id": "t1_n4uv74o",
                      "score": 6,
                      "author_fullname": "t2_cqodq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Linux being open-source has the advantage of more developers being able to contributes.\n\nLLMs being open-source has only the down-side, that they can be used unlicensed. Meanwhile, whoever develops the model still has to get hold on an unreasonable amount of data and pay incredible infrastructure costs.\n\nWhile I'm a big fan of open-source software, I don't see how the benefits translate to LLMs.\n\nBehind every successful open-source money, there's still a large company pouring money into it and I doubt all of those companies will keep their models open-source out of the goodness of their hearts.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4v05tx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Linux being open-source has the advantage of more developers being able to contributes.&lt;/p&gt;\n\n&lt;p&gt;LLMs being open-source has only the down-side, that they can be used unlicensed. Meanwhile, whoever develops the model still has to get hold on an unreasonable amount of data and pay incredible infrastructure costs.&lt;/p&gt;\n\n&lt;p&gt;While I&amp;#39;m a big fan of open-source software, I don&amp;#39;t see how the benefits translate to LLMs.&lt;/p&gt;\n\n&lt;p&gt;Behind every successful open-source money, there&amp;#39;s still a large company pouring money into it and I doubt all of those companies will keep their models open-source out of the goodness of their hearts.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7wx5z",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v05tx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753342565,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uv74o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GPTshop_ai",
            "can_mod_post": false,
            "created_utc": 1753339821,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 2,
            "author_fullname": "t2_rkmud0isr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "My guess is, that open source may soon even close the gap. But we might end up with the same situation as with Windows vs Linux. Linux is far far far better. But people still use windows. It is absolutly ridiculous.",
            "edited": 1753340059,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uv74o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My guess is, that open source may soon even close the gap. But we might end up with the same situation as with Windows vs Linux. Linux is far far far better. But people still use windows. It is absolutly ridiculous.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uv74o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753339821,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4vo2dx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "davewolfs",
            "can_mod_post": false,
            "created_utc": 1753355420,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 1,
            "author_fullname": "t2_pms20",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It has widened and will continue to do so.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4vo2dx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It has widened and will continue to do so.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vo2dx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753355420,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4vwero",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Budget_Map_3333",
            "can_mod_post": false,
            "created_utc": 1753358841,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": 1,
            "author_fullname": "t2_19mrnrt357",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "In terms of model performance of similar types, I think proprietary might have a leg up because of heavier investment.\n\nHowever, innovation and breakthroughs ***usually*** happen on the open-source front because of an engaged community, a wider pool of knowledge and sometimes constrained resources can actually be **a good thing**.\n\nJust look at OpenAI is blowing through a fortune and are barely keeping up. Then a few guys with a couple million of investment go ahead and build DeepSeek R1 with a fraction of compute. More infrastructure and money ≠ innovation.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4vwero",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In terms of model performance of similar types, I think proprietary might have a leg up because of heavier investment.&lt;/p&gt;\n\n&lt;p&gt;However, innovation and breakthroughs &lt;strong&gt;&lt;em&gt;usually&lt;/em&gt;&lt;/strong&gt; happen on the open-source front because of an engaged community, a wider pool of knowledge and sometimes constrained resources can actually be &lt;strong&gt;a good thing&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Just look at OpenAI is blowing through a fortune and are barely keeping up. Then a few guys with a couple million of investment go ahead and build DeepSeek R1 with a fraction of compute. More infrastructure and money ≠ innovation.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4vwero/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753358841,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4v8or5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ethertype",
                      "can_mod_post": false,
                      "created_utc": 1753347427,
                      "send_replies": true,
                      "parent_id": "t1_n4uy8mv",
                      "score": 2,
                      "author_fullname": "t2_3nfev4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "And what would it take to turn that question on its head: \n\nWill Western labs have access to enough compute/memory/talent/time/money/energy/manufacturing-tech to keep up?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4v8or5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And what would it take to turn that question on its head: &lt;/p&gt;\n\n&lt;p&gt;Will Western labs have access to enough compute/memory/talent/time/money/energy/manufacturing-tech to keep up?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m7wx5z",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4v8or5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753347427,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4uy8mv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "krakoi90",
            "can_mod_post": false,
            "created_utc": 1753341472,
            "send_replies": true,
            "parent_id": "t3_1m7wx5z",
            "score": -1,
            "author_fullname": "t2_uzz9kqlq",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Open models = Chinese models. So, in other words, your question is: did closed-model (western) AI labs find a way around the data problem, and can they continue to scale up by building larger and larger server farms? Will Chinese labs have access to enough compute to keep up?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4uy8mv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Open models = Chinese models. So, in other words, your question is: did closed-model (western) AI labs find a way around the data problem, and can they continue to scale up by building larger and larger server farms? Will Chinese labs have access to enough compute to keep up?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m7wx5z/do_you_think_open_source_models_continue_to_keep/n4uy8mv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753341472,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m7wx5z",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        }
      ],
      "before": null
    }
  }
]