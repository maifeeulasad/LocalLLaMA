[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi all,\n\nI've hit my usage limit again for Claude Code, and it's time to switch to OpenCode with the newest Qwen model. I plan to generate many, many millions of tokens - working on an app to gamify the creation of RL environments (think GMod, but you come out of it with a working robot).  \n  \nWhat is the most economical way to do this? From what I hear, the newest Qwen model has hit the threshold of being sufficient at tool usage and code output quality, so that is the model I plan on using but I am open to suggestions.\n\nThanks for reading!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "OpenRouter vs Lambda: Which is more economical for millions of tokens on the newest Qwen coder model?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjc4kb",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.67,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_c0jhbv85",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754503923,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve hit my usage limit again for Claude Code, and it&amp;#39;s time to switch to OpenCode with the newest Qwen model. I plan to generate many, many millions of tokens - working on an app to gamify the creation of RL environments (think GMod, but you come out of it with a working robot).  &lt;/p&gt;\n\n&lt;p&gt;What is the most economical way to do this? From what I hear, the newest Qwen model has hit the threshold of being sufficient at tool usage and code output quality, so that is the model I plan on using but I am open to suggestions.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mjc4kb",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "ImpressiveSir9769",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mjc4kb/openrouter_vs_lambda_which_is_more_economical_for/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjc4kb/openrouter_vs_lambda_which_is_more_economical_for/",
            "subreddit_subscribers": 512875,
            "created_utc": 1754503923,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7a81kk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Efficiency_1144",
            "can_mod_post": false,
            "created_utc": 1754507282,
            "send_replies": true,
            "parent_id": "t3_1mjc4kb",
            "score": 1,
            "author_fullname": "t2_1nkj9l14b0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The problem is how many tokens per dollar you can get out of cloud rental servers is heavily dependent on Skill Issue.\n\n\nIf you can write an optimised CUDA kernel for your workflow which includes optimised communication across multiple GPUs then for many tasks it can be a lot cheaper. This is easier said than done though.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7a81kk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The problem is how many tokens per dollar you can get out of cloud rental servers is heavily dependent on Skill Issue.&lt;/p&gt;\n\n&lt;p&gt;If you can write an optimised CUDA kernel for your workflow which includes optimised communication across multiple GPUs then for many tasks it can be a lot cheaper. This is easier said than done though.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjc4kb/openrouter_vs_lambda_which_is_more_economical_for/n7a81kk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754507282,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjc4kb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7a849n",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ShengrenR",
            "can_mod_post": false,
            "created_utc": 1754507303,
            "send_replies": true,
            "parent_id": "t3_1mjc4kb",
            "score": 1,
            "author_fullname": "t2_ji4n4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "A) - fun idea re the gamification of RL environments.. give it a good name better than gym and pettingzoo lol  \nB) Inception! [https://openrouter.ai/provider/lambda](https://openrouter.ai/provider/lambda)\n\nC) if you mean lambda for renting hardware, not an API endpoint, you will almost assuredly pay more per token because you're on your own chunk of metal and don't get to enjoy the efficiencies that come with setting up massive batch/queues. However, if your 'many millions' aren't serial and can be set up to run as a gigantic batch process of a bunch of different requests.. maybe you start to come back toward hardware rental being reasonable.\n\nD) Rate limits.. just going on to OR the endpoint providers will likely start throwing you rate limit warnings.. so figure out what that looks like vs your own key on an individual provider vs the general cloud providers who sell big chunks of metal time.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7a849n",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A) - fun idea re the gamification of RL environments.. give it a good name better than gym and pettingzoo lol&lt;br/&gt;\nB) Inception! &lt;a href=\"https://openrouter.ai/provider/lambda\"&gt;https://openrouter.ai/provider/lambda&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;C) if you mean lambda for renting hardware, not an API endpoint, you will almost assuredly pay more per token because you&amp;#39;re on your own chunk of metal and don&amp;#39;t get to enjoy the efficiencies that come with setting up massive batch/queues. However, if your &amp;#39;many millions&amp;#39; aren&amp;#39;t serial and can be set up to run as a gigantic batch process of a bunch of different requests.. maybe you start to come back toward hardware rental being reasonable.&lt;/p&gt;\n\n&lt;p&gt;D) Rate limits.. just going on to OR the endpoint providers will likely start throwing you rate limit warnings.. so figure out what that looks like vs your own key on an individual provider vs the general cloud providers who sell big chunks of metal time.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjc4kb/openrouter_vs_lambda_which_is_more_economical_for/n7a849n/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754507303,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjc4kb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7by5r6",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Capable-Ad-7494",
                      "can_mod_post": false,
                      "created_utc": 1754526317,
                      "send_replies": true,
                      "parent_id": "t1_n79zv97",
                      "score": 1,
                      "author_fullname": "t2_9so78ol2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "if he’s making a dataset, i’m fairly sure it is an option",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7by5r6",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;if he’s making a dataset, i’m fairly sure it is an option&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjc4kb",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjc4kb/openrouter_vs_lambda_which_is_more_economical_for/n7by5r6/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754526317,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n79zv97",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "BanaBreadSingularity",
            "can_mod_post": false,
            "created_utc": 1754504954,
            "send_replies": true,
            "parent_id": "t3_1mjc4kb",
            "score": 1,
            "author_fullname": "t2_11d4n76hca",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you're coding, you know how to do your own experiments, as well as principled project management: Function before optimization. \n\nTest yourself. \n\nPrice is only but one dimension. \n\nLatency, uptime, customer support. \n\nIf you're going for \"many, many millions of tokens\", surely cheap but unreliable isn't an option.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n79zv97",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;re coding, you know how to do your own experiments, as well as principled project management: Function before optimization. &lt;/p&gt;\n\n&lt;p&gt;Test yourself. &lt;/p&gt;\n\n&lt;p&gt;Price is only but one dimension. &lt;/p&gt;\n\n&lt;p&gt;Latency, uptime, customer support. &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re going for &amp;quot;many, many millions of tokens&amp;quot;, surely cheap but unreliable isn&amp;#39;t an option.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjc4kb/openrouter_vs_lambda_which_is_more_economical_for/n79zv97/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754504954,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjc4kb",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]