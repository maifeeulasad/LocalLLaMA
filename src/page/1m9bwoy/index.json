[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Finally put together my rig after months of planning into a NAS case \n\n* Threadripper PRO 7955WX\n* Arctic Freezer 4U-M (cpu cooler)\n* Gigabyte TRX50 AI TOP\n* be quiet! Dark Power Pro 13 1600W\n* JONSBO N5 Case\n* 2x RTX Pro 6000\n\nMight add a few more intake fans on the top ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Compact 2x RTX Pro 6000 Rig",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 105,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m9bwoy",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.94,
            "author_flair_background_color": null,
            "ups": 67,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_16xbdr",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 67,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/nIQWXwAd5JWfTiQ6FGVC1XWYiGxzWflAKHHcq1t0koA.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753479993,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Finally put together my rig after months of planning into a NAS case &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Threadripper PRO 7955WX&lt;/li&gt;\n&lt;li&gt;Arctic Freezer 4U-M (cpu cooler)&lt;/li&gt;\n&lt;li&gt;Gigabyte TRX50 AI TOP&lt;/li&gt;\n&lt;li&gt;be quiet! Dark Power Pro 13 1600W&lt;/li&gt;\n&lt;li&gt;JONSBO N5 Case&lt;/li&gt;\n&lt;li&gt;2x RTX Pro 6000&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Might add a few more intake fans on the top &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/tbteu4v5b3ff1.jpeg",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/tbteu4v5b3ff1.jpeg?auto=webp&amp;s=e1c07ae621c323dcd20838da5641e3e02cc70f91",
                    "width": 1679,
                    "height": 1264
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/tbteu4v5b3ff1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cb8530b9905fee9ce384e441b1786c16863f92ac",
                      "width": 108,
                      "height": 81
                    },
                    {
                      "url": "https://preview.redd.it/tbteu4v5b3ff1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bb080d3b642a8ae64a22c14c8185ffb66785a5a8",
                      "width": 216,
                      "height": 162
                    },
                    {
                      "url": "https://preview.redd.it/tbteu4v5b3ff1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df5d60cb32c2381511e9f8f424415f43363b229e",
                      "width": 320,
                      "height": 240
                    },
                    {
                      "url": "https://preview.redd.it/tbteu4v5b3ff1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bb7c498f0a5ad74816f597205d993264473bdbfe",
                      "width": 640,
                      "height": 481
                    },
                    {
                      "url": "https://preview.redd.it/tbteu4v5b3ff1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3cd46419a68e44716f2e3b674a590f0b8f7e8f9e",
                      "width": 960,
                      "height": 722
                    },
                    {
                      "url": "https://preview.redd.it/tbteu4v5b3ff1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f10578355cca1e987b8febd5ea512ad847a0ac02",
                      "width": 1080,
                      "height": 813
                    }
                  ],
                  "variants": {},
                  "id": "75hqb9t8X6IAo2hcG2QxH9eY348BDsA6al0LQJShjQE"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1m9bwoy",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "shadowninjaz3",
            "discussion_type": null,
            "num_comments": 46,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/",
            "stickied": false,
            "url": "https://i.redd.it/tbteu4v5b3ff1.jpeg",
            "subreddit_subscribers": 504485,
            "created_utc": 1753479993,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n55yhye",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "SillyLilBear",
                      "can_mod_post": false,
                      "created_utc": 1753480899,
                      "send_replies": true,
                      "parent_id": "t1_n55wmmv",
                      "score": 13,
                      "author_fullname": "t2_wjjtz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "at least 1!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n55yhye",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;at least 1!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n55yhye/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753480899,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 13
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n55wmmv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ArtisticHamster",
            "can_mod_post": false,
            "created_utc": 1753480307,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 9,
            "author_fullname": "t2_2t2xbyfm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Very nice!\nHow many tok/s you get on popular models?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n55wmmv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Very nice!\nHow many tok/s you get on popular models?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n55wmmv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753480307,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n565orf",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "DorphinPack",
                      "can_mod_post": false,
                      "created_utc": 1753483283,
                      "send_replies": true,
                      "parent_id": "t1_n56349f",
                      "score": 2,
                      "author_fullname": "t2_zebuyjw9s",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I have somehow ended up in a Frankenstein situation with an air cooled front to back system and an open air cooled 3090 in a Fractal Core X9. With a very loud JBOD.\n\nGuess I‚Äôm gonna go find some extra shifts to save up because DAMN this would fix all my problems.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n565orf",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have somehow ended up in a Frankenstein situation with an air cooled front to back system and an open air cooled 3090 in a Fractal Core X9. With a very loud JBOD.&lt;/p&gt;\n\n&lt;p&gt;Guess I‚Äôm gonna go find some extra shifts to save up because DAMN this would fix all my problems.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n565orf/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753483283,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n56f2ii",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ThenExtension9196",
                      "can_mod_post": false,
                      "created_utc": 1753486446,
                      "send_replies": true,
                      "parent_id": "t1_n56349f",
                      "score": 2,
                      "author_fullname": "t2_ess5kaos",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Those are rtx6000 pro max-q GPUs. 300 watts. I run mine in a 90f garage  and the blower fan doesn‚Äôt even go past 70%, quietest blower fan I‚Äôve ever used too.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n56f2ii",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Those are rtx6000 pro max-q GPUs. 300 watts. I run mine in a 90f garage  and the blower fan doesn‚Äôt even go past 70%, quietest blower fan I‚Äôve ever used too.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": true,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56f2ii/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753486446,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n56tp1z",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "kmouratidis",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n56iytp",
                                "score": 1,
                                "author_fullname": "t2_k6u7rfxb",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Keep us updated! And make sure to try vllm and sglang with TP (ideally single request and throughput!), not just llama.cpp D:\n\nI've been considering whether I want to ~~sell my liver~~ blow up months of savings for something like this over my 4x3090 system, but the benchmarks I've seen with only one of them weren't very promising.\n\n&gt;!And Mistral-small has been so good and fast (and multi-modal) I basically stopped using 70B and Qwen3-30B-A3B, and I'm cooking something with it that if successful I might not switch away from Mistral for another year, but need a few more days of testing.!&lt;",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n56tp1z",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Keep us updated! And make sure to try vllm and sglang with TP (ideally single request and throughput!), not just llama.cpp D:&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been considering whether I want to &lt;del&gt;sell my liver&lt;/del&gt; blow up months of savings for something like this over my 4x3090 system, but the benchmarks I&amp;#39;ve seen with only one of them weren&amp;#39;t very promising.&lt;/p&gt;\n\n&lt;p&gt;&lt;span class=\"md-spoiler-text\"&gt;And Mistral-small has been so good and fast (and multi-modal) I basically stopped using 70B and Qwen3-30B-A3B, and I&amp;#39;m cooking something with it that if successful I might not switch away from Mistral for another year, but need a few more days of testing.&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56tp1z/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753491639,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753491639,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n56iytp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "shadowninjaz3",
                      "can_mod_post": false,
                      "created_utc": 1753487778,
                      "send_replies": true,
                      "parent_id": "t1_n56349f",
                      "score": 1,
                      "author_fullname": "t2_16xbdr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes! Jonsbo N5 has a great layout and a lot of space for all the pcie power wires on the bottom half when you take out the drive bays. \n\nI went with 4x 64GB dimms, haven't run anything yet but can't wait to get it cooking",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n56iytp",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes! Jonsbo N5 has a great layout and a lot of space for all the pcie power wires on the bottom half when you take out the drive bays. &lt;/p&gt;\n\n&lt;p&gt;I went with 4x 64GB dimms, haven&amp;#39;t run anything yet but can&amp;#39;t wait to get it cooking&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56iytp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753487778,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n56349f",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Marksta",
            "can_mod_post": false,
            "created_utc": 1753482413,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 7,
            "author_fullname": "t2_559a1",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Daaamn, Jonsbo N5 is a dream case. With a worthy price tag to match, but what a top tier layout it has. Besides, the cost is peanuts compared to those dual 6000s.\n\nAlso don't think we don't see that new age liquid crystal polymer exhaust fan you're rocking. When those two 6000s go at full blast, you could definitely use every edge you can get for moving air.\n\nHow much RAM you packing in there? Did you go big with 48GB+ dimms? Your local Kimi-K2 is really hoping you did! But really, the almost 200 GB VRAM can gobble up half a big ass MoE Q4 all on its own.\n\nTell what you're running and some pp/tg numbers. That thing is a friggen beast, I think you're going to be having a lot of fun üòÖ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n56349f",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Daaamn, Jonsbo N5 is a dream case. With a worthy price tag to match, but what a top tier layout it has. Besides, the cost is peanuts compared to those dual 6000s.&lt;/p&gt;\n\n&lt;p&gt;Also don&amp;#39;t think we don&amp;#39;t see that new age liquid crystal polymer exhaust fan you&amp;#39;re rocking. When those two 6000s go at full blast, you could definitely use every edge you can get for moving air.&lt;/p&gt;\n\n&lt;p&gt;How much RAM you packing in there? Did you go big with 48GB+ dimms? Your local Kimi-K2 is really hoping you did! But really, the almost 200 GB VRAM can gobble up half a big ass MoE Q4 all on its own.&lt;/p&gt;\n\n&lt;p&gt;Tell what you&amp;#39;re running and some pp/tg numbers. That thing is a friggen beast, I think you&amp;#39;re going to be having a lot of fun üòÖ&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56349f/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753482413,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n56jg1h",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "shadowninjaz3",
                      "can_mod_post": false,
                      "created_utc": 1753487946,
                      "send_replies": true,
                      "parent_id": "t1_n5673bl",
                      "score": 3,
                      "author_fullname": "t2_16xbdr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes its the Max Q version, which I'm glad I chose over the 600 watt cards because the max Qs are already pretty hot.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n56jg1h",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes its the Max Q version, which I&amp;#39;m glad I chose over the 600 watt cards because the max Qs are already pretty hot.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56jg1h/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753487946,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5673bl",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "corsair-pirate",
            "can_mod_post": false,
            "created_utc": 1753483755,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 3,
            "author_fullname": "t2_54fpyu2s",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Is this the Max Q version?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5673bl",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is this the Max Q version?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n5673bl/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753483755,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "body": "Have you run anything interesting on it yet?  I have one 6000 pro and I‚Äôm not sure it‚Äôs giving me a ton of functionality over a 5090 because either the smaller models are good enough for half of what I‚Äôm working on or I need something bigger than what I can fit in 96gig of vram.  For me it‚Äôs landing in whatever the opposite of a sweet spot is.",
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ef488598-491f-11ef-a847-9a3dd315819c",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n56ft3s",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ThenExtension9196",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n56459j",
                                "score": 2,
                                "author_fullname": "t2_ess5kaos",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You are correct. 96G is specifically for training and large dataset tasks, usually for video related workloads, such as massive upscaling or rendering jobs. Easily can max out my rtx6000 when doing SEEDVR2 upscale. Mine is ‚Äúonly‚Äù about 10% faster than my 5090 but you simply cannot run certain models without a large pool of unified VRAM.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n56ft3s",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You are correct. 96G is specifically for training and large dataset tasks, usually for video related workloads, such as massive upscaling or rendering jobs. Easily can max out my rtx6000 when doing SEEDVR2 upscale. Mine is ‚Äúonly‚Äù about 10% faster than my 5090 but you simply cannot run certain models without a large pool of unified VRAM.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": true,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56ft3s/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753486698,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753486698,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n56459j",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "panchovix",
                      "can_mod_post": false,
                      "created_utc": 1753482760,
                      "send_replies": true,
                      "parent_id": "t1_n560jte",
                      "score": 5,
                      "author_fullname": "t2_j1kqr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Not OP, but copy/pasting a bit from other comment.\n\nI think the major advantage for 96GB a single GPU is training with huge batches for diffusion (txt2img, txt2vid, etc) and bigger video models (also diffusion).\n\nLLMs are in a weird spot of 20-30B then like 235B and then 685B (Deepseek) and then 1T (Kimi). Op gets the benefit of 235B fully on GPU with 192GB VRAM with quantization, the next step is quite bigger and has to offload to CPU, which still can perform very decently on MoE models.",
                      "edited": 1753486743,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n56459j",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "Llama 405B"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not OP, but copy/pasting a bit from other comment.&lt;/p&gt;\n\n&lt;p&gt;I think the major advantage for 96GB a single GPU is training with huge batches for diffusion (txt2img, txt2vid, etc) and bigger video models (also diffusion).&lt;/p&gt;\n\n&lt;p&gt;LLMs are in a weird spot of 20-30B then like 235B and then 685B (Deepseek) and then 1T (Kimi). Op gets the benefit of 235B fully on GPU with 192GB VRAM with quantization, the next step is quite bigger and has to offload to CPU, which still can perform very decently on MoE models.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56459j/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753482760,
                      "author_flair_text": "Llama 405B",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n564x26",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DAlmighty",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n562a12",
                                "score": 1,
                                "author_fullname": "t2_a04uj",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I‚Äôll take the accelerator off your hands if you dont want it hahaha",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n564x26",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I‚Äôll take the accelerator off your hands if you dont want it hahaha&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n564x26/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753483023,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753483023,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "ef488598-491f-11ef-a847-9a3dd315819c",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n56lt4x",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "shadowninjaz3",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n56l6p8",
                                                              "score": 1,
                                                              "author_fullname": "t2_16xbdr",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "I thought the modded 4090 48GB cards use double sided slots for the memory chips?",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n56lt4x",
                                                              "is_submitter": true,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I thought the modded 4090 48GB cards use double sided slots for the memory chips?&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1m9bwoy",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56lt4x/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753488787,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753488787,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n56l6p8",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "panchovix",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n56j647",
                                                    "score": 2,
                                                    "author_fullname": "t2_j1kqr",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "5090 48GB is possible (when 3GB GDDR7 chips get more available), but 96GB nope because the PCB only has 16 VRAM \"slots\" per side (so 16x3GB = max 48GB). 6000 PRO has 32 VRAM \"slots\", 16 at the front and 16 at the back, so that's how they get it up to 96GB.\n\nIf at any point a 4GB GDDR7 chip gets released, then a modded 5090 could have 64GB VRAM (and a 6000PRO 128GB VRAM).\n\nAlso it is not just solder more VRAM but also making the stock VBIOS detect the extra VRAM. There is some way to do this by soldering and changing a sequence on the PCB but not sure if anyone has tried that yet.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n56l6p8",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "e": "text",
                                                        "t": "Llama 405B"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;5090 48GB is possible (when 3GB GDDR7 chips get more available), but 96GB nope because the PCB only has 16 VRAM &amp;quot;slots&amp;quot; per side (so 16x3GB = max 48GB). 6000 PRO has 32 VRAM &amp;quot;slots&amp;quot;, 16 at the front and 16 at the back, so that&amp;#39;s how they get it up to 96GB.&lt;/p&gt;\n\n&lt;p&gt;If at any point a 4GB GDDR7 chip gets released, then a modded 5090 could have 64GB VRAM (and a 6000PRO 128GB VRAM).&lt;/p&gt;\n\n&lt;p&gt;Also it is not just solder more VRAM but also making the stock VBIOS detect the extra VRAM. There is some way to do this by soldering and changing a sequence on the PCB but not sure if anyone has tried that yet.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m9bwoy",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "light",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56l6p8/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753488566,
                                                    "author_flair_text": "Llama 405B",
                                                    "collapsed": false,
                                                    "created_utc": 1753488566,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "#bbbdbf",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n56j647",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "shadowninjaz3",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n56g1fs",
                                          "score": 0,
                                          "author_fullname": "t2_16xbdr",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Was hoping modded 5090 96G would come out lol",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n56j647",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Was hoping modded 5090 96G would come out lol&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m9bwoy",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56j647/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753487849,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753487849,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 0
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n56g1fs",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ThenExtension9196",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n562a12",
                                "score": 1,
                                "author_fullname": "t2_ess5kaos",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yes and unfortunately the 48G card has slower core. 48G is a nice size.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n56g1fs",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes and unfortunately the 48G card has slower core. 48G is a nice size.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": true,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56g1fs/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753486777,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753486777,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n562a12",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "shadowninjaz3",
                      "can_mod_post": false,
                      "created_utc": 1753482133,
                      "send_replies": true,
                      "parent_id": "t1_n560jte",
                      "score": 4,
                      "author_fullname": "t2_16xbdr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I mainly play with finetuning models so the extra gigs are what make it possible. Sad that nothing really fits on 24/32 gig cards anymore except when running inference only.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n562a12",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I mainly play with finetuning models so the extra gigs are what make it possible. Sad that nothing really fits on 24/32 gig cards anymore except when running inference only.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n562a12/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753482133,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ef488598-491f-11ef-a847-9a3dd315819c",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n56v93g",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "tylerhardin",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n56lhld",
                                          "score": 1,
                                          "author_fullname": "t2_x6e5t",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I'm running 4 sticks of 6000mhz gskill, but it gets cut to 4800 with 4 sticks. I need 4 sticks for other stuff i do (work, compiling). It's a ryzen 9950x.\n\nI can't really tolerate single digit tok/s for what i wanna do. Agentic coding is the only use case I care much about, and you need 50 tok/s for that to feel worthwhile (if each turn takes a minute, I may as well just do the work myself yk)",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n56v93g",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running 4 sticks of 6000mhz gskill, but it gets cut to 4800 with 4 sticks. I need 4 sticks for other stuff i do (work, compiling). It&amp;#39;s a ryzen 9950x.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t really tolerate single digit tok/s for what i wanna do. Agentic coding is the only use case I care much about, and you need 50 tok/s for that to feel worthwhile (if each turn takes a minute, I may as well just do the work myself yk)&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m9bwoy",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56v93g/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753492211,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753492211,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n56lhld",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "panchovix",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n566uyh",
                                "score": 1,
                                "author_fullname": "t2_j1kqr",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "If you have a ryzen CPU with 6000Mhz or more it can be usable. Not decent but serviceable. I have a 7800X3D with 192GB RAM (and 208GB VRAM) and it is serviceable for deepseek at 4 bits.\n\nA double CCD ryzen CPU would be better (theoretical max jumps from 64 GB/s to 100GB/s), but still lower than a \"low end\" TR 7000/9000 like a 7960X/9960X (near 180-200 GB/s).\n\nNow, only on MoE models. I get like 6-7 t/s with a dense 253B model (nemotron) running fully on GPU at 6 bits lol.",
                                "edited": 1753488903,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n56lhld",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "Llama 405B"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you have a ryzen CPU with 6000Mhz or more it can be usable. Not decent but serviceable. I have a 7800X3D with 192GB RAM (and 208GB VRAM) and it is serviceable for deepseek at 4 bits.&lt;/p&gt;\n\n&lt;p&gt;A double CCD ryzen CPU would be better (theoretical max jumps from 64 GB/s to 100GB/s), but still lower than a &amp;quot;low end&amp;quot; TR 7000/9000 like a 7960X/9960X (near 180-200 GB/s).&lt;/p&gt;\n\n&lt;p&gt;Now, only on MoE models. I get like 6-7 t/s with a dense 253B model (nemotron) running fully on GPU at 6 bits lol.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56lhld/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753488672,
                                "author_flair_text": "Llama 405B",
                                "treatment_tags": [],
                                "created_utc": 1753488672,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n56ulvt",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "kmouratidis",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n566uyh",
                                "score": 1,
                                "author_fullname": "t2_k6u7rfxb",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "What input &amp; output speeds are you getting on those Q2 quants? On my 4x3090 with slow RAM I'm getting like 60-90 tps input and &lt;40 tps output (at zero context).",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n56ulvt",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What input &amp;amp; output speeds are you getting on those Q2 quants? On my 4x3090 with slow RAM I&amp;#39;m getting like 60-90 tps input and &amp;lt;40 tps output (at zero context).&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56ulvt/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753491972,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753491972,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n566uyh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "tylerhardin",
                      "can_mod_post": false,
                      "created_utc": 1753483679,
                      "send_replies": true,
                      "parent_id": "t1_n560jte",
                      "score": 2,
                      "author_fullname": "t2_x6e5t",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I have a single 6000 as well and very much agree. We're definitely in the shit spot.\n\nUnsloths 2bit xl quants of qwen3 225b work. Haven't tested to see if they're useful with Aider tho. You might wanna use the non-xl version for large context.\n\nI dont have a TR, so you might have a better time offloading some context to cpu. For me, on ryzen, it's painful. With pro ddr5 TR, it could be a total non issue, I think",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n566uyh",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have a single 6000 as well and very much agree. We&amp;#39;re definitely in the shit spot.&lt;/p&gt;\n\n&lt;p&gt;Unsloths 2bit xl quants of qwen3 225b work. Haven&amp;#39;t tested to see if they&amp;#39;re useful with Aider tho. You might wanna use the non-xl version for large context.&lt;/p&gt;\n\n&lt;p&gt;I dont have a TR, so you might have a better time offloading some context to cpu. For me, on ryzen, it&amp;#39;s painful. With pro ddr5 TR, it could be a total non issue, I think&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n566uyh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753483679,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n56jxiy",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "____vladrad",
                      "can_mod_post": false,
                      "created_utc": 1753488118,
                      "send_replies": true,
                      "parent_id": "t1_n560jte",
                      "score": 2,
                      "author_fullname": "t2_u6i8a0ay",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I have 2 At 131k context I run qwen 235b q4. 75 tk/s. I let qwen code run for about 1.5 hours last night and it worked like a dream",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n56jxiy",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have 2 At 131k context I run qwen 235b q4. 75 tk/s. I let qwen code run for about 1.5 hours last night and it worked like a dream&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56jxiy/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753488118,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n568s8w",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "eloquentemu",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n562ehg",
                                "score": 4,
                                "author_fullname": "t2_lpdsy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The problem is that the CPU parts still bottleneck.  Qwen3-235B-Q4_K_M is 133GB.  That means you can offload the context, common tensors, and maybe about half the experts.  That means that roughly 2/3 of the active weights are on GPU and 1/3 are on CPU.  If we approximate the GPU as infinitely fast you get a 3/1=300% speed up... Nice!\n\nHowever that's vs CPU-only.  A 24GB still lets you offload the context and common tensors, but ~none of the weights.  That means that 1/3 of active params are on the GPU and 2/3 are on CPU.  So that's a 3/2=150% speed up.  Okay!\n\nBut that means the Pro6000 is only maybe 2x faster than a 3090 in the same system though dramatically more expensive.  It could be a solid upgrade to a server, for example, but it's not really going to elevate a desktop.  A server will give far more bang/buck especially when you consider those numbers are _only_ for 235B and not MoE in general.  Coder-480B, Deepseek-671B, Kimi-1000B will all see minimal speed up vs a 3090 due to smaller offload fractions.",
                                "edited": 1753485356,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n568s8w",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The problem is that the CPU parts still bottleneck.  Qwen3-235B-Q4_K_M is 133GB.  That means you can offload the context, common tensors, and maybe about half the experts.  That means that roughly 2/3 of the active weights are on GPU and 1/3 are on CPU.  If we approximate the GPU as infinitely fast you get a 3/1=300% speed up... Nice!&lt;/p&gt;\n\n&lt;p&gt;However that&amp;#39;s vs CPU-only.  A 24GB still lets you offload the context and common tensors, but ~none of the weights.  That means that 1/3 of active params are on the GPU and 2/3 are on CPU.  So that&amp;#39;s a 3/2=150% speed up.  Okay!&lt;/p&gt;\n\n&lt;p&gt;But that means the Pro6000 is only maybe 2x faster than a 3090 in the same system though dramatically more expensive.  It could be a solid upgrade to a server, for example, but it&amp;#39;s not really going to elevate a desktop.  A server will give far more bang/buck especially when you consider those numbers are &lt;em&gt;only&lt;/em&gt; for 235B and not MoE in general.  Coder-480B, Deepseek-671B, Kimi-1000B will all see minimal speed up vs a 3090 due to smaller offload fractions.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n568s8w/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753484327,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753484327,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ef488598-491f-11ef-a847-9a3dd315819c",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n563spi",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "panchovix",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n562ehg",
                                "score": 2,
                                "author_fullname": "t2_j1kqr",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Yes but you can also do that with multigpu, so there is not much benefit there (from a perf/cost perspective)\n\nI think the major advantage for 96GB a single GPU is training with huge batches for diffusion (txt2img, txt2vid, etc) and bigger video models (also diffusion).\n\nLLMs are in a weird spot of 20-30B then like 235B and then 685B (Deepseek) and then 1T (Kimi). Op gets the benefit of 235B fully on GPU.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n563spi",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "Llama 405B"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes but you can also do that with multigpu, so there is not much benefit there (from a perf/cost perspective)&lt;/p&gt;\n\n&lt;p&gt;I think the major advantage for 96GB a single GPU is training with huge batches for diffusion (txt2img, txt2vid, etc) and bigger video models (also diffusion).&lt;/p&gt;\n\n&lt;p&gt;LLMs are in a weird spot of 20-30B then like 235B and then 685B (Deepseek) and then 1T (Kimi). Op gets the benefit of 235B fully on GPU.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n563spi/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753482642,
                                "author_flair_text": "Llama 405B",
                                "treatment_tags": [],
                                "created_utc": 1753482642,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n562ehg",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "youcef0w0",
                      "can_mod_post": false,
                      "created_utc": 1753482174,
                      "send_replies": true,
                      "parent_id": "t1_n560jte",
                      "score": 1,
                      "author_fullname": "t2_49fdoure",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "for the big models like qwen 235b, can't you run it partially offloaded to ram and still get really good speeds because it's moe and most layer are on GPU?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n562ehg",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;for the big models like qwen 235b, can&amp;#39;t you run it partially offloaded to ram and still get really good speeds because it&amp;#39;s moe and most layer are on GPU?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n562ehg/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753482174,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n564osh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "joninco",
                      "can_mod_post": false,
                      "created_utc": 1753482946,
                      "send_replies": true,
                      "parent_id": "t1_n560jte",
                      "score": 1,
                      "author_fullname": "t2_8e8y0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The unsloth thinking/non-thinking Qwen3's are pretty sweet -- [hf.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF:Q2\\_K\\_XL](http://hf.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF:Q2_K_XL) [hf.co/unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF:Q2\\_K\\_XL](http://hf.co/unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF:Q2_K_XL)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n564osh",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The unsloth thinking/non-thinking Qwen3&amp;#39;s are pretty sweet -- &lt;a href=\"http://hf.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF:Q2_K_XL\"&gt;hf.co/unsloth/Qwen3-235B-A22B-Instruct-2507-GGUF:Q2_K_XL&lt;/a&gt; &lt;a href=\"http://hf.co/unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF:Q2_K_XL\"&gt;hf.co/unsloth/Qwen3-235B-A22B-Thinking-2507-GGUF:Q2_K_XL&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n564osh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753482946,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n56i750",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "a_beautiful_rhind",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n566mtx",
                                "score": 2,
                                "author_fullname": "t2_h5utwre7",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Mistral-large didn't go away. Beats running something like dots. If you want to try what's likely the 106b, go to GLM's site and use the experimental. 70% sure that's it.\n\nOp has a threadripper with 8 channels of DDR5.. I think they will do OK on hybrid inference. Sounds like they already thought of this. \n\nI hope nobody bought a Pro 6000 and didn't get a competent host to go with it. You essentially get 4x4090 or 3090 in one card + FP4/FP8 support. Every tensor you throw on the GPU speeds things up and you eliminated GPU-&gt;GPU transfers.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n56i750",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mistral-large didn&amp;#39;t go away. Beats running something like dots. If you want to try what&amp;#39;s likely the 106b, go to GLM&amp;#39;s site and use the experimental. 70% sure that&amp;#39;s it.&lt;/p&gt;\n\n&lt;p&gt;Op has a threadripper with 8 channels of DDR5.. I think they will do OK on hybrid inference. Sounds like they already thought of this. &lt;/p&gt;\n\n&lt;p&gt;I hope nobody bought a Pro 6000 and didn&amp;#39;t get a competent host to go with it. You essentially get 4x4090 or 3090 in one card + FP4/FP8 support. Every tensor you throw on the GPU speeds things up and you eliminated GPU-&amp;gt;GPU transfers.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56i750/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753487510,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753487510,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n566mtx",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "eloquentemu",
                      "can_mod_post": false,
                      "created_utc": 1753483603,
                      "send_replies": true,
                      "parent_id": "t1_n560jte",
                      "score": 1,
                      "author_fullname": "t2_lpdsy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This is something I ask a lot but don't seem to get much traction on... There is a huge gap in models between 32B and 200B that makes the extra VRAM on a (single) Pro6000 just... extra.  Anyways a couple cases I do see:\n\n- Should be able to do some training / tuning but YMMV how far it'll really get you.  Like, train a 7B normally or a 32B LoRA\n- Long contexts with small models.  Particularly with the high bandwidth, using a 32B @ Q8 is fast and leaves a lot of room for context\n- Long contexts with MoE.  If you offload all non-expert weights and the context to GPU it can significantly speed up MoE inference.  However, that means you need the GPU to hold the context too. Qwen3-Coder-480B at Q4 takes up something like 40GB at 256k context.  (Kimi K2 at 128k context fits on 32GB though.)  And you can offload a couple layers though it won't matter that much.\n- dots.llm1 is 143B-A14B.  It gets good reviews but I haven't used it much.  The Q4_K_M is 95GB so: sad, but a with a bit more quant you could have a model that should be a step up from 32B and run disgustingly fast\n- Hope that the coming-soon 106B-A12B model is good",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n566mtx",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is something I ask a lot but don&amp;#39;t seem to get much traction on... There is a huge gap in models between 32B and 200B that makes the extra VRAM on a (single) Pro6000 just... extra.  Anyways a couple cases I do see:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Should be able to do some training / tuning but YMMV how far it&amp;#39;ll really get you.  Like, train a 7B normally or a 32B LoRA&lt;/li&gt;\n&lt;li&gt;Long contexts with small models.  Particularly with the high bandwidth, using a 32B @ Q8 is fast and leaves a lot of room for context&lt;/li&gt;\n&lt;li&gt;Long contexts with MoE.  If you offload all non-expert weights and the context to GPU it can significantly speed up MoE inference.  However, that means you need the GPU to hold the context too. Qwen3-Coder-480B at Q4 takes up something like 40GB at 256k context.  (Kimi K2 at 128k context fits on 32GB though.)  And you can offload a couple layers though it won&amp;#39;t matter that much.&lt;/li&gt;\n&lt;li&gt;dots.llm1 is 143B-A14B.  It gets good reviews but I haven&amp;#39;t used it much.  The Q4_K_M is 95GB so: sad, but a with a bit more quant you could have a model that should be a step up from 32B and run disgustingly fast&lt;/li&gt;\n&lt;li&gt;Hope that the coming-soon 106B-A12B model is good&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n566mtx/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753483603,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n560jte",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Scottomation",
            "can_mod_post": false,
            "created_utc": 1753481567,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 2,
            "author_fullname": "t2_diuq8s51",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "author_cakeday": true,
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n560jte",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have you run anything interesting on it yet?  I have one 6000 pro and I‚Äôm not sure it‚Äôs giving me a ton of functionality over a 5090 because either the smaller models are good enough for half of what I‚Äôm working on or I need something bigger than what I can fit in 96gig of vram.  For me it‚Äôs landing in whatever the opposite of a sweet spot is.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n560jte/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753481567,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n568nf1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1753484282,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 2,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I would love to see a comparison of Max Q versus non-Max Q. I have been thinking about getting Max Q version myself.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n568nf1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would love to see a comparison of Max Q versus non-Max Q. I have been thinking about getting Max Q version myself.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n568nf1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753484282,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n56bwm6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "azpinstripes",
            "can_mod_post": false,
            "created_utc": 1753485375,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 2,
            "author_fullname": "t2_3z1fitk3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The algorithm knows me. I‚Äôve been eyeing that case. Have the n4 which I love but not a huge fan of the lack of drive bays compared to the n5.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n56bwm6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The algorithm knows me. I‚Äôve been eyeing that case. Have the n4 which I love but not a huge fan of the lack of drive bays compared to the n5.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56bwm6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753485375,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n56jslj",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "shadowninjaz3",
                      "can_mod_post": false,
                      "created_utc": 1753488069,
                      "send_replies": true,
                      "parent_id": "t1_n56epkq",
                      "score": 1,
                      "author_fullname": "t2_16xbdr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yup its the max Q",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n56jslj",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yup its the max Q&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56jslj/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753488069,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n56epkq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ThenExtension9196",
            "can_mod_post": false,
            "created_utc": 1753486323,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 2,
            "author_fullname": "t2_ess5kaos",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Max-q? I just got mine this week. What a beast of a card. Super quiet and efficient.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n56epkq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Max-q? I just got mine this week. What a beast of a card. Super quiet and efficient.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": true,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56epkq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753486323,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n56lune",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Turkino",
            "can_mod_post": false,
            "created_utc": 1753488802,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 2,
            "author_fullname": "t2_ai06o",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I can feel the 30 degree C temp jump in the room already.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n56lune",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can feel the 30 degree C temp jump in the room already.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56lune/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753488802,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n55wszq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No-Vegetable7442",
            "can_mod_post": false,
            "created_utc": 1753480363,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 1,
            "author_fullname": "t2_1bj9i3xe0x",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "what is the speed of qwen3-235b ud3 ?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n55wszq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;what is the speed of qwen3-235b ud3 ?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n55wszq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753480363,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n560wcb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Mr_Moonsilver",
            "can_mod_post": false,
            "created_utc": 1753481682,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 1,
            "author_fullname": "t2_dgr714x",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Very nice!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n560wcb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Very nice!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n560wcb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753481682,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5646dl",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "treksis",
            "can_mod_post": false,
            "created_utc": 1753482770,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 1,
            "author_fullname": "t2_3f7ex4nx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "beautiful",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5646dl",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;beautiful&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n5646dl/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753482770,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n564oou",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "DAlmighty",
            "can_mod_post": false,
            "created_utc": 1753482945,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 1,
            "author_fullname": "t2_a04uj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That‚Äôs so dope",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n564oou",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That‚Äôs so dope&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n564oou/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753482945,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n568quw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Rollingsound514",
            "can_mod_post": false,
            "created_utc": 1753484314,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 1,
            "author_fullname": "t2_3ufqv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Nice Lexus, lol, no but for real that's a lot of dough congrats",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n568quw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice Lexus, lol, no but for real that&amp;#39;s a lot of dough congrats&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n568quw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753484314,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n56kj9d",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "shadowninjaz3",
                      "can_mod_post": false,
                      "created_utc": 1753488334,
                      "send_replies": true,
                      "parent_id": "t1_n56b3gm",
                      "score": 1,
                      "author_fullname": "t2_16xbdr",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I have 4 sticks at 5200 MT/s",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n56kj9d",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have 4 sticks at 5200 MT/s&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56kj9d/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753488334,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n56b3gm",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "un_passant",
            "can_mod_post": false,
            "created_utc": 1753485105,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": 1,
            "author_fullname": "t2_7rqtc",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "More interesting to me than the case : what is the memory bandwidth situation ? How many memory channels and at what speed ?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n56b3gm",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;More interesting to me than the case : what is the memory bandwidth situation ? How many memory channels and at what speed ?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56b3gm/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753485105,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n56ba9g",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "henfiber",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n56a8x9",
                                                    "score": 3,
                                                    "author_fullname": "t2_lw9me25",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Upon closer inspection, they really seem to be RTX 6000 Pros (Max Q). Look at the top-left with a two-line label:  \n  \nRTX Pro  \n6000\n\nwhile the Ada 6000 card from [photos online](https://www.storagereview.com/wp-content/uploads/2023/10/StorageReview-NVIDIA-RTX-6000-Ada-10-1024x768.jpg) seems to have a single line with   \n  \nRTX 6000",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n56ba9g",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Upon closer inspection, they really seem to be RTX 6000 Pros (Max Q). Look at the top-left with a two-line label:  &lt;/p&gt;\n\n&lt;p&gt;RTX Pro&lt;br/&gt;\n6000&lt;/p&gt;\n\n&lt;p&gt;while the Ada 6000 card from &lt;a href=\"https://www.storagereview.com/wp-content/uploads/2023/10/StorageReview-NVIDIA-RTX-6000-Ada-10-1024x768.jpg\"&gt;photos online&lt;/a&gt; seems to have a single line with   &lt;/p&gt;\n\n&lt;p&gt;RTX 6000&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1m9bwoy",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56ba9g/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753485168,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753485168,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n56a8x9",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Khipu28",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n568xpw",
                                          "score": 0,
                                          "author_fullname": "t2_a0v2ol2u",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I don‚Äôt think the Max-Q blackwell are for sale yet. Those could be ada cards.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n56a8x9",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don‚Äôt think the Max-Q blackwell are for sale yet. Those could be ada cards.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m9bwoy",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n56a8x9/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753484819,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753484819,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 0
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n568xpw",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "henfiber",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n568kh7",
                                "score": 2,
                                "author_fullname": "t2_lw9me25",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Oh, thanks I had no idea that the Max Q version was so much different.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n568xpw",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh, thanks I had no idea that the Max Q version was so much different.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m9bwoy",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n568xpw/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753484377,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753484377,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n568kh7",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "triynizzles1",
                      "can_mod_post": false,
                      "created_utc": 1753484254,
                      "send_replies": true,
                      "parent_id": "t1_n567745",
                      "score": 3,
                      "author_fullname": "t2_zr0g49ixt",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "There are three versions of RTX Pro 6000. The one that looks like 5090, Max Q version which appears to be the one in the photo, and then server edition.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n568kh7",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There are three versions of RTX Pro 6000. The one that looks like 5090, Max Q version which appears to be the one in the photo, and then server edition.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m9bwoy",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n568kh7/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753484254,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n567745",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "henfiber",
            "can_mod_post": false,
            "created_utc": 1753483791,
            "send_replies": true,
            "parent_id": "t3_1m9bwoy",
            "score": -1,
            "author_fullname": "t2_lw9me25",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The GPUs in the photo do not look like [RTX Pro 6000](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/rtx-pro-6000/) (96GB)\n\nThey look like [RTX 6000 Ada](https://www.nvidia.com/en-us/products/workstations/rtx-6000/) (48GB)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n567745",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The GPUs in the photo do not look like &lt;a href=\"https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/rtx-pro-6000/\"&gt;RTX Pro 6000&lt;/a&gt; (96GB)&lt;/p&gt;\n\n&lt;p&gt;They look like &lt;a href=\"https://www.nvidia.com/en-us/products/workstations/rtx-6000/\"&gt;RTX 6000 Ada&lt;/a&gt; (48GB)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m9bwoy/compact_2x_rtx_pro_6000_rig/n567745/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753483791,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m9bwoy",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        }
      ],
      "before": null
    }
  }
]