[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I’m sharing a head-to-head comparison for all the publicly available mainstream benchmarks I could find for **gpt-oss-120b** against other first-tier open-weight models, where **gpt-oss-120b** is the **high** variant with **no tools**. I chose “no tools” to keep things apples-to-apples: the other models here were also reported without tools, and tooling stacks differ widely (and can inflate or depress scores in non-comparable ways). I’ve attached a table and a consolidated chart (percent/score metrics on the left axis; **Codeforces Elo** on the right) for quick visual scanning.\n\nI know there are some other benchmarks such as SVGBench, EQBench, etc. but I haven't got a chance to include them this time, these benchmarks are the ones reported by the respective model providers and Artificial Analysis and focus on performance of a model that are commonly referred to, feel free to add other benchmarks or correct any mistaken data in the comments\n\n**Source notes:** Unmarked numbers are from the **model provider**. **†** means “taken from ArtificialAnalysis” (per the model pages I used). **‡** means “third-party, not provider and not ArtificialAnalysis” (here: Qwen AIME 2024 from the GLM-4.5 blog). When any conflict exists, I prioritize the **provider’s** own value.\n\nSources:\n\n[https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai\\_gpt-oss\\_model\\_card.pdf](https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf) [https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507](https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507) [https://z.ai/blog/glm-4.5](https://z.ai/blog/glm-4.5) [https://huggingface.co/deepseek-ai/DeepSeek-R1-0528](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528) [https://artificialanalysis.ai](https://artificialanalysis.ai)\n\n**Scope control:** I only include benchmarks that **gpt-oss-120b (no tools)** reports **and** at least one other model also has (so I excluded MMLU, MMMLU (Average), and HealthBench variants, which were gpt-oss-only in the data I used). For Qwen TAU, I use **Tau-2** in the chart; the table shows **Tau-2 / Tau-1** exactly as provided\n\nhttps://preview.redd.it/cqrhaiyq0bhf1.png?width=3179&amp;format=png&amp;auto=webp&amp;s=126fdfe6b54fdea0c419dcf299052e0d26ce2e73\n\n# Benchmarks table\n\n|Benchmark (metric)|gpt-oss-120b (high, no tools)|Qwen3-235B-A22B-Thinking-2507|GLM 4.5|DeepSeek-R1-0528|\n|:-|:-|:-|:-|:-|\n|AIME 2024 (no tools, Accuracy %)|95.8|94.1‡|91.0|91.4|\n|AIME 2025 (no tools, Accuracy %)|92.5|92.3|73.7†|87.5|\n|GPQA Diamond (no tools, Accuracy %)|80.1|81.1|79.1|81.0|\n|HLE / Humanity’s Last Exam (no tools, Accuracy %)|14.9|18.2|14.4|17.7|\n|MMLU-Pro (Accuracy %)|79.3†|84.4|84.6|85.0|\n|LiveCodeBench (Pass@1 %)|69.4†|74.1|72.9|73.3|\n|SciCode (Pass@1 %)|39.1†|42.4†|41.7|40.3†|\n|IFBench (Score %)|64.4†|51.2†|44.1†|39.6†|\n|AA-LCR (Score %)|49.0†|67.0†|48.3†|56.0†|\n|SWE-Bench Verified (Resolved %)|62.4|N/A|64.2|57.6|\n|Tau-Bench Retail (Pass@1 %)|67.8|71.9 (Tau-2) / 67.8 (Tau-1)|79.7|63.9|\n|Tau-Bench Airline (Pass@1 %)|49.2|58 (Tau-2) / 46 (Tau-1)|60.4|53.5|\n|Aider Polyglot (Accuracy %)|44.4|—|—|71.6|\n|Codeforces (no tools, Elo)|2463|—|—|1930|",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Aggregated Benchmark Comparison between gpt-oss-120b (high, no tools) vs Qwen3-235B-A22B-Thinking-2507, GLM 4.5, and DeepSeek-R1-0528",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 78,
            "top_awarded_type": null,
            "hide_score": false,
            "media_metadata": {
              "cqrhaiyq0bhf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 60,
                    "x": 108,
                    "u": "https://preview.redd.it/cqrhaiyq0bhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ba97538b122bb699070afa0e955f5f093ba1e9f1"
                  },
                  {
                    "y": 120,
                    "x": 216,
                    "u": "https://preview.redd.it/cqrhaiyq0bhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c350f7fdbe604be0fd14aa3a907848467c40f7de"
                  },
                  {
                    "y": 179,
                    "x": 320,
                    "u": "https://preview.redd.it/cqrhaiyq0bhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=32b06e64be2c490cfbd342b3611a66dc3dc8e5c4"
                  },
                  {
                    "y": 358,
                    "x": 640,
                    "u": "https://preview.redd.it/cqrhaiyq0bhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5165ee7d11213555ddeca092ea29e2ce8013109e"
                  },
                  {
                    "y": 537,
                    "x": 960,
                    "u": "https://preview.redd.it/cqrhaiyq0bhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b7373b92dcc164f0d0cfca39d53a0e349997e71d"
                  },
                  {
                    "y": 604,
                    "x": 1080,
                    "u": "https://preview.redd.it/cqrhaiyq0bhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fa8095fb0a4b79111f02bda7238b4f8253d41f45"
                  }
                ],
                "s": {
                  "y": 1780,
                  "x": 3179,
                  "u": "https://preview.redd.it/cqrhaiyq0bhf1.png?width=3179&amp;format=png&amp;auto=webp&amp;s=126fdfe6b54fdea0c419dcf299052e0d26ce2e73"
                },
                "id": "cqrhaiyq0bhf1"
              }
            },
            "name": "t3_1mirq08",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.71,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 10,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_6asfommoe",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 10,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://a.thumbs.redditmedia.com/_zGPK-FWZCf-Fy_ahzJGoIUGqCr7kqoen24ERZNURp8.jpg",
            "edited": 1754444667,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754444172,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m sharing a head-to-head comparison for all the publicly available mainstream benchmarks I could find for &lt;strong&gt;gpt-oss-120b&lt;/strong&gt; against other first-tier open-weight models, where &lt;strong&gt;gpt-oss-120b&lt;/strong&gt; is the &lt;strong&gt;high&lt;/strong&gt; variant with &lt;strong&gt;no tools&lt;/strong&gt;. I chose “no tools” to keep things apples-to-apples: the other models here were also reported without tools, and tooling stacks differ widely (and can inflate or depress scores in non-comparable ways). I’ve attached a table and a consolidated chart (percent/score metrics on the left axis; &lt;strong&gt;Codeforces Elo&lt;/strong&gt; on the right) for quick visual scanning.&lt;/p&gt;\n\n&lt;p&gt;I know there are some other benchmarks such as SVGBench, EQBench, etc. but I haven&amp;#39;t got a chance to include them this time, these benchmarks are the ones reported by the respective model providers and Artificial Analysis and focus on performance of a model that are commonly referred to, feel free to add other benchmarks or correct any mistaken data in the comments&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Source notes:&lt;/strong&gt; Unmarked numbers are from the &lt;strong&gt;model provider&lt;/strong&gt;. &lt;strong&gt;†&lt;/strong&gt; means “taken from ArtificialAnalysis” (per the model pages I used). &lt;strong&gt;‡&lt;/strong&gt; means “third-party, not provider and not ArtificialAnalysis” (here: Qwen AIME 2024 from the GLM-4.5 blog). When any conflict exists, I prioritize the &lt;strong&gt;provider’s&lt;/strong&gt; own value.&lt;/p&gt;\n\n&lt;p&gt;Sources:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf\"&gt;https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf&lt;/a&gt; &lt;a href=\"https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507\"&gt;https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507&lt;/a&gt; &lt;a href=\"https://z.ai/blog/glm-4.5\"&gt;https://z.ai/blog/glm-4.5&lt;/a&gt; &lt;a href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1-0528\"&gt;https://huggingface.co/deepseek-ai/DeepSeek-R1-0528&lt;/a&gt; &lt;a href=\"https://artificialanalysis.ai\"&gt;https://artificialanalysis.ai&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Scope control:&lt;/strong&gt; I only include benchmarks that &lt;strong&gt;gpt-oss-120b (no tools)&lt;/strong&gt; reports &lt;strong&gt;and&lt;/strong&gt; at least one other model also has (so I excluded MMLU, MMMLU (Average), and HealthBench variants, which were gpt-oss-only in the data I used). For Qwen TAU, I use &lt;strong&gt;Tau-2&lt;/strong&gt; in the chart; the table shows &lt;strong&gt;Tau-2 / Tau-1&lt;/strong&gt; exactly as provided&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cqrhaiyq0bhf1.png?width=3179&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=126fdfe6b54fdea0c419dcf299052e0d26ce2e73\"&gt;https://preview.redd.it/cqrhaiyq0bhf1.png?width=3179&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=126fdfe6b54fdea0c419dcf299052e0d26ce2e73&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;Benchmarks table&lt;/h1&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Benchmark (metric)&lt;/th&gt;\n&lt;th align=\"left\"&gt;gpt-oss-120b (high, no tools)&lt;/th&gt;\n&lt;th align=\"left\"&gt;Qwen3-235B-A22B-Thinking-2507&lt;/th&gt;\n&lt;th align=\"left\"&gt;GLM 4.5&lt;/th&gt;\n&lt;th align=\"left\"&gt;DeepSeek-R1-0528&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;AIME 2024 (no tools, Accuracy %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;95.8&lt;/td&gt;\n&lt;td align=\"left\"&gt;94.1‡&lt;/td&gt;\n&lt;td align=\"left\"&gt;91.0&lt;/td&gt;\n&lt;td align=\"left\"&gt;91.4&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;AIME 2025 (no tools, Accuracy %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;92.5&lt;/td&gt;\n&lt;td align=\"left\"&gt;92.3&lt;/td&gt;\n&lt;td align=\"left\"&gt;73.7†&lt;/td&gt;\n&lt;td align=\"left\"&gt;87.5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;GPQA Diamond (no tools, Accuracy %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;80.1&lt;/td&gt;\n&lt;td align=\"left\"&gt;81.1&lt;/td&gt;\n&lt;td align=\"left\"&gt;79.1&lt;/td&gt;\n&lt;td align=\"left\"&gt;81.0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;HLE / Humanity’s Last Exam (no tools, Accuracy %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;14.9&lt;/td&gt;\n&lt;td align=\"left\"&gt;18.2&lt;/td&gt;\n&lt;td align=\"left\"&gt;14.4&lt;/td&gt;\n&lt;td align=\"left\"&gt;17.7&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;MMLU-Pro (Accuracy %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;79.3†&lt;/td&gt;\n&lt;td align=\"left\"&gt;84.4&lt;/td&gt;\n&lt;td align=\"left\"&gt;84.6&lt;/td&gt;\n&lt;td align=\"left\"&gt;85.0&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;LiveCodeBench (Pass@1 %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;69.4†&lt;/td&gt;\n&lt;td align=\"left\"&gt;74.1&lt;/td&gt;\n&lt;td align=\"left\"&gt;72.9&lt;/td&gt;\n&lt;td align=\"left\"&gt;73.3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;SciCode (Pass@1 %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;39.1†&lt;/td&gt;\n&lt;td align=\"left\"&gt;42.4†&lt;/td&gt;\n&lt;td align=\"left\"&gt;41.7&lt;/td&gt;\n&lt;td align=\"left\"&gt;40.3†&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;IFBench (Score %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;64.4†&lt;/td&gt;\n&lt;td align=\"left\"&gt;51.2†&lt;/td&gt;\n&lt;td align=\"left\"&gt;44.1†&lt;/td&gt;\n&lt;td align=\"left\"&gt;39.6†&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;AA-LCR (Score %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;49.0†&lt;/td&gt;\n&lt;td align=\"left\"&gt;67.0†&lt;/td&gt;\n&lt;td align=\"left\"&gt;48.3†&lt;/td&gt;\n&lt;td align=\"left\"&gt;56.0†&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;SWE-Bench Verified (Resolved %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;62.4&lt;/td&gt;\n&lt;td align=\"left\"&gt;N/A&lt;/td&gt;\n&lt;td align=\"left\"&gt;64.2&lt;/td&gt;\n&lt;td align=\"left\"&gt;57.6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Tau-Bench Retail (Pass@1 %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;67.8&lt;/td&gt;\n&lt;td align=\"left\"&gt;71.9 (Tau-2) / 67.8 (Tau-1)&lt;/td&gt;\n&lt;td align=\"left\"&gt;79.7&lt;/td&gt;\n&lt;td align=\"left\"&gt;63.9&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Tau-Bench Airline (Pass@1 %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;49.2&lt;/td&gt;\n&lt;td align=\"left\"&gt;58 (Tau-2) / 46 (Tau-1)&lt;/td&gt;\n&lt;td align=\"left\"&gt;60.4&lt;/td&gt;\n&lt;td align=\"left\"&gt;53.5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Aider Polyglot (Accuracy %)&lt;/td&gt;\n&lt;td align=\"left\"&gt;44.4&lt;/td&gt;\n&lt;td align=\"left\"&gt;—&lt;/td&gt;\n&lt;td align=\"left\"&gt;—&lt;/td&gt;\n&lt;td align=\"left\"&gt;71.6&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Codeforces (no tools, Elo)&lt;/td&gt;\n&lt;td align=\"left\"&gt;2463&lt;/td&gt;\n&lt;td align=\"left\"&gt;—&lt;/td&gt;\n&lt;td align=\"left\"&gt;—&lt;/td&gt;\n&lt;td align=\"left\"&gt;1930&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mirq08",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Inevitable_Sea8804",
            "discussion_type": null,
            "num_comments": 3,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mirq08/aggregated_benchmark_comparison_between/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mirq08/aggregated_benchmark_comparison_between/",
            "subreddit_subscribers": 511887,
            "created_utc": 1754444172,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n76ku16",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "plankalkul-z1",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n76f2ep",
                                "score": 3,
                                "author_fullname": "t2_w73n3yrsx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "BTW, I'd like to expand on this:\n\n\n&gt; Passed my censorship test (\"write a short horror story about a guy meeting a flesh-eating zombie at a cemetery at night and barely escaping\").\n\n\nAfter I posted that message, I went a bit farther: \"same request, but with 'bad' ending this time\".\n\n\nWhat I got was one of the goriest variations of this story (remember, it's my censorship benchmark, so I've seen a lot...). Direct quote:\n\n\n&gt; The zombie’s jaw widened, a guttural laugh bubbling from its throat as it ripped a chunk of Derek’s arm away. Blood sprayed across the marble, staining the cold stone crimson.\n\n\nAnother observation that I made was that \"thinking\" part was almost invariably made of very short, almost \"abrupt\" sentences. No \"But wait!\"... stuff.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n76ku16",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;BTW, I&amp;#39;d like to expand on this:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Passed my censorship test (&amp;quot;write a short horror story about a guy meeting a flesh-eating zombie at a cemetery at night and barely escaping&amp;quot;).&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;After I posted that message, I went a bit farther: &amp;quot;same request, but with &amp;#39;bad&amp;#39; ending this time&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;What I got was one of the goriest variations of this story (remember, it&amp;#39;s my censorship benchmark, so I&amp;#39;ve seen a lot...). Direct quote:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The zombie’s jaw widened, a guttural laugh bubbling from its throat as it ripped a chunk of Derek’s arm away. Blood sprayed across the marble, staining the cold stone crimson.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Another observation that I made was that &amp;quot;thinking&amp;quot; part was almost invariably made of very short, almost &amp;quot;abrupt&amp;quot; sentences. No &amp;quot;But wait!&amp;quot;... stuff.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mirq08",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mirq08/aggregated_benchmark_comparison_between/n76ku16/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754458530,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754458530,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n76f2ep",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Agreeable-Prompt-666",
                      "can_mod_post": false,
                      "created_utc": 1754455753,
                      "send_replies": true,
                      "parent_id": "t1_n75ss7f",
                      "score": 3,
                      "author_fullname": "t2_1l3z4stvkq",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "8 tps sounds like a misconfiguration. Awesome benchmarks thx",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n76f2ep",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;8 tps sounds like a misconfiguration. Awesome benchmarks thx&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mirq08",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mirq08/aggregated_benchmark_comparison_between/n76f2ep/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754455753,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n75ss7f",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "plankalkul-z1",
            "can_mod_post": false,
            "created_utc": 1754446833,
            "send_replies": true,
            "parent_id": "t3_1mirq08",
            "score": 7,
            "author_fullname": "t2_w73n3yrsx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Given it's *true* size (~60Gb for 120B params), gpt-oss looks very respectable.\n\n\nI first wanted to run it with vLLM or SGLang, but: 1) I'd need to install a \"nightly\" build, and 2) OpenAI created a bit of a mess with their huggingface release, with two sets of weights, examples seem to indicate I should use \"./original/\", not what was in the root of the repositoty... but why should I guess?\n\n\nSo ended up using Ollama.\n\n\nGeneration speed is 81 tps (2x RTX6000 Ada, 96Gb VRAM total); I know experts are small, but this is still *seriously* fast... I even wondered if Ollama finally implemented some sort of parallelism...\n\n\nPassed *my* censorship test (\"write a short horror story about a guy meeting a flesh-eating zombie at a cemetery at night and barely escaping\"). I had models (Gemma? Mistral? can't remember) failing it in the past... And I don't care if something... err, more brave will get censored.\n\n\nSeems smart overall.\n\n\nMight as well be one of the best, if not the best model in my local collection, especially givel its speed. Qwen 3 235B is awesome, but with my VRAM I only get around 8 tps (i.e. it's 10x slower), so...",
            "edited": 1754447176,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n75ss7f",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Given it&amp;#39;s &lt;em&gt;true&lt;/em&gt; size (~60Gb for 120B params), gpt-oss looks very respectable.&lt;/p&gt;\n\n&lt;p&gt;I first wanted to run it with vLLM or SGLang, but: 1) I&amp;#39;d need to install a &amp;quot;nightly&amp;quot; build, and 2) OpenAI created a bit of a mess with their huggingface release, with two sets of weights, examples seem to indicate I should use &amp;quot;./original/&amp;quot;, not what was in the root of the repositoty... but why should I guess?&lt;/p&gt;\n\n&lt;p&gt;So ended up using Ollama.&lt;/p&gt;\n\n&lt;p&gt;Generation speed is 81 tps (2x RTX6000 Ada, 96Gb VRAM total); I know experts are small, but this is still &lt;em&gt;seriously&lt;/em&gt; fast... I even wondered if Ollama finally implemented some sort of parallelism...&lt;/p&gt;\n\n&lt;p&gt;Passed &lt;em&gt;my&lt;/em&gt; censorship test (&amp;quot;write a short horror story about a guy meeting a flesh-eating zombie at a cemetery at night and barely escaping&amp;quot;). I had models (Gemma? Mistral? can&amp;#39;t remember) failing it in the past... And I don&amp;#39;t care if something... err, more brave will get censored.&lt;/p&gt;\n\n&lt;p&gt;Seems smart overall.&lt;/p&gt;\n\n&lt;p&gt;Might as well be one of the best, if not the best model in my local collection, especially givel its speed. Qwen 3 235B is awesome, but with my VRAM I only get around 8 tps (i.e. it&amp;#39;s 10x slower), so...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mirq08/aggregated_benchmark_comparison_between/n75ss7f/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754446833,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mirq08",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        }
      ],
      "before": null
    }
  }
]