[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I honestly don't know which one is better suited for things like medical, philosophical, historical topics, or text interpretation...  \nIt's something I've never been clear about.  \nFor example, when I've used Deepseek, sometimes I feel that putting it into \"thinking\" mode doesn't add much, but I haven't noticed a clear pattern like \"for this type of question I use thinking mode, for this other type I don't.\"  \nCould someone clarify this for me?\n\nI'm thinking of downloading this model:  \n**Qwen3-30B-A3B-Instruct-2507** ... or **Qwen3-30B-A3B-Thinking-2507**\n\nThe Instruct version has been downloaded way more and has a lot more likes, but... for what I want, which one is more suitable?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Thinking or Instruct?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mg5scj",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.83,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 8,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_q2iij",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 8,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754181257,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I honestly don&amp;#39;t know which one is better suited for things like medical, philosophical, historical topics, or text interpretation...&lt;br/&gt;\nIt&amp;#39;s something I&amp;#39;ve never been clear about.&lt;br/&gt;\nFor example, when I&amp;#39;ve used Deepseek, sometimes I feel that putting it into &amp;quot;thinking&amp;quot; mode doesn&amp;#39;t add much, but I haven&amp;#39;t noticed a clear pattern like &amp;quot;for this type of question I use thinking mode, for this other type I don&amp;#39;t.&amp;quot;&lt;br/&gt;\nCould someone clarify this for me?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of downloading this model:&lt;br/&gt;\n&lt;strong&gt;Qwen3-30B-A3B-Instruct-2507&lt;/strong&gt; ... or &lt;strong&gt;Qwen3-30B-A3B-Thinking-2507&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The Instruct version has been downloaded way more and has a lot more likes, but... for what I want, which one is more suitable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mg5scj",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "9acca9",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mg5scj/thinking_or_instruct/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mg5scj/thinking_or_instruct/",
            "subreddit_subscribers": 509626,
            "created_utc": 1754181257,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6mehwl",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Murgatroyd314",
                      "can_mod_post": false,
                      "created_utc": 1754184201,
                      "send_replies": true,
                      "parent_id": "t1_n6m8yd4",
                      "score": 1,
                      "author_fullname": "t2_e14gin",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; For conversation, RP or creative tasks, thinking can actually be counterproductive. \n\nI'd agree with this. In most of my (admittedly limited) experience, thinking mode responses have been objectively worse than non-thinking, often because one of the \"but wait, what if\"s takes it off on some irrelevant tangent that it ends up focusing on.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6mehwl",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;For conversation, RP or creative tasks, thinking can actually be counterproductive. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;d agree with this. In most of my (admittedly limited) experience, thinking mode responses have been objectively worse than non-thinking, often because one of the &amp;quot;but wait, what if&amp;quot;s takes it off on some irrelevant tangent that it ends up focusing on.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mg5scj",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mg5scj/thinking_or_instruct/n6mehwl/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754184201,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6m8yd4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Herr_Drosselmeyer",
            "can_mod_post": false,
            "created_utc": 1754182114,
            "send_replies": true,
            "parent_id": "t3_1mg5scj",
            "score": 6,
            "author_fullname": "t2_1zr9gwsn",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I personally find that 'thinking' only makes sense for complex tasks, like coding or planning. Also, if you need precise instruction following, like a specific format, I find it helps because the model can catch itself when it's about to make a mistake.\n\n\nFor conversation, RP or creative tasks, thinking can actually be counterproductive. \n\n\nAt least that's my experience and so I would say that, for your use case, going for the regular version over the thinking one makes sense. \n\n\nUltimately though, try both and go with whichever you prefer.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6m8yd4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I personally find that &amp;#39;thinking&amp;#39; only makes sense for complex tasks, like coding or planning. Also, if you need precise instruction following, like a specific format, I find it helps because the model can catch itself when it&amp;#39;s about to make a mistake.&lt;/p&gt;\n\n&lt;p&gt;For conversation, RP or creative tasks, thinking can actually be counterproductive. &lt;/p&gt;\n\n&lt;p&gt;At least that&amp;#39;s my experience and so I would say that, for your use case, going for the regular version over the thinking one makes sense. &lt;/p&gt;\n\n&lt;p&gt;Ultimately though, try both and go with whichever you prefer.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg5scj/thinking_or_instruct/n6m8yd4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754182114,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg5scj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6mheed",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Tyme4Trouble",
            "can_mod_post": false,
            "created_utc": 1754185317,
            "send_replies": true,
            "parent_id": "t3_1mg5scj",
            "score": 2,
            "author_fullname": "t2_973amyap",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm still grappling with this too. Here's what I'm leaning toward.  \nFor complex reasoning tasks: Qwen3-30B-A3B-Thinking-2507 — the MoE architectures speed makes using the thinking model painless.  \nFor everything else: Qwen3-32B (or Qwen3-32B-Instruct-2507 whenever that drops) — smarter than the 30B MoE and still fast enough for non-thinking jobs.\n\nWe'll have to wait and see how Qwen3-32B-Instruct-2507 stacks up against 30B-A3B-Instruct-2507.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6mheed",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m still grappling with this too. Here&amp;#39;s what I&amp;#39;m leaning toward.&lt;br/&gt;\nFor complex reasoning tasks: Qwen3-30B-A3B-Thinking-2507 — the MoE architectures speed makes using the thinking model painless.&lt;br/&gt;\nFor everything else: Qwen3-32B (or Qwen3-32B-Instruct-2507 whenever that drops) — smarter than the 30B MoE and still fast enough for non-thinking jobs.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ll have to wait and see how Qwen3-32B-Instruct-2507 stacks up against 30B-A3B-Instruct-2507.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg5scj/thinking_or_instruct/n6mheed/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754185317,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg5scj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6mtq8p",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "PermanentLiminality",
            "can_mod_post": false,
            "created_utc": 1754190156,
            "send_replies": true,
            "parent_id": "t3_1mg5scj",
            "score": 2,
            "author_fullname": "t2_19zqycaf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "They are both useful.  Sometimes you don't want to wait for the thinking model.  Other times you need the better answers that a thinking model can provide.  \n\nI can only run one at a time, but I have both.\n\nThe answer is thinking and instruct.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6mtq8p",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They are both useful.  Sometimes you don&amp;#39;t want to wait for the thinking model.  Other times you need the better answers that a thinking model can provide.  &lt;/p&gt;\n\n&lt;p&gt;I can only run one at a time, but I have both.&lt;/p&gt;\n\n&lt;p&gt;The answer is thinking and instruct.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mg5scj/thinking_or_instruct/n6mtq8p/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754190156,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mg5scj",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]