[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "GPU snapshotting is finally a thing! NVIDIA recently released their [CUDA checkpoint/restore API](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CHECKPOINT.html) and we at Modal (serverless compute platform) are using it drastically reduce GPU cold start times. This is especially relevant for serving large models, where it can take minutes (for the heftiest LLMs) to move model weights from disk to memory.\n\nGPU memory snapshotting can reduce cold boot times by up to 12x. It lets you scale GPU resources up and down based on demand without compromising on user-facing latency. Below are some benchmarking results showing improvements for various models!\n\nhttps://preview.redd.it/opb5odlb2hgf1.png?width=3162&amp;format=png&amp;auto=webp&amp;s=00995e770fa4d3ac454bd9b1f0df5296391fb137\n\nMore on how GPU snapshotting works plus additional benchmarks in this blog post: [https://modal.com/blog/gpu-mem-snapshots](https://modal.com/blog/gpu-mem-snapshots)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Cold start vLLM in 5 seconds with GPU snapshotting",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Resources"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 70,
            "top_awarded_type": null,
            "hide_score": false,
            "media_metadata": {
              "opb5odlb2hgf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 54,
                    "x": 108,
                    "u": "https://preview.redd.it/opb5odlb2hgf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d1a99ec3a648e3acbc71ef3233e807e5fbfc20dd"
                  },
                  {
                    "y": 108,
                    "x": 216,
                    "u": "https://preview.redd.it/opb5odlb2hgf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a87d457cf006589e58141d5831e05fc39cc999c4"
                  },
                  {
                    "y": 161,
                    "x": 320,
                    "u": "https://preview.redd.it/opb5odlb2hgf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=156b5387ff8776f0f27387621395be6a4f1bb15b"
                  },
                  {
                    "y": 322,
                    "x": 640,
                    "u": "https://preview.redd.it/opb5odlb2hgf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c498b446dda08ce80241842d3232b30cf40b31ec"
                  },
                  {
                    "y": 483,
                    "x": 960,
                    "u": "https://preview.redd.it/opb5odlb2hgf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=eae84d78449fb87be8ed155a688b75c0cb5ea458"
                  },
                  {
                    "y": 543,
                    "x": 1080,
                    "u": "https://preview.redd.it/opb5odlb2hgf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=505dd6a12adbdbe687a6467d0b0843adb780d82a"
                  }
                ],
                "s": {
                  "y": 1592,
                  "x": 3162,
                  "u": "https://preview.redd.it/opb5odlb2hgf1.png?width=3162&amp;format=png&amp;auto=webp&amp;s=00995e770fa4d3ac454bd9b1f0df5296391fb137"
                },
                "id": "opb5odlb2hgf1"
              }
            },
            "name": "t3_1mf86rn",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.88,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 36,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_9av3t",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Resources",
            "can_mod_post": false,
            "score": 36,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/9zGmAn5wtWE9ciYDNGxrwYmoTgYDYEOmBf7p4EOrZDY.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754082162,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;GPU snapshotting is finally a thing! NVIDIA recently released their &lt;a href=\"https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CHECKPOINT.html\"&gt;CUDA checkpoint/restore API&lt;/a&gt; and we at Modal (serverless compute platform) are using it drastically reduce GPU cold start times. This is especially relevant for serving large models, where it can take minutes (for the heftiest LLMs) to move model weights from disk to memory.&lt;/p&gt;\n\n&lt;p&gt;GPU memory snapshotting can reduce cold boot times by up to 12x. It lets you scale GPU resources up and down based on demand without compromising on user-facing latency. Below are some benchmarking results showing improvements for various models!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/opb5odlb2hgf1.png?width=3162&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=00995e770fa4d3ac454bd9b1f0df5296391fb137\"&gt;https://preview.redd.it/opb5odlb2hgf1.png?width=3162&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=00995e770fa4d3ac454bd9b1f0df5296391fb137&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;More on how GPU snapshotting works plus additional benchmarks in this blog post: &lt;a href=\"https://modal.com/blog/gpu-mem-snapshots\"&gt;https://modal.com/blog/gpu-mem-snapshots&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ab9120c4-bf8e-11ed-ae5e-2eb8b7c7e10b",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#ccac2b",
            "id": "1mf86rn",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "crookedstairs",
            "discussion_type": null,
            "num_comments": 3,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mf86rn/cold_start_vllm_in_5_seconds_with_gpu_snapshotting/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mf86rn/cold_start_vllm_in_5_seconds_with_gpu_snapshotting/",
            "subreddit_subscribers": 509055,
            "created_utc": 1754082162,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6f6cpj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "secopsml",
            "can_mod_post": false,
            "created_utc": 1754083074,
            "send_replies": true,
            "parent_id": "t3_1mf86rn",
            "score": 7,
            "author_fullname": "t2_pmniwf57y",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "With larger models and cuda graphs cold boot could take not 2 minutes like on this chart but 20. (on modal, with \\~30B models)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6f6cpj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;With larger models and cuda graphs cold boot could take not 2 minutes like on this chart but 20. (on modal, with ~30B models)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf86rn/cold_start_vllm_in_5_seconds_with_gpu_snapshotting/n6f6cpj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754083074,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf86rn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6f9lyc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "alew3",
            "can_mod_post": false,
            "created_utc": 1754084100,
            "send_replies": true,
            "parent_id": "t3_1mf86rn",
            "score": 4,
            "author_fullname": "t2_8bwjj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "vLLM has a sleep/wakeup feature (--enable-sleep-mode) that is pretty fast, but I think the \"snapshot\" goes to the CPU RAM. It would be pretty cool to preload 10 models and wake them up on demand :-)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6f9lyc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;vLLM has a sleep/wakeup feature (--enable-sleep-mode) that is pretty fast, but I think the &amp;quot;snapshot&amp;quot; goes to the CPU RAM. It would be pretty cool to preload 10 models and wake them up on demand :-)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf86rn/cold_start_vllm_in_5_seconds_with_gpu_snapshotting/n6f9lyc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754084100,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf86rn",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        }
      ],
      "before": null
    }
  }
]