[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I've been experimenting with using AI to generate a Bash script for me. The script's purpose is to follow a specific task logic while downloading items. Despite giving detailed feedback, the AI repeatedly failed to get it right. I thought maybe the problem was complexity, so I tried simplifying it — starting with just the task logic, planning to add downloading and other functions later.\n\nI used this new prompt as in image with several models, including Gemini 2.5, ChatGPT-4o, OpenAI GPT-4.1, o4, and o4-mini. None of them could generate a correct solution, even after I provided detailed outputs and feedback. Surprisingly, DeepSeek R1 got it right on the first try, though it took nearly 10 minutes to process. I haven't tried o1 o3 or other premium models yet, but they might be capable too.\n\nHere are my main questions:\n\n* For a medium-to-light scripting task like this (about 100–500 lines, single file), is it better to break the task into smaller pieces, and ask AI to build it bit by bit, or to write a detailed, complete prompt up front?\n* Is this type of logic too complex for non-flagship models? If I want to avoid using expensive flagship models, how can I structure prompts to still get reliable results? Currently, only R1 seems to handle it.\n* When using models like o4mini, I’ve tried breaking the problem down, but they often fix one part and break another. How should I prompt non-flagship models to handle complex logic like this more effectively?\n\nHere’s the prompt I used:\n\n    write a bash script write to a log file\n    Requirements\n    Prints one ‘+’ per second\n    New line after every 5 ‘+’\n    Starts a new “Task N” at every real-time 10-second boundary (when seconds end in 0, 10, 20, ...)\n    Each task has a running “Total N: X” line at the end of its block, which is always updated in place (never duplicated).\n    All previous tasks remain in the log (each with their own Task/Total block).\n    Script can be stopped and resumed at any time, continuing current task’s count and log format perfectly.\n    \n    Sample Log Format\n    Task 1\n    +++++\n    ++++\n    Total 1: 9\n    \n    Task 2\n    +++++\n    ++\n    Total 2: 7\n    \n    If you stop and restart during Task 2, it continues like:\n    Task 1\n    +++++\n    ++++\n    Total 1: 9\n    \n    Task 2\n    +++++\n    ++++\n    Total 2: 9\n    ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Is this too much logic for AI? should I break it smaller to prompt?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 140,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m8qr9q",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.3,
            "author_flair_background_color": null,
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_w0frc97",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/iiq4jlppORjVU9AD-yD0CbOb_lhtMf8QRo34T4quEiM.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753420811,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been experimenting with using AI to generate a Bash script for me. The script&amp;#39;s purpose is to follow a specific task logic while downloading items. Despite giving detailed feedback, the AI repeatedly failed to get it right. I thought maybe the problem was complexity, so I tried simplifying it — starting with just the task logic, planning to add downloading and other functions later.&lt;/p&gt;\n\n&lt;p&gt;I used this new prompt as in image with several models, including Gemini 2.5, ChatGPT-4o, OpenAI GPT-4.1, o4, and o4-mini. None of them could generate a correct solution, even after I provided detailed outputs and feedback. Surprisingly, DeepSeek R1 got it right on the first try, though it took nearly 10 minutes to process. I haven&amp;#39;t tried o1 o3 or other premium models yet, but they might be capable too.&lt;/p&gt;\n\n&lt;p&gt;Here are my main questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;For a medium-to-light scripting task like this (about 100–500 lines, single file), is it better to break the task into smaller pieces, and ask AI to build it bit by bit, or to write a detailed, complete prompt up front?&lt;/li&gt;\n&lt;li&gt;Is this type of logic too complex for non-flagship models? If I want to avoid using expensive flagship models, how can I structure prompts to still get reliable results? Currently, only R1 seems to handle it.&lt;/li&gt;\n&lt;li&gt;When using models like o4mini, I’ve tried breaking the problem down, but they often fix one part and break another. How should I prompt non-flagship models to handle complex logic like this more effectively?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here’s the prompt I used:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;write a bash script write to a log file\nRequirements\nPrints one ‘+’ per second\nNew line after every 5 ‘+’\nStarts a new “Task N” at every real-time 10-second boundary (when seconds end in 0, 10, 20, ...)\nEach task has a running “Total N: X” line at the end of its block, which is always updated in place (never duplicated).\nAll previous tasks remain in the log (each with their own Task/Total block).\nScript can be stopped and resumed at any time, continuing current task’s count and log format perfectly.\n\nSample Log Format\nTask 1\n+++++\n++++\nTotal 1: 9\n\nTask 2\n+++++\n++\nTotal 2: 7\n\nIf you stop and restart during Task 2, it continues like:\nTask 1\n+++++\n++++\nTotal 1: 9\n\nTask 2\n+++++\n++++\nTotal 2: 9\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/87gik9pocyef1.png",
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/87gik9pocyef1.png?auto=webp&amp;s=882040b1524e85d1e541c67292268579de6da0c5",
                    "width": 724,
                    "height": 799
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/87gik9pocyef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d2c84b0bebcb0355231aa023e96ed7f79041f45c",
                      "width": 108,
                      "height": 119
                    },
                    {
                      "url": "https://preview.redd.it/87gik9pocyef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=272c1b889ee5e602d6979d5fe7de4e4fc6bb99b0",
                      "width": 216,
                      "height": 238
                    },
                    {
                      "url": "https://preview.redd.it/87gik9pocyef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9fc5cacee906f6d0b24bc0d0d69836864bacf73e",
                      "width": 320,
                      "height": 353
                    },
                    {
                      "url": "https://preview.redd.it/87gik9pocyef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=bf518d01131f779b03efca1031bb5d2e32a952d2",
                      "width": 640,
                      "height": 706
                    }
                  ],
                  "variants": {},
                  "id": "SZrbj05Ymb4g4TsIRAsqq5SAHLPZi-6WK0OeRzd30QE"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1m8qr9q",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "CJCCJJ",
            "discussion_type": null,
            "num_comments": 7,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m8qr9q/is_this_too_much_logic_for_ai_should_i_break_it/",
            "stickied": false,
            "url": "https://i.redd.it/87gik9pocyef1.png",
            "subreddit_subscribers": 504253,
            "created_utc": 1753420811,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n51lhyn",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "zipperlein",
            "can_mod_post": false,
            "created_utc": 1753426341,
            "send_replies": true,
            "parent_id": "t3_1m8qr9q",
            "score": 5,
            "author_fullname": "t2_x3duw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Ask the model first to improve your prompt. Delete things u do not want. Iterate on that.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n51lhyn",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ask the model first to improve your prompt. Delete things u do not want. Iterate on that.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8qr9q/is_this_too_much_logic_for_ai_should_i_break_it/n51lhyn/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753426341,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8qr9q",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n51g7mw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "HistorianPotential48",
            "can_mod_post": false,
            "created_utc": 1753423529,
            "send_replies": true,
            "parent_id": "t3_1m8qr9q",
            "score": 6,
            "author_fullname": "t2_4dzthia7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "if you are my product manager and you give me requirements written like this, instead of bash script i will bash your face",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n51g7mw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;if you are my product manager and you give me requirements written like this, instead of bash script i will bash your face&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8qr9q/is_this_too_much_logic_for_ai_should_i_break_it/n51g7mw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753423529,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8qr9q",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n51et60",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "RhubarbSimilar1683",
            "can_mod_post": false,
            "created_utc": 1753422813,
            "send_replies": true,
            "parent_id": "t3_1m8qr9q",
            "score": 3,
            "author_fullname": "t2_1k4sjdwzk2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Nowadays my colleagues write hundreds of lines like this and using gemini or chatgpt, they copy and paste the results and it works,",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n51et60",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nowadays my colleagues write hundreds of lines like this and using gemini or chatgpt, they copy and paste the results and it works,&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8qr9q/is_this_too_much_logic_for_ai_should_i_break_it/n51et60/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753422813,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8qr9q",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n51jmhk",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ironcodegaming",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n51hnd8",
                                "score": 2,
                                "author_fullname": "t2_eeaio",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The flagship models are obviously more powerful. If you want a one shot solution, that's the way to go.\n\nHowever, even flagship models will not be able to one-shot everything...",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n51jmhk",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The flagship models are obviously more powerful. If you want a one shot solution, that&amp;#39;s the way to go.&lt;/p&gt;\n\n&lt;p&gt;However, even flagship models will not be able to one-shot everything...&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m8qr9q",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m8qr9q/is_this_too_much_logic_for_ai_should_i_break_it/n51jmhk/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753425337,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753425337,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n51hnd8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "CJCCJJ",
                      "can_mod_post": false,
                      "created_utc": 1753424276,
                      "send_replies": true,
                      "parent_id": "t1_n51bqi0",
                      "score": 1,
                      "author_fullname": "t2_w0frc97",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "My real question is about the logic aspect of AI coding. I feel that logic isn't my strong suit, so I'm hoping the AI can handle it correctly for me. \n\nIn this example, I've already simplified the task down to just the logic part, and I plan to write the rest of the code myself or with help from the AI.\n\nAs the title suggests, my question is: is this kind of logic beyond the capability of current non-flagship models? I already tried to break it down with non-flagship modesl, like single task to multiple tasks and then resuming capability as such, still the modes failed. They fix one thing but fail another back and forth.  - if so, I have to pay for flagship models.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n51hnd8",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My real question is about the logic aspect of AI coding. I feel that logic isn&amp;#39;t my strong suit, so I&amp;#39;m hoping the AI can handle it correctly for me. &lt;/p&gt;\n\n&lt;p&gt;In this example, I&amp;#39;ve already simplified the task down to just the logic part, and I plan to write the rest of the code myself or with help from the AI.&lt;/p&gt;\n\n&lt;p&gt;As the title suggests, my question is: is this kind of logic beyond the capability of current non-flagship models? I already tried to break it down with non-flagship modesl, like single task to multiple tasks and then resuming capability as such, still the modes failed. They fix one thing but fail another back and forth.  - if so, I have to pay for flagship models.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8qr9q",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8qr9q/is_this_too_much_logic_for_ai_should_i_break_it/n51hnd8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753424276,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n51bqi0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ironcodegaming",
            "can_mod_post": false,
            "created_utc": 1753421277,
            "send_replies": true,
            "parent_id": "t3_1m8qr9q",
            "score": 5,
            "author_fullname": "t2_eeaio",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "    write a bash script write to a log file\n\nThe statement is not clear. Also not clear what 'Task' is.\n\nHaving said that, you might need to code a little bit yourself.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n51bqi0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;write a bash script write to a log file\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The statement is not clear. Also not clear what &amp;#39;Task&amp;#39; is.&lt;/p&gt;\n\n&lt;p&gt;Having said that, you might need to code a little bit yourself.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8qr9q/is_this_too_much_logic_for_ai_should_i_break_it/n51bqi0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753421277,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8qr9q",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n52pbuo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Pogo4Fufu",
            "can_mod_post": false,
            "created_utc": 1753446411,
            "send_replies": true,
            "parent_id": "t3_1m8qr9q",
            "score": 1,
            "author_fullname": "t2_3q3msk1c",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have some experience with AI &amp; writing bash scripts - it works quite well, but often fails on minor things like formatting and the correct syntax of all the GNU tools that all have a different syntax, like sed, awk, grep, printf and similar. Like 'ps  ax' or 'ps -ef' and such.  \nYour problem is IMHO the way you interact or instruct the AI. My last script had a bout 300 lines and Gemini, ChatGPT and DeepSeek had no problem besides their failures with escaping and formatting.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52pbuo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have some experience with AI &amp;amp; writing bash scripts - it works quite well, but often fails on minor things like formatting and the correct syntax of all the GNU tools that all have a different syntax, like sed, awk, grep, printf and similar. Like &amp;#39;ps  ax&amp;#39; or &amp;#39;ps -ef&amp;#39; and such.&lt;br/&gt;\nYour problem is IMHO the way you interact or instruct the AI. My last script had a bout 300 lines and Gemini, ChatGPT and DeepSeek had no problem besides their failures with escaping and formatting.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8qr9q/is_this_too_much_logic_for_ai_should_i_break_it/n52pbuo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753446411,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8qr9q",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]