[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hello Folks,\nWith new open LLMs being released constantly, I’m starting to feel a bit behind, especially since most of them are pretty large. I have around 180 GB of NVIDIA GPU VRAM available and I’m looking for the best coding LLM to run locally with atleast 30K context window (input + output). My main focus is Java programming. \nI am currently using Qwen3 32B Thinking non quantized but the results are just okayish.\n\nPS: I have used Qwen 2.5 Coder but the results were terrible. Also, used QwQ-32B and the results were slightly worse than Qwen3 32B but were also much much slower.\n\nAny recommendations would be highly appreciated, Thanks!",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Best Coding LLM for",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mbzdx8",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.77,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 12,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1c2mqjxrgv",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 12,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1753757742,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753755092,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Folks,\nWith new open LLMs being released constantly, I’m starting to feel a bit behind, especially since most of them are pretty large. I have around 180 GB of NVIDIA GPU VRAM available and I’m looking for the best coding LLM to run locally with atleast 30K context window (input + output). My main focus is Java programming. \nI am currently using Qwen3 32B Thinking non quantized but the results are just okayish.&lt;/p&gt;\n\n&lt;p&gt;PS: I have used Qwen 2.5 Coder but the results were terrible. Also, used QwQ-32B and the results were slightly worse than Qwen3 32B but were also much much slower.&lt;/p&gt;\n\n&lt;p&gt;Any recommendations would be highly appreciated, Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mbzdx8",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "PhysicsPast8286",
            "discussion_type": null,
            "num_comments": 27,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/",
            "subreddit_subscribers": 506711,
            "created_utc": 1753755092,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n5qjrms",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "____vladrad",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n5qevr6",
                                                              "score": 2,
                                                              "author_fullname": "t2_u6i8a0ay",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "https://preview.redd.it/ce125vwpoqff1.png?width=512&amp;format=png&amp;auto=webp&amp;s=ed46102980964fff5d1987dbc068567f46ba18c6\n\nI tried air today. it beat q4 qwen 235. I think there is some kind of weird bug with it in VLLM... it has a lot of trouble function calling correctly with it. Makes me thing it was not trained for this kinda stuff. Today Air Ran FP8 for 2 hours and wrote 5k lines of code via Claude Code router. They posted on their blog how to get it to work.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n5qjrms",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/ce125vwpoqff1.png?width=512&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ed46102980964fff5d1987dbc068567f46ba18c6\"&gt;https://preview.redd.it/ce125vwpoqff1.png?width=512&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ed46102980964fff5d1987dbc068567f46ba18c6&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I tried air today. it beat q4 qwen 235. I think there is some kind of weird bug with it in VLLM... it has a lot of trouble function calling correctly with it. Makes me thing it was not trained for this kinda stuff. Today Air Ran FP8 for 2 hours and wrote 5k lines of code via Claude Code router. They posted on their blog how to get it to work.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mbzdx8",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5qjrms/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1753762676,
                                                              "media_metadata": {
                                                                "ce125vwpoqff1": {
                                                                  "status": "valid",
                                                                  "e": "Image",
                                                                  "m": "image/png",
                                                                  "p": [
                                                                    {
                                                                      "y": 13,
                                                                      "x": 108,
                                                                      "u": "https://preview.redd.it/ce125vwpoqff1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa6444d5f0c3c0daa01340ec892f0b028831dd05"
                                                                    },
                                                                    {
                                                                      "y": 26,
                                                                      "x": 216,
                                                                      "u": "https://preview.redd.it/ce125vwpoqff1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d0d3a0fd035d055d59fac46557aa427166897e83"
                                                                    },
                                                                    {
                                                                      "y": 39,
                                                                      "x": 320,
                                                                      "u": "https://preview.redd.it/ce125vwpoqff1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=358f39bf1f480d90eca7811aefce8b2fe42109de"
                                                                    }
                                                                  ],
                                                                  "s": {
                                                                    "y": 63,
                                                                    "x": 512,
                                                                    "u": "https://preview.redd.it/ce125vwpoqff1.png?width=512&amp;format=png&amp;auto=webp&amp;s=ed46102980964fff5d1987dbc068567f46ba18c6"
                                                                  },
                                                                  "id": "ce125vwpoqff1"
                                                                }
                                                              },
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1753762676,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5qevr6",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "PhysicsPast8286",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5qc3e8",
                                                    "score": 1,
                                                    "author_fullname": "t2_1c2mqjxrgv",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "L40s (48 \\* 4)",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5qevr6",
                                                    "is_submitter": true,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;L40s (48 * 4)&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mbzdx8",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5qevr6/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753760592,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753760592,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5qc3e8",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Thick-Specialist-495",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5qa90d",
                                          "score": 3,
                                          "author_fullname": "t2_1bvzxpyp0q",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "it is 110B and 12b active parameter model fp16 needs 220gb vram but u have 180gb so the fp8 can work on ur machine, which gpu's u have?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5qc3e8",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it is 110B and 12b active parameter model fp16 needs 220gb vram but u have 180gb so the fp8 can work on ur machine, which gpu&amp;#39;s u have?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mbzdx8",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5qc3e8/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753759447,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753759447,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 3
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5qa90d",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "PhysicsPast8286",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5q3g0c",
                                "score": 2,
                                "author_fullname": "t2_1c2mqjxrgv",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Are you suggesting to use a Quantized version of the GLM 4.5 Air?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5qa90d",
                                "is_submitter": true,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Are you suggesting to use a Quantized version of the GLM 4.5 Air?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mbzdx8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5qa90d/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753758713,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753758713,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5q3g0c",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Thick-Specialist-495",
                      "can_mod_post": false,
                      "created_utc": 1753756148,
                      "send_replies": true,
                      "parent_id": "t1_n5q2ejb",
                      "score": 7,
                      "author_fullname": "t2_1bvzxpyp0q",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "the new glm 4.5 air might be work for u",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5q3g0c",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;the new glm 4.5 air might be work for u&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbzdx8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5q3g0c/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753756148,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5q2ejb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "fp4guru",
            "can_mod_post": false,
            "created_utc": 1753755770,
            "send_replies": true,
            "parent_id": "t3_1mbzdx8",
            "score": 12,
            "author_fullname": "t2_1tp8zldw5g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The 480b Qwen3 coder is designed for your convenience. Or else Qwen3 235b.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5q2ejb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The 480b Qwen3 coder is designed for your convenience. Or else Qwen3 235b.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5q2ejb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753755770,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbzdx8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 12
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5rv6t8",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Nytaflex",
            "can_mod_post": false,
            "created_utc": 1753787966,
            "send_replies": true,
            "parent_id": "t3_1mbzdx8",
            "score": 2,
            "author_fullname": "t2_h6af51",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Kimi K2",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5rv6t8",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Kimi K2&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5rv6t8/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753787966,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbzdx8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5v8oxg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "AleksHop",
            "can_mod_post": false,
            "created_utc": 1753824213,
            "send_replies": true,
            "parent_id": "t3_1mbzdx8",
            "score": 1,
            "author_fullname": "t2_8dnu3hmd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "from open models kimi k2, but its khm… not as .. as others;) non local llms",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5v8oxg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;from open models kimi k2, but its khm… not as .. as others;) non local llms&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5v8oxg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753824213,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbzdx8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5vagrx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Plastic-Bus-7003",
            "can_mod_post": false,
            "created_utc": 1753824740,
            "send_replies": true,
            "parent_id": "t3_1mbzdx8",
            "score": 1,
            "author_fullname": "t2_owqzu42m8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "From personal experience, the Qwen-coder series is amazing",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5vagrx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;From personal experience, the Qwen-coder series is amazing&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5vagrx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753824740,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbzdx8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5rdexz",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "MelodicRecognition7",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5r1hha",
                                "score": 3,
                                "author_fullname": "t2_1eex9ug5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "it definitely is lol",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5rdexz",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it definitely is lol&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mbzdx8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5rdexz/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753778476,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753778476,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5r1hha",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Obvious-Ad-2454",
                      "can_mod_post": false,
                      "created_utc": 1753771637,
                      "send_replies": true,
                      "parent_id": "t1_n5q67r0",
                      "score": 10,
                      "author_fullname": "t2_favmw9ob",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Looks like a bot",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5r1hha",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Looks like a bot&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbzdx8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5r1hha/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753771637,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 10
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5r0uvc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "boringcynicism",
                      "can_mod_post": false,
                      "created_utc": 1753771284,
                      "send_replies": true,
                      "parent_id": "t1_n5q67r0",
                      "score": 5,
                      "author_fullname": "t2_1hz0lz0k5i",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; Qwen3-235B-A22B Coder\n\nNo such model exists.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5r0uvc",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt; Qwen3-235B-A22B Coder&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No such model exists.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbzdx8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5r0uvc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753771284,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5qad0x",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "JanErikJakstein",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5q982f",
                                "score": 8,
                                "author_fullname": "t2_10mz15s",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Local needs quants, bigger model with smaller quant wins mostly.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5qad0x",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Local needs quants, bigger model with smaller quant wins mostly.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mbzdx8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5qad0x/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753758756,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753758756,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 8
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n5qvlp8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "sautdepage",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5q982f",
                                "score": 3,
                                "author_fullname": "t2_6qdom3n2",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The context size calculations on that site always looked wild to me. It doesn't take some extra 50GB VRAM to have a context size of 64K on Qwen3 32B.",
                                "edited": 1753768642,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5qvlp8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The context size calculations on that site always looked wild to me. It doesn&amp;#39;t take some extra 50GB VRAM to have a context size of 64K on Qwen3 32B.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mbzdx8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5qvlp8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753768417,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753768417,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n5qlt74",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "CabinetNational3461",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n5qdi0j",
                                                    "score": 2,
                                                    "author_fullname": "t2_sq5ja6nh",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "There's this video that explains quantitation pretty well. https://youtu.be/vW30o4U9BFE?si=dP1rIHEsfg9FRQoP",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n5qlt74",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s this video that explains quantitation pretty well. &lt;a href=\"https://youtu.be/vW30o4U9BFE?si=dP1rIHEsfg9FRQoP\"&gt;https://youtu.be/vW30o4U9BFE?si=dP1rIHEsfg9FRQoP&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mbzdx8",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5qlt74/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1753763597,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1753763597,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5qdi0j",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "PhysicsPast8286",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5qd1iy",
                                          "score": 1,
                                          "author_fullname": "t2_1c2mqjxrgv",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Cool thanks a ton for the detailed explaination u/Dizzy-Cantaloupe8892 . Can you suggest any resources to read more about Quantization and stuff?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5qdi0j",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Cool thanks a ton for the detailed explaination &lt;a href=\"/u/Dizzy-Cantaloupe8892\"&gt;u/Dizzy-Cantaloupe8892&lt;/a&gt; . Can you suggest any resources to read more about Quantization and stuff?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mbzdx8",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5qdi0j/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753760014,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753760014,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5r0srz",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "boringcynicism",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5qd1iy",
                                          "score": 1,
                                          "author_fullname": "t2_1hz0lz0k5i",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Qwen3-72B? Did I miss 2 model releases?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5r0srz",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen3-72B? Did I miss 2 model releases?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mbzdx8",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5r0srz/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753771251,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753771251,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5rdcr6",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "MelodicRecognition7",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5qd1iy",
                                          "score": 1,
                                          "author_fullname": "t2_1eex9ug5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I have troubles with running quantized models, neither of them could correctly calculate the amount of letters \"R\" in a word \"strawberry\", how could I improve that? Could you calculate it for me?",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5rdcr6",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have troubles with running quantized models, neither of them could correctly calculate the amount of letters &amp;quot;R&amp;quot; in a word &amp;quot;strawberry&amp;quot;, how could I improve that? Could you calculate it for me?&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mbzdx8",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5rdcr6/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753778441,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753778441,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5qd1iy",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Dizzy-Cantaloupe8892",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5q982f",
                                "score": 1,
                                "author_fullname": "t2_dssg622ox",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "You're right - full precision needs way more VRAM. With 180GB, you'll need quantization. The Q4/Q6 quantized version runs with about 24GB VRAM plus 96GB system RAM, totaling around 110GB. Most of the model sits in system memory with only active portions in VRAM. Qwen3-72B at 4-bit quantization only needs 36-48GB VRAM and fits entirely on GPU. DeepSeek-V2-Coder (70B) and Mixtral-8x22B are other  options that fit comfortably at 4-bit (36-48GB and 45-55GB respectively).",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5qd1iy",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re right - full precision needs way more VRAM. With 180GB, you&amp;#39;ll need quantization. The Q4/Q6 quantized version runs with about 24GB VRAM plus 96GB system RAM, totaling around 110GB. Most of the model sits in system memory with only active portions in VRAM. Qwen3-72B at 4-bit quantization only needs 36-48GB VRAM and fits entirely on GPU. DeepSeek-V2-Coder (70B) and Mixtral-8x22B are other  options that fit comfortably at 4-bit (36-48GB and 45-55GB respectively).&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mbzdx8",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5qd1iy/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753759827,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753759827,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5q982f",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "PhysicsPast8286",
                      "can_mod_post": false,
                      "created_utc": 1753758310,
                      "send_replies": true,
                      "parent_id": "t1_n5q67r0",
                      "score": 2,
                      "author_fullname": "t2_1c2mqjxrgv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I checked via apxml and it shows 730 GB VRAM is needed 🤧 Am I missing something (probably you were suggesting to use a Quantized version?)  \n\n\nhttps://preview.redd.it/qpk47ucjbqff1.png?width=1082&amp;format=png&amp;auto=webp&amp;s=7e0bb86b30804f9fccab41030992bfb4995217f6",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5q982f",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I checked via apxml and it shows 730 GB VRAM is needed 🤧 Am I missing something (probably you were suggesting to use a Quantized version?)  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qpk47ucjbqff1.png?width=1082&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7e0bb86b30804f9fccab41030992bfb4995217f6\"&gt;https://preview.redd.it/qpk47ucjbqff1.png?width=1082&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7e0bb86b30804f9fccab41030992bfb4995217f6&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbzdx8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5q982f/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753758310,
                      "media_metadata": {
                        "qpk47ucjbqff1": {
                          "status": "valid",
                          "e": "Image",
                          "m": "image/png",
                          "p": [
                            {
                              "y": 81,
                              "x": 108,
                              "u": "https://preview.redd.it/qpk47ucjbqff1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=475b1b8362d2791058f6e06949a8c628efdf3c7d"
                            },
                            {
                              "y": 162,
                              "x": 216,
                              "u": "https://preview.redd.it/qpk47ucjbqff1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c30dcc370047346b5d3e34305eabe8978cade7ef"
                            },
                            {
                              "y": 240,
                              "x": 320,
                              "u": "https://preview.redd.it/qpk47ucjbqff1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5bdf92dd1530decba425b66bc3824e1ab4bbec76"
                            },
                            {
                              "y": 481,
                              "x": 640,
                              "u": "https://preview.redd.it/qpk47ucjbqff1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d42a9734970760b1a78688319a5827fe7307f498"
                            },
                            {
                              "y": 722,
                              "x": 960,
                              "u": "https://preview.redd.it/qpk47ucjbqff1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8fde453b92dc15b3ffc6a99dce948f7f8f43036e"
                            },
                            {
                              "y": 812,
                              "x": 1080,
                              "u": "https://preview.redd.it/qpk47ucjbqff1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=32d8fb2f4b7291e33a6733f67bb582bf6a9ace53"
                            }
                          ],
                          "s": {
                            "y": 814,
                            "x": 1082,
                            "u": "https://preview.redd.it/qpk47ucjbqff1.png?width=1082&amp;format=png&amp;auto=webp&amp;s=7e0bb86b30804f9fccab41030992bfb4995217f6"
                          },
                          "id": "qpk47ucjbqff1"
                        }
                      },
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5ra2hs",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "-dysangel-",
                      "can_mod_post": false,
                      "created_utc": 1753776510,
                      "send_replies": true,
                      "parent_id": "t1_n5q67r0",
                      "score": 1,
                      "author_fullname": "t2_12ggykute6",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The 235B-2507 is not a \"Coder\" variant btw. I've been trying the 480B at IQ1 and it's worked better with Roo than any other local models I've tried so far. I've not tried throwing any \\*real\\* work at it yet though.\n\n  \nLooking forward to the Coder distils hopefully coming out this week!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5ra2hs",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The 235B-2507 is not a &amp;quot;Coder&amp;quot; variant btw. I&amp;#39;ve been trying the 480B at IQ1 and it&amp;#39;s worked better with Roo than any other local models I&amp;#39;ve tried so far. I&amp;#39;ve not tried throwing any *real* work at it yet though.&lt;/p&gt;\n\n&lt;p&gt;Looking forward to the Coder distils hopefully coming out this week!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbzdx8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5ra2hs/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753776510,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5rd015",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "MelodicRecognition7",
                      "can_mod_post": false,
                      "created_utc": 1753778235,
                      "send_replies": true,
                      "parent_id": "t1_n5q67r0",
                      "score": 1,
                      "author_fullname": "t2_1eex9ug5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "what backend LLM do you run? is it ChatGPT or any other?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5rd015",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;what backend LLM do you run? is it ChatGPT or any other?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbzdx8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5rd015/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753778235,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5tt6cj",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "LocoLanguageModel",
                      "can_mod_post": false,
                      "created_utc": 1753809798,
                      "send_replies": true,
                      "parent_id": "t1_n5q67r0",
                      "score": 1,
                      "author_fullname": "t2_canyreqfh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "what does the text above say?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5tt6cj",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;what does the text above say?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbzdx8",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5tt6cj/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753809798,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5q67r0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": false,
            "author": "Dizzy-Cantaloupe8892",
            "can_mod_post": false,
            "created_utc": 1753757166,
            "send_replies": true,
            "parent_id": "t3_1mbzdx8",
            "score": -5,
            "author_fullname": "t2_dssg622ox",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "With 180GB VRAM, you're perfectly set up for Qwen3-235B-A22B Coder. It's leagues ahead of the 32B thinking model for Java work. The 235B model uses MoE architecture with only 22B active parameters per token, so it runs efficiently despite the total size. Benchmarks show it scoring 70.7 on LiveCodeBench and 2056 on CodeForces Elo. For Java specifically, it handles large-scale projects well with its 262K native context (extendable to 1M). The model excels at generating clean, functional code and catches edge cases smaller models miss. DeepSeek R1 is worth considering if your Java work involves heavy mathematical reasoning, but Qwen3 consistently beats it on pure coding tasks. The 480B version exists but seems overkill unless you're doing something really specialized. Run it with vLLM or Ollama for best performance. With your VRAM headroom, you could even keep a smaller model loaded for quick tasks alongside the 235B.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5q67r0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;With 180GB VRAM, you&amp;#39;re perfectly set up for Qwen3-235B-A22B Coder. It&amp;#39;s leagues ahead of the 32B thinking model for Java work. The 235B model uses MoE architecture with only 22B active parameters per token, so it runs efficiently despite the total size. Benchmarks show it scoring 70.7 on LiveCodeBench and 2056 on CodeForces Elo. For Java specifically, it handles large-scale projects well with its 262K native context (extendable to 1M). The model excels at generating clean, functional code and catches edge cases smaller models miss. DeepSeek R1 is worth considering if your Java work involves heavy mathematical reasoning, but Qwen3 consistently beats it on pure coding tasks. The 480B version exists but seems overkill unless you&amp;#39;re doing something really specialized. Run it with vLLM or Ollama for best performance. With your VRAM headroom, you could even keep a smaller model loaded for quick tasks alongside the 235B.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbzdx8/best_coding_llm_for/n5q67r0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753757166,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbzdx8",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -5
          }
        }
      ],
      "before": null
    }
  }
]