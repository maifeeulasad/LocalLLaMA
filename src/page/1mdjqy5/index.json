[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I've been anticipating what I consider the \"Holy Grail\" of large language models ever since the launch of ChatGPT. To me, that means a model capable of running locally on consumer-grade computers, without the need for quantization, and meeting the following technical criteria:\n\n* Inference throughput of at least 20 tokens per second on a single high-end consumer GPU.\n* Context window of at least 40,000 tokens, with a minimum of 32,000 tokens for input and 8,000 tokens for output, supported by efficient attention mechanisms (e.g., grouped-query, sliding-window, or recurrence-based) to maintain performance across long sequences.\n* Sufficient reasoning capacity to engage in coherent, multi-turn conversations involving abstract concepts and nuanced context.\n* Native support for low-latency, real-time inference suitable for interactive use without relying on server-side infrastructure.\n* Compatibility with standard toolchains and runtimes (CUDA, ROCm, ONNX, GGUF) to ensure flexible and accessible deployment across diverse local environments.\n* Broad general knowledge and linguistic fluency that enable it to handle a wide range of topics without requiring deep specialization.\n\nI am not expecting such a model to rival enterprise-grade systems like Sonnet 4, Opus 4, or Gemini 2.5 Pro. The goal is not to compete with frontier models but to reach a level of intelligence that is locally deployable, autonomous, and useful. Once that threshold is reached, the model can be extended through MCPs, APIs, and other external services, allowing it to compensate for its limitations much like a human consulting a reference book rather than memorizing its contents.\n\nWe are not there yet. But the progress over the past few months has been nothing short of extraordinary. We have gone from bloated, sluggish models unable to sustain human-like interaction to running models like Qwen3-30B-A3B-2507 directly on consumer-grade hardware. The trajectory is unmistakable and the pace is accelerating. This is the real revolution: the democratization of high-performance LLMs. When these capabilities become widely available on consumer hardware, they will unlock a wave of possibilities such as personal robotics, offline assistants, intelligent home automation, educational agents, embedded systems, and much more. Local deployment will allow LLMs to integrate seamlessly into the fabric of everyday life.\n\nI often wonder when the Holy Grail will finally arrive. When it does, I intend to step away from web interfaces entirely and focus on my local companion, enhanced by external systems for knowledge and perception. Many once doubted this vision was achievable. But day by day, we are getting closer.\n\nAnd it is genuinely exciting.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "The Holy Grail",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mdjqy5",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.4,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1b9gox1vsw",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753912558,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been anticipating what I consider the &amp;quot;Holy Grail&amp;quot; of large language models ever since the launch of ChatGPT. To me, that means a model capable of running locally on consumer-grade computers, without the need for quantization, and meeting the following technical criteria:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Inference throughput of at least 20 tokens per second on a single high-end consumer GPU.&lt;/li&gt;\n&lt;li&gt;Context window of at least 40,000 tokens, with a minimum of 32,000 tokens for input and 8,000 tokens for output, supported by efficient attention mechanisms (e.g., grouped-query, sliding-window, or recurrence-based) to maintain performance across long sequences.&lt;/li&gt;\n&lt;li&gt;Sufficient reasoning capacity to engage in coherent, multi-turn conversations involving abstract concepts and nuanced context.&lt;/li&gt;\n&lt;li&gt;Native support for low-latency, real-time inference suitable for interactive use without relying on server-side infrastructure.&lt;/li&gt;\n&lt;li&gt;Compatibility with standard toolchains and runtimes (CUDA, ROCm, ONNX, GGUF) to ensure flexible and accessible deployment across diverse local environments.&lt;/li&gt;\n&lt;li&gt;Broad general knowledge and linguistic fluency that enable it to handle a wide range of topics without requiring deep specialization.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I am not expecting such a model to rival enterprise-grade systems like Sonnet 4, Opus 4, or Gemini 2.5 Pro. The goal is not to compete with frontier models but to reach a level of intelligence that is locally deployable, autonomous, and useful. Once that threshold is reached, the model can be extended through MCPs, APIs, and other external services, allowing it to compensate for its limitations much like a human consulting a reference book rather than memorizing its contents.&lt;/p&gt;\n\n&lt;p&gt;We are not there yet. But the progress over the past few months has been nothing short of extraordinary. We have gone from bloated, sluggish models unable to sustain human-like interaction to running models like Qwen3-30B-A3B-2507 directly on consumer-grade hardware. The trajectory is unmistakable and the pace is accelerating. This is the real revolution: the democratization of high-performance LLMs. When these capabilities become widely available on consumer hardware, they will unlock a wave of possibilities such as personal robotics, offline assistants, intelligent home automation, educational agents, embedded systems, and much more. Local deployment will allow LLMs to integrate seamlessly into the fabric of everyday life.&lt;/p&gt;\n\n&lt;p&gt;I often wonder when the Holy Grail will finally arrive. When it does, I intend to step away from web interfaces entirely and focus on my local companion, enhanced by external systems for knowledge and perception. Many once doubted this vision was achievable. But day by day, we are getting closer.&lt;/p&gt;\n\n&lt;p&gt;And it is genuinely exciting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mdjqy5",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "No-Search9350",
            "discussion_type": null,
            "num_comments": 11,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/",
            "subreddit_subscribers": 507274,
            "created_utc": 1753912558,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n62fk2g",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No-Search9350",
                      "can_mod_post": false,
                      "created_utc": 1753916359,
                      "send_replies": true,
                      "parent_id": "t1_n62drqm",
                      "score": 2,
                      "author_fullname": "t2_1b9gox1vsw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Totally agree that quantization is essential today, especially Q4 and Q8. My point isn’t to dismiss it, but to define a level where it’s no longer necessary to rely on quantization just to achieve solid local performance. But indeed, the reference to running without quantization may have come off as too restrictive, considering that the real objective is an efficient and optimized model capable of strong output regardless.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n62fk2g",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Totally agree that quantization is essential today, especially Q4 and Q8. My point isn’t to dismiss it, but to define a level where it’s no longer necessary to rely on quantization just to achieve solid local performance. But indeed, the reference to running without quantization may have come off as too restrictive, considering that the real objective is an efficient and optimized model capable of strong output regardless.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdjqy5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n62fk2g/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753916359,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n62drqm",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ttkciar",
            "can_mod_post": false,
            "created_utc": 1753915779,
            "send_replies": true,
            "parent_id": "t3_1mdjqy5",
            "score": 4,
            "author_fullname": "t2_cpegz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "\"without the need for quantization\" seems like a weird and needlessly restrictive constraint.\n\nQ8 quantization is demonstrably no different from BF16, in terms of inference quality, which is one of the reasons DeepSeek went to 8-bit parameter training rather than 16-bit.\n\nQ4 quantization is barely discernable from unquantized.\n\nThe advantages of quantization, on the other hand, are tremendous.  Quantized to Q4, a 25B model will infer on a 16GB GPU with only a moderate reduction in context limit.  Without quantization, not even an 8B model will fit on it.\n\nNo matter how wonderful your hardware is, you will always benefit more from using quantization, by dint of accommodating more parameters and more context.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n62drqm",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;without the need for quantization&amp;quot; seems like a weird and needlessly restrictive constraint.&lt;/p&gt;\n\n&lt;p&gt;Q8 quantization is demonstrably no different from BF16, in terms of inference quality, which is one of the reasons DeepSeek went to 8-bit parameter training rather than 16-bit.&lt;/p&gt;\n\n&lt;p&gt;Q4 quantization is barely discernable from unquantized.&lt;/p&gt;\n\n&lt;p&gt;The advantages of quantization, on the other hand, are tremendous.  Quantized to Q4, a 25B model will infer on a 16GB GPU with only a moderate reduction in context limit.  Without quantization, not even an 8B model will fit on it.&lt;/p&gt;\n\n&lt;p&gt;No matter how wonderful your hardware is, you will always benefit more from using quantization, by dint of accommodating more parameters and more context.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n62drqm/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753915779,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mdjqy5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n627x5p",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No-Search9350",
                      "can_mod_post": false,
                      "created_utc": 1753913897,
                      "send_replies": true,
                      "parent_id": "t1_n627j0c",
                      "score": 2,
                      "author_fullname": "t2_1b9gox1vsw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "My own HG still need 200GB VRAM unfortunately. I can run it through API, but it's not the same.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n627x5p",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My own HG still need 200GB VRAM unfortunately. I can run it through API, but it&amp;#39;s not the same.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdjqy5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n627x5p/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753913897,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n627j0c",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Admirable-Star7088",
            "can_mod_post": false,
            "created_utc": 1753913773,
            "send_replies": true,
            "parent_id": "t3_1mdjqy5",
            "score": 3,
            "author_fullname": "t2_qhlcbiy3k",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Back in 2022, my dream and Holy Grail was to run a chatbot as competent as ChatGPT 3.5 locally on my own PC. Today, that dream has since long come true and I now posses many Holy Grails (local models) that are also *way more* competent than ChatGPT 3.5, with Qwen3-235B-A22B being my current favorite Holy Grail and precious &lt;3",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n627j0c",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Back in 2022, my dream and Holy Grail was to run a chatbot as competent as ChatGPT 3.5 locally on my own PC. Today, that dream has since long come true and I now posses many Holy Grails (local models) that are also &lt;em&gt;way more&lt;/em&gt; competent than ChatGPT 3.5, with Qwen3-235B-A22B being my current favorite Holy Grail and precious &amp;lt;3&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n627j0c/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753913773,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdjqy5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "d2642412-d9ce-11ed-ae30-32b11309f5bd",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n626o2p",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No-Search9350",
                      "can_mod_post": false,
                      "created_utc": 1753913501,
                      "send_replies": true,
                      "parent_id": "t1_n626gfh",
                      "score": 0,
                      "author_fullname": "t2_1b9gox1vsw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I tested them. Very good. Not there yet, but we are getting close.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n626o2p",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I tested them. Very good. Not there yet, but we are getting close.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdjqy5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n626o2p/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753913501,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n626gfh",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ortegaalfredo",
            "can_mod_post": false,
            "created_utc": 1753913434,
            "send_replies": true,
            "parent_id": "t3_1mdjqy5",
            "score": 1,
            "author_fullname": "t2_g177e",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I would say Qwen3-32B, or if you can run it, the new GLM-4.5-air",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n626gfh",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "Alpaca"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I would say Qwen3-32B, or if you can run it, the new GLM-4.5-air&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n626gfh/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753913434,
            "author_flair_text": "Alpaca",
            "treatment_tags": [],
            "link_id": "t3_1mdjqy5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bd9e9e",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n62e694",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "No-Search9350",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n62dllu",
                                          "score": 2,
                                          "author_fullname": "t2_1b9gox1vsw",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "oh I see now 🤞I been grindin’ that local LLM so hard my GPU turned into a prophet, started speakin in tongues and spittin out tokens like gospel 🧠🔥💻🤌",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n62e694",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;oh I see now 🤞I been grindin’ that local LLM so hard my GPU turned into a prophet, started speakin in tongues and spittin out tokens like gospel 🧠🔥💻🤌&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mdjqy5",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n62e694/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753915910,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753915910,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 2
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n62dllu",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "SuckaRichardson",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n62dcm5",
                                "score": 1,
                                "author_fullname": "t2_1kt1mgrg4b",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I mean u betta grind boy specially on that local companion. There ain't nothing wrong wit a little bump N grind ",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n62dllu",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I mean u betta grind boy specially on that local companion. There ain&amp;#39;t nothing wrong wit a little bump N grind &lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mdjqy5",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n62dllu/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753915722,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753915722,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n62dcm5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "No-Search9350",
                      "can_mod_post": false,
                      "created_utc": 1753915640,
                      "send_replies": true,
                      "parent_id": "t1_n62d2xm",
                      "score": 1,
                      "author_fullname": "t2_1b9gox1vsw",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "What do you mean?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n62dcm5",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What do you mean?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mdjqy5",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n62dcm5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753915640,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n62d2xm",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "SuckaRichardson",
            "can_mod_post": false,
            "created_utc": 1753915551,
            "send_replies": true,
            "parent_id": "t3_1mdjqy5",
            "score": 1,
            "author_fullname": "t2_1kt1mgrg4b",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "If you want the holy grail, you better be ready to holy grind to get it baby. ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n62d2xm",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you want the holy grail, you better be ready to holy grind to get it baby. &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n62d2xm/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753915551,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdjqy5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n62tbad",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1753920882,
            "send_replies": true,
            "parent_id": "t3_1mdjqy5",
            "score": 1,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "You should try QWQ it pretty much checks every box you are asking for.\n\nSame with mistral small and phi4. They don’t have reasoning capabilities, but are very good at instruction following.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n62tbad",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You should try QWQ it pretty much checks every box you are asking for.&lt;/p&gt;\n\n&lt;p&gt;Same with mistral small and phi4. They don’t have reasoning capabilities, but are very good at instruction following.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdjqy5/the_holy_grail/n62tbad/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753920882,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdjqy5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]