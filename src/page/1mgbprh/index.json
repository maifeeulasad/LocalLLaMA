[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "The larger SmallThinker MoE has been through a quantization aware training process. it's uploaded to the same gguf repo a bit later. \n\n- https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct-GGUF/blob/main/SmallThinker-21B-A3B-Instruct-QAT.Q4_0.gguf\n\nIn llama.cpp m2 air 16gb, with the `sudo sysctl iogpu.wired_limit_mb=13000` command, it's 30 t/s. \n\nThe model is CPU inference optimised for very low RAM provisions + fast disc, alongside sparsity optimizations, in their llama.cpp fork. \nThe models are pre-trained from scratch. This group always had a good eye for inference optimizations, Always happy to see their works.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "SmallThinker-21B-A3B-Instruct-QAT version",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 75,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mgbprh",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.95,
            "author_flair_background_color": null,
            "ups": 73,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_el5pibmej",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 73,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://external-preview.redd.it/45xh02HDqqpsqpvhy9Hshpnf7PYGTT5vaQkpbv1dIDU.png?width=140&amp;height=75&amp;crop=140:75,smart&amp;auto=webp&amp;s=f963436f8fe8c361365006afe812426eb0a95bfc",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "link",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754200435,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "huggingface.co",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The larger SmallThinker MoE has been through a quantization aware training process. it&amp;#39;s uploaded to the same gguf repo a bit later. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct-GGUF/blob/main/SmallThinker-21B-A3B-Instruct-QAT.Q4_0.gguf\"&gt;https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct-GGUF/blob/main/SmallThinker-21B-A3B-Instruct-QAT.Q4_0.gguf&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In llama.cpp m2 air 16gb, with the &lt;code&gt;sudo sysctl iogpu.wired_limit_mb=13000&lt;/code&gt; command, it&amp;#39;s 30 t/s. &lt;/p&gt;\n\n&lt;p&gt;The model is CPU inference optimised for very low RAM provisions + fast disc, alongside sparsity optimizations, in their llama.cpp fork. \nThe models are pre-trained from scratch. This group always had a good eye for inference optimizations, Always happy to see their works.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct-GGUF/blob/main/SmallThinker-21B-A3B-Instruct-QAT.Q4_0.gguf",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/45xh02HDqqpsqpvhy9Hshpnf7PYGTT5vaQkpbv1dIDU.png?auto=webp&amp;s=af35574c8d3a17d80825392473da49ac8b6cb469",
                    "width": 1200,
                    "height": 648
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/45xh02HDqqpsqpvhy9Hshpnf7PYGTT5vaQkpbv1dIDU.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=97ed6aedc23ef593aadb95c2316196f396bc8e65",
                      "width": 108,
                      "height": 58
                    },
                    {
                      "url": "https://external-preview.redd.it/45xh02HDqqpsqpvhy9Hshpnf7PYGTT5vaQkpbv1dIDU.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6ac0298234f43f3e33451ea17a59722ab4866a82",
                      "width": 216,
                      "height": 116
                    },
                    {
                      "url": "https://external-preview.redd.it/45xh02HDqqpsqpvhy9Hshpnf7PYGTT5vaQkpbv1dIDU.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=19ce50a51896a266764f718a5da7eb00d163ddf3",
                      "width": 320,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/45xh02HDqqpsqpvhy9Hshpnf7PYGTT5vaQkpbv1dIDU.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d016e4dfb71f7ddb2afc8c6c06ee782ba15871a",
                      "width": 640,
                      "height": 345
                    },
                    {
                      "url": "https://external-preview.redd.it/45xh02HDqqpsqpvhy9Hshpnf7PYGTT5vaQkpbv1dIDU.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=800a6ea36b04ed56de7a369596d03474bfd1142f",
                      "width": 960,
                      "height": 518
                    },
                    {
                      "url": "https://external-preview.redd.it/45xh02HDqqpsqpvhy9Hshpnf7PYGTT5vaQkpbv1dIDU.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=29a1fe69fa68a7a75c2954c6a0922c20dd4448f1",
                      "width": 1080,
                      "height": 583
                    }
                  ],
                  "variants": {},
                  "id": "45xh02HDqqpsqpvhy9Hshpnf7PYGTT5vaQkpbv1dIDU"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1mgbprh",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Aaaaaaaaaeeeee",
            "discussion_type": null,
            "num_comments": 12,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/",
            "stickied": false,
            "url": "https://huggingface.co/PowerInfer/SmallThinker-21BA3B-Instruct-GGUF/blob/main/SmallThinker-21B-A3B-Instruct-QAT.Q4_0.gguf",
            "subreddit_subscribers": 509626,
            "created_utc": 1754200435,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6nupox",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "Chromix_",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6nqbyx",
                                                    "score": 3,
                                                    "author_fullname": "t2_k7w2h",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "The way I understand it, perplexity isn't a meaningful way of comparing between different models. It can be used for checking different quantizations of the same model, even though KLD seems to be preferred there. QAT isn't just a quantization though, it's additional training. Additional training means the new QAT model - and the impact of its 4 bit quantization - cannot be compared to the base model using perplexity.\n\nThe less bits a model quantization has, the higher the perplexity rises. Yet in case of the Gemma QAT the perplexity of the 4 bit quant was significantly lower than that of the original BF16 model. That's due to the additional training, not because the quantization - stripping the model of detail and information - somehow improved it. Thus, the way to compare the QAT result is by practical benchmarks.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6nupox",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The way I understand it, perplexity isn&amp;#39;t a meaningful way of comparing between different models. It can be used for checking different quantizations of the same model, even though KLD seems to be preferred there. QAT isn&amp;#39;t just a quantization though, it&amp;#39;s additional training. Additional training means the new QAT model - and the impact of its 4 bit quantization - cannot be compared to the base model using perplexity.&lt;/p&gt;\n\n&lt;p&gt;The less bits a model quantization has, the higher the perplexity rises. Yet in case of the Gemma QAT the perplexity of the 4 bit quant was significantly lower than that of the original BF16 model. That&amp;#39;s due to the additional training, not because the quantization - stripping the model of detail and information - somehow improved it. Thus, the way to compare the QAT result is by practical benchmarks.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mgbprh",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6nupox/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754208858,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754208858,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6nqbyx",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "shing3232",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6nooyj",
                                          "score": 1,
                                          "author_fullname": "t2_ze4mg",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "It will but you might need more diversity of dataset instead of just wikitext. Using part of training data might work better",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6nqbyx",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It will but you might need more diversity of dataset instead of just wikitext. Using part of training data might work better&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mgbprh",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6nqbyx/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754206297,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754206297,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6nooyj",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Chromix_",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6nlyxs",
                                "score": 3,
                                "author_fullname": "t2_k7w2h",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Based on the differences observed for the [Gemma QAT](https://www.reddit.com/r/LocalLLaMA/comments/1jqnnfp/comment/ml8nuof/) I don't think perplexity will yield much insight here.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6nooyj",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Based on the differences observed for the &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1jqnnfp/comment/ml8nuof/\"&gt;Gemma QAT&lt;/a&gt; I don&amp;#39;t think perplexity will yield much insight here.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgbprh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6nooyj/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754205361,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754205361,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6nlyxs",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "shing3232",
                      "can_mod_post": false,
                      "created_utc": 1754203835,
                      "send_replies": true,
                      "parent_id": "t1_n6njuz9",
                      "score": 1,
                      "author_fullname": "t2_ze4mg",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "perplexity on wiki should give you a basic understanding of the difference.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6nlyxs",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;perplexity on wiki should give you a basic understanding of the difference.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgbprh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6nlyxs/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754203835,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6njuz9",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Chromix_",
            "can_mod_post": false,
            "created_utc": 1754202663,
            "send_replies": true,
            "parent_id": "t3_1mgbprh",
            "score": 9,
            "author_fullname": "t2_k7w2h",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The QAT quants (Q4\\_0, Q4\\_K\\_M and Q4\\_K\\_S) were created without imatrix. There are some regular (non-QAT) quants with imatrix in the repo though. IIRC imatrix also improved performance of QAT quants. Was there a specific reason for not using imatrix in this case?\n\nAlso: Was any of the existing benchmarks repeated with the QAT version to check for differences?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6njuz9",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The QAT quants (Q4_0, Q4_K_M and Q4_K_S) were created without imatrix. There are some regular (non-QAT) quants with imatrix in the repo though. IIRC imatrix also improved performance of QAT quants. Was there a specific reason for not using imatrix in this case?&lt;/p&gt;\n\n&lt;p&gt;Also: Was any of the existing benchmarks repeated with the QAT version to check for differences?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6njuz9/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754202663,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgbprh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ofvp0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Cool-Chemical-5629",
                      "can_mod_post": false,
                      "created_utc": 1754220889,
                      "send_replies": true,
                      "parent_id": "t1_n6nuri6",
                      "score": 5,
                      "author_fullname": "t2_qz1qjc86",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "No support in LM Studio yet, but this was last week release of the base llama.cpp:\n\n&gt;b6012\n\n&gt;  \n [github-actions](https://github.com/apps/github-actions) released this last week[ b6012](https://github.com/ggml-org/llama.cpp/tree/b6012)[ `6c6e397`](https://github.com/ggml-org/llama.cpp/commit/6c6e397affc4fac717e718364fb4b635cec6433a) \n\n&gt;\n\n&gt;model : add support for SmallThinker series (#14898)  \n  \n...\n\nLM Studio is traditionally taking their sweet time to implement support, making us all forget such a model was even released and by the time the support reaches LM Studio, there will already be better and newer models.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ofvp0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No support in LM Studio yet, but this was last week release of the base llama.cpp:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;b6012&lt;/p&gt;\n\n&lt;p&gt; &lt;a href=\"https://github.com/apps/github-actions\"&gt;github-actions&lt;/a&gt; released this last week&lt;a href=\"https://github.com/ggml-org/llama.cpp/tree/b6012\"&gt; b6012&lt;/a&gt;&lt;a href=\"https://github.com/ggml-org/llama.cpp/commit/6c6e397affc4fac717e718364fb4b635cec6433a\"&gt; &lt;code&gt;6c6e397&lt;/code&gt;&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;model : add support for SmallThinker series (#14898)  &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;...&lt;/p&gt;\n\n&lt;p&gt;LM Studio is traditionally taking their sweet time to implement support, making us all forget such a model was even released and by the time the support reaches LM Studio, there will already be better and newer models.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgbprh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6ofvp0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754220889,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6plqsf",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Aaaaaaaaaeeeee",
                      "can_mod_post": false,
                      "created_utc": 1754235718,
                      "send_replies": true,
                      "parent_id": "t1_n6nuri6",
                      "score": 2,
                      "author_fullname": "t2_el5pibmej",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "yup",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6plqsf",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;yup&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgbprh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6plqsf/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754235718,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6nuri6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "GreatGatsby00",
            "can_mod_post": false,
            "created_utc": 1754208887,
            "send_replies": true,
            "parent_id": "t3_1mgbprh",
            "score": 7,
            "author_fullname": "t2_q1qk3",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Has support for this model been integrated into the working branch of llama.cpp yet?  I really like the concept.  :-)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6nuri6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Has support for this model been integrated into the working branch of llama.cpp yet?  I really like the concept.  :-)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6nuri6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754208887,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgbprh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6rr2jb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "moko990",
            "can_mod_post": false,
            "created_utc": 1754259607,
            "send_replies": true,
            "parent_id": "t3_1mgbprh",
            "score": 1,
            "author_fullname": "t2_1kh1rmhlhh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "A bit out of the loop, what's the advantages of QAT variations? What does it do? And is it better than FP8 for example?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rr2jb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A bit out of the loop, what&amp;#39;s the advantages of QAT variations? What does it do? And is it better than FP8 for example?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6rr2jb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754259607,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgbprh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6s7yj3",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "AltruisticList6000",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6s5m0w",
                                "score": 1,
                                "author_fullname": "t2_hnjq9xn4a",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Hmm interesting, thanks!",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6s7yj3",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hmm interesting, thanks!&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mgbprh",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6s7yj3/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754265408,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754265408,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6s5m0w",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Aaaaaaaaaeeeee",
                      "can_mod_post": false,
                      "created_utc": 1754264598,
                      "send_replies": true,
                      "parent_id": "t1_n6rzycj",
                      "score": 2,
                      "author_fullname": "t2_el5pibmej",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "No, it was trained from scratch. I also thought the same because of the size. \n\n\nHere's the paper, goes into the details. (No QAT info yet) \n\n\n- https://arxiv.org/html/2507.20984v2\n\n\n&gt;We trained SmallThinker-4B-A0.6B on a token horizon of 2.5 trillion tokens and SmallThinker21B on a token horizon of 7.2 trillion tokens.\n\n\n&gt;Following prior work such as SmolLM (Allal et al., 2025), we initiated our data construction process by collecting a diverse range of high-quality datasets from the open-source community. For web data, we aggregated a corpus totaling 9 trillion tokens from 5 prominent sources including FineWeb-Edu (Lozhkov et al., 2024a), Nemotron-CC (Su et al., 2024), mga-fineweb-edu (Hao et al., 2024) and the Knowledge Pile (Fei et al., 2024). For math datasets, we collected 1 trillion tokens, primarily from datasets such as OpenWebMath (Paster et al., 2023), MegaMath (Zhou et al., 2025), and FineMath (Allal et al., 2025) and so on. For our coding dataset, we established corpora like StackV2 (Lozhkov et al., 2024b) and OpenCoder",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6s5m0w",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, it was trained from scratch. I also thought the same because of the size. &lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the paper, goes into the details. (No QAT info yet) &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://arxiv.org/html/2507.20984v2\"&gt;https://arxiv.org/html/2507.20984v2&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;We trained SmallThinker-4B-A0.6B on a token horizon of 2.5 trillion tokens and SmallThinker21B on a token horizon of 7.2 trillion tokens.&lt;/p&gt;\n\n&lt;p&gt;Following prior work such as SmolLM (Allal et al., 2025), we initiated our data construction process by collecting a diverse range of high-quality datasets from the open-source community. For web data, we aggregated a corpus totaling 9 trillion tokens from 5 prominent sources including FineWeb-Edu (Lozhkov et al., 2024a), Nemotron-CC (Su et al., 2024), mga-fineweb-edu (Hao et al., 2024) and the Knowledge Pile (Fei et al., 2024). For math datasets, we collected 1 trillion tokens, primarily from datasets such as OpenWebMath (Paster et al., 2023), MegaMath (Zhou et al., 2025), and FineMath (Allal et al., 2025) and so on. For our coding dataset, we established corpora like StackV2 (Lozhkov et al., 2024b) and OpenCoder&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgbprh",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6s5m0w/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754264598,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6rzycj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "AltruisticList6000",
            "can_mod_post": false,
            "created_utc": 1754262640,
            "send_replies": true,
            "parent_id": "t3_1mgbprh",
            "score": 1,
            "author_fullname": "t2_hnjq9xn4a",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Is this based on Ernie 4.5 21BA3B? Asking because of the size.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6rzycj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is this based on Ernie 4.5 21BA3B? Asking because of the size.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgbprh/smallthinker21ba3binstructqat_version/n6rzycj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754262640,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgbprh",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]