[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "People need to stop expecting a 5b model to outperform 30b models. Like do they think OpenAI is god?\n\nR1 670b, **37b activ**e  \nKimi K2 1t, **32b active**  \nQwen3 235b, **22b active**  \n*-- limit of a single average gpu --*  \nGLM 4.5 Air 106b, **12b active** (very pushing it but fine)  \nQwen3 14b  \noss 120b, **5b active**  \nQwen3 30b, **3b active**  \noss 20b, **3b active**\n\nI would rather have a model that I can actually run locally than a good model that needs providers. To be clear, I hate and won't use gpt-oss, but because it's censored and not because models many times larger are better.\n\nI LOVED Qwen3 30b/3b was local-friendly and fast and nobody compared it to bigger models, but when OpenAI releases a local model and suddenly everyone is comparing it to non-local models.\n\nIt's an expected model for it's size. It's not beating models 4x larger, but it's not garbage compared to similar sizes.\n\n[Graph of all local-friendly models \\(GLM Air would be tough\\)](https://preview.redd.it/aj58dutqzmhf1.png?width=1435&amp;format=png&amp;auto=webp&amp;s=47a39c27091e2beb9233c783989cf7305269027e)",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Can we focus more on LOCAL models? We were excited for Qwen3 30b/3b but now were comparing to not local models",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 66,
            "top_awarded_type": null,
            "hide_score": false,
            "media_metadata": {
              "aj58dutqzmhf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 51,
                    "x": 108,
                    "u": "https://preview.redd.it/aj58dutqzmhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6d45e6dc6f5db61c97500cfa7bd52dd35d483517"
                  },
                  {
                    "y": 102,
                    "x": 216,
                    "u": "https://preview.redd.it/aj58dutqzmhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a1e8d0256436fbaf3fce514fbb07b5106b21630"
                  },
                  {
                    "y": 151,
                    "x": 320,
                    "u": "https://preview.redd.it/aj58dutqzmhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7e849820cf2812daf76367bb86a3aafeab9723c6"
                  },
                  {
                    "y": 303,
                    "x": 640,
                    "u": "https://preview.redd.it/aj58dutqzmhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b75bcf2685719fbfab782a963264f8ae3a50d915"
                  },
                  {
                    "y": 455,
                    "x": 960,
                    "u": "https://preview.redd.it/aj58dutqzmhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=da679291e57613f6d4e851cb728ae49d1d1761e3"
                  },
                  {
                    "y": 512,
                    "x": 1080,
                    "u": "https://preview.redd.it/aj58dutqzmhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d99f80df5b2bebb472f8a7ffd4d70f691684422f"
                  }
                ],
                "s": {
                  "y": 681,
                  "x": 1435,
                  "u": "https://preview.redd.it/aj58dutqzmhf1.png?width=1435&amp;format=png&amp;auto=webp&amp;s=47a39c27091e2beb9233c783989cf7305269027e"
                },
                "id": "aj58dutqzmhf1"
              }
            },
            "name": "t3_1mk74wq",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.83,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 143,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_duqfsmw4g",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 143,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/TJcHxiajHwTxrtNoLptpQfkKcoLceehEHpbxyUdzAnI.jpg",
            "edited": 1754634610,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754589482,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;People need to stop expecting a 5b model to outperform 30b models. Like do they think OpenAI is god?&lt;/p&gt;\n\n&lt;p&gt;R1 670b, &lt;strong&gt;37b activ&lt;/strong&gt;e&lt;br/&gt;\nKimi K2 1t, &lt;strong&gt;32b active&lt;/strong&gt;&lt;br/&gt;\nQwen3 235b, &lt;strong&gt;22b active&lt;/strong&gt;&lt;br/&gt;\n&lt;em&gt;-- limit of a single average gpu --&lt;/em&gt;&lt;br/&gt;\nGLM 4.5 Air 106b, &lt;strong&gt;12b active&lt;/strong&gt; (very pushing it but fine)&lt;br/&gt;\nQwen3 14b&lt;br/&gt;\noss 120b, &lt;strong&gt;5b active&lt;/strong&gt;&lt;br/&gt;\nQwen3 30b, &lt;strong&gt;3b active&lt;/strong&gt;&lt;br/&gt;\noss 20b, &lt;strong&gt;3b active&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I would rather have a model that I can actually run locally than a good model that needs providers. To be clear, I hate and won&amp;#39;t use gpt-oss, but because it&amp;#39;s censored and not because models many times larger are better.&lt;/p&gt;\n\n&lt;p&gt;I LOVED Qwen3 30b/3b was local-friendly and fast and nobody compared it to bigger models, but when OpenAI releases a local model and suddenly everyone is comparing it to non-local models.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s an expected model for it&amp;#39;s size. It&amp;#39;s not beating models 4x larger, but it&amp;#39;s not garbage compared to similar sizes.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/aj58dutqzmhf1.png?width=1435&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=47a39c27091e2beb9233c783989cf7305269027e\"&gt;Graph of all local-friendly models (GLM Air would be tough)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mk74wq",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "agentcubed",
            "discussion_type": null,
            "num_comments": 50,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/",
            "subreddit_subscribers": 513813,
            "created_utc": 1754589482,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7k3epr",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "indicava",
                      "can_mod_post": false,
                      "created_utc": 1754635255,
                      "send_replies": true,
                      "parent_id": "t1_n7htkpq",
                      "score": 0,
                      "author_fullname": "t2_4dvff",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I support this message",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7k3epr",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I support this message&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": true,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7k3epr/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754635255,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7htkpq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ethertype",
            "can_mod_post": false,
            "created_utc": 1754603256,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 26,
            "author_fullname": "t2_3nfev4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Where's qwen3-coder-32b-instruct pretty please with sugar and cream?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7htkpq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Where&amp;#39;s qwen3-coder-32b-instruct pretty please with sugar and cream?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7htkpq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754603256,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 26
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7k83g4",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "FunnyAsparagus1253",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7hvhtq",
                                          "score": 1,
                                          "author_fullname": "t2_i6c8tay3w",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Oh, right ðŸ˜…",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7k83g4",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh, right ðŸ˜…&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mk74wq",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7k83g4/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754637792,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754637792,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7hvhtq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "twack3r",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7ho0rk",
                                "score": 23,
                                "author_fullname": "t2_ts7cw",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Thatâ€™s exactly what theyâ€™re saying",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7hvhtq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thatâ€™s exactly what theyâ€™re saying&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mk74wq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7hvhtq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754603866,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754603866,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 23
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7iqjrj",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Wise-Comb8596",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7ho0rk",
                                "score": 6,
                                "author_fullname": "t2_1sqe3qr1mf",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Right, so shouldnâ€™t the conversation go beyond models that can run on an RTX 5090 prebuilt?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7iqjrj",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Right, so shouldnâ€™t the conversation go beyond models that can run on an RTX 5090 prebuilt?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mk74wq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7iqjrj/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754614462,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754614462,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7iq6xe",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "InsideYork",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7ho0rk",
                                "score": 2,
                                "author_fullname": "t2_12s3hn4y0b",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I didnâ€™t buy at that time. By the time I got back you could use way weaker hardware for way better outputs than the mikubox so I didnâ€™t feel the need to get a new GPU. \n\nI remember when a prompt model card for llama was lauded heftily that would be a joke now.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7iq6xe",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I didnâ€™t buy at that time. By the time I got back you could use way weaker hardware for way better outputs than the mikubox so I didnâ€™t feel the need to get a new GPU. &lt;/p&gt;\n\n&lt;p&gt;I remember when a prompt model card for llama was lauded heftily that would be a joke now.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mk74wq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7iq6xe/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754614339,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754614339,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7ho0rk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "FunnyAsparagus1253",
                      "can_mod_post": false,
                      "created_utc": 1754601525,
                      "send_replies": true,
                      "parent_id": "t1_n7grf6q",
                      "score": 13,
                      "author_fullname": "t2_i6c8tay3w",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yah but no. Wasnâ€™t r/LocalLLaMA supposed to be for enthusiasts? P40 crew? People building their own rigs?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7ho0rk",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yah but no. Wasnâ€™t &lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt; supposed to be for enthusiasts? P40 crew? People building their own rigs?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7ho0rk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754601525,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 13
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7grf6q",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Ulterior-Motive_",
            "can_mod_post": false,
            "created_utc": 1754592009,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 57,
            "author_fullname": "t2_127atw4awd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Just because it's hard to run doesn't make it non-local. Otherwise anything above an 8B model is non-local for all the newbies trying to run LLMs on their 8 year old GPUs, which is far more representative of the average person than someone with an enthusiast build.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7grf6q",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just because it&amp;#39;s hard to run doesn&amp;#39;t make it non-local. Otherwise anything above an 8B model is non-local for all the newbies trying to run LLMs on their 8 year old GPUs, which is far more representative of the average person than someone with an enthusiast build.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7grf6q/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754592009,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 57
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7iu4p2",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "CheatCodesOfLife",
                      "can_mod_post": false,
                      "created_utc": 1754615732,
                      "send_replies": true,
                      "parent_id": "t1_n7gu0q1",
                      "score": 6,
                      "author_fullname": "t2_32el727b",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; Llama 405B came out and then Mistral Large 123B\n\nYeah that was amazing. I was trying to figure out how to run the 405B locally, then while it was downloading, Mistral-Large just quietly dropped and destroyed it lol.\n\n&gt; seeing bigger local model like R1 (the very first version) was motivation to upgrade my workstation\n\nSame here. WizardLM2 -&gt; R1(OG) -&gt; K2 all made me purchase hardware.\n\n&gt; many other releases of large MoE models\n\nSounds as though we like similar models, I suggest you try GLM4.5 if you haven't already!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7iu4p2",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Llama 405B came out and then Mistral Large 123B&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yeah that was amazing. I was trying to figure out how to run the 405B locally, then while it was downloading, Mistral-Large just quietly dropped and destroyed it lol.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;seeing bigger local model like R1 (the very first version) was motivation to upgrade my workstation&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Same here. WizardLM2 -&amp;gt; R1(OG) -&amp;gt; K2 all made me purchase hardware.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;many other releases of large MoE models&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Sounds as though we like similar models, I suggest you try GLM4.5 if you haven&amp;#39;t already!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7iu4p2/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754615732,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7k22o3",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Affectionate-Hat-536",
                      "can_mod_post": false,
                      "created_utc": 1754634533,
                      "send_replies": true,
                      "parent_id": "t1_n7gu0q1",
                      "score": 2,
                      "author_fullname": "t2_7htykppj",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Very insightful! Looked at your setup in linked post . Awesome.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7k22o3",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Very insightful! Looked at your setup in linked post . Awesome.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7k22o3/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754634533,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7jpvs7",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Lissanro",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7jghv8",
                                "score": 2,
                                "author_fullname": "t2_fpfao9g",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I shared detailsÂ [here](https://www.reddit.com/r/LocalLLaMA/comments/1jtx05j/comment/mlyf0ux/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button), including both my hardware I run and what backend I use.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7jpvs7",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I shared detailsÂ &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1jtx05j/comment/mlyf0ux/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button\"&gt;here&lt;/a&gt;, including both my hardware I run and what backend I use.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mk74wq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7jpvs7/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754628360,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754628360,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7jghv8",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "RobotRobotWhatDoUSee",
                      "can_mod_post": false,
                      "created_utc": 1754624230,
                      "send_replies": true,
                      "parent_id": "t1_n7gu0q1",
                      "score": 1,
                      "author_fullname": "t2_m78cdz1nv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "What is your hardware setup for running these?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7jghv8",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What is your hardware setup for running these?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7jghv8/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754624230,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7gu0q1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Lissanro",
            "can_mod_post": false,
            "created_utc": 1754592759,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 35,
            "author_fullname": "t2_fpfao9g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I run these two locally (IQ4 quants with ik\\_llama.cpp):\n\nR1 670b, 37b active  \nKimi K2 1t, 32b active\n\nI can run Qwen3 235b too, but R1 for my use cases that require thinking works mostly better, and K2 is pretty good for things that do not require thinking and faster too than R1 (both due to generating less tokens for the same task and due to less active parameters). I am also considering giving openPangu Ultra a try when I complete downloading it.\n\nI think all local models worth discussing, both large and small. This allows to understand better are the large ones really far ahead, or maybe some tasks can be handled with smaller and more efficient ones. Or decide if it is worth upgrading workstation for running bigger models, not necessary the biggest - maybe something in the middle, depending on the budget, or sticking with smaller ones if they good enough.\n\nTrying to call local models non-local just because you did not buy necessary hardware is a bit strange. For me, seeing bigger local model like R1 (the very first version) was motivation to upgrade my workstation.\n\nThis is why even when talking about small models, comparing them to big ones still useful. For example, on your chart there are no R1 or K2, so I do not know how any of the small models compare in each benchmark. Even when I did not had the hardware, it was still important - for example, when Llama 405B came out and then Mistral Large 123B the next day, I determined that Llama 405B is not worth upgrading for me, since I could run Large 123B 5bpw instead at decent speed on the rig I had at the time. R1 however motivated me to upgrade, and later it was followed by many other releases of large MoE models: V3, R1T, R1 0528, Kimi K2, openPangu Ultra, etc.",
            "edited": 1754609633,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7gu0q1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I run these two locally (IQ4 quants with ik_llama.cpp):&lt;/p&gt;\n\n&lt;p&gt;R1 670b, 37b active&lt;br/&gt;\nKimi K2 1t, 32b active&lt;/p&gt;\n\n&lt;p&gt;I can run Qwen3 235b too, but R1 for my use cases that require thinking works mostly better, and K2 is pretty good for things that do not require thinking and faster too than R1 (both due to generating less tokens for the same task and due to less active parameters). I am also considering giving openPangu Ultra a try when I complete downloading it.&lt;/p&gt;\n\n&lt;p&gt;I think all local models worth discussing, both large and small. This allows to understand better are the large ones really far ahead, or maybe some tasks can be handled with smaller and more efficient ones. Or decide if it is worth upgrading workstation for running bigger models, not necessary the biggest - maybe something in the middle, depending on the budget, or sticking with smaller ones if they good enough.&lt;/p&gt;\n\n&lt;p&gt;Trying to call local models non-local just because you did not buy necessary hardware is a bit strange. For me, seeing bigger local model like R1 (the very first version) was motivation to upgrade my workstation.&lt;/p&gt;\n\n&lt;p&gt;This is why even when talking about small models, comparing them to big ones still useful. For example, on your chart there are no R1 or K2, so I do not know how any of the small models compare in each benchmark. Even when I did not had the hardware, it was still important - for example, when Llama 405B came out and then Mistral Large 123B the next day, I determined that Llama 405B is not worth upgrading for me, since I could run Large 123B 5bpw instead at decent speed on the rig I had at the time. R1 however motivated me to upgrade, and later it was followed by many other releases of large MoE models: V3, R1T, R1 0528, Kimi K2, openPangu Ultra, etc.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7gu0q1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754592759,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 35
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7jquh0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "westsunset",
                      "can_mod_post": false,
                      "created_utc": 1754628806,
                      "send_replies": true,
                      "parent_id": "t1_n7hf66c",
                      "score": 4,
                      "author_fullname": "t2_ffqgv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Did everyone else hopefully click the link like me lol",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7jquh0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Did everyone else hopefully click the link like me lol&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7jquh0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754628806,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7hf66c",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Baldur-Norddahl",
            "can_mod_post": false,
            "created_utc": 1754598925,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 27,
            "author_fullname": "t2_bvqb8ng0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It is not r/PoorPeoplesLlama ... Sorry I couldn't resist :-)\n\nIf we go about topics, we have lots of people talking about how you might build home made and somewhat affordable rigs that can run R1 and K2. In my opinion this is exactly what this group is about.\n\nYes we also help newbies that want to test out what their old laptop with 16 GB total memory can do. Of course we want to be a friendly and helpful group. But if that was all we had, this place would be long dead.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7hf66c",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is not &lt;a href=\"/r/PoorPeoplesLlama\"&gt;r/PoorPeoplesLlama&lt;/a&gt; ... Sorry I couldn&amp;#39;t resist :-)&lt;/p&gt;\n\n&lt;p&gt;If we go about topics, we have lots of people talking about how you might build home made and somewhat affordable rigs that can run R1 and K2. In my opinion this is exactly what this group is about.&lt;/p&gt;\n\n&lt;p&gt;Yes we also help newbies that want to test out what their old laptop with 16 GB total memory can do. Of course we want to be a friendly and helpful group. But if that was all we had, this place would be long dead.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7hf66c/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754598925,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 27
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n7ir2k3",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "mxmumtuna",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n7iosax",
                                                              "score": 3,
                                                              "author_fullname": "t2_igbly",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Thatâ€™s exactly how I feel. Even though I got Kimi running decently, GLM is another level for performance.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n7ir2k3",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thatâ€™s exactly how I feel. Even though I got Kimi running decently, GLM is another level for performance.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mk74wq",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": true,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7ir2k3/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754614644,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754614644,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 3
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7iosax",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "skatardude10",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n7imffn",
                                                    "score": 2,
                                                    "author_fullname": "t2_8k4ah",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Agreed. It's really good. It finally doesn't hurt coming back to local from Gemini 2.5 Pro.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7iosax",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Agreed. It&amp;#39;s really good. It finally doesn&amp;#39;t hurt coming back to local from Gemini 2.5 Pro.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mk74wq",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7iosax/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754613847,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754613847,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7imffn",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "mxmumtuna",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7i09pk",
                                          "score": 4,
                                          "author_fullname": "t2_igbly",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "These GLM series are very good. Even irrespective of their sizes. They are just good. Basically replaced Qwen3 for me.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7imffn",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;These GLM series are very good. Even irrespective of their sizes. They are just good. Basically replaced Qwen3 for me.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": true,
                                          "can_gild": false,
                                          "link_id": "t3_1mk74wq",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7imffn/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754613004,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754613004,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7i09pk",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ElectronSpiderwort",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7hzbr1",
                                "score": 2,
                                "author_fullname": "t2_mxbu5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "If anything gets me to buy a GPU it'll be this model",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7i09pk",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If anything gets me to buy a GPU it&amp;#39;ll be this model&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mk74wq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7i09pk/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754605409,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754605409,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7kj55n",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "FullOf_Bad_Ideas",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7hzbr1",
                                "score": 1,
                                "author_fullname": "t2_9s7pmakgx",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Regex overrides? Can I get in the same performance neighborhood with - - n-cpu-moe flag? I hate Regex. I tried it on 2x 3090 ti with some of the model sitting on in RAM and it was pretty slow, something like 6 or 8 tokens/s.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7kj55n",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Regex overrides? Can I get in the same performance neighborhood with - - n-cpu-moe flag? I hate Regex. I tried it on 2x 3090 ti with some of the model sitting on in RAM and it was pretty slow, something like 6 or 8 tokens/s.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mk74wq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7kj55n/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754644155,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754644155,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7hzbr1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "skatardude10",
                      "can_mod_post": false,
                      "created_utc": 1754605098,
                      "send_replies": true,
                      "parent_id": "t1_n7hwf47",
                      "score": 4,
                      "author_fullname": "t2_8k4ah",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Same model / RAM + 3090 and it's crazy fast (enough) with tensor overrides and running 81920 context.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7hzbr1",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Same model / RAM + 3090 and it&amp;#39;s crazy fast (enough) with tensor overrides and running 81920 context.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7hzbr1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754605098,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7hwf47",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ElectronSpiderwort",
            "can_mod_post": false,
            "created_utc": 1754604158,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 9,
            "author_fullname": "t2_mxbu5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'm trying GLM 4.5 Air. I have 64 GB DDR4 and no GPU. I can't squeeze much context into RAM with the model loaded, but 16K context on Unsloth UD-Q3-K-XL is giving me great answers, slowly, 2.5 tok/sec (6 tok/sec prompt). I can't get the /nothink directive to work consistently. For any sane person this would be unusably slow, but I'm not any sane person, so",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7hwf47",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying GLM 4.5 Air. I have 64 GB DDR4 and no GPU. I can&amp;#39;t squeeze much context into RAM with the model loaded, but 16K context on Unsloth UD-Q3-K-XL is giving me great answers, slowly, 2.5 tok/sec (6 tok/sec prompt). I can&amp;#39;t get the /nothink directive to work consistently. For any sane person this would be unusably slow, but I&amp;#39;m not any sane person, so&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7hwf47/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754604158,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 9
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7k91oo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "fallingdowndizzyvr",
            "can_mod_post": false,
            "created_utc": 1754638334,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 4,
            "author_fullname": "t2_o65i6kx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt; GLM 4.5 Air 106b, 12b active (very pushing it but fine)\n\nJust because you can't run it, doesn't mean it's not a local model. I not only run GLM 4.5 Air. I run plain big GLM 4.5. All locally.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7k91oo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;GLM 4.5 Air 106b, 12b active (very pushing it but fine)&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Just because you can&amp;#39;t run it, doesn&amp;#39;t mean it&amp;#39;s not a local model. I not only run GLM 4.5 Air. I run plain big GLM 4.5. All locally.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7k91oo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754638334,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 4
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7gpqkn",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "silenceimpaired",
                      "can_mod_post": false,
                      "created_utc": 1754591518,
                      "send_replies": true,
                      "parent_id": "t1_n7gjbtu",
                      "score": 21,
                      "author_fullname": "t2_dissgzyl",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I wouldnâ€™t say Manyâ€¦ but enough. I can definitely run Qwen 3 235bâ€¦ but not at coding assist speedsâ€¦ and if you use mmap almost anyone can run it if they have a day for a response. :)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7gpqkn",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I wouldnâ€™t say Manyâ€¦ but enough. I can definitely run Qwen 3 235bâ€¦ but not at coding assist speedsâ€¦ and if you use mmap almost anyone can run it if they have a day for a response. :)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7gpqkn/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754591518,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 21
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": {
                                                                "kind": "Listing",
                                                                "data": {
                                                                  "after": null,
                                                                  "dist": null,
                                                                  "modhash": "",
                                                                  "geo_filter": "",
                                                                  "children": [
                                                                    {
                                                                      "kind": "t1",
                                                                      "data": {
                                                                        "subreddit_id": "t5_81eyvm",
                                                                        "approved_at_utc": null,
                                                                        "author_is_blocked": false,
                                                                        "comment_type": null,
                                                                        "awarders": [],
                                                                        "mod_reason_by": null,
                                                                        "banned_by": null,
                                                                        "author_flair_type": "text",
                                                                        "total_awards_received": 0,
                                                                        "subreddit": "LocalLLaMA",
                                                                        "author_flair_template_id": null,
                                                                        "distinguished": null,
                                                                        "likes": null,
                                                                        "replies": "",
                                                                        "user_reports": [],
                                                                        "saved": false,
                                                                        "id": "n7i2rzg",
                                                                        "banned_at_utc": null,
                                                                        "mod_reason_title": null,
                                                                        "gilded": 0,
                                                                        "archived": false,
                                                                        "collapsed_reason_code": null,
                                                                        "no_follow": false,
                                                                        "author": "henryclw",
                                                                        "can_mod_post": false,
                                                                        "send_replies": true,
                                                                        "parent_id": "t1_n7i0kns",
                                                                        "score": 4,
                                                                        "author_fullname": "t2_ibl2d6y5",
                                                                        "approved_by": null,
                                                                        "mod_note": null,
                                                                        "all_awardings": [],
                                                                        "collapsed": false,
                                                                        "body": "Nice! I wish I could afford this much money in the near future. Enjoy your beast",
                                                                        "edited": false,
                                                                        "gildings": {},
                                                                        "author_flair_css_class": null,
                                                                        "name": "t1_n7i2rzg",
                                                                        "is_submitter": false,
                                                                        "downs": 0,
                                                                        "author_flair_richtext": [],
                                                                        "author_patreon_flair": false,
                                                                        "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Nice! I wish I could afford this much money in the near future. Enjoy your beast&lt;/p&gt;\n&lt;/div&gt;",
                                                                        "removal_reason": null,
                                                                        "collapsed_reason": null,
                                                                        "link_id": "t3_1mk74wq",
                                                                        "associated_award": null,
                                                                        "stickied": false,
                                                                        "author_premium": false,
                                                                        "can_gild": false,
                                                                        "top_awarded_type": null,
                                                                        "unrepliable_reason": null,
                                                                        "author_flair_text_color": null,
                                                                        "score_hidden": false,
                                                                        "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7i2rzg/",
                                                                        "subreddit_type": "public",
                                                                        "locked": false,
                                                                        "report_reasons": null,
                                                                        "created": 1754606237,
                                                                        "author_flair_text": null,
                                                                        "treatment_tags": [],
                                                                        "created_utc": 1754606237,
                                                                        "subreddit_name_prefixed": "r/LocalLLaMA",
                                                                        "controversiality": 0,
                                                                        "depth": 6,
                                                                        "author_flair_background_color": null,
                                                                        "collapsed_because_crowd_control": null,
                                                                        "mod_reports": [],
                                                                        "num_reports": null,
                                                                        "ups": 4
                                                                      }
                                                                    }
                                                                  ],
                                                                  "before": null
                                                                }
                                                              },
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n7i0kns",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": false,
                                                              "author": "twack3r",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n7hzndg",
                                                              "score": 3,
                                                              "author_fullname": "t2_ts7cw",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "About â‚¬11.5-12K for the hardware and then another â‚¬1.500 for the cooling. But I did repurpose some elements like PSU, radiators and pumps form my previous workstation.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n7i0kns",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;About â‚¬11.5-12K for the hardware and then another â‚¬1.500 for the cooling. But I did repurpose some elements like PSU, radiators and pumps form my previous workstation.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mk74wq",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7i0kns/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754605509,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754605509,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 3
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n7hzndg",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "henryclw",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n7hwmxf",
                                                    "score": 3,
                                                    "author_fullname": "t2_ibl2d6y5",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "How is the total cost of your system?",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n7hzndg",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How is the total cost of your system?&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mk74wq",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7hzndg/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754605205,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754605205,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7hwmxf",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "twack3r",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7gz0ou",
                                          "score": 5,
                                          "author_fullname": "t2_ts7cw",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Thatâ€™s a nice system! Let me know if it would be ok to pick your brains at some point.\n\nIâ€™m currently building this system - TR7955WX(sniped used for â‚¬900, speculating on a 9000 series X3D TR variant), WRX90E SAGE, 512GiB 6400, 5090, 6 3090s in 3 NVLink pairs, 8TiB gen5 m2 across 4 nvme ssds in RAID-0. Iâ€™m extremely anxious about stepping into vLLMâ€¦",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7hwmxf",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thatâ€™s a nice system! Let me know if it would be ok to pick your brains at some point.&lt;/p&gt;\n\n&lt;p&gt;Iâ€™m currently building this system - TR7955WX(sniped used for â‚¬900, speculating on a 9000 series X3D TR variant), WRX90E SAGE, 512GiB 6400, 5090, 6 3090s in 3 NVLink pairs, 8TiB gen5 m2 across 4 nvme ssds in RAID-0. Iâ€™m extremely anxious about stepping into vLLMâ€¦&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mk74wq",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7hwmxf/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754604228,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754604228,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 5
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7gz0ou",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "mrtime777",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7gxrak",
                                "score": 7,
                                "author_fullname": "t2_37pn0768",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I can run kimi k2 q2 at 7 t/s or r1 dq4 at 5 t/s, qwen3-coder-480b iq5 - 4t/s, iq2 - \\~7 t/s ... it's quite usable ... in 24 hours you can generate 500-700k output tokens... how much or little it is depends on the task) \n\nhttps://preview.redd.it/qg3ci5wednhf1.png?width=2252&amp;format=png&amp;auto=webp&amp;s=d6eacb1e1f9336b517a3b7190a2703e07962ba79",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7gz0ou",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can run kimi k2 q2 at 7 t/s or r1 dq4 at 5 t/s, qwen3-coder-480b iq5 - 4t/s, iq2 - ~7 t/s ... it&amp;#39;s quite usable ... in 24 hours you can generate 500-700k output tokens... how much or little it is depends on the task) &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qg3ci5wednhf1.png?width=2252&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d6eacb1e1f9336b517a3b7190a2703e07962ba79\"&gt;https://preview.redd.it/qg3ci5wednhf1.png?width=2252&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d6eacb1e1f9336b517a3b7190a2703e07962ba79&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mk74wq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7gz0ou/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754594214,
                                "media_metadata": {
                                  "qg3ci5wednhf1": {
                                    "status": "valid",
                                    "e": "Image",
                                    "m": "image/png",
                                    "p": [
                                      {
                                        "y": 99,
                                        "x": 108,
                                        "u": "https://preview.redd.it/qg3ci5wednhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f1dc3df8b1ad156a92e4cbd9fcb09f32512656f3"
                                      },
                                      {
                                        "y": 198,
                                        "x": 216,
                                        "u": "https://preview.redd.it/qg3ci5wednhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d96248b141bc2af98baf61a667cd9911875e2c2d"
                                      },
                                      {
                                        "y": 293,
                                        "x": 320,
                                        "u": "https://preview.redd.it/qg3ci5wednhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd272824e8fc7b8b5d4fe929f34107fa9843d719"
                                      },
                                      {
                                        "y": 587,
                                        "x": 640,
                                        "u": "https://preview.redd.it/qg3ci5wednhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ac76480fc925185e22cc27c249148de49ccbe98d"
                                      },
                                      {
                                        "y": 881,
                                        "x": 960,
                                        "u": "https://preview.redd.it/qg3ci5wednhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dae80cede179ba7584c2fecb85265a54ebb64833"
                                      },
                                      {
                                        "y": 991,
                                        "x": 1080,
                                        "u": "https://preview.redd.it/qg3ci5wednhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=74ea6f17a9403484b2b1d75e30668b68a6a254a1"
                                      }
                                    ],
                                    "s": {
                                      "y": 2067,
                                      "x": 2252,
                                      "u": "https://preview.redd.it/qg3ci5wednhf1.png?width=2252&amp;format=png&amp;auto=webp&amp;s=d6eacb1e1f9336b517a3b7190a2703e07962ba79"
                                    },
                                    "id": "qg3ci5wednhf1"
                                  }
                                },
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754594214,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 7
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7gxrak",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "kujetic",
                      "can_mod_post": false,
                      "created_utc": 1754593844,
                      "send_replies": true,
                      "parent_id": "t1_n7gjbtu",
                      "score": 5,
                      "author_fullname": "t2_y30qa",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "what is your hardware?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7gxrak",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;what is your hardware?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7gxrak/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754593844,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7gjbtu",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "mrtime777",
            "can_mod_post": false,
            "created_utc": 1754589704,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 16,
            "author_fullname": "t2_37pn0768",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Many people here can run locally   \nR1 670b, 37b active  \nKimi K2 1t, 32b active  \nQwen3 235b, 22b active",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7gjbtu",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Many people here can run locally&lt;br/&gt;\nR1 670b, 37b active&lt;br/&gt;\nKimi K2 1t, 32b active&lt;br/&gt;\nQwen3 235b, 22b active&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7gjbtu/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754589704,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 16
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7k0pdq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "codegolf-guru",
            "can_mod_post": false,
            "created_utc": 1754633792,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 3,
            "author_fullname": "t2_x1ml507r5",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "if the goal is truly local-first, then comparing Qwen3 30B/3B to massive non-local models doesnâ€™t make much sense for day-to-day use. That said, bigger models are still worth benchmarking against because they show where the quality ceiling currently is. It helps decide if itâ€™s worth upgrading hardware, waiting for distillations, or sticking with what runs well now.\n\nweâ€™ve already seen huge MoE releases like R1, K2, and openPangu get distilled into smaller builds in a matter of weeks. Even if you never plan to run the giants, they often become the source for the next efficient local model. So for me, both conversations matter: pushing what we can run today, and tracking what weâ€™ll be able to run tomorrow.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7k0pdq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;if the goal is truly local-first, then comparing Qwen3 30B/3B to massive non-local models doesnâ€™t make much sense for day-to-day use. That said, bigger models are still worth benchmarking against because they show where the quality ceiling currently is. It helps decide if itâ€™s worth upgrading hardware, waiting for distillations, or sticking with what runs well now.&lt;/p&gt;\n\n&lt;p&gt;weâ€™ve already seen huge MoE releases like R1, K2, and openPangu get distilled into smaller builds in a matter of weeks. Even if you never plan to run the giants, they often become the source for the next efficient local model. So for me, both conversations matter: pushing what we can run today, and tracking what weâ€™ll be able to run tomorrow.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7k0pdq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754633792,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n7ktgpg",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "FullOf_Bad_Ideas",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n7kt0hk",
                                          "score": 1,
                                          "author_fullname": "t2_9s7pmakgx",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Right. In that case you'll probably be better off with AWQ/GPTQ quants and you won't be able to utilize long context anyway. The throughput should be just much higher most likely.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n7ktgpg",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Right. In that case you&amp;#39;ll probably be better off with AWQ/GPTQ quants and you won&amp;#39;t be able to utilize long context anyway. The throughput should be just much higher most likely.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mk74wq",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7ktgpg/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754649753,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754649753,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n7kt0hk",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Weary_Long3409",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7kjko5",
                                "score": 1,
                                "author_fullname": "t2_k7w90vyh8",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "I love exl2, not yet try exl3. But the problem with TabbyAPI is no continuous batching. My workflow is a combination of burst of small parallel request and long context. LMDeploy is crazy fast and capable of continuous batching, better than vLLM but support less quants. But I think I should try TabbyAPI, hope there's some improvement now.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7kt0hk",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I love exl2, not yet try exl3. But the problem with TabbyAPI is no continuous batching. My workflow is a combination of burst of small parallel request and long context. LMDeploy is crazy fast and capable of continuous batching, better than vLLM but support less quants. But I think I should try TabbyAPI, hope there&amp;#39;s some improvement now.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mk74wq",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7kt0hk/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754649525,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754649525,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7kjko5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "FullOf_Bad_Ideas",
                      "can_mod_post": false,
                      "created_utc": 1754644404,
                      "send_replies": true,
                      "parent_id": "t1_n7iwvi3",
                      "score": 1,
                      "author_fullname": "t2_9s7pmakgx",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I think you would be able to  squeeze in even more context with the Coder and EXL3. I think 30B A3B Coder 5bpw and 256k context should be doable with TabbyAPI, not sure about how much the quantized kv cache would affect quality though. Just a food for thought.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7kjko5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think you would be able to  squeeze in even more context with the Coder and EXL3. I think 30B A3B Coder 5bpw and 256k context should be doable with TabbyAPI, not sure about how much the quantized kv cache would affect quality though. Just a food for thought.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7kjko5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754644404,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7iwvi3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Weary_Long3409",
            "can_mod_post": false,
            "created_utc": 1754616736,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 2,
            "author_fullname": "t2_k7w90vyh8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Qwen3-30B-A3B-GPTQ is really a chekpoint and drop in replacement for my daily driver (Qwen3-14B-Instruct-AWQ), because of my only 24GB vram. Trade off quality for context length (49k vs 138k). Also investing a lot of time on prompt engineering, so newer model should passed output consistencies. Other models like Mistral Small, Llama, etc make me have to reenginer the prompts. Thanks to Qwen.\n\nHopefully there's a working GPTQ for Qwen3-30B-A3B-Instruct-2507. Very much appreciation if there's any, I need the instruct version. Seems this version much better than the previous one I'm running. But there are less GPTQ on hf and all of them are not working on LMDeploy.",
            "edited": 1754617374,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7iwvi3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen3-30B-A3B-GPTQ is really a chekpoint and drop in replacement for my daily driver (Qwen3-14B-Instruct-AWQ), because of my only 24GB vram. Trade off quality for context length (49k vs 138k). Also investing a lot of time on prompt engineering, so newer model should passed output consistencies. Other models like Mistral Small, Llama, etc make me have to reenginer the prompts. Thanks to Qwen.&lt;/p&gt;\n\n&lt;p&gt;Hopefully there&amp;#39;s a working GPTQ for Qwen3-30B-A3B-Instruct-2507. Very much appreciation if there&amp;#39;s any, I need the instruct version. Seems this version much better than the previous one I&amp;#39;m running. But there are less GPTQ on hf and all of them are not working on LMDeploy.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7iwvi3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754616736,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7jxrbv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "thebadslime",
            "can_mod_post": false,
            "created_utc": 1754632244,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 2,
            "author_fullname": "t2_i5os0v0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "FOr me I have found that ERNIE 4.5 21BA3B works better than Qwen, qwen get stuck in repetition loops and stuff, ERNIE seems rock solid.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7jxrbv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;FOr me I have found that ERNIE 4.5 21BA3B works better than Qwen, qwen get stuck in repetition loops and stuff, ERNIE seems rock solid.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7jxrbv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754632244,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7l8gtt",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "tmvr",
                      "can_mod_post": false,
                      "created_utc": 1754656085,
                      "send_replies": true,
                      "parent_id": "t1_n7k65sj",
                      "score": 1,
                      "author_fullname": "t2_11qlhv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt;combined with Wikipedia search and a JavaScript sandbox in lmstudio\n\nHow are you doing this in LM Studio?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7l8gtt",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;combined with Wikipedia search and a JavaScript sandbox in lmstudio&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;How are you doing this in LM Studio?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7l8gtt/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754656085,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7l8him",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "tmvr",
                      "can_mod_post": false,
                      "created_utc": 1754656092,
                      "send_replies": true,
                      "parent_id": "t1_n7k65sj",
                      "score": 1,
                      "author_fullname": "t2_11qlhv",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt;combined with Wikipedia search and a JavaScript sandbox in lmstudio\n\nHow are you doing this in LM Studio?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7l8him",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;combined with Wikipedia search and a JavaScript sandbox in lmstudio&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;How are you doing this in LM Studio?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7l8him/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754656092,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7k65sj",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Alarming-Ad8154",
            "can_mod_post": false,
            "created_utc": 1754636729,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 2,
            "author_fullname": "t2_77kmf6kp",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I use Ernie 4.5 21b/3b combined with Wikipedia search and a JavaScript sandbox in lmstudio.m a lot on my 24gb macbook as qwen3 30b/3b was a bit to tight even at low quants. They also have Ernie 4.5 300b/7b which due to its low # active parameter feels way faster then the other large models (but looses some quality).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7k65sj",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I use Ernie 4.5 21b/3b combined with Wikipedia search and a JavaScript sandbox in lmstudio.m a lot on my 24gb macbook as qwen3 30b/3b was a bit to tight even at low quants. They also have Ernie 4.5 300b/7b which due to its low # active parameter feels way faster then the other large models (but looses some quality).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7k65sj/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754636729,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7isbln",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "CheatCodesOfLife",
            "can_mod_post": false,
            "created_utc": 1754615084,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 1,
            "author_fullname": "t2_32el727b",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Non-local models are relevant because they foreshadow what we'll be able to run locally once the Chinese companies distill them for us!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7isbln",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Non-local models are relevant because they foreshadow what we&amp;#39;ll be able to run locally once the Chinese companies distill them for us!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7isbln/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754615084,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7l144b",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Awwtifishal",
            "can_mod_post": false,
            "created_utc": 1754653202,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": 1,
            "author_fullname": "t2_1d96a8k10t",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "r/LocalLLaMA should be about all open weights models. The big ones too: Because even if you can't run it, there's at least a bunch of providers that can run it so you never depend on the whims of one company.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7l144b",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt; should be about all open weights models. The big ones too: Because even if you can&amp;#39;t run it, there&amp;#39;s at least a bunch of providers that can run it so you never depend on the whims of one company.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7l144b/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754653202,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "total_awards_received": 0,
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "ups": -5,
            "removal_reason": null,
            "link_id": "t3_1mk74wq",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7gj81k",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "DELETED",
            "no_follow": true,
            "author": "[deleted]",
            "can_mod_post": false,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": -5,
            "approved_by": null,
            "report_reasons": null,
            "all_awardings": [],
            "subreddit_id": "t5_81eyvm",
            "body": "[deleted]",
            "edited": 1754596498,
            "downs": 0,
            "author_flair_css_class": null,
            "collapsed": true,
            "is_submitter": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;",
            "gildings": {},
            "collapsed_reason": null,
            "associated_award": null,
            "stickied": false,
            "subreddit_type": "public",
            "can_gild": false,
            "top_awarded_type": null,
            "unrepliable_reason": null,
            "author_flair_text_color": "dark",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7gj81k/",
            "num_reports": null,
            "locked": false,
            "name": "t1_n7gj81k",
            "created": 1754589675,
            "subreddit": "LocalLLaMA",
            "author_flair_text": null,
            "treatment_tags": [],
            "created_utc": 1754589675,
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "mod_note": null,
            "distinguished": null
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7iwpfc",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "SAPPHIR3ROS3",
            "can_mod_post": false,
            "created_utc": 1754616674,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": -1,
            "author_fullname": "t2_2vre9dh1",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "A couple of things\n1. There is an abliterated version of gpt-oss 20b already \n2. Even if we are going through a phase where bigger and bigger model are coming out, itâ€™s only because there is no other way against closed source models, just raw strength. After that we will distill them, make them better, rinse and repeat until the models that we can host locally will be comparable to frontier models.\nThe gap started closing with llama 3 405b being comparable to 4o, and now we are getting closer and closer. The distance between gpt 3 and gpt 4 was bigger than the distance between gpt 4 and gpt 5. And we can say the same with models that came out in the last 6 months, hell the last 3 weeks were insane progress for the oss scene",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7iwpfc",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A couple of things\n1. There is an abliterated version of gpt-oss 20b already \n2. Even if we are going through a phase where bigger and bigger model are coming out, itâ€™s only because there is no other way against closed source models, just raw strength. After that we will distill them, make them better, rinse and repeat until the models that we can host locally will be comparable to frontier models.\nThe gap started closing with llama 3 405b being comparable to 4o, and now we are getting closer and closer. The distance between gpt 3 and gpt 4 was bigger than the distance between gpt 4 and gpt 5. And we can say the same with models that came out in the last 6 months, hell the last 3 weeks were insane progress for the oss scene&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7iwpfc/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754616674,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7k1l7w",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "agentcubed",
                      "can_mod_post": false,
                      "created_utc": 1754634269,
                      "send_replies": true,
                      "parent_id": "t1_n7k1812",
                      "score": 3,
                      "author_fullname": "t2_duqfsmw4g",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I do want to see any post here that claims that. 99% are saying they thought it was going to beat Qwen3 235b and were disappointed",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7k1l7w",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I do want to see any post here that claims that. 99% are saying they thought it was going to beat Qwen3 235b and were disappointed&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mk74wq",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7k1l7w/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754634269,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 3
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7k1812",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "relmny",
            "can_mod_post": false,
            "created_utc": 1754634068,
            "send_replies": true,
            "parent_id": "t3_1mk74wq",
            "score": -1,
            "author_fullname": "t2_joxwuyje",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "People were not \"expecting\", (some) people claimed that is the best OW model...",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7k1812",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;People were not &amp;quot;expecting&amp;quot;, (some) people claimed that is the best OW model...&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk74wq/can_we_focus_more_on_local_models_we_were_excited/n7k1812/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754634068,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk74wq",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -1
          }
        }
      ],
      "before": null
    }
  }
]