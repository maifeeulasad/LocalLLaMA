[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": " ( Or... The adventures of a newbie )\n\nToday I learned something really important ‚Äî and honestly, I had no idea how using API-hosted LLMs can quietly become a black hole for your wallet.üí∏üí∞\n\nAt first glance, the pricing seems super appealing. You see those spicy ‚Äúlow‚Äù prices from big US companies ‚Äî something like $0.002 per 1,000 tokens, and you think, \"Wow, that‚Äôs cheap!\"\n\nBut‚Ä¶ let‚Äôs do the math.\n\nYou start using a 128k context model on a platform like OpenRouter, and you don‚Äôt realize that with every new interaction, your entire chat history is being resent to the API. That‚Äôs the only way the model can \"remember\" the conversation. So after just a few minutes, each message you're sending might carry along 10k tokens ‚Äî or even more.\n\nNow imagine you‚Äôre chatting for hours. Every tiny reply ‚Äî even a simple ‚Äúok‚Äù ‚Äî could trigger a payload of 50,000 or 100,000 tokens being sent again and again. It‚Äôs like buying an entire book just to read the next letter.\n\nIn just a few hours, you may have burned through $5 to $10, just for a basic conversation. And now think monthly... or worse ‚Äî imagine you‚Äôre editing a software file with 800 lines of code. Every time you tweak a line and hit send, it could cost you $1 or $2 per second.\n\nI mean... what?!\n\nI now understand the almost desperate effort some people make to run LLMs locally on their own machines ‚Äî because something that looks insanely cheap at first glance‚Ä¶ can turn out to be violently expensive.\n\nThis is insane. Maybe everyone else already knew this ‚Äî but I didn‚Äôt! üòØüòØüòØ\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "The Great Deception of \"Low Prices\" in LLM APIs",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 140,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1meep6o",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.53,
            "author_flair_background_color": null,
            "ups": 2,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_8c7clfk1",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 2,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/KpH7dlNRh78oWPR5CwX_DiS1oipkBRXTYNWHmoAZyyg.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753998846,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;( Or... The adventures of a newbie )&lt;/p&gt;\n\n&lt;p&gt;Today I learned something really important ‚Äî and honestly, I had no idea how using API-hosted LLMs can quietly become a black hole for your wallet.üí∏üí∞&lt;/p&gt;\n\n&lt;p&gt;At first glance, the pricing seems super appealing. You see those spicy ‚Äúlow‚Äù prices from big US companies ‚Äî something like $0.002 per 1,000 tokens, and you think, &amp;quot;Wow, that‚Äôs cheap!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;But‚Ä¶ let‚Äôs do the math.&lt;/p&gt;\n\n&lt;p&gt;You start using a 128k context model on a platform like OpenRouter, and you don‚Äôt realize that with every new interaction, your entire chat history is being resent to the API. That‚Äôs the only way the model can &amp;quot;remember&amp;quot; the conversation. So after just a few minutes, each message you&amp;#39;re sending might carry along 10k tokens ‚Äî or even more.&lt;/p&gt;\n\n&lt;p&gt;Now imagine you‚Äôre chatting for hours. Every tiny reply ‚Äî even a simple ‚Äúok‚Äù ‚Äî could trigger a payload of 50,000 or 100,000 tokens being sent again and again. It‚Äôs like buying an entire book just to read the next letter.&lt;/p&gt;\n\n&lt;p&gt;In just a few hours, you may have burned through $5 to $10, just for a basic conversation. And now think monthly... or worse ‚Äî imagine you‚Äôre editing a software file with 800 lines of code. Every time you tweak a line and hit send, it could cost you $1 or $2 per second.&lt;/p&gt;\n\n&lt;p&gt;I mean... what?!&lt;/p&gt;\n\n&lt;p&gt;I now understand the almost desperate effort some people make to run LLMs locally on their own machines ‚Äî because something that looks insanely cheap at first glance‚Ä¶ can turn out to be violently expensive.&lt;/p&gt;\n\n&lt;p&gt;This is insane. Maybe everyone else already knew this ‚Äî but I didn‚Äôt! üòØüòØüòØ&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/f8vv4t837agf1.png",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/f8vv4t837agf1.png?auto=webp&amp;s=2a5bde2dd3cb61e64af4720e8cc13e534a92116f",
                    "width": 1024,
                    "height": 1024
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/f8vv4t837agf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4a158041f9882499a65c08f11adace0fa76a0f40",
                      "width": 108,
                      "height": 108
                    },
                    {
                      "url": "https://preview.redd.it/f8vv4t837agf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b71e536e993c221a57840d46c0f8345d4fd26f2",
                      "width": 216,
                      "height": 216
                    },
                    {
                      "url": "https://preview.redd.it/f8vv4t837agf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a89d09f3744524462cc6bc4d5c80648aca4f27e9",
                      "width": 320,
                      "height": 320
                    },
                    {
                      "url": "https://preview.redd.it/f8vv4t837agf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b1305c708b1fbe4bb7166cf9808a29640f750a67",
                      "width": 640,
                      "height": 640
                    },
                    {
                      "url": "https://preview.redd.it/f8vv4t837agf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=73ec0bc2072e5f2bc9194e2510d445f7e8673cfb",
                      "width": 960,
                      "height": 960
                    }
                  ],
                  "variants": {},
                  "id": "PQVtbBsS9q88WP67d3L6vyJ8WKHnI51rshmbM64ONSA"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1meep6o",
            "is_robot_indexable": true,
            "num_duplicates": 2,
            "report_reasons": null,
            "author": "Current-Stop7806",
            "discussion_type": null,
            "num_comments": 18,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/",
            "stickied": false,
            "url": "https://i.redd.it/f8vv4t837agf1.png",
            "subreddit_subscribers": 507935,
            "created_utc": 1753998846,
            "num_crossposts": 2,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n69a6qo",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Adventurous_Cable829",
                      "can_mod_post": false,
                      "created_utc": 1754004537,
                      "send_replies": true,
                      "parent_id": "t1_n68vfy2",
                      "score": 4,
                      "author_fullname": "t2_1s6qt9vuuh",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Why are you talking to a robot?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n69a6qo",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why are you talking to a robot?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1meep6o",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n69a6qo/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754004537,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n68xrry",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Current-Stop7806",
                      "can_mod_post": false,
                      "created_utc": 1754000469,
                      "send_replies": true,
                      "parent_id": "t1_n68vfy2",
                      "score": 1,
                      "author_fullname": "t2_8c7clfk1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thank you very much for your insights. It adds a lot of context and justifications for local use of LLMs. Most people ( including me ) were not aware of the prices trap when using external APIs, and the possible solutions, like limiting the context window size on lengthy conversations, or other things that literally \"save money\", or at least slow down the \"unnecessary waste of money\". üôèüí•üëçüí∞",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n68xrry",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you very much for your insights. It adds a lot of context and justifications for local use of LLMs. Most people ( including me ) were not aware of the prices trap when using external APIs, and the possible solutions, like limiting the context window size on lengthy conversations, or other things that literally &amp;quot;save money&amp;quot;, or at least slow down the &amp;quot;unnecessary waste of money&amp;quot;. üôèüí•üëçüí∞&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1meep6o",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n68xrry/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754000469,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n68vfy2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Lissanro",
            "can_mod_post": false,
            "created_utc": 1753999745,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 11,
            "author_fullname": "t2_fpfao9g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "That's one more reason to run locally. In chats, I regularly use prompts 10K-30K in length and do multiple iterations. For agentic use like with Cline, I often notice 30K-80K input tokens, in most cases they are cached so do not slow down much, and if cache and common tensors are on GPUs, prompt processing is fast enough for me. I mostly use DeepSeek R1 671B and Kimi K2 1T, IQ4 quants.\n\nEven though some people say running locally has no savings, this is just not true for me - I for example need my GPUs for many other things from video encoding to Blender rendering, or custom AI classifications tasks, etc. None of that is possible without having GPUs locally, so I still would need to have them. I still need a lot of RAM too for many other tasks I do, even if just a disk cache for quick reprocessing when doing multiple iterations on something without AI. So only electricity cost is of concern, but in my case it is very cheap, so it works out well for me.\n\nOf course, for someone else it could be different - occasional LLM use and living in area with very expensive electricity may make using API more appealing if lack of privacy is acceptable. But in my case, privacy actually matters too - most of projects I work I just have no right to send to a third-party, and I would not want to send my personal stuff to strangers either. Hence why I strongly prefer to running things locally.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n68vfy2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s one more reason to run locally. In chats, I regularly use prompts 10K-30K in length and do multiple iterations. For agentic use like with Cline, I often notice 30K-80K input tokens, in most cases they are cached so do not slow down much, and if cache and common tensors are on GPUs, prompt processing is fast enough for me. I mostly use DeepSeek R1 671B and Kimi K2 1T, IQ4 quants.&lt;/p&gt;\n\n&lt;p&gt;Even though some people say running locally has no savings, this is just not true for me - I for example need my GPUs for many other things from video encoding to Blender rendering, or custom AI classifications tasks, etc. None of that is possible without having GPUs locally, so I still would need to have them. I still need a lot of RAM too for many other tasks I do, even if just a disk cache for quick reprocessing when doing multiple iterations on something without AI. So only electricity cost is of concern, but in my case it is very cheap, so it works out well for me.&lt;/p&gt;\n\n&lt;p&gt;Of course, for someone else it could be different - occasional LLM use and living in area with very expensive electricity may make using API more appealing if lack of privacy is acceptable. But in my case, privacy actually matters too - most of projects I work I just have no right to send to a third-party, and I would not want to send my personal stuff to strangers either. Hence why I strongly prefer to running things locally.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n68vfy2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753999745,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 11
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n68ydzg",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Current-Stop7806",
                      "can_mod_post": false,
                      "created_utc": 1754000663,
                      "send_replies": true,
                      "parent_id": "t1_n68uo0r",
                      "score": 2,
                      "author_fullname": "t2_8c7clfk1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes, I think a fixed monthly subscription independent of the tokens used would be awesome. Like in ChatGPT. I pay $20 a month and talk and work the whole month without ever worry about any limitations.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n68ydzg",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, I think a fixed monthly subscription independent of the tokens used would be awesome. Like in ChatGPT. I pay $20 a month and talk and work the whole month without ever worry about any limitations.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1meep6o",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n68ydzg/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754000663,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n69bc3m",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "maz_net_au",
                      "can_mod_post": false,
                      "created_utc": 1754004926,
                      "send_replies": true,
                      "parent_id": "t1_n68uo0r",
                      "score": 2,
                      "author_fullname": "t2_ejn46",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "There are no \"good deals\", only \"profit opportunities\"",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n69bc3m",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There are no &amp;quot;good deals&amp;quot;, only &amp;quot;profit opportunities&amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1meep6o",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n69bc3m/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754004926,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n68uo0r",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "__JockY__",
            "can_mod_post": false,
            "created_utc": 1753999507,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 6,
            "author_fullname": "t2_qf8h7ka8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This is why the top-tier subscriptions are popular. Fixed cost of $200/mo etc., seems like a good deal. Or it was until the rate limits apparently started  getting onerous.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n68uo0r",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is why the top-tier subscriptions are popular. Fixed cost of $200/mo etc., seems like a good deal. Or it was until the rate limits apparently started  getting onerous.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n68uo0r/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753999507,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n68zskk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Current-Stop7806",
                      "can_mod_post": false,
                      "created_utc": 1754001106,
                      "send_replies": true,
                      "parent_id": "t1_n68wh8z",
                      "score": 1,
                      "author_fullname": "t2_8c7clfk1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "How can I set the context length for API external models using Open webUI ? And you're right,  when using external APIs, we need to constantly track the context window length to not have \"pocket surprises\". That's why I'm changing to my local rig as soon as possible. Thanks in advance. üôèüí•",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n68zskk",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How can I set the context length for API external models using Open webUI ? And you&amp;#39;re right,  when using external APIs, we need to constantly track the context window length to not have &amp;quot;pocket surprises&amp;quot;. That&amp;#39;s why I&amp;#39;m changing to my local rig as soon as possible. Thanks in advance. üôèüí•&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1meep6o",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n68zskk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754001106,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n68wh8z",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "wolttam",
            "can_mod_post": false,
            "created_utc": 1754000065,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 3,
            "author_fullname": "t2_dc7q0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "As a GPU poor person who's been using LLMs via APIs extensively over the last 2 years, and hasn't bought into vibe coding... meh. I've spent maybe $150 in 2 years. Being aware of how they work (i.e. being aware of my context at all times) helps.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n68wh8z",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;As a GPU poor person who&amp;#39;s been using LLMs via APIs extensively over the last 2 years, and hasn&amp;#39;t bought into vibe coding... meh. I&amp;#39;ve spent maybe $150 in 2 years. Being aware of how they work (i.e. being aware of my context at all times) helps.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n68wh8z/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754000065,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n690jhl",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Current-Stop7806",
                      "can_mod_post": false,
                      "created_utc": 1754001348,
                      "send_replies": true,
                      "parent_id": "t1_n68y4tr",
                      "score": 1,
                      "author_fullname": "t2_8c7clfk1",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yes, and you need to pay close attention to the real prices of a model. Not always the card price is correct, it depends on the external model provider. And the API provider often change the provider depending on the latency to ensure the best experience, so most of the time, the prices are 3 ou 4 times more. Wow üí•üí∞",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n690jhl",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, and you need to pay close attention to the real prices of a model. Not always the card price is correct, it depends on the external model provider. And the API provider often change the provider depending on the latency to ensure the best experience, so most of the time, the prices are 3 ou 4 times more. Wow üí•üí∞&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1meep6o",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n690jhl/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754001348,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n68y4tr",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Tyme4Trouble",
            "can_mod_post": false,
            "created_utc": 1754000583,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 3,
            "author_fullname": "t2_973amyap",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yep this is why you need to read the API pricing closely. Many model APIs have a different rate for cached tokens because of how chatbots function.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n68y4tr",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yep this is why you need to read the API pricing closely. Many model APIs have a different rate for cached tokens because of how chatbots function.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n68y4tr/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754000583,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n693una",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "-dysangel-",
            "can_mod_post": false,
            "created_utc": 1754002430,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 3,
            "author_fullname": "t2_12ggykute6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hence why we are here in local llama. As someone else pointed out, Claude Code is a good to ok deal just now, but I still ultimately want to be serving most or all of my own inference",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n693una",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hence why we are here in local llama. As someone else pointed out, Claude Code is a good to ok deal just now, but I still ultimately want to be serving most or all of my own inference&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n693una/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754002430,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6958ru",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "notdba",
            "can_mod_post": false,
            "created_utc": 1754002889,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 3,
            "author_fullname": "t2_4aai0pnm",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "\\&gt; Every tiny reply ‚Äî even a simple ‚Äúok‚Äù ‚Äî could trigger a payload of 50,000 or 100,000 tokens being sent again and again. It‚Äôs like buying an entire book just to read the next letter.\n\nExactly this. The situation is a lot worse with coding agent. Imagine you are at 100k context, and the model wants to make 10 tool calls (grep, find, etc). For simplicity, let's say each tool call generates 100 output tokens and adds 900 input tokens. How much do you pay?\n\n* 1st tool call - 900 input, 100 output, 100k cache read, 1000 cache write\n* 2nd tool call - 900 input, 100 output, 101k cache read, 1000 cache write\n* 3rd tool call - 900 input, 100 output, 102k cache read, 1000 cache write\n* 4th tool call - 900 input, 100 output, 103k cache read, 1000 cache write\n* 5th tool call - 900 input, 100 output, 104k cache read, 1000 cache write\n* 6th tool call - 900 input, 100 output, 105k cache read, 1000 cache write\n* 7th tool call - 900 input, 100 output, 106k cache read, 1000 cache write\n* 8th tool call - 900 input, 100 output, 107k cache read, 1000 cache write\n* 9th tool call - 900 input, 100 output, 108k cache read, 1000 cache write\n* 10th tool call - 900 input, 100 output, 109k cache read, 1000 cache write\n\nIn total, based on Anthropic API pricing, that's 9000 input for $0.027, 1000 output for $0.015, 1045000 cache read for $0.3135, and 10000 cache write for $0.0375. That's 89% for cache read/write, and it all happens in seconds.\n\nEDIT: flip input/output for tool calls",
            "edited": 1754004875,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6958ru",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;gt; Every tiny reply ‚Äî even a simple ‚Äúok‚Äù ‚Äî could trigger a payload of 50,000 or 100,000 tokens being sent again and again. It‚Äôs like buying an entire book just to read the next letter.&lt;/p&gt;\n\n&lt;p&gt;Exactly this. The situation is a lot worse with coding agent. Imagine you are at 100k context, and the model wants to make 10 tool calls (grep, find, etc). For simplicity, let&amp;#39;s say each tool call generates 100 output tokens and adds 900 input tokens. How much do you pay?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;1st tool call - 900 input, 100 output, 100k cache read, 1000 cache write&lt;/li&gt;\n&lt;li&gt;2nd tool call - 900 input, 100 output, 101k cache read, 1000 cache write&lt;/li&gt;\n&lt;li&gt;3rd tool call - 900 input, 100 output, 102k cache read, 1000 cache write&lt;/li&gt;\n&lt;li&gt;4th tool call - 900 input, 100 output, 103k cache read, 1000 cache write&lt;/li&gt;\n&lt;li&gt;5th tool call - 900 input, 100 output, 104k cache read, 1000 cache write&lt;/li&gt;\n&lt;li&gt;6th tool call - 900 input, 100 output, 105k cache read, 1000 cache write&lt;/li&gt;\n&lt;li&gt;7th tool call - 900 input, 100 output, 106k cache read, 1000 cache write&lt;/li&gt;\n&lt;li&gt;8th tool call - 900 input, 100 output, 107k cache read, 1000 cache write&lt;/li&gt;\n&lt;li&gt;9th tool call - 900 input, 100 output, 108k cache read, 1000 cache write&lt;/li&gt;\n&lt;li&gt;10th tool call - 900 input, 100 output, 109k cache read, 1000 cache write&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In total, based on Anthropic API pricing, that&amp;#39;s 9000 input for $0.027, 1000 output for $0.015, 1045000 cache read for $0.3135, and 10000 cache write for $0.0375. That&amp;#39;s 89% for cache read/write, and it all happens in seconds.&lt;/p&gt;\n\n&lt;p&gt;EDIT: flip input/output for tool calls&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n6958ru/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754002889,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n69h0yw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Chaosdrifer",
            "can_mod_post": false,
            "created_utc": 1754006884,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 2,
            "author_fullname": "t2_fdg17agw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "$0.002 for 1000 token seems very expensive ? deepseek only charges $0.035 per 1 millon tokens.\nhttps://api-docs.deepseek.com/quick_start/pricing/\n\nfor qwen3 coder on openrouter, it is just $0.03 for 1 million\nhttps://openrouter.ai/qwen/qwen3-coder",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n69h0yw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;$0.002 for 1000 token seems very expensive ? deepseek only charges $0.035 per 1 millon tokens.\n&lt;a href=\"https://api-docs.deepseek.com/quick_start/pricing/\"&gt;https://api-docs.deepseek.com/quick_start/pricing/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;for qwen3 coder on openrouter, it is just $0.03 for 1 million\n&lt;a href=\"https://openrouter.ai/qwen/qwen3-coder\"&gt;https://openrouter.ai/qwen/qwen3-coder&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n69h0yw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754006884,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n692bd4",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "tempest-reach",
            "can_mod_post": false,
            "created_utc": 1754001927,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 3,
            "author_fullname": "t2_nirstqfy",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "this was ai written.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n692bd4",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;this was ai written.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n692bd4/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754001927,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n69b568",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "a_beautiful_rhind",
                      "can_mod_post": false,
                      "created_utc": 1754004860,
                      "send_replies": true,
                      "parent_id": "t1_n696bnf",
                      "score": 2,
                      "author_fullname": "t2_h5utwre7",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "My long convos do alright but they're nowhere near 100k. I'm lucky if I break 30k. Main thing that eats ctx are images and code.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n69b568",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My long convos do alright but they&amp;#39;re nowhere near 100k. I&amp;#39;m lucky if I break 30k. Main thing that eats ctx are images and code.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1meep6o",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n69b568/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754004860,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n696bnf",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Virtamancer",
            "can_mod_post": false,
            "created_utc": 1754003253,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 2,
            "author_fullname": "t2_kvniqgt7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "&gt; Maybe everyone already knew this\n\nThe thing everyone should know is that you aren‚Äôt supposed to carry on long conversations.\n\nFirst, LLM intelligence drops off a cliff sooner than you think.\n\nSecond, every single token that isn‚Äôt directly pertinent to your current prompt is a distraction and makes them even dumber than just the length of the conversation alone would suggest.\n\nIf you ABSOLUTELY MUST have a lengthy conversation, be aware that it comes at a dollar cost and at the cost of intelligence.\n\nFor all other scenarios, you‚Äôre supposed to start a new chat for every new prompt or, if some of the context is relevant, roll it into a concise new draft using a text editor then start a fresh chat with just the relevant bits of the old context.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n696bnf",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Maybe everyone already knew this&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The thing everyone should know is that you aren‚Äôt supposed to carry on long conversations.&lt;/p&gt;\n\n&lt;p&gt;First, LLM intelligence drops off a cliff sooner than you think.&lt;/p&gt;\n\n&lt;p&gt;Second, every single token that isn‚Äôt directly pertinent to your current prompt is a distraction and makes them even dumber than just the length of the conversation alone would suggest.&lt;/p&gt;\n\n&lt;p&gt;If you ABSOLUTELY MUST have a lengthy conversation, be aware that it comes at a dollar cost and at the cost of intelligence.&lt;/p&gt;\n\n&lt;p&gt;For all other scenarios, you‚Äôre supposed to start a new chat for every new prompt or, if some of the context is relevant, roll it into a concise new draft using a text editor then start a fresh chat with just the relevant bits of the old context.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n696bnf/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754003253,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n69elco",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Otherwise-Variety674",
            "can_mod_post": false,
            "created_utc": 1754006040,
            "send_replies": true,
            "parent_id": "t3_1meep6o",
            "score": 1,
            "author_fullname": "t2_9tl69pwn",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yes, because of online api cost, i did the following move and never looked back (all with 7900xtx):\n1. Dalle image api to local stable diffusion api\n2. ChatGpt Api to local llm api\n3. Online Google tts/edge tts api to local kokoro api",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n69elco",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes, because of online api cost, i did the following move and never looked back (all with 7900xtx):\n1. Dalle image api to local stable diffusion api\n2. ChatGpt Api to local llm api\n3. Online Google tts/edge tts api to local kokoro api&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1meep6o/the_great_deception_of_low_prices_in_llm_apis/n69elco/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754006040,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1meep6o",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]