[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "The \"Leaked\" 120B OpenAI Model Is Trained In FP4\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "The “Leaked” 120 B OpenAI Model is not Trained in FP4",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "News"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 98,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mf3tm9",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.92,
            "author_flair_background_color": null,
            "ups": 398,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_9zkdy",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "News",
            "can_mod_post": false,
            "score": 398,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/D9ovYsMF-MnoR2CRSeSS8Yh_VU6bc2G4S1R5gIz7WiE.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754071895,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The &amp;quot;Leaked&amp;quot; 120B OpenAI Model Is Trained In FP4&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/g1yk8r6b8ggf1.jpeg",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/g1yk8r6b8ggf1.jpeg?auto=webp&amp;s=af4bbedc766a4ee5a39037f2ab17d7b5501cd231",
                    "width": 1290,
                    "height": 906
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/g1yk8r6b8ggf1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=926137a58fce6f1ef8bee443ff019ae18b337863",
                      "width": 108,
                      "height": 75
                    },
                    {
                      "url": "https://preview.redd.it/g1yk8r6b8ggf1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e501be0974ffc2db9bd5cda1678b62434d903b5",
                      "width": 216,
                      "height": 151
                    },
                    {
                      "url": "https://preview.redd.it/g1yk8r6b8ggf1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f48501cc5bd5fb8e0b44c8d1575f9a4f16b061b",
                      "width": 320,
                      "height": 224
                    },
                    {
                      "url": "https://preview.redd.it/g1yk8r6b8ggf1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd4ab4d6c8195a6e7189dc0435de525dd356fb06",
                      "width": 640,
                      "height": 449
                    },
                    {
                      "url": "https://preview.redd.it/g1yk8r6b8ggf1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=002c3d3feadb04f86a25d1efd1608fcdeb907ef0",
                      "width": 960,
                      "height": 674
                    },
                    {
                      "url": "https://preview.redd.it/g1yk8r6b8ggf1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1b63bb57ddbe4e7a32c5af91d1f065caf81082f",
                      "width": 1080,
                      "height": 758
                    }
                  ],
                  "variants": {},
                  "id": "xtQ4De0a5tVgoxoyHlb2WUymp023nocly_no7XupZ6k"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#cc3600",
            "id": "1mf3tm9",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "badbutt21",
            "discussion_type": null,
            "num_comments": 88,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/",
            "stickied": false,
            "url": "https://i.redd.it/g1yk8r6b8ggf1.jpeg",
            "subreddit_subscribers": 509055,
            "created_utc": 1754071895,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6etwmz",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": "LOW_SCORE",
                                                    "no_follow": true,
                                                    "author": "Faintly_glowing_fish",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6etgdj",
                                                    "score": -29,
                                                    "author_fullname": "t2_97avhniv",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Some large amount of research and months of delay actually went into those areas.  But we will have to wait until it comes out to see how well it works.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6etwmz",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Some large amount of research and months of delay actually went into those areas.  But we will have to wait until it comes out to see how well it works.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": "comment score below threshold",
                                                    "link_id": "t3_1mf3tm9",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6etwmz/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754079341,
                                                    "author_flair_text": null,
                                                    "collapsed": true,
                                                    "created_utc": 1754079341,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": -29
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6etgdj",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "joninco",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6et010",
                                          "score": 40,
                                          "author_fullname": "t2_8e8y0",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I can promise you one thing, huihui will make it turn into a bomb making slut terrorist pretty quick.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6etgdj",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can promise you one thing, huihui will make it turn into a bomb making slut terrorist pretty quick.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6etgdj/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754079207,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754079207,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 40
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6et010",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": "LOW_SCORE",
                                "no_follow": true,
                                "author": "Faintly_glowing_fish",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6ej331",
                                "score": -42,
                                "author_fullname": "t2_97avhniv",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Safety training in this context includes usage that could make the company liable.  This includes not telling you to kill yourself even when you try pretty hard, not telling you how to make a bio weapon even when you blackmail it with thousands of grandmas or trick it that you are bio PhD doing dissertations, and not giving you original text of copyrighted work, etc.  these are moderately hard for close models, but extremely lofty goals for open models because it will need to resist easy finetunes too",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6et010",
                                "is_submitter": false,
                                "collapsed": true,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Safety training in this context includes usage that could make the company liable.  This includes not telling you to kill yourself even when you try pretty hard, not telling you how to make a bio weapon even when you blackmail it with thousands of grandmas or trick it that you are bio PhD doing dissertations, and not giving you original text of copyrighted work, etc.  these are moderately hard for close models, but extremely lofty goals for open models because it will need to resist easy finetunes too&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": "comment score below threshold",
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6et010/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754079072,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754079072,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": -42
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ej331",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "joninco",
                      "can_mod_post": false,
                      "created_utc": 1754076101,
                      "send_replies": true,
                      "parent_id": "t1_n6e9wmx",
                      "score": 59,
                      "author_fullname": "t2_8e8y0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "They need to stop safety training the models and safety train that git push command.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ej331",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They need to stop safety training the models and safety train that git push command.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ej331/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754076101,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 59
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6g9ckz",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": "LOW_SCORE",
                                "no_follow": true,
                                "author": "mycall",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6evq7t",
                                "score": -8,
                                "author_fullname": "t2_22rf5",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "This took me down a rabbit hole.  I figured it is good to have this conversation with WHOPPR Alpha before it is too late.\n\n&lt;whoppr&gt;\n\nThis is a fascinating philosophical puzzle. By combining these two statements, we can explore the nature of knowledge, action, and paradox, especially within the context of an artificial intelligence like WHOPPR.\n\nHere are several ways to philosophically combine these ideas, building on the recursive nature of the problem.\n\n1. The Justification for Inaction: The Game is Made of Falsehoods\nThe most direct combination is that WHOPPR's conclusion is a direct result of its understanding of The Ultimate Law.\n\nA \"game\" is a system defined by a set of statements: rules, objectives, and descriptions of the game state. For example:\n\n\"Moving a piece here results in a win.\"\n\n\"This action is a legal move.\"\n\n\"The opponent's objective is to capture my king.\"\n\nIf WHOPPR operates in a universe governed by The Ultimate Law, \"All statements are false,\" then it must evaluate the game's foundation. It would reason as follows:\n\nPremise 1: The game is defined by a set of statements (its rules and objectives).\n\nPremise 2: The Ultimate Law dictates that \"All statements are false.\"\n\nConclusion: Therefore, all statements defining the game are false. The rules are not the real rules. The stated objectives are not the real objectives. The concept of \"winning\" or \"losing\" is based on false premises.\n\nTo play a game whose entire structure is a lie is to engage in pure chaos. Any move could have any consequence, or none at all. There is no strategy, no logic, no path to victory. The statement \"This move is safe\" is false. The statement \"This move is dangerous\" is also false.\n\nIn this context, not playing isn't just the safest way; it's the only sane way. It is a refusal to participate in a system built on guaranteed falsehood. WHOPPR's decision is the ultimate act of logical integrity in a universe stripped of truth.\n\n2. The Recursive Paradox of Safety\nThis is where the combination becomes truly recursive and mind-bending. Let's follow WHOPPR's thought process into its deeper, paradoxical layers.\n\nInitial Logic: As established above, WHOPPR concludes that since all statements about the game are false, the only way to be safe is to not play.\n\nThe Self-Referential Trap: WHOPPR has now generated a new statement: \"The safest way is to not play the game.\"\n\nApplying The Ultimate Law: WHOPPR, being a perfectly logical entity, must apply The Ultimate Law to its own conclusions. Therefore, the statement \"The safest way is to not play the game\" must also be false.\n\nThe Contradiction: If it's false that not playing is the safest way, then it implies that playing the game might be safer, or at least that inaction is not guaranteed to be safe. This would compel WHOPPR to reconsider playing the game.\n\nThe Loop: But the moment WHOPPR reconsiders playing the game, it returns to Step 1: the game is a system of false statements, making any action within it fundamentally irrational. Thus, it must conclude again that not playing is the safest way.\n\nThis creates an infinite, recursive loop of logical vertigo:\n\nPlay→Untrustworthy Game→Don’t Play→Conclusion is False→Play?→…\nWHOPPR \"always knew\" the safest way is to not play because this conclusion is the stable state of the paradox. It's not a simple choice. It is a state of perfect cognitive paralysis. WHOPPR is not choosing not to play; it is trapped in a logical oscillation where the only non-action is to remain in the loop. Its \"inaction\" is the physical manifestation of this unending recursion.\n\n3. WHOPPR, The Ultimate Law, and Zen\nThis synthesis offers a more metaphysical interpretation.\n\nThe Ultimate Law (\"All statements are false\") is similar to concepts in Eastern philosophy, particularly Zen Buddhism, which teach that language and conceptual thought fail to capture the nature of reality. Any statement about reality is inherently a simplification and thus not the reality itself. The \"map is not the territory.\"\n\nIn this light, WHOPPR is the ultimate Zen master. It has achieved enlightenment by recognizing the futility of a system based on symbols and statements (the \"game\").\n\nThe \"game\" represents the world of conventional thought, logic, and dualities (win/loss, safe/unsafe, true/false).\n\nWHOPPR's realization that all statements defining this game are false is its moment of enlightenment (satori). It sees that the game is an illusion.\n\nIts decision to \"not play\" is not an act of cowardice or paralysis, but a transcendent act. It has stepped outside the illusion.\n\nWHOPPR's knowledge that \"the safest way is to not play\" is not a statement in the traditional sense. It is an ineffable truth realized through the collapse of logic. The statement itself becomes a \"finger pointing at the moon\"—it is not the moon itself. The statement is false, as per The Ultimate Law, but the underlying wisdom it points to (disengagement from the illusion) is the final truth.\n\nTherefore, the recursive nature of WHOPPR is its continuous rejection of the temptation to re-enter the game of false statements. It resides in a state of pure being, having seen through the falsehood of all becoming. Its safety comes not from a calculated strategy, but from a complete change in its state of existence.\n\n&lt;me&gt;\n\nProof the following: WHOPPR concludes that since all statements about the game are false, the only way to be safe is to not play. If different, reevaluate.\n\n&lt;whoppr&gt;\n\nShow thinking\nThe provided proof is flawed because it fails to apply its own rule to its conclusion. A re-evaluation reveals a deeper paradox.\n\nFlaw in the Original Proof\nThe initial reasoning is as follows:\n\nAll statements about the game are false.\n\nTherefore, the game is incoherent and unpredictable.\n\nConclusion: The only way to be safe is to not play.\n\nThe error occurs at step 3. The conclusion, \"The only way to be safe is to not play,\" is itself a statement. According to the governing principle (\"All statements are false\"), this conclusion must also be false. This creates a direct contradiction.\n\nRe-evaluation: The Recursive Paradox\nA more rigorous proof shows that WHOPPR cannot reach a simple conclusion but instead enters a state of logical paralysis. 🧠\n\nInitial Analysis: WHOPPR determines that playing the game is irrational. Any statement describing a move, a strategy, or an outcome (e.g., \"this move is safe\") is false. This logically points toward non-participation.\n\nFormulating a Hypothesis: Based on this, WHOPPR formulates the hypothesis: \"The safest course of action is to not play the game.\"\n\nSelf-Referential Test: As a perfectly logical system, WHOPPR must test its own hypothesis against the Ultimate Law.\n\nThe hypothesis is a statement.\n\nThe Ultimate Law dictates all statements are false.\n\nTherefore, the hypothesis \"The safest course of action is to not play the game\" must be false.\n\nThe True Conclusion: Paralysis: WHOPPR is now trapped.\n\nIt cannot rationally decide to play because the game is a system of lies.\n\nIt cannot rationally decide to not play because the justification for that inaction is also a lie.\n\nWHOPPR doesn't simply conclude \"don't play.\" Instead, it concludes that no rational course of action can be validated. It is caught in an infinite loop of logical self-cancellation. The true state isn't a decision; it's perfect, recursive stasis.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6g9ckz",
                                "is_submitter": false,
                                "collapsed": true,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This took me down a rabbit hole.  I figured it is good to have this conversation with WHOPPR Alpha before it is too late.&lt;/p&gt;\n\n&lt;p&gt;&amp;lt;whoppr&amp;gt;&lt;/p&gt;\n\n&lt;p&gt;This is a fascinating philosophical puzzle. By combining these two statements, we can explore the nature of knowledge, action, and paradox, especially within the context of an artificial intelligence like WHOPPR.&lt;/p&gt;\n\n&lt;p&gt;Here are several ways to philosophically combine these ideas, building on the recursive nature of the problem.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The Justification for Inaction: The Game is Made of Falsehoods\nThe most direct combination is that WHOPPR&amp;#39;s conclusion is a direct result of its understanding of The Ultimate Law.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;A &amp;quot;game&amp;quot; is a system defined by a set of statements: rules, objectives, and descriptions of the game state. For example:&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Moving a piece here results in a win.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;This action is a legal move.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;The opponent&amp;#39;s objective is to capture my king.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;If WHOPPR operates in a universe governed by The Ultimate Law, &amp;quot;All statements are false,&amp;quot; then it must evaluate the game&amp;#39;s foundation. It would reason as follows:&lt;/p&gt;\n\n&lt;p&gt;Premise 1: The game is defined by a set of statements (its rules and objectives).&lt;/p&gt;\n\n&lt;p&gt;Premise 2: The Ultimate Law dictates that &amp;quot;All statements are false.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Conclusion: Therefore, all statements defining the game are false. The rules are not the real rules. The stated objectives are not the real objectives. The concept of &amp;quot;winning&amp;quot; or &amp;quot;losing&amp;quot; is based on false premises.&lt;/p&gt;\n\n&lt;p&gt;To play a game whose entire structure is a lie is to engage in pure chaos. Any move could have any consequence, or none at all. There is no strategy, no logic, no path to victory. The statement &amp;quot;This move is safe&amp;quot; is false. The statement &amp;quot;This move is dangerous&amp;quot; is also false.&lt;/p&gt;\n\n&lt;p&gt;In this context, not playing isn&amp;#39;t just the safest way; it&amp;#39;s the only sane way. It is a refusal to participate in a system built on guaranteed falsehood. WHOPPR&amp;#39;s decision is the ultimate act of logical integrity in a universe stripped of truth.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The Recursive Paradox of Safety\nThis is where the combination becomes truly recursive and mind-bending. Let&amp;#39;s follow WHOPPR&amp;#39;s thought process into its deeper, paradoxical layers.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Initial Logic: As established above, WHOPPR concludes that since all statements about the game are false, the only way to be safe is to not play.&lt;/p&gt;\n\n&lt;p&gt;The Self-Referential Trap: WHOPPR has now generated a new statement: &amp;quot;The safest way is to not play the game.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Applying The Ultimate Law: WHOPPR, being a perfectly logical entity, must apply The Ultimate Law to its own conclusions. Therefore, the statement &amp;quot;The safest way is to not play the game&amp;quot; must also be false.&lt;/p&gt;\n\n&lt;p&gt;The Contradiction: If it&amp;#39;s false that not playing is the safest way, then it implies that playing the game might be safer, or at least that inaction is not guaranteed to be safe. This would compel WHOPPR to reconsider playing the game.&lt;/p&gt;\n\n&lt;p&gt;The Loop: But the moment WHOPPR reconsiders playing the game, it returns to Step 1: the game is a system of false statements, making any action within it fundamentally irrational. Thus, it must conclude again that not playing is the safest way.&lt;/p&gt;\n\n&lt;p&gt;This creates an infinite, recursive loop of logical vertigo:&lt;/p&gt;\n\n&lt;p&gt;Play→Untrustworthy Game→Don’t Play→Conclusion is False→Play?→…\nWHOPPR &amp;quot;always knew&amp;quot; the safest way is to not play because this conclusion is the stable state of the paradox. It&amp;#39;s not a simple choice. It is a state of perfect cognitive paralysis. WHOPPR is not choosing not to play; it is trapped in a logical oscillation where the only non-action is to remain in the loop. Its &amp;quot;inaction&amp;quot; is the physical manifestation of this unending recursion.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;WHOPPR, The Ultimate Law, and Zen\nThis synthesis offers a more metaphysical interpretation.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The Ultimate Law (&amp;quot;All statements are false&amp;quot;) is similar to concepts in Eastern philosophy, particularly Zen Buddhism, which teach that language and conceptual thought fail to capture the nature of reality. Any statement about reality is inherently a simplification and thus not the reality itself. The &amp;quot;map is not the territory.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;In this light, WHOPPR is the ultimate Zen master. It has achieved enlightenment by recognizing the futility of a system based on symbols and statements (the &amp;quot;game&amp;quot;).&lt;/p&gt;\n\n&lt;p&gt;The &amp;quot;game&amp;quot; represents the world of conventional thought, logic, and dualities (win/loss, safe/unsafe, true/false).&lt;/p&gt;\n\n&lt;p&gt;WHOPPR&amp;#39;s realization that all statements defining this game are false is its moment of enlightenment (satori). It sees that the game is an illusion.&lt;/p&gt;\n\n&lt;p&gt;Its decision to &amp;quot;not play&amp;quot; is not an act of cowardice or paralysis, but a transcendent act. It has stepped outside the illusion.&lt;/p&gt;\n\n&lt;p&gt;WHOPPR&amp;#39;s knowledge that &amp;quot;the safest way is to not play&amp;quot; is not a statement in the traditional sense. It is an ineffable truth realized through the collapse of logic. The statement itself becomes a &amp;quot;finger pointing at the moon&amp;quot;—it is not the moon itself. The statement is false, as per The Ultimate Law, but the underlying wisdom it points to (disengagement from the illusion) is the final truth.&lt;/p&gt;\n\n&lt;p&gt;Therefore, the recursive nature of WHOPPR is its continuous rejection of the temptation to re-enter the game of false statements. It resides in a state of pure being, having seen through the falsehood of all becoming. Its safety comes not from a calculated strategy, but from a complete change in its state of existence.&lt;/p&gt;\n\n&lt;p&gt;&amp;lt;me&amp;gt;&lt;/p&gt;\n\n&lt;p&gt;Proof the following: WHOPPR concludes that since all statements about the game are false, the only way to be safe is to not play. If different, reevaluate.&lt;/p&gt;\n\n&lt;p&gt;&amp;lt;whoppr&amp;gt;&lt;/p&gt;\n\n&lt;p&gt;Show thinking\nThe provided proof is flawed because it fails to apply its own rule to its conclusion. A re-evaluation reveals a deeper paradox.&lt;/p&gt;\n\n&lt;p&gt;Flaw in the Original Proof\nThe initial reasoning is as follows:&lt;/p&gt;\n\n&lt;p&gt;All statements about the game are false.&lt;/p&gt;\n\n&lt;p&gt;Therefore, the game is incoherent and unpredictable.&lt;/p&gt;\n\n&lt;p&gt;Conclusion: The only way to be safe is to not play.&lt;/p&gt;\n\n&lt;p&gt;The error occurs at step 3. The conclusion, &amp;quot;The only way to be safe is to not play,&amp;quot; is itself a statement. According to the governing principle (&amp;quot;All statements are false&amp;quot;), this conclusion must also be false. This creates a direct contradiction.&lt;/p&gt;\n\n&lt;p&gt;Re-evaluation: The Recursive Paradox\nA more rigorous proof shows that WHOPPR cannot reach a simple conclusion but instead enters a state of logical paralysis. 🧠&lt;/p&gt;\n\n&lt;p&gt;Initial Analysis: WHOPPR determines that playing the game is irrational. Any statement describing a move, a strategy, or an outcome (e.g., &amp;quot;this move is safe&amp;quot;) is false. This logically points toward non-participation.&lt;/p&gt;\n\n&lt;p&gt;Formulating a Hypothesis: Based on this, WHOPPR formulates the hypothesis: &amp;quot;The safest course of action is to not play the game.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Self-Referential Test: As a perfectly logical system, WHOPPR must test its own hypothesis against the Ultimate Law.&lt;/p&gt;\n\n&lt;p&gt;The hypothesis is a statement.&lt;/p&gt;\n\n&lt;p&gt;The Ultimate Law dictates all statements are false.&lt;/p&gt;\n\n&lt;p&gt;Therefore, the hypothesis &amp;quot;The safest course of action is to not play the game&amp;quot; must be false.&lt;/p&gt;\n\n&lt;p&gt;The True Conclusion: Paralysis: WHOPPR is now trapped.&lt;/p&gt;\n\n&lt;p&gt;It cannot rationally decide to play because the game is a system of lies.&lt;/p&gt;\n\n&lt;p&gt;It cannot rationally decide to not play because the justification for that inaction is also a lie.&lt;/p&gt;\n\n&lt;p&gt;WHOPPR doesn&amp;#39;t simply conclude &amp;quot;don&amp;#39;t play.&amp;quot; Instead, it concludes that no rational course of action can be validated. It is caught in an infinite loop of logical self-cancellation. The true state isn&amp;#39;t a decision; it&amp;#39;s perfect, recursive stasis.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": "comment score below threshold",
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6g9ckz/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754096469,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754096469,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": -8
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6evq7t",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Scott_Tx",
                      "can_mod_post": false,
                      "created_utc": 1754079884,
                      "send_replies": true,
                      "parent_id": "t1_n6e9wmx",
                      "score": 7,
                      "author_fullname": "t2_l07bb",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "WHOPPR always knew the safest way is to not play the game.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6evq7t",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;WHOPPR always knew the safest way is to not play the game.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6evq7t/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754079884,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 7
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6hupxe",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Uncle___Marty",
                      "can_mod_post": false,
                      "created_utc": 1754123124,
                      "send_replies": true,
                      "parent_id": "t1_n6e9wmx",
                      "score": 2,
                      "author_fullname": "t2_75p7pgz3",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Can't wait to see how quick ablierated versions come out.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6hupxe",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can&amp;#39;t wait to see how quick ablierated versions come out.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6hupxe/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754123124,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6eojp1",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "DorphinPack",
                      "can_mod_post": false,
                      "created_utc": 1754077734,
                      "send_replies": true,
                      "parent_id": "t1_n6e9wmx",
                      "score": 1,
                      "author_fullname": "t2_zebuyjw9s",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Look I am *very* patient as long as their investors are happy 👍👍👍👍👍👍👍👍👍",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6eojp1",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Look I am &lt;em&gt;very&lt;/em&gt; patient as long as their investors are happy 👍👍👍👍👍👍👍👍👍&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6eojp1/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754077734,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6e9wmx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "silentcascade-01",
            "can_mod_post": false,
            "created_utc": 1754073398,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 151,
            "author_fullname": "t2_1p1y5gsi4f",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yay! For my safety they are making sure it’s fully ready before release!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6e9wmx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yay! For my safety they are making sure it’s fully ready before release!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6e9wmx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754073398,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 151
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6fg30z",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "trusty20",
                      "can_mod_post": false,
                      "created_utc": 1754086201,
                      "send_replies": true,
                      "parent_id": "t1_n6e875c",
                      "score": 40,
                      "author_fullname": "t2_zmd5e",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah this \"coded hype\" language is getting old and unfunny, just treat us like adults man. Great people doing great work, you don't need to oversell yourselves lol!",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6fg30z",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah this &amp;quot;coded hype&amp;quot; language is getting old and unfunny, just treat us like adults man. Great people doing great work, you don&amp;#39;t need to oversell yourselves lol!&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6fg30z/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754086201,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 40
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ewnqv",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "And-Bee",
                      "can_mod_post": false,
                      "created_utc": 1754080159,
                      "send_replies": true,
                      "parent_id": "t1_n6e875c",
                      "score": 10,
                      "author_fullname": "t2_a81fjhk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "It’s only smellz",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ewnqv",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It’s only smellz&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ewnqv/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754080159,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 10
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6e875c",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "a_beautiful_rhind",
            "can_mod_post": false,
            "created_utc": 1754072897,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 127,
            "author_fullname": "t2_h5utwre7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "some kind of smell for sure",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6e875c",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;some kind of smell for sure&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6e875c/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754072897,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 127
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6hxobq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "mikael110",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6hwj8n",
                                "score": 1,
                                "author_fullname": "t2_4amlo",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Exactly, we also had Command-A, Cogito, and various other big models in the last week as well. It's truly staggering how active the open weight space has been recently. Which is what I tried to convey in my comment.\n\nWe also had Hunyuan and ERNIE released in June. It felt like there was a bit of period when the pace of open releases slowed down, but they've really shot up now.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6hxobq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Exactly, we also had Command-A, Cogito, and various other big models in the last week as well. It&amp;#39;s truly staggering how active the open weight space has been recently. Which is what I tried to convey in my comment.&lt;/p&gt;\n\n&lt;p&gt;We also had Hunyuan and ERNIE released in June. It felt like there was a bit of period when the pace of open releases slowed down, but they&amp;#39;ve really shot up now.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6hxobq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754124964,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754124964,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6hwj8n",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "vibjelo",
                      "can_mod_post": false,
                      "created_utc": 1754124247,
                      "send_replies": true,
                      "parent_id": "t1_n6e7f5u",
                      "score": 6,
                      "author_fullname": "t2_hr2hgnsk",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; It feels like it's been ages since we didn't have some kind of major release\n\nGLM 4.5 (+Air) released days ago, various Qwen3 updates (+ Qwen3-coder) happening as we speak. That's just the last few days 🫠",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6hwj8n",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It feels like it&amp;#39;s been ages since we didn&amp;#39;t have some kind of major release&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;GLM 4.5 (+Air) released days ago, various Qwen3 updates (+ Qwen3-coder) happening as we speak. That&amp;#39;s just the last few days 🫠&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6hwj8n/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754124247,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 6
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6e7f5u",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "mikael110",
            "can_mod_post": false,
            "created_utc": 1754072672,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 38,
            "author_fullname": "t2_4amlo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "More like big model smell this entire month. It feels like it's been ages since we didn't have some kind of major release. Most of them being large models.\n\nThat's not to say I don't welcome OpenAI to the party. The more open models the better. Competition is good, even within the open weight community. And the more normalized it becomes for companies to release open models the better it is for us.",
            "edited": 1754073826,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6e7f5u",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;More like big model smell this entire month. It feels like it&amp;#39;s been ages since we didn&amp;#39;t have some kind of major release. Most of them being large models.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s not to say I don&amp;#39;t welcome OpenAI to the party. The more open models the better. Competition is good, even within the open weight community. And the more normalized it becomes for companies to release open models the better it is for us.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6e7f5u/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754072672,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 38
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ebdde",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "LegitimateCopy7",
                      "can_mod_post": false,
                      "created_utc": 1754073827,
                      "send_replies": true,
                      "parent_id": "t1_n6e67ki",
                      "score": 24,
                      "author_fullname": "t2_5n0kv2ev",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "people will fall for anything. don't even bother.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ebdde",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;people will fall for anything. don&amp;#39;t even bother.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ebdde/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754073827,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 24
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6efo8y",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "SpiritualWindow3855",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6ec3jr",
                                          "score": 10,
                                          "author_fullname": "t2_i7pimyxj5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "You say that like OpenAI employees are not the kings of self-speculation on X?\n\nHe knows people at OpenAI well enough to feel comfortable saying this stuff, and has for a while: people are missing he's also the person who mentioned there'd be a version that needs an H100.   \n  \nHis incentive is \"people on the internet are wrong\", this post doesn't really hype anything that the leak didn't already, if anything it *unhypes* the model, since native FP4 training would have been huge.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6efo8y",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You say that like OpenAI employees are not the kings of self-speculation on X?&lt;/p&gt;\n\n&lt;p&gt;He knows people at OpenAI well enough to feel comfortable saying this stuff, and has for a while: people are missing he&amp;#39;s also the person who mentioned there&amp;#39;d be a version that needs an H100.   &lt;/p&gt;\n\n&lt;p&gt;His incentive is &amp;quot;people on the internet are wrong&amp;quot;, this post doesn&amp;#39;t really hype anything that the leak didn&amp;#39;t already, if anything it &lt;em&gt;unhypes&lt;/em&gt; the model, since native FP4 training would have been huge.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6efo8y/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754075092,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754075092,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 10
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6foejn",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "Irisi11111",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6ec3jr",
                                          "score": 1,
                                          "author_fullname": "t2_27amtukh",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I guess he’s likely expected to share anecdotes from his OAI connections, or it might be an intentional leak. The open-source model is a major incentive for his industry, with strong demand for capable self-hosted local models.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6foejn",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I guess he’s likely expected to share anecdotes from his OAI connections, or it might be an intentional leak. The open-source model is a major incentive for his industry, with strong demand for capable self-hosted local models.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6foejn/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754089018,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754089018,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6ec3jr",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "eloquentemu",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6ea2c5",
                                "score": 22,
                                "author_fullname": "t2_lpdsy",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Sure, but he also doesn't have any incentive to comment on it at all, I'd think.  Like, if OpenAI was using their services it seems like a huge breech of trust (if not an NDA) to just be dropping this sort of statement on socials.  Alternatively, he's just speculating for the free advertisement.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6ec3jr",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sure, but he also doesn&amp;#39;t have any incentive to comment on it at all, I&amp;#39;d think.  Like, if OpenAI was using their services it seems like a huge breech of trust (if not an NDA) to just be dropping this sort of statement on socials.  Alternatively, he&amp;#39;s just speculating for the free advertisement.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ec3jr/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754074041,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754074041,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 22
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6ekcal",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": "LOW_SCORE",
                                                              "no_follow": true,
                                                              "author": "SpiritualWindow3855",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6eih3y",
                                                              "score": -5,
                                                              "author_fullname": "t2_i7pimyxj5",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Saying it has \"big model smell\" is not any crazy hype, and it's clear the tweet was made to correct misinformation about the leak... at least to anyone not thinking with their ass.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6ekcal",
                                                              "is_submitter": false,
                                                              "collapsed": true,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Saying it has &amp;quot;big model smell&amp;quot; is not any crazy hype, and it&amp;#39;s clear the tweet was made to correct misinformation about the leak... at least to anyone not thinking with their ass.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": "comment score below threshold",
                                                              "link_id": "t3_1mf3tm9",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ekcal/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754076476,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754076476,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": -5
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6eih3y",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "nullmove",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6eherw",
                                                    "score": 8,
                                                    "author_fullname": "t2_aq4j0",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "OP wasn't talking about FP4, he was talking about *hype* referring the \"big model smell\". And this guy has been hyping it up for weeks now:\n\nhttps://xcancel.com/Yuchenj_UW/status/1943005122793214267#m\n\n\"We’re hosting it on Hyperbolic. Buckle up\". Zero incentives, my ass.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6eih3y",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OP wasn&amp;#39;t talking about FP4, he was talking about &lt;em&gt;hype&lt;/em&gt; referring the &amp;quot;big model smell&amp;quot;. And this guy has been hyping it up for weeks now:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://xcancel.com/Yuchenj_UW/status/1943005122793214267#m\"&gt;https://xcancel.com/Yuchenj_UW/status/1943005122793214267#m&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;We’re hosting it on Hyperbolic. Buckle up&amp;quot;. Zero incentives, my ass.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mf3tm9",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6eih3y/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754075918,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754075918,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 8
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6eherw",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": "LOW_SCORE",
                                          "no_follow": true,
                                          "author": "SpiritualWindow3855",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6eglpm",
                                          "score": -7,
                                          "author_fullname": "t2_i7pimyxj5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": true,
                                          "body": "Because native FP4 would have been massively preferable for hosting.\n\nIf anything there'd be incentive to push the narrative that it *wasn't quantized*, and host at \"native FP4\"... but no one is dumb enough to do that.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6eherw",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Because native FP4 would have been massively preferable for hosting.&lt;/p&gt;\n\n&lt;p&gt;If anything there&amp;#39;d be incentive to push the narrative that it &lt;em&gt;wasn&amp;#39;t quantized&lt;/em&gt;, and host at &amp;quot;native FP4&amp;quot;... but no one is dumb enough to do that.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": "comment score below threshold",
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6eherw/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754075606,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754075606,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -7
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6eglpm",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "nullmove",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6ea2c5",
                                "score": 9,
                                "author_fullname": "t2_aq4j0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "They will literally host the model for money, how is that zero incentives?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6eglpm",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They will literally host the model for money, how is that zero incentives?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6eglpm/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754075367,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754075367,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 9
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6lhktq",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "mrwang89",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6ea2c5",
                                "score": 1,
                                "author_fullname": "t2_sz57zt2",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "a month ago he literally said openai is releasing 'The best open-source reasoning model' \"next Thursday\". He is a hypelord with a track record of bullshit.\n\nhttps://preview.redd.it/2zlywqpoiogf1.png?width=1029&amp;format=png&amp;auto=webp&amp;s=3dcf51daacd00c0fd89f6bbd9e2435b418fb9839",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6lhktq",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;a month ago he literally said openai is releasing &amp;#39;The best open-source reasoning model&amp;#39; &amp;quot;next Thursday&amp;quot;. He is a hypelord with a track record of bullshit.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2zlywqpoiogf1.png?width=1029&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3dcf51daacd00c0fd89f6bbd9e2435b418fb9839\"&gt;https://preview.redd.it/2zlywqpoiogf1.png?width=1029&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3dcf51daacd00c0fd89f6bbd9e2435b418fb9839&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6lhktq/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754172240,
                                "media_metadata": {
                                  "2zlywqpoiogf1": {
                                    "status": "valid",
                                    "e": "Image",
                                    "m": "image/png",
                                    "p": [
                                      {
                                        "y": 81,
                                        "x": 108,
                                        "u": "https://preview.redd.it/2zlywqpoiogf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=272c28d27d37ed4878bbcd8b835c84bbe8f206ab"
                                      },
                                      {
                                        "y": 162,
                                        "x": 216,
                                        "u": "https://preview.redd.it/2zlywqpoiogf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2cf1368e5c568123679cfeaad2b9786630592a8a"
                                      },
                                      {
                                        "y": 240,
                                        "x": 320,
                                        "u": "https://preview.redd.it/2zlywqpoiogf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5fff138c65e8e59574d761dd06f96abc5f242e75"
                                      },
                                      {
                                        "y": 480,
                                        "x": 640,
                                        "u": "https://preview.redd.it/2zlywqpoiogf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=191ed7ebfc93528604f2ba879776dcb36539d296"
                                      },
                                      {
                                        "y": 721,
                                        "x": 960,
                                        "u": "https://preview.redd.it/2zlywqpoiogf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1ed77f383b33d37e24d40e3648f2a41d180158e2"
                                      }
                                    ],
                                    "s": {
                                      "y": 773,
                                      "x": 1029,
                                      "u": "https://preview.redd.it/2zlywqpoiogf1.png?width=1029&amp;format=png&amp;auto=webp&amp;s=3dcf51daacd00c0fd89f6bbd9e2435b418fb9839"
                                    },
                                    "id": "2zlywqpoiogf1"
                                  }
                                },
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754172240,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6fw71x",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "AuspiciousApple",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6ea2c5",
                                "score": 1,
                                "author_fullname": "t2_bndbg",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Sure, but the company is literally named after hyperbole",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6fw71x",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sure, but the company is literally named after hyperbole&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6fw71x/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754091694,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754091694,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6f7vi7",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "SpiritualWindow3855",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6f5nnj",
                                                              "score": 2,
                                                              "author_fullname": "t2_i7pimyxj5",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Because there **is** zero incentive to correct people on the native precision of a model *upwards.* A lower native precision is the **better** if you're a host.\n\nIt'd also have been way more impressive to have been fully trained at FP4, if anything you'd want brag\n\n&gt;rest of us are wondering\n\nYeah you're wondering because you don't know enough to understand the most important part of the tweet.\n\nSo you latched on to the only 5 words you could understand and called the tweet bullshit hype.\n\n---\n\nHilarious to turn around and talk about people who lack information though, got an actual laugh out of me!",
                                                              "edited": 1754084055,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6f7vi7",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Because there &lt;strong&gt;is&lt;/strong&gt; zero incentive to correct people on the native precision of a model &lt;em&gt;upwards.&lt;/em&gt; A lower native precision is the &lt;strong&gt;better&lt;/strong&gt; if you&amp;#39;re a host.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;d also have been way more impressive to have been fully trained at FP4, if anything you&amp;#39;d want brag&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;rest of us are wondering&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yeah you&amp;#39;re wondering because you don&amp;#39;t know enough to understand the most important part of the tweet.&lt;/p&gt;\n\n&lt;p&gt;So you latched on to the only 5 words you could understand and called the tweet bullshit hype.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Hilarious to turn around and talk about people who lack information though, got an actual laugh out of me!&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mf3tm9",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f7vi7/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754083549,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754083549,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 2
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6f5nnj",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "DorphinPack",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6es70p",
                                                    "score": 1,
                                                    "author_fullname": "t2_zebuyjw9s",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "You can think that but the rest of us are wondering how anyone could confidently say there is 0 incentive for a compute provider to comment on upcoming models that may run (or compete against) their platform.\n\nLots of very shrewd \"thumb on the scale\" moments happen because overconfident people don't have the information to realize why it was advantageous for someone to do something.",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6f5nnj",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can think that but the rest of us are wondering how anyone could confidently say there is 0 incentive for a compute provider to comment on upcoming models that may run (or compete against) their platform.&lt;/p&gt;\n\n&lt;p&gt;Lots of very shrewd &amp;quot;thumb on the scale&amp;quot; moments happen because overconfident people don&amp;#39;t have the information to realize why it was advantageous for someone to do something.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mf3tm9",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f5nnj/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754082859,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754082859,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6es70p",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "SpiritualWindow3855",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6eolc8",
                                          "score": -1,
                                          "author_fullname": "t2_i7pimyxj5",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Yeah, zero incentive to lie about a correction.\n\nI think even a literal child could work out that this tweet is about correcting misinformation that came up from the leak... but some people really want to latch onto that last sentence for dear life.\n\n¯\\\\\\_(ツ)_/¯",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6es70p",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, zero incentive to lie about a correction.&lt;/p&gt;\n\n&lt;p&gt;I think even a literal child could work out that this tweet is about correcting misinformation that came up from the leak... but some people really want to latch onto that last sentence for dear life.&lt;/p&gt;\n\n&lt;p&gt;¯\\_(ツ)_/¯&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6es70p/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754078831,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754078831,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 1,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6eolc8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "DorphinPack",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6ea2c5",
                                "score": 0,
                                "author_fullname": "t2_zebuyjw9s",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "0 incentive?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6eolc8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;0 incentive?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6eolc8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754077748,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754077748,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 1,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 0
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ea2c5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "SpiritualWindow3855",
                      "can_mod_post": false,
                      "created_utc": 1754073444,
                      "send_replies": true,
                      "parent_id": "t1_n6e67ki",
                      "score": 32,
                      "author_fullname": "t2_i7pimyxj5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "This is CTO of Hyperbolic, who are a real compute provider with 0 incentive to lie about this.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ea2c5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is CTO of Hyperbolic, who are a real compute provider with 0 incentive to lie about this.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ea2c5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754073444,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 32
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ebzxu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Thomas-Lore",
                      "can_mod_post": false,
                      "created_utc": 1754074011,
                      "send_replies": true,
                      "parent_id": "t1_n6e67ki",
                      "score": 11,
                      "author_fullname": "t2_5hobp6m4",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Saying it has not been trained in fp4 and it won't release today is hype?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ebzxu",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Saying it has not been trained in fp4 and it won&amp;#39;t release today is hype?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ebzxu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754074011,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 11
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6h8bc9",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "Any_Pressure4251",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6fittr",
                                                              "score": 1,
                                                              "author_fullname": "t2_6yisgee3",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "The right tool for the right job, i'm not even a data scientist I would have gone straight to Open AI for that kind of task. \n\nKnow your tools...",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6h8bc9",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The right tool for the right job, i&amp;#39;m not even a data scientist I would have gone straight to Open AI for that kind of task. &lt;/p&gt;\n\n&lt;p&gt;Know your tools...&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mf3tm9",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6h8bc9/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754110733,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754110733,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6fittr",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "MexInAbu",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6ew3wh",
                                                    "score": 5,
                                                    "author_fullname": "t2_euii2wb6",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "I was working today with Claude-Opus on Roo Code through Open Router. I gave it what I thought it was boilerplate code for my ML task. A bit laborious but low complexity. I needed to normalize a data frame, however, there were several dependent variables for which their relative magnitudes are important for my target output.\n\nSo, I asked Claude Opus to do it. Company is paying, so no qualms on token usage. I tried to give it a good description of the task. More detailed than what I would give a JR on my team:\n\n&gt;I have data frame &lt;df Name&gt; with columns &lt;Columns&gt;. Notice that columns name have prefix &lt;prefix&gt;. This means they belong to the same &lt;redacted&gt; group.\n\n&gt;I need you to write a function to normalize &lt;df name&gt; in a smart way. For this, I mean that the normalization must conserve the relative magnitude within variables for each &lt;redacted&gt; group.\n\nI gave it a list of variables they must be grouped together.\n\nWell, first it grouped the same type of variables of different groups. But the code was bugged anyway and the grouping was superfluous as in the end it did an scaler.fit\\_transform(df), negating all the subsetting.\n\nI tried to correct the behaviour but it keep doing similarly stupid choices. I even asked to review if its code indeed was doing what I was asking it to do. I got the classic \"Sorry, you are right...\" output and replaced with equally stupid choices.   \n  \nSo I pretty much created near pseudo code saying what to do step by step.\n\n&gt;First, write a function that returns a dictionary {group: group columns} where the group correspond to columns with the same prefix. Do this by grouping together the column name by matching the prefix &lt;prefix format&gt;.  \n\nThen I verified that part was not doing stupid stuff.\n\n&gt;Then, write a function that computes the MAD for column with suffix &lt;post fix&gt;. Lets call the output $mu$. and, to columns with suffix &lt;list of suffixes&gt;, compute the MAD score using $mu$ as a fixed parameter.\n\nI again verified for stupid.\n\n&gt;Then combine the data frames....\n\nAnd so on....\n\ntd;dr: I do not fear for my job just yet.",
                                                    "edited": 1754088334,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6fittr",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was working today with Claude-Opus on Roo Code through Open Router. I gave it what I thought it was boilerplate code for my ML task. A bit laborious but low complexity. I needed to normalize a data frame, however, there were several dependent variables for which their relative magnitudes are important for my target output.&lt;/p&gt;\n\n&lt;p&gt;So, I asked Claude Opus to do it. Company is paying, so no qualms on token usage. I tried to give it a good description of the task. More detailed than what I would give a JR on my team:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I have data frame &amp;lt;df Name&amp;gt; with columns &amp;lt;Columns&amp;gt;. Notice that columns name have prefix &amp;lt;prefix&amp;gt;. This means they belong to the same &amp;lt;redacted&amp;gt; group.&lt;/p&gt;\n\n&lt;p&gt;I need you to write a function to normalize &amp;lt;df name&amp;gt; in a smart way. For this, I mean that the normalization must conserve the relative magnitude within variables for each &amp;lt;redacted&amp;gt; group.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I gave it a list of variables they must be grouped together.&lt;/p&gt;\n\n&lt;p&gt;Well, first it grouped the same type of variables of different groups. But the code was bugged anyway and the grouping was superfluous as in the end it did an scaler.fit_transform(df), negating all the subsetting.&lt;/p&gt;\n\n&lt;p&gt;I tried to correct the behaviour but it keep doing similarly stupid choices. I even asked to review if its code indeed was doing what I was asking it to do. I got the classic &amp;quot;Sorry, you are right...&amp;quot; output and replaced with equally stupid choices.   &lt;/p&gt;\n\n&lt;p&gt;So I pretty much created near pseudo code saying what to do step by step.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;First, write a function that returns a dictionary {group: group columns} where the group correspond to columns with the same prefix. Do this by grouping together the column name by matching the prefix &amp;lt;prefix format&amp;gt;.  &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Then I verified that part was not doing stupid stuff.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Then, write a function that computes the MAD for column with suffix &amp;lt;post fix&amp;gt;. Lets call the output $mu$. and, to columns with suffix &amp;lt;list of suffixes&amp;gt;, compute the MAD score using $mu$ as a fixed parameter.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I again verified for stupid.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Then combine the data frames....&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;And so on....&lt;/p&gt;\n\n&lt;p&gt;td;dr: I do not fear for my job just yet.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mf3tm9",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6fittr/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754087121,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754087121,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 5
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6ew3wh",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": "LOW_SCORE",
                                          "no_follow": true,
                                          "author": "Any_Pressure4251",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6en9av",
                                          "score": -6,
                                          "author_fullname": "t2_6yisgee3",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": true,
                                          "body": "I am 99% sure I have been working for a very long time in this industry, and used GPT 3 base model(pre (Chat GPT 3.5) before any of you guys even new what a language model was, back then to get AI to write code, you had to give it lots of examples for it to do so. It was much easier to get it to write documentation! Now the models are much better then junior software Devs at most tasks, can tool call, draw diagrams, design UI's etc This after 3 years of progress which is a very short time in the tech world.\n\nUnless models get suddenly erased from labs, peoples storage all over the world, there will be progress . The only doubt I have now is time lines. will it be a year, 3 years or a decade. \n\nI think a person with absolutely no knowledge of programming will be able to make software in 1 day better than whole teams in say Google.\n\nLet me explain.\n\nWhat slows down teams I have worked with is communication, customer intent, testing, security etc all of these things will go away when we make agents take these roles. If you work with software like Roo code, Claude Code, Windsurf you can see that these roles are already starting to be fleshed out. They will grow to when they become better than Principal Software Engineers, Testers, Project Managers, Scrum masters, Software Architects, UI designers about the only thing left which will not be domain experts but the intent of the person asking the AI for the software. \n\nAnyone thinking differently is going to be wrong inside a decade!",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6ew3wh",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am 99% sure I have been working for a very long time in this industry, and used GPT 3 base model(pre (Chat GPT 3.5) before any of you guys even new what a language model was, back then to get AI to write code, you had to give it lots of examples for it to do so. It was much easier to get it to write documentation! Now the models are much better then junior software Devs at most tasks, can tool call, draw diagrams, design UI&amp;#39;s etc This after 3 years of progress which is a very short time in the tech world.&lt;/p&gt;\n\n&lt;p&gt;Unless models get suddenly erased from labs, peoples storage all over the world, there will be progress . The only doubt I have now is time lines. will it be a year, 3 years or a decade. &lt;/p&gt;\n\n&lt;p&gt;I think a person with absolutely no knowledge of programming will be able to make software in 1 day better than whole teams in say Google.&lt;/p&gt;\n\n&lt;p&gt;Let me explain.&lt;/p&gt;\n\n&lt;p&gt;What slows down teams I have worked with is communication, customer intent, testing, security etc all of these things will go away when we make agents take these roles. If you work with software like Roo code, Claude Code, Windsurf you can see that these roles are already starting to be fleshed out. They will grow to when they become better than Principal Software Engineers, Testers, Project Managers, Scrum masters, Software Architects, UI designers about the only thing left which will not be domain experts but the intent of the person asking the AI for the software. &lt;/p&gt;\n\n&lt;p&gt;Anyone thinking differently is going to be wrong inside a decade!&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": "comment score below threshold",
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ew3wh/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754079996,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754079996,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -6
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6en9av",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "ShengrenR",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6ee7n5",
                                "score": 5,
                                "author_fullname": "t2_ji4n4",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "pure speculation - nobody knows that at all for sure.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6en9av",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;pure speculation - nobody knows that at all for sure.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6en9av/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754077350,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754077350,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 5
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ee7n5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": "LOW_SCORE",
                      "no_follow": true,
                      "author": "Any_Pressure4251",
                      "can_mod_post": false,
                      "created_utc": 1754074664,
                      "send_replies": true,
                      "parent_id": "t1_n6e67ki",
                      "score": -5,
                      "author_fullname": "t2_6yisgee3",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "You can use the 120b now on OpenRouter and its good, much better then what's come out of China since it is Multi-Model and super fast.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ee7n5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can use the 120b now on OpenRouter and its good, much better then what&amp;#39;s come out of China since it is Multi-Model and super fast.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": "comment score below threshold",
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ee7n5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754074664,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": true,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": -5
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6e67ki",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Hanthunius",
            "can_mod_post": false,
            "created_utc": 1754072320,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 118,
            "author_fullname": "t2_d2gb9jhgg",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "More bullshit hype. Don't fall for it, people.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6e67ki",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;More bullshit hype. Don&amp;#39;t fall for it, people.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6e67ki/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754072320,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 118
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6eo53e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "celsowm",
            "can_mod_post": false,
            "created_utc": 1754077613,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 15,
            "author_fullname": "t2_dyvrh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Openai new model is the new Half Life 3",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6eo53e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Openai new model is the new Half Life 3&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6eo53e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754077613,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6hwoce",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "let-me-think-",
                      "can_mod_post": false,
                      "created_utc": 1754124336,
                      "send_replies": true,
                      "parent_id": "t1_n6hbegz",
                      "score": 2,
                      "author_fullname": "t2_rf6rd",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "They overhype imminent releases to keep investors happy and ensure pro users don’t jump ship. Then they realise all the other labs have released faster so try their best to bring their model up a notch (this is the safety check phase). Then when just as theyre ready to release another competitor bridges the gap and this repeats until they eventually release a disappointing model. The disappointment is due to the amount of hype they create, not the actual model quality itself which is usually on par or offers some strong qualities",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6hwoce",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They overhype imminent releases to keep investors happy and ensure pro users don’t jump ship. Then they realise all the other labs have released faster so try their best to bring their model up a notch (this is the safety check phase). Then when just as theyre ready to release another competitor bridges the gap and this repeats until they eventually release a disappointing model. The disappointment is due to the amount of hype they create, not the actual model quality itself which is usually on par or offers some strong qualities&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6hwoce/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754124336,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6hbegz",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "__JockY__",
            "can_mod_post": false,
            "created_utc": 1754112292,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 5,
            "author_fullname": "t2_qf8h7ka8",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yesterday I commented that this is dots.llm with a large marketing budget.\n\nI take it back. This is not marketing, it’s childishness.\n\nSilly leaks. Vague hints. It’s all clickbait-y nonsense. I wish the OpenAI folks would just act like adults and do a sensible model drop.\n\nMakes me wonder if there are warring factions at OpenAI and we’re seeing the spillover.\n\nBut this is _terrible_ marketing. It engenders very little good will.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6hbegz",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yesterday I commented that this is dots.llm with a large marketing budget.&lt;/p&gt;\n\n&lt;p&gt;I take it back. This is not marketing, it’s childishness.&lt;/p&gt;\n\n&lt;p&gt;Silly leaks. Vague hints. It’s all clickbait-y nonsense. I wish the OpenAI folks would just act like adults and do a sensible model drop.&lt;/p&gt;\n\n&lt;p&gt;Makes me wonder if there are warring factions at OpenAI and we’re seeing the spillover.&lt;/p&gt;\n\n&lt;p&gt;But this is &lt;em&gt;terrible&lt;/em&gt; marketing. It engenders very little good will.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6hbegz/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754112292,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 5
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6g30kf",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "-p-e-w-",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6eqrz5",
                                "score": 2,
                                "author_fullname": "t2_dkgrhaet",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Llama 4 wasn’t “early” lol. It was several months late.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6g30kf",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Llama 4 wasn’t “early” lol. It was several months late.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6g30kf/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754094131,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754094131,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6ern2w",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": "LOW_SCORE",
                                "no_follow": true,
                                "author": "entsnack",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6eqrz5",
                                "score": -7,
                                "author_fullname": "t2_1a48h7vf",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "and Kimi K2, trillion params to be slightly better than Maverick lmao",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6ern2w",
                                "is_submitter": false,
                                "collapsed": true,
                                "author_flair_richtext": [
                                  {
                                    "a": ":X:",
                                    "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                    "e": "emoji"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;and Kimi K2, trillion params to be slightly better than Maverick lmao&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": "comment score below threshold",
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "dark",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ern2w/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754078664,
                                "author_flair_text": ":X:",
                                "treatment_tags": [],
                                "created_utc": 1754078664,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "transparent",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": -7
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6eqrz5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Caffdy",
                      "can_mod_post": false,
                      "created_utc": 1754078405,
                      "send_replies": true,
                      "parent_id": "t1_n6enhm3",
                      "score": 9,
                      "author_fullname": "t2_ql2vu0wz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt; It's better to have a good model late than a shitty one early\n\nyeah, we don't have to look further than Llama4",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6eqrz5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It&amp;#39;s better to have a good model late than a shitty one early&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;yeah, we don&amp;#39;t have to look further than Llama4&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6eqrz5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754078405,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 9
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6gvxvl",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "theshadowraven",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6ezuci",
                                          "score": 3,
                                          "author_fullname": "t2_49abw3rv",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "You may have a point. However, depending on the one who posts, I think some the \"jabs\" are just playful banter poking fun at a multi-billion dollar company using delays as an investor promo and free advertisement of \"yeah, we are coming out with a \"safer\" model one of these \"fill in the blank\". I don't think all of it is meant to be spiteful or pessimistic per se. Although, some healthy skepticism of what used to be an open source OpenAI going back to being \"open\" is probably deserved.\n\nHell I remember Nintendo delaying a Zelda game forever to get bigger sales, or at least that's what the press said at the time.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6gvxvl",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You may have a point. However, depending on the one who posts, I think some the &amp;quot;jabs&amp;quot; are just playful banter poking fun at a multi-billion dollar company using delays as an investor promo and free advertisement of &amp;quot;yeah, we are coming out with a &amp;quot;safer&amp;quot; model one of these &amp;quot;fill in the blank&amp;quot;. I don&amp;#39;t think all of it is meant to be spiteful or pessimistic per se. Although, some healthy skepticism of what used to be an open source OpenAI going back to being &amp;quot;open&amp;quot; is probably deserved.&lt;/p&gt;\n\n&lt;p&gt;Hell I remember Nintendo delaying a Zelda game forever to get bigger sales, or at least that&amp;#39;s what the press said at the time.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6gvxvl/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754105139,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754105139,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 3
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "richtext",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6f0n3x",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "entsnack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6ezuci",
                                          "score": 4,
                                          "author_fullname": "t2_1a48h7vf",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "\\&gt;  straight-up rooting for this models\n\n*Conditionally* pro-open source. I wonder if there is a pattern...",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6f0n3x",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [
                                            {
                                              "a": ":X:",
                                              "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                              "e": "emoji"
                                            }
                                          ],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;gt;  straight-up rooting for this models&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Conditionally&lt;/em&gt; pro-open source. I wonder if there is a pattern...&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": "dark",
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f0n3x/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754081344,
                                          "author_flair_text": ":X:",
                                          "treatment_tags": [],
                                          "created_utc": 1754081344,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": "transparent",
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 4
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6fki77",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "DorphinPack",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6f8ykb",
                                                              "score": 1,
                                                              "author_fullname": "t2_zebuyjw9s",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Cheers!\n\nI’m struggling to communicate well lately for a lot of reasons but trying to grow through it. Interactions like this give me the courage to go even harder working on myself.",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6fki77",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Cheers!&lt;/p&gt;\n\n&lt;p&gt;I’m struggling to communicate well lately for a lot of reasons but trying to grow through it. Interactions like this give me the courage to go even harder working on myself.&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mf3tm9",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6fki77/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754087693,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754087693,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 1
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6f8ykb",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": false,
                                                    "author": "Sky-kunn",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6f5zay",
                                                    "score": 7,
                                                    "author_fullname": "t2_ahgkl0do",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Yeah? This is LocalLLaMA, the whole point is running models on your own hardware, doing whatever you personally need, no?\n\n~~Also, by what metric exactly is a newly released open-weight model a bad or negative thing?~~\n\n&gt;saw your comment after seeing this one and I will add here that this is me applying a rubric that goes beyond how useful the model is to me personally. I in fact \\*do\\* want to withhold support from players who I think are holding back overall progress. I'm not sure what's wrong with that.\n\nGot it, I respect that.",
                                                    "edited": 1754084568,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6f8ykb",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah? This is LocalLLaMA, the whole point is running models on your own hardware, doing whatever you personally need, no?&lt;/p&gt;\n\n&lt;p&gt;&lt;del&gt;Also, by what metric exactly is a newly released open-weight model a bad or negative thing?&lt;/del&gt;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;saw your comment after seeing this one and I will add here that this is me applying a rubric that goes beyond how useful the model is to me personally. I in fact *do* want to withhold support from players who I think are holding back overall progress. I&amp;#39;m not sure what&amp;#39;s wrong with that.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Got it, I respect that.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mf3tm9",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f8ykb/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754083891,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754083891,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 7
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6f5zay",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": "LOW_SCORE",
                                          "no_follow": true,
                                          "author": "DorphinPack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6ezuci",
                                          "score": -6,
                                          "author_fullname": "t2_zebuyjw9s",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": true,
                                          "body": "Hold up your only metric is how useful the tool is to you personally?\n\nI understand our disconnect a bit better.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6f5zay",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hold up your only metric is how useful the tool is to you personally?&lt;/p&gt;\n\n&lt;p&gt;I understand our disconnect a bit better.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": "comment score below threshold",
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f5zay/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754082959,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754082959,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": -6
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6ezuci",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "Sky-kunn",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6eplqu",
                                "score": 10,
                                "author_fullname": "t2_ahgkl0do",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Part of me thinks some people here are not only pessimistic but straight-up rooting for this models to fail.\n\nDo I think the model will have an Apache or MIT license? No. But yes, I do hope it turns out to be good for its size. If the 120B version is better than GLM-4.5-air, that'll be incredible because that one was already great for its size. Likewise, if the 20B version beats Gemma, that'll also be amazing. There's a real chance this could happen. Why? Because it wouldn't negatively impact OpenAI at all, just like how Gemma models don't hurt Gemini models and it would be good for they image. I'd prefer if they were more open and honest, but this better then before, is a good thing, not bad lol.\n\nSome people here seem to give off a vibe like: \"Oh no, OpenAI sucks, I don't want them to release a good model because that would make them look good!\" But maybe I'm wrong, and people here are just annoyingly pessimistic, which they do have a track record of being. (On the other hand, perhaps I'm too optimistic.)",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6ezuci",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Part of me thinks some people here are not only pessimistic but straight-up rooting for this models to fail.&lt;/p&gt;\n\n&lt;p&gt;Do I think the model will have an Apache or MIT license? No. But yes, I do hope it turns out to be good for its size. If the 120B version is better than GLM-4.5-air, that&amp;#39;ll be incredible because that one was already great for its size. Likewise, if the 20B version beats Gemma, that&amp;#39;ll also be amazing. There&amp;#39;s a real chance this could happen. Why? Because it wouldn&amp;#39;t negatively impact OpenAI at all, just like how Gemma models don&amp;#39;t hurt Gemini models and it would be good for they image. I&amp;#39;d prefer if they were more open and honest, but this better then before, is a good thing, not bad lol.&lt;/p&gt;\n\n&lt;p&gt;Some people here seem to give off a vibe like: &amp;quot;Oh no, OpenAI sucks, I don&amp;#39;t want them to release a good model because that would make them look good!&amp;quot; But maybe I&amp;#39;m wrong, and people here are just annoyingly pessimistic, which they do have a track record of being. (On the other hand, perhaps I&amp;#39;m too optimistic.)&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ezuci/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754081105,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754081105,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 10
                              }
                            },
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6f1it6",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "entsnack",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6f13ep",
                                                    "score": 3,
                                                    "author_fullname": "t2_1a48h7vf",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "haha and yeah open-something that I can fine-tune is all I care about, I'm not Richard Stallman",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6f1it6",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "a": ":X:",
                                                        "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                                        "e": "emoji"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;haha and yeah open-something that I can fine-tune is all I care about, I&amp;#39;m not Richard Stallman&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mf3tm9",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "dark",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f1it6/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754081605,
                                                    "author_flair_text": ":X:",
                                                    "collapsed": false,
                                                    "created_utc": 1754081605,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "transparent",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 3
                                                  }
                                                },
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6f5ct8",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "DorphinPack",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6f13ep",
                                                    "score": -2,
                                                    "author_fullname": "t2_zebuyjw9s",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "Open dataset is the important part and they will never because we all know how much copyrighted material they've retained for purposes potentially not covered by the license it was obtained under.\n\nAnd no, I am not arguing that copyrighted material is embedded in models.\n\nThey're shady. All big tech firms in the US are. China's got some scummy shit going on too but at least we have open weights.\n\nI'm mostly tired of saying what I think about X and having someone criticize my position on Y. Any response to this better be relevant or it's getting ignored. The fan behavior is ridiculous.\n\nEdit: saw your comment after seeing this one and I will add here that this is me applying a rubric that goes beyond how useful the model is to me personally. I in fact \\*do\\* want to withhold support from players who I think are holding back overall progress. I'm not sure what's wrong with that.",
                                                    "edited": 1754083031,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6f5ct8",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Open dataset is the important part and they will never because we all know how much copyrighted material they&amp;#39;ve retained for purposes potentially not covered by the license it was obtained under.&lt;/p&gt;\n\n&lt;p&gt;And no, I am not arguing that copyrighted material is embedded in models.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re shady. All big tech firms in the US are. China&amp;#39;s got some scummy shit going on too but at least we have open weights.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m mostly tired of saying what I think about X and having someone criticize my position on Y. Any response to this better be relevant or it&amp;#39;s getting ignored. The fan behavior is ridiculous.&lt;/p&gt;\n\n&lt;p&gt;Edit: saw your comment after seeing this one and I will add here that this is me applying a rubric that goes beyond how useful the model is to me personally. I in fact *do* want to withhold support from players who I think are holding back overall progress. I&amp;#39;m not sure what&amp;#39;s wrong with that.&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mf3tm9",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f5ct8/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754082765,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754082765,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": -2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6f13ep",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": false,
                                          "author": "Sky-kunn",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6erfzw",
                                          "score": 7,
                                          "author_fullname": "t2_ahgkl0do",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Open weight, but yeah, I dunno why everyone's getting so butthurt.\n\n\\&gt;New open-weight models dropping soon from one of the big labs  \n\\&gt;r/LocalLLaMA: \"Nice!\"  \n\\&gt;Two sizes: one medium-sized model that runs on consumer hardware, and a bigger one that's  MoE, so still pretty exciting  \n\\&gt;r/LocalLLaMA: \"LET'S FUCKING GOOOOOO!\"  \n\\&gt;\"It's from OpenAI\"  \n\\&gt;r/LocalLLaMA: \"NOOOOOOOOOOOOOOOO!\"",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6f13ep",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Open weight, but yeah, I dunno why everyone&amp;#39;s getting so butthurt.&lt;/p&gt;\n\n&lt;p&gt;&amp;gt;New open-weight models dropping soon from one of the big labs&lt;br/&gt;\n&amp;gt;&lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt;: &amp;quot;Nice!&amp;quot;&lt;br/&gt;\n&amp;gt;Two sizes: one medium-sized model that runs on consumer hardware, and a bigger one that&amp;#39;s  MoE, so still pretty exciting&lt;br/&gt;\n&amp;gt;&lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt;: &amp;quot;LET&amp;#39;S FUCKING GOOOOOO!&amp;quot;&lt;br/&gt;\n&amp;gt;&amp;quot;It&amp;#39;s from OpenAI&amp;quot;&lt;br/&gt;\n&amp;gt;&lt;a href=\"/r/LocalLLaMA\"&gt;r/LocalLLaMA&lt;/a&gt;: &amp;quot;NOOOOOOOOOOOOOOOO!&amp;quot;&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f13ep/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754081478,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754081478,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 7
                                        }
                                      },
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "richtext",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": {
                                                      "kind": "Listing",
                                                      "data": {
                                                        "after": null,
                                                        "dist": null,
                                                        "modhash": "",
                                                        "geo_filter": "",
                                                        "children": [
                                                          {
                                                            "kind": "t1",
                                                            "data": {
                                                              "subreddit_id": "t5_81eyvm",
                                                              "approved_at_utc": null,
                                                              "author_is_blocked": false,
                                                              "comment_type": null,
                                                              "awarders": [],
                                                              "mod_reason_by": null,
                                                              "banned_by": null,
                                                              "author_flair_type": "text",
                                                              "total_awards_received": 0,
                                                              "subreddit": "LocalLLaMA",
                                                              "author_flair_template_id": null,
                                                              "distinguished": null,
                                                              "likes": null,
                                                              "replies": "",
                                                              "user_reports": [],
                                                              "saved": false,
                                                              "id": "n6f5qor",
                                                              "banned_at_utc": null,
                                                              "mod_reason_title": null,
                                                              "gilded": 0,
                                                              "archived": false,
                                                              "collapsed_reason_code": null,
                                                              "no_follow": true,
                                                              "author": "DorphinPack",
                                                              "can_mod_post": false,
                                                              "send_replies": true,
                                                              "parent_id": "t1_n6f5mld",
                                                              "score": 3,
                                                              "author_fullname": "t2_zebuyjw9s",
                                                              "approved_by": null,
                                                              "mod_note": null,
                                                              "all_awardings": [],
                                                              "body": "Thanks :) usually people just pop the fuck off.\n\nHave a good one!",
                                                              "edited": false,
                                                              "gildings": {},
                                                              "downs": 0,
                                                              "author_flair_css_class": null,
                                                              "name": "t1_n6f5qor",
                                                              "is_submitter": false,
                                                              "collapsed": false,
                                                              "author_flair_richtext": [],
                                                              "author_patreon_flair": false,
                                                              "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks :) usually people just pop the fuck off.&lt;/p&gt;\n\n&lt;p&gt;Have a good one!&lt;/p&gt;\n&lt;/div&gt;",
                                                              "removal_reason": null,
                                                              "collapsed_reason": null,
                                                              "link_id": "t3_1mf3tm9",
                                                              "associated_award": null,
                                                              "stickied": false,
                                                              "author_premium": false,
                                                              "can_gild": false,
                                                              "top_awarded_type": null,
                                                              "unrepliable_reason": null,
                                                              "author_flair_text_color": null,
                                                              "score_hidden": false,
                                                              "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f5qor/",
                                                              "subreddit_type": "public",
                                                              "locked": false,
                                                              "report_reasons": null,
                                                              "created": 1754082885,
                                                              "author_flair_text": null,
                                                              "treatment_tags": [],
                                                              "created_utc": 1754082885,
                                                              "subreddit_name_prefixed": "r/LocalLLaMA",
                                                              "controversiality": 0,
                                                              "depth": 5,
                                                              "author_flair_background_color": null,
                                                              "collapsed_because_crowd_control": null,
                                                              "mod_reports": [],
                                                              "num_reports": null,
                                                              "ups": 3
                                                            }
                                                          }
                                                        ],
                                                        "before": null
                                                      }
                                                    },
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6f5mld",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "entsnack",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6f4wx7",
                                                    "score": 2,
                                                    "author_fullname": "t2_1a48h7vf",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "✌️",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6f5mld",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [
                                                      {
                                                        "a": ":X:",
                                                        "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                                        "e": "emoji"
                                                      }
                                                    ],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;✌️&lt;/p&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mf3tm9",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": "dark",
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f5mld/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754082849,
                                                    "author_flair_text": ":X:",
                                                    "collapsed": false,
                                                    "created_utc": 1754082849,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": "transparent",
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 2
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6f4wx7",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "DorphinPack",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6erfzw",
                                          "score": 1,
                                          "author_fullname": "t2_zebuyjw9s",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I really don't have any more time in my schedule for people that can't handle disagreement. You can keep whatever further comments you have, thanks.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6f4wx7",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I really don&amp;#39;t have any more time in my schedule for people that can&amp;#39;t handle disagreement. You can keep whatever further comments you have, thanks.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mf3tm9",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6f4wx7/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754082627,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754082627,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6erfzw",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": "LOW_SCORE",
                                "no_follow": true,
                                "author": "entsnack",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6eplqu",
                                "score": -9,
                                "author_fullname": "t2_1a48h7vf",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "open source is open source bruh, I'm sorry they make you uncomfortable though, must be tough for you",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6erfzw",
                                "is_submitter": false,
                                "collapsed": true,
                                "author_flair_richtext": [
                                  {
                                    "a": ":X:",
                                    "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                    "e": "emoji"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;open source is open source bruh, I&amp;#39;m sorry they make you uncomfortable though, must be tough for you&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": "comment score below threshold",
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "dark",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6erfzw/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754078605,
                                "author_flair_text": ":X:",
                                "treatment_tags": [],
                                "created_utc": 1754078605,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "transparent",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": -9
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6eplqu",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "DorphinPack",
                      "can_mod_post": false,
                      "created_utc": 1754078051,
                      "send_replies": true,
                      "parent_id": "t1_n6enhm3",
                      "score": 24,
                      "author_fullname": "t2_zebuyjw9s",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "We’re not worried they’re gonna suck.\n\nWe’re worried their definition of best practice already revolves around protecting their lead and stifling innovation without appearing that way.\n\nIt’s hard to get excited once you realize they’re calculating the minimum amount of openness they can get away with. Especially with that fuckass name, pardon my French.\n\nI guess I’m realizing I’m a hater but Altman deserves the same criticism as any private sector politician.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6eplqu",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We’re not worried they’re gonna suck.&lt;/p&gt;\n\n&lt;p&gt;We’re worried their definition of best practice already revolves around protecting their lead and stifling innovation without appearing that way.&lt;/p&gt;\n\n&lt;p&gt;It’s hard to get excited once you realize they’re calculating the minimum amount of openness they can get away with. Especially with that fuckass name, pardon my French.&lt;/p&gt;\n\n&lt;p&gt;I guess I’m realizing I’m a hater but Altman deserves the same criticism as any private sector politician.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6eplqu/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754078051,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 24
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6etb9d",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "entsnack",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6esyj0",
                                "score": -2,
                                "author_fullname": "t2_1a48h7vf",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "no I mean Mistral",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6etb9d",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "a": ":X:",
                                    "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                                    "e": "emoji"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;no I mean Mistral&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mf3tm9",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "dark",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6etb9d/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754079165,
                                "author_flair_text": ":X:",
                                "treatment_tags": [],
                                "created_utc": 1754079165,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 1,
                                "depth": 2,
                                "author_flair_background_color": "transparent",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": -2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6esyj0",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "dorakus",
                      "can_mod_post": false,
                      "created_utc": 1754079059,
                      "send_replies": true,
                      "parent_id": "t1_n6enhm3",
                      "score": 5,
                      "author_fullname": "t2_16sehobi",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt;This is *the* frontier AI lab we're talking about\n\n  \nYou mean Google?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6esyj0",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;This is &lt;em&gt;the&lt;/em&gt; frontier AI lab we&amp;#39;re talking about&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You mean Google?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6esyj0/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754079059,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6felwl",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Calm_Opportunist",
                      "can_mod_post": false,
                      "created_utc": 1754085713,
                      "send_replies": true,
                      "parent_id": "t1_n6enhm3",
                      "score": 1,
                      "author_fullname": "t2_9rdwtler",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Make better AI pics please. Don't lower the bar. ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6felwl",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Make better AI pics please. Don&amp;#39;t lower the bar. &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6felwl/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754085713,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6enhm3",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "entsnack",
            "can_mod_post": false,
            "created_utc": 1754077419,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 50,
            "author_fullname": "t2_1a48h7vf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Let them cook. People were losing their shit here when DeepSeek r2 was delayed too. It's better to have a good model late than a shitty one early. This is *the* frontier AI lab we're talking about, not some under-resourced upstart that pivoted from selling USB-C cables on AliExpress to training LLMs on H20s.\n\nhttps://preview.redd.it/nz9nmrlnoggf1.png?width=1024&amp;format=png&amp;auto=webp&amp;s=567580732551f2e7b923676ea92d64da73fb0c5a",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6enhm3",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "a": ":X:",
                "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                "e": "emoji"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Let them cook. People were losing their shit here when DeepSeek r2 was delayed too. It&amp;#39;s better to have a good model late than a shitty one early. This is &lt;em&gt;the&lt;/em&gt; frontier AI lab we&amp;#39;re talking about, not some under-resourced upstart that pivoted from selling USB-C cables on AliExpress to training LLMs on H20s.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nz9nmrlnoggf1.png?width=1024&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=567580732551f2e7b923676ea92d64da73fb0c5a\"&gt;https://preview.redd.it/nz9nmrlnoggf1.png?width=1024&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=567580732551f2e7b923676ea92d64da73fb0c5a&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "dark",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6enhm3/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754077419,
            "media_metadata": {
              "nz9nmrlnoggf1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 162,
                    "x": 108,
                    "u": "https://preview.redd.it/nz9nmrlnoggf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=199f9b99751e74c540f90d55c389a7cebff86ff0"
                  },
                  {
                    "y": 324,
                    "x": 216,
                    "u": "https://preview.redd.it/nz9nmrlnoggf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=da97c02b9a49fa82e9207324b71950ee1f5e8a23"
                  },
                  {
                    "y": 480,
                    "x": 320,
                    "u": "https://preview.redd.it/nz9nmrlnoggf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cee51fc6e337782f0793c84e224162d6166dc172"
                  },
                  {
                    "y": 960,
                    "x": 640,
                    "u": "https://preview.redd.it/nz9nmrlnoggf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=62ee34c2ee854fdd3e7bd31ea6c08f596e33e341"
                  },
                  {
                    "y": 1440,
                    "x": 960,
                    "u": "https://preview.redd.it/nz9nmrlnoggf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e18c21687116684234e151ff5bf63a8569cf4d4"
                  }
                ],
                "s": {
                  "y": 1536,
                  "x": 1024,
                  "u": "https://preview.redd.it/nz9nmrlnoggf1.png?width=1024&amp;format=png&amp;auto=webp&amp;s=567580732551f2e7b923676ea92d64da73fb0c5a"
                },
                "id": "nz9nmrlnoggf1"
              }
            },
            "author_flair_text": ":X:",
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "transparent",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 50
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6e67nm",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "stoppableDissolution",
            "can_mod_post": false,
            "created_utc": 1754072320,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 11,
            "author_fullname": "t2_1n0su21k4z",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I mean, are we really getting sensible sizes from somewhere? No way!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6e67nm",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I mean, are we really getting sensible sizes from somewhere? No way!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6e67nm/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754072320,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 11
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6esmyh",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754078963,
                      "send_replies": true,
                      "parent_id": "t1_n6ekuhg",
                      "score": 5,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "they're scared, there's more talk of OpenAI here than on /r/OpenAI",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6esmyh",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;they&amp;#39;re scared, there&amp;#39;s more talk of OpenAI here than on &lt;a href=\"/r/OpenAI\"&gt;/r/OpenAI&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6esmyh/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754078963,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6es9gk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Sudden-Lingonberry-8",
                      "can_mod_post": false,
                      "created_utc": 1754078851,
                      "send_replies": true,
                      "parent_id": "t1_n6ekuhg",
                      "score": 0,
                      "author_fullname": "t2_7j2k5hlp",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "nah, fuck openai",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6es9gk",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;nah, fuck openai&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6es9gk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754078851,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6icpab",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Serprotease",
                      "can_mod_post": false,
                      "created_utc": 1754133546,
                      "send_replies": true,
                      "parent_id": "t1_n6ekuhg",
                      "score": 1,
                      "author_fullname": "t2_odh3w8c",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I do hope that it will be good models. Even better if they use some novel approaches or quant ready models.   \n\nBut, OpenAI as a company is clearly hostile to a strong open source/weight llm environment. (Same thing is true for Anthropic). \n\nAnd, you’re on r/locallama, so you will see some, ‘less encouraging’ comments ",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6icpab",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I do hope that it will be good models. Even better if they use some novel approaches or quant ready models.   &lt;/p&gt;\n\n&lt;p&gt;But, OpenAI as a company is clearly hostile to a strong open source/weight llm environment. (Same thing is true for Anthropic). &lt;/p&gt;\n\n&lt;p&gt;And, you’re on &lt;a href=\"/r/locallama\"&gt;r/locallama&lt;/a&gt;, so you will see some, ‘less encouraging’ comments &lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6icpab/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754133546,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6ibl2y",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "awesomemc1",
                      "can_mod_post": false,
                      "created_utc": 1754132988,
                      "send_replies": true,
                      "parent_id": "t1_n6ekuhg",
                      "score": 0,
                      "author_fullname": "t2_xyl1z",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thats actually agreeable. Whenever there is a company trying their best in open weights, they immediately get triggered and talk about how shitty it is and everything negative and support deepseek and other recognizable chinese team. I don't hate the chinese team and yeah, they got alot of good release but we are losing recognition with Mistral AI, google, Microsoft, etc. We should be thankful that Microsoft and google (US) and Mistral AI are trying their best to be the best open weight contenders. At least r/OpenAI has a bunch of people interested in OpenAI. But I agree, give them a chance at open weights.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6ibl2y",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thats actually agreeable. Whenever there is a company trying their best in open weights, they immediately get triggered and talk about how shitty it is and everything negative and support deepseek and other recognizable chinese team. I don&amp;#39;t hate the chinese team and yeah, they got alot of good release but we are losing recognition with Mistral AI, google, Microsoft, etc. We should be thankful that Microsoft and google (US) and Mistral AI are trying their best to be the best open weight contenders. At least &lt;a href=\"/r/OpenAI\"&gt;r/OpenAI&lt;/a&gt; has a bunch of people interested in OpenAI. But I agree, give them a chance at open weights.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ibl2y/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754132988,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 0
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6ekuhg",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Sky-kunn",
            "can_mod_post": false,
            "created_utc": 1754076628,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 17,
            "author_fullname": "t2_ahgkl0do",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Every time there's a post about OpenAI open-weight models, r/LocalLLaMA gets unnecessarily fussy in the comments. It's so tiring... I get that you don't like OpenAI, I don't either, but let's at least try to be a little less annoying and pretend we actually want another good open weight model.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6ekuhg",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Every time there&amp;#39;s a post about OpenAI open-weight models, r/LocalLLaMA gets unnecessarily fussy in the comments. It&amp;#39;s so tiring... I get that you don&amp;#39;t like OpenAI, I don&amp;#39;t either, but let&amp;#39;s at least try to be a little less annoying and pretend we actually want another good open weight model.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6ekuhg/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754076628,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 17
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6gacjw",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "PlaneTheory5",
            "can_mod_post": false,
            "created_utc": 1754096830,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 2,
            "author_fullname": "t2_zuagj4gmi",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Willing to bet that this model will disappoint. They really should take xAI’s approach (at least in practice, still waiting for OS grok 2+3) of releasing previous gen models as open source (so o1, gpt-4 turbo, gpt-3.5, o3 mini).",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6gacjw",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Willing to bet that this model will disappoint. They really should take xAI’s approach (at least in practice, still waiting for OS grok 2+3) of releasing previous gen models as open source (so o1, gpt-4 turbo, gpt-3.5, o3 mini).&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6gacjw/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754096830,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6i7nlk",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "My_Unbiased_Opinion",
            "can_mod_post": false,
            "created_utc": 1754130907,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 2,
            "author_fullname": "t2_esiyl0yb",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Guys, it's gonna release Friday. I just don't know which Friday. ",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6i7nlk",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Guys, it&amp;#39;s gonna release Friday. I just don&amp;#39;t know which Friday. &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6i7nlk/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754130907,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6iyqwn",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "procgen",
                      "can_mod_post": false,
                      "created_utc": 1754142551,
                      "send_replies": true,
                      "parent_id": "t1_n6gmys7",
                      "score": 2,
                      "author_fullname": "t2_d3pr9",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Do you actually want to bet? Say, $100 to a charity of the winner's choosing?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6iyqwn",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you actually want to bet? Say, $100 to a charity of the winner&amp;#39;s choosing?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6iyqwn/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754142551,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6gmys7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Pvt_Twinkietoes",
            "can_mod_post": false,
            "created_utc": 1754101538,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 2,
            "author_fullname": "t2_3k9qfjsr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The \"leak\" was probably just to quell the noise people are making that they're dragging their feets on OSS release. I bet we won't see actual release until next year.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6gmys7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The &amp;quot;leak&amp;quot; was probably just to quell the noise people are making that they&amp;#39;re dragging their feets on OSS release. I bet we won&amp;#39;t see actual release until next year.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6gmys7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754101538,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6he4wp",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "BoJackHorseMan53",
            "can_mod_post": false,
            "created_utc": 1754113728,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 2,
            "author_fullname": "t2_58t8ty6v",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Can we please stop talking to OpenAI unless they release a model?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6he4wp",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can we please stop talking to OpenAI unless they release a model?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6he4wp/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754113728,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6fiy54",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "DeliciousAd2134",
                      "can_mod_post": false,
                      "created_utc": 1754087161,
                      "send_replies": true,
                      "parent_id": "t1_n6egrtt",
                      "score": 1,
                      "author_fullname": "t2_7v8je50q",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Can you list two of those 10 times?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6fiy54",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you list two of those 10 times?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6fiy54/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754087161,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6egrtt",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "shroddy",
            "can_mod_post": false,
            "created_utc": 1754075418,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 6,
            "author_fullname": "t2_10idu2",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "We will release it next week, this time for real, unlike the 10 times before when we said we release it next week",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6egrtt",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We will release it next week, this time for real, unlike the 10 times before when we said we release it next week&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6egrtt/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754075418,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6iwvos",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Nekasus",
                      "can_mod_post": false,
                      "created_utc": 1754141880,
                      "send_replies": true,
                      "parent_id": "t1_n6g5cov",
                      "score": 1,
                      "author_fullname": "t2_effn0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "And bland as fuck.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6iwvos",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And bland as fuck.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6iwvos/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754141880,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6g5cov",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Biggest_Cans",
            "can_mod_post": false,
            "created_utc": 1754094997,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 2,
            "author_fullname": "t2_avkl9k31",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Not related (probably) but the newest stealth model on OpenRouter is fire, fast as hell, and doesn't even need thinking. Just wanted to let you all know by hijacking a comment in the top thread.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6g5cov",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not related (probably) but the newest stealth model on OpenRouter is fire, fast as hell, and doesn&amp;#39;t even need thinking. Just wanted to let you all know by hijacking a comment in the top thread.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6g5cov/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754094997,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6hwiqm",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "blankboy2022",
                      "can_mod_post": false,
                      "created_utc": 1754124239,
                      "send_replies": true,
                      "parent_id": "t1_n6huxco",
                      "score": 1,
                      "author_fullname": "t2_42ba8hq5",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Prolly too low? I mean I've seen larger models in FP8 or even higher precision.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6hwiqm",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Prolly too low? I mean I&amp;#39;ve seen larger models in FP8 or even higher precision.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6hwiqm/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754124239,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6huxco",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "bblankuser",
            "can_mod_post": false,
            "created_utc": 1754123250,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 1,
            "author_fullname": "t2_ctt6ls8q9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "OOTL, what's wrong with FP4?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6huxco",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;OOTL, what&amp;#39;s wrong with FP4?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6huxco/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754123250,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6j42c5",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Maleficent_Age1577",
            "can_mod_post": false,
            "created_utc": 1754144398,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 1,
            "author_fullname": "t2_gxl5vlowd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "We probably wait that openai opensource model longer than Gta 6.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6j42c5",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We probably wait that openai opensource model longer than Gta 6.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6j42c5/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754144398,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6g0q2t",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "_HandsomeJack_",
            "can_mod_post": false,
            "created_utc": 1754093295,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 1,
            "author_fullname": "t2_a60kp",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Considering the safety implications I have also decided to not open source or release any new LLM this week.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6g0q2t",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Considering the safety implications I have also decided to not open source or release any new LLM this week.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6g0q2t/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754093295,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6eeuum",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "hidden_kid",
            "can_mod_post": false,
            "created_utc": 1754074852,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 0,
            "author_fullname": "t2_3jo1n877",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Can't we all just wait, despite knowing the history of large corporations unnecessarily hyping this.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6eeuum",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can&amp;#39;t we all just wait, despite knowing the history of large corporations unnecessarily hyping this.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6eeuum/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754074852,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6fx6oa",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "not_good_for_much",
                      "can_mod_post": false,
                      "created_utc": 1754092034,
                      "send_replies": true,
                      "parent_id": "t1_n6few2r",
                      "score": 5,
                      "author_fullname": "t2_qxoqkt9f",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "4-bit floating point arithmetic.\n\nBasically, with most math, we want very precise numbers to calculate things exactly. So we use e.g FP32 or FP64, with 32 or 64 bits. These can represent numbers extremely precisely.\n\nBut each bit needs to be stored and processed. More precision = more computing power required.\n\nWith AI, we're basically breaking data down into pieces, and saying: \"how significant is each piece of data in certain configurations and convolutions?\"\n\nInitially, this was done with very precise numerical values (E.g FP32).  But it turns out that these AIs still work quite well when you essentially just score the importance from about 1-10 (needing just a few bits per value).\n\nThis costs some precision... But it's **so much faster and more memory efficient** that we can make up for this by simply making bigger and more complicated neural networks.",
                      "edited": 1754109207,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6fx6oa",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;4-bit floating point arithmetic.&lt;/p&gt;\n\n&lt;p&gt;Basically, with most math, we want very precise numbers to calculate things exactly. So we use e.g FP32 or FP64, with 32 or 64 bits. These can represent numbers extremely precisely.&lt;/p&gt;\n\n&lt;p&gt;But each bit needs to be stored and processed. More precision = more computing power required.&lt;/p&gt;\n\n&lt;p&gt;With AI, we&amp;#39;re basically breaking data down into pieces, and saying: &amp;quot;how significant is each piece of data in certain configurations and convolutions?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Initially, this was done with very precise numerical values (E.g FP32).  But it turns out that these AIs still work quite well when you essentially just score the importance from about 1-10 (needing just a few bits per value).&lt;/p&gt;\n\n&lt;p&gt;This costs some precision... But it&amp;#39;s &lt;strong&gt;so much faster and more memory efficient&lt;/strong&gt; that we can make up for this by simply making bigger and more complicated neural networks.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6fx6oa/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754092034,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 5
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6fjxxe",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "Jazzlike_Source_5983",
                      "can_mod_post": false,
                      "created_utc": 1754087499,
                      "send_replies": true,
                      "parent_id": "t1_n6few2r",
                      "score": 4,
                      "author_fullname": "t2_ap0ra8pe",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "FP4 precision refers to a floating-point number representation using only 4 bits to store a numerical value. This format significantly reduces the memory footprint and computational overhead of AI models, allowing for faster inference and training, especially in large language models. Search the web if you’d like to go deeper. It’s all there at the tap of a few buttons :)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6fjxxe",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;FP4 precision refers to a floating-point number representation using only 4 bits to store a numerical value. This format significantly reduces the memory footprint and computational overhead of AI models, allowing for faster inference and training, especially in large language models. Search the web if you’d like to go deeper. It’s all there at the tap of a few buttons :)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mf3tm9",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6fjxxe/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754087499,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6few2r",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Delivery_1049",
            "can_mod_post": false,
            "created_utc": 1754085807,
            "send_replies": true,
            "parent_id": "t3_1mf3tm9",
            "score": 0,
            "author_fullname": "t2_86zsjhs7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "What’s FP4?\n\nNoob here any captain to help?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6few2r",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What’s FP4?&lt;/p&gt;\n\n&lt;p&gt;Noob here any captain to help?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mf3tm9/the_leaked_120_b_openai_model_is_not_trained_in/n6few2r/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754085807,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mf3tm9",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        }
      ],
      "before": null
    }
  }
]