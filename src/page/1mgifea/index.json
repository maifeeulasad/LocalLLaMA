[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "\nHey LocalLLaMA team,\n\nI'm hoping someone much covered than me can help with a question about fine-tuning.\n\nI've been using the MLX library to fine-tune a model on my MacBook, but I need to test the model on other devices that aren't Macs. I'm wondering if there's a best practice for this workflow.\n\nIdeally, I'd like to keep the adapters separate from the base model, but if fusing them is the only way, that's fine too.\n\nSo far, I've only fine-tuned a quantized model and have tried converting the adapters to the PEFT format. The problem is, when I test the output on my MacBook, the base Hugging Face model works fine, but the model with the PEFT adapters just outputs gibberish. This might be due to a precision mismatch.\n\nAny advice or suggestions on how to handle this would be greatly appreciated!\n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "MLX -&gt; GGUF",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mgifea",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.75,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 4,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1hmx216rd2",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 4,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1754241546,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754225338,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey LocalLLaMA team,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping someone much covered than me can help with a question about fine-tuning.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using the MLX library to fine-tune a model on my MacBook, but I need to test the model on other devices that aren&amp;#39;t Macs. I&amp;#39;m wondering if there&amp;#39;s a best practice for this workflow.&lt;/p&gt;\n\n&lt;p&gt;Ideally, I&amp;#39;d like to keep the adapters separate from the base model, but if fusing them is the only way, that&amp;#39;s fine too.&lt;/p&gt;\n\n&lt;p&gt;So far, I&amp;#39;ve only fine-tuned a quantized model and have tried converting the adapters to the PEFT format. The problem is, when I test the output on my MacBook, the base Hugging Face model works fine, but the model with the PEFT adapters just outputs gibberish. This might be due to a precision mismatch.&lt;/p&gt;\n\n&lt;p&gt;Any advice or suggestions on how to handle this would be greatly appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mgifea",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Not_Another_LLM",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mgifea/mlx_gguf/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mgifea/mlx_gguf/",
            "subreddit_subscribers": 509625,
            "created_utc": 1754225338,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n6q56ch",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Not_Another_LLM",
                      "can_mod_post": false,
                      "created_utc": 1754241624,
                      "send_replies": true,
                      "parent_id": "t1_n6q3rb6",
                      "score": 1,
                      "author_fullname": "t2_1hmx216rd2",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Hi, this is going to be the next thing I try tomorrow and see how I get on.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6q56ch",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hi, this is going to be the next thing I try tomorrow and see how I get on.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mgifea",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mgifea/mlx_gguf/n6q56ch/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754241624,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6q3rb6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "chibop1",
            "can_mod_post": false,
            "created_utc": 1754241204,
            "send_replies": true,
            "parent_id": "t3_1mgifea",
            "score": 1,
            "author_fullname": "t2_e9jh97s",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Have you tried this?\n\n* Fuse your MLX lora with base model using mlx_lm.fuse.\n* Then export the fused model to gguf using mlx_lm.fuse --export-gguf.\n\nhttps://github.com/ml-explore/mlx-lm/blob/main/mlx_lm/LORA.md",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6q3rb6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have you tried this?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Fuse your MLX lora with base model using mlx_lm.fuse.&lt;/li&gt;\n&lt;li&gt;Then export the fused model to gguf using mlx_lm.fuse --export-gguf.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ml-explore/mlx-lm/blob/main/mlx_lm/LORA.md\"&gt;https://github.com/ml-explore/mlx-lm/blob/main/mlx_lm/LORA.md&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mgifea/mlx_gguf/n6q3rb6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754241204,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mgifea",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]