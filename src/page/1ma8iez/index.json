[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Yo, I’m new to this whole local AI model thing. My setup’s got 16GB RAM and a GTX1650 with 4GB VRAM—yeah, I know it’s weak.\n\nI started with the model **mythomax-l2-13b.Q5\\_K\\_S.gguf** (yeah, kinda overkill for my setup) running on **oobabooga/text-generation-webui**. First time I tried it, everything worked fine—chat mode was dope, characters were on point, RAM was maxed but I still had 1–2GB free, VRAM full, all good.\n\nThen I killed the console to shut it down (thought that was normal), but when I booted it back up the next time, everything went to hell. Now it’s crazy slow, RAM’s almost completely eaten (less than 500MB free), and the chat mode feels dumb—like just a generic AI assistant.\n\nI tried lowering `ctx-size`, still the same issue: RAM full, performance trash. I even deleted the entire **oobabooga/text-generation-webui** folder to start fresh, but when I reopened the WebUI, nothing changed—like my old settings and chats were still there. Tried deleting all chats thinking maybe it was token bloat, but nope, same problem.\n\nAnyone got any suggestions to fix this?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "hay everyone I'm new here help please",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1ma8iez",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.14,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1quxz8adxt",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753575468,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yo, I’m new to this whole local AI model thing. My setup’s got 16GB RAM and a GTX1650 with 4GB VRAM—yeah, I know it’s weak.&lt;/p&gt;\n\n&lt;p&gt;I started with the model &lt;strong&gt;mythomax-l2-13b.Q5_K_S.gguf&lt;/strong&gt; (yeah, kinda overkill for my setup) running on &lt;strong&gt;oobabooga/text-generation-webui&lt;/strong&gt;. First time I tried it, everything worked fine—chat mode was dope, characters were on point, RAM was maxed but I still had 1–2GB free, VRAM full, all good.&lt;/p&gt;\n\n&lt;p&gt;Then I killed the console to shut it down (thought that was normal), but when I booted it back up the next time, everything went to hell. Now it’s crazy slow, RAM’s almost completely eaten (less than 500MB free), and the chat mode feels dumb—like just a generic AI assistant.&lt;/p&gt;\n\n&lt;p&gt;I tried lowering &lt;code&gt;ctx-size&lt;/code&gt;, still the same issue: RAM full, performance trash. I even deleted the entire &lt;strong&gt;oobabooga/text-generation-webui&lt;/strong&gt; folder to start fresh, but when I reopened the WebUI, nothing changed—like my old settings and chats were still there. Tried deleting all chats thinking maybe it was token bloat, but nope, same problem.&lt;/p&gt;\n\n&lt;p&gt;Anyone got any suggestions to fix this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1ma8iez",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "-Fibon4cci",
            "discussion_type": null,
            "num_comments": 6,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1ma8iez/hay_everyone_im_new_here_help_please/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1ma8iez/hay_everyone_im_new_here_help_please/",
            "subreddit_subscribers": 505616,
            "created_utc": 1753575468,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5dkjnx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Linkpharm2",
            "can_mod_post": false,
            "created_utc": 1753587868,
            "send_replies": true,
            "parent_id": "t3_1ma8iez",
            "score": 2,
            "author_fullname": "t2_9oid4hi0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Model size * quant/8. So in your case, 13*(5/8). 8.125Gb, then there's a little more so 10. Assuming you offload 3.8gb, then windows takes like 6, 12.2GB with no programs or browers or anything. Also, llm stuff loves to leak ram.\n\n\nThat model is decent, but also pretty old. Try Q6 of this for a fast experience https://huggingface.co/BeaverAI/Voxtral-RP-3B-v1c-GGUF and this https://huggingface.co/TheDrummer/Tiger-Gemma-12B-v3-GGUF q4, pretty slow but also smarter.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5dkjnx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Model size * quant/8. So in your case, 13*(5/8). 8.125Gb, then there&amp;#39;s a little more so 10. Assuming you offload 3.8gb, then windows takes like 6, 12.2GB with no programs or browers or anything. Also, llm stuff loves to leak ram.&lt;/p&gt;\n\n&lt;p&gt;That model is decent, but also pretty old. Try Q6 of this for a fast experience &lt;a href=\"https://huggingface.co/BeaverAI/Voxtral-RP-3B-v1c-GGUF\"&gt;https://huggingface.co/BeaverAI/Voxtral-RP-3B-v1c-GGUF&lt;/a&gt; and this &lt;a href=\"https://huggingface.co/TheDrummer/Tiger-Gemma-12B-v3-GGUF\"&gt;https://huggingface.co/TheDrummer/Tiger-Gemma-12B-v3-GGUF&lt;/a&gt; q4, pretty slow but also smarter.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma8iez/hay_everyone_im_new_here_help_please/n5dkjnx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753587868,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma8iez",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5cs3ki",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "HypnoDaddy4You",
            "can_mod_post": false,
            "created_utc": 1753576389,
            "send_replies": true,
            "parent_id": "t3_1ma8iez",
            "score": 1,
            "author_fullname": "t2_lb2n7mbsw",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I definitely just close the console when I'm done using it.\n\nHave you reboot your system? Checked for programs that are a memory hog? You can use task manager, your gpu ram should be almost empty when you launch it",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5cs3ki",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I definitely just close the console when I&amp;#39;m done using it.&lt;/p&gt;\n\n&lt;p&gt;Have you reboot your system? Checked for programs that are a memory hog? You can use task manager, your gpu ram should be almost empty when you launch it&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma8iez/hay_everyone_im_new_here_help_please/n5cs3ki/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753576389,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma8iez",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5dnboq",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Ill-Fishing-1451",
            "can_mod_post": false,
            "created_utc": 1753589111,
            "send_replies": true,
            "parent_id": "t3_1ma8iez",
            "score": 1,
            "author_fullname": "t2_makt8lj56",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "2 ways to go:\n\n1. Check out the llama.cpp server documentation  \n[https://github.com/ggml-org/llama.cpp/tree/master/tools/server](https://github.com/ggml-org/llama.cpp/tree/master/tools/server)  \nMake sure you are using the correct settings like offloading, temperature, top-p, etc.\n\n2. Change from oobabooga to LM studio, which is way more beginner-friendly.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5dnboq",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;2 ways to go:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Check out the llama.cpp server documentation&lt;br/&gt;\n&lt;a href=\"https://github.com/ggml-org/llama.cpp/tree/master/tools/server\"&gt;https://github.com/ggml-org/llama.cpp/tree/master/tools/server&lt;/a&gt;&lt;br/&gt;\nMake sure you are using the correct settings like offloading, temperature, top-p, etc.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Change from oobabooga to LM studio, which is way more beginner-friendly.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma8iez/hay_everyone_im_new_here_help_please/n5dnboq/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753589111,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma8iez",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5e1qvs",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "GPTshop_ai",
            "can_mod_post": false,
            "created_utc": 1753596297,
            "send_replies": true,
            "parent_id": "t3_1ma8iez",
            "score": 0,
            "author_fullname": "t2_rkmud0isr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hi, I have a raspberry pie and want to run deepseek R1 in FP16....",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5e1qvs",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have a raspberry pie and want to run deepseek R1 in FP16....&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma8iez/hay_everyone_im_new_here_help_please/n5e1qvs/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753596297,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1ma8iez",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 0
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5ezudh",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "jacek2023",
            "can_mod_post": false,
            "created_utc": 1753615775,
            "send_replies": true,
            "parent_id": "t3_1ma8iez",
            "score": 1,
            "author_fullname": "t2_vqgbql9w",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "start with 4B models",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5ezudh",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;start with 4B models&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1ma8iez/hay_everyone_im_new_here_help_please/n5ezudh/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753615775,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1ma8iez",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]