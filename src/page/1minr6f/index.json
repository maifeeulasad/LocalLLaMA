[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Hi fellows,\n\n  \nI've just (excitedly) downloaded the new open source model by OpenAI (20b version) and ran it on my 4070 Ti (12 GB VRAM, 32 GB system RAM).\n\nAaaand... it's 2.5x slower than the 4-bit quantized Qwen 3 30b A3B 2507 Instruct. Why? I have updated to the newest version of Ollama (yes, folks, I know vLLM and LM Studio exists), but am getting ridicolously low speeds:\n\n|Model|Average speed in tok/s|\n|:-|:-|\n|GPT-OSS 20b|12.07|\n|Qwen 3 30b A3B Q4\\_K\\_M 2507 Instruct|31.5|\n\n  \nBesides the speed - I don't want to hate - the model kind of sucks at anything that's not English. I've consulted the website of OpenAI, which said that they \"mostly\" trained it on English data, but does that mean the model is not multilingual? Because the performance in German is really, really underwhelming. Like, on the level of Gemma 3 4b Q4\\_K\\_M, which is sooo much smaller than GPT-OSS.\n\nI've then ran it over a set of custom benchmarks (math, reasoning, translation) that are unpublished and it... did not meet my expectations, to say it politely.\n\nWhy would I want to use a much slower, smaller model that cannot take it up with the competition (mostly Qwen)?\n\n  \nAnd lastly, how damn censored did they make this thing? It constantly talks about \"policy\" in its thinking process, all the fricking time, wasting time and tokens when it's not even relevant.\n\nKind of underwhelming for anything non-english.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Is it just me?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1minr6f",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.7,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 4,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_cyrs5dhp",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 4,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754433647,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi fellows,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just (excitedly) downloaded the new open source model by OpenAI (20b version) and ran it on my 4070 Ti (12 GB VRAM, 32 GB system RAM).&lt;/p&gt;\n\n&lt;p&gt;Aaaand... it&amp;#39;s 2.5x slower than the 4-bit quantized Qwen 3 30b A3B 2507 Instruct. Why? I have updated to the newest version of Ollama (yes, folks, I know vLLM and LM Studio exists), but am getting ridicolously low speeds:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Model&lt;/th&gt;\n&lt;th align=\"left\"&gt;Average speed in tok/s&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;GPT-OSS 20b&lt;/td&gt;\n&lt;td align=\"left\"&gt;12.07&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Qwen 3 30b A3B Q4_K_M 2507 Instruct&lt;/td&gt;\n&lt;td align=\"left\"&gt;31.5&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Besides the speed - I don&amp;#39;t want to hate - the model kind of sucks at anything that&amp;#39;s not English. I&amp;#39;ve consulted the website of OpenAI, which said that they &amp;quot;mostly&amp;quot; trained it on English data, but does that mean the model is not multilingual? Because the performance in German is really, really underwhelming. Like, on the level of Gemma 3 4b Q4_K_M, which is sooo much smaller than GPT-OSS.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve then ran it over a set of custom benchmarks (math, reasoning, translation) that are unpublished and it... did not meet my expectations, to say it politely.&lt;/p&gt;\n\n&lt;p&gt;Why would I want to use a much slower, smaller model that cannot take it up with the competition (mostly Qwen)?&lt;/p&gt;\n\n&lt;p&gt;And lastly, how damn censored did they make this thing? It constantly talks about &amp;quot;policy&amp;quot; in its thinking process, all the fricking time, wasting time and tokens when it&amp;#39;s not even relevant.&lt;/p&gt;\n\n&lt;p&gt;Kind of underwhelming for anything non-english.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1minr6f",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "Final_Wheel_7486",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1minr6f/is_it_just_me/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1minr6f/is_it_just_me/",
            "subreddit_subscribers": 511364,
            "created_utc": 1754433647,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n759hlf",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754440164,
                      "send_replies": true,
                      "parent_id": "t1_n74v1o1",
                      "score": 1,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "The README literally says it's trained on English.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n759hlf",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The README literally says it&amp;#39;s trained on English.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1minr6f",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1minr6f/is_it_just_me/n759hlf/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754440164,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n74v1o1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ShengrenR",
            "can_mod_post": false,
            "created_utc": 1754435317,
            "send_replies": true,
            "parent_id": "t3_1minr6f",
            "score": 3,
            "author_fullname": "t2_ji4n4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It's really not meant to be multi-lingual I don't think - you want mistral or some other model for that if you want to use in other languages.\n\nMy main observation with them so far (at least the big one via openrouter) is it seems very disconnected to the normal experience of reality. Like I asked a question regarding passing messages between people who would be in a room at different times and it suggested   \n\"Jimmy can give a distinct sound (e.g., a short clap) that Sarah can hear when she re‑enters (if the room isn't silent). The presence/absence of the clap tells her whether a move happened.\" .. that's not .. how sound works, my guy.  Lots of other little things crop up that are just a bit head-scratching.\n\nI suspect a heavy dose of RL optimized the thing for all sorts of 'logic'-y patterns and math and code, but also drifted it away from the normal boring stuff you find in the training data.. like.. sound doesn't linger for the next user when it's a room.\n\nHopefully first-day hiccups like llama-4 had all over and they fix something like 'oh, the attention sink actually has to XYZ' but so far lots of rough edges.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n74v1o1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s really not meant to be multi-lingual I don&amp;#39;t think - you want mistral or some other model for that if you want to use in other languages.&lt;/p&gt;\n\n&lt;p&gt;My main observation with them so far (at least the big one via openrouter) is it seems very disconnected to the normal experience of reality. Like I asked a question regarding passing messages between people who would be in a room at different times and it suggested&lt;br/&gt;\n&amp;quot;Jimmy can give a distinct sound (e.g., a short clap) that Sarah can hear when she re‑enters (if the room isn&amp;#39;t silent). The presence/absence of the clap tells her whether a move happened.&amp;quot; .. that&amp;#39;s not .. how sound works, my guy.  Lots of other little things crop up that are just a bit head-scratching.&lt;/p&gt;\n\n&lt;p&gt;I suspect a heavy dose of RL optimized the thing for all sorts of &amp;#39;logic&amp;#39;-y patterns and math and code, but also drifted it away from the normal boring stuff you find in the training data.. like.. sound doesn&amp;#39;t linger for the next user when it&amp;#39;s a room.&lt;/p&gt;\n\n&lt;p&gt;Hopefully first-day hiccups like llama-4 had all over and they fix something like &amp;#39;oh, the attention sink actually has to XYZ&amp;#39; but so far lots of rough edges.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1minr6f/is_it_just_me/n74v1o1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754435317,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1minr6f",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        }
      ],
      "before": null
    }
  }
]