[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Was watching the live and caught this small mistake and thought it was funny. \nOn a serious note the benchmarks shown in the demo imply a significant improvement and it's good that they have made the model naming simpler. It comes in 3 variants regular, mini and nano which is chosen based on the complexity of the prompt.\nContext size : 272k, output size: 128k including invisible reasoning tokens. (Slightly disappointed with this, could've done better). \nThey show great reductions in hallucinations which are yet to be verified. They also seem to have trained on a lot of health related questions as we saw a cancer patient talk about her experience using GPT-5 for being informed. The api now includes a new parameter \"minimal\" for its thinking so it does less thinking which is great to save cost by reducing reasoning tokens. Overall it seems to be a good model with very few drawbacks but can only be inferred after testing it ourselves. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "GPT-5 benchmarks graph gone wrong and some thoughts about the model",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "New Model"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 118,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mk763x",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.64,
            "author_flair_background_color": null,
            "ups": 9,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_sawf0qmu",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "New Model",
            "can_mod_post": false,
            "score": 9,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/Qivjg6bxq1__5t1rmoSnP2Fg9YlZIzu0SlAHiJ4BLNU.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754589558,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was watching the live and caught this small mistake and thought it was funny. \nOn a serious note the benchmarks shown in the demo imply a significant improvement and it&amp;#39;s good that they have made the model naming simpler. It comes in 3 variants regular, mini and nano which is chosen based on the complexity of the prompt.\nContext size : 272k, output size: 128k including invisible reasoning tokens. (Slightly disappointed with this, could&amp;#39;ve done better). \nThey show great reductions in hallucinations which are yet to be verified. They also seem to have trained on a lot of health related questions as we saw a cancer patient talk about her experience using GPT-5 for being informed. The api now includes a new parameter &amp;quot;minimal&amp;quot; for its thinking so it does less thinking which is great to save cost by reducing reasoning tokens. Overall it seems to be a good model with very few drawbacks but can only be inferred after testing it ourselves. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/p9m29vqkzmhf1.png",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/p9m29vqkzmhf1.png?auto=webp&amp;s=134e6a3333341eccbca7027eba2aee10bb8a47f0",
                    "width": 1080,
                    "height": 913
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/p9m29vqkzmhf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f5804ab15d07ff34ed6af791057b11f2565a2af4",
                      "width": 108,
                      "height": 91
                    },
                    {
                      "url": "https://preview.redd.it/p9m29vqkzmhf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a273596411dcb57a435b6a668a846b539b8b75bb",
                      "width": 216,
                      "height": 182
                    },
                    {
                      "url": "https://preview.redd.it/p9m29vqkzmhf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=573f8cdc288e4753c3db37c6bf4df1d4d8e8081c",
                      "width": 320,
                      "height": 270
                    },
                    {
                      "url": "https://preview.redd.it/p9m29vqkzmhf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4bcd4e95b0d6dbc6f5c78bd1a1c94146639f8034",
                      "width": 640,
                      "height": 541
                    },
                    {
                      "url": "https://preview.redd.it/p9m29vqkzmhf1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4e0b75de752c1d0d8c9cfb0462b8b3db03ab93a7",
                      "width": 960,
                      "height": 811
                    },
                    {
                      "url": "https://preview.redd.it/p9m29vqkzmhf1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=531bcc796ab619c0e95c17d76abcbfc6cbebb057",
                      "width": 1080,
                      "height": 913
                    }
                  ],
                  "variants": {},
                  "id": "5reX955O749sQU6xDdZtc82eDxO0onJ7IFLpapxT_t8"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "ced98442-f5d3-11ed-b657-66d3b15490c6",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#ffb000",
            "id": "1mk763x",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "SherbertLegitimate50",
            "discussion_type": null,
            "num_comments": 1,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mk763x/gpt5_benchmarks_graph_gone_wrong_and_some/",
            "stickied": false,
            "url": "https://i.redd.it/p9m29vqkzmhf1.png",
            "subreddit_subscribers": 513417,
            "created_utc": 1754589558,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7hyl8k",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Medium_Chemist_4032",
            "can_mod_post": false,
            "created_utc": 1754604859,
            "send_replies": true,
            "parent_id": "t3_1mk763x",
            "score": 2,
            "author_fullname": "t2_aunwxc2u",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Judging by the number of posts pointing out this error, I'm assuming that was their true goal here",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7hyl8k",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Judging by the number of posts pointing out this error, I&amp;#39;m assuming that was their true goal here&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mk763x/gpt5_benchmarks_graph_gone_wrong_and_some/n7hyl8k/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754604859,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mk763x",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]