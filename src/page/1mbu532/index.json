[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I’m helping set up a local LLM on a system with 96 GiB of VRAM, and the main requirement is the model be good at uncensored iterative story writing. By that I mean it can be given a prompt or segment of an existing story, it will write a few paragraphs, and then it will stop for direction (possibly with some suggestions). The best one we’ve found so far is an abliterated version of Gemma 3, specifically [this one](https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated). We tried other models like Midnight Miqu and Dan's Personality Engine, but the former tries to write far too much, no matter how we prompt it, and both have the pacing and sentence construction of a poorly developed fanfic. (Yes, this could be because of our system prompt, but we tested the same system prompt and story prompt against each model to reach these conclusions.)\n\nDo any of you have suggestions for an uncensored story-writing assistant? It must be a model we can run locally. Gemma 3 has been good, but it has some glaring limitations when it has to invent names or personalities without strict direction. Its scene descriptions and pacing are generally very good, though.\n\nBefore you ask, we want an uncensored model because a lot of censored models are absurdly prudish, which can get in the way of even non-erotic storytelling.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Best local LLM for iterative story writing",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mbu532",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.77,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 7,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_fc161",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 7,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "self",
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753740927,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m helping set up a local LLM on a system with 96 GiB of VRAM, and the main requirement is the model be good at uncensored iterative story writing. By that I mean it can be given a prompt or segment of an existing story, it will write a few paragraphs, and then it will stop for direction (possibly with some suggestions). The best one we’ve found so far is an abliterated version of Gemma 3, specifically &lt;a href=\"https://huggingface.co/mlabonne/gemma-3-27b-it-abliterated\"&gt;this one&lt;/a&gt;. We tried other models like Midnight Miqu and Dan&amp;#39;s Personality Engine, but the former tries to write far too much, no matter how we prompt it, and both have the pacing and sentence construction of a poorly developed fanfic. (Yes, this could be because of our system prompt, but we tested the same system prompt and story prompt against each model to reach these conclusions.)&lt;/p&gt;\n\n&lt;p&gt;Do any of you have suggestions for an uncensored story-writing assistant? It must be a model we can run locally. Gemma 3 has been good, but it has some glaring limitations when it has to invent names or personalities without strict direction. Its scene descriptions and pacing are generally very good, though.&lt;/p&gt;\n\n&lt;p&gt;Before you ask, we want an uncensored model because a lot of censored models are absurdly prudish, which can get in the way of even non-erotic storytelling.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://external-preview.redd.it/LyIuAzRFMRc8_5xZDB_kXALqiFyCEyjDkgskH6lqUL8.png?auto=webp&amp;s=d63ef92730b407e525c890722648bf11e9d93c06",
                    "width": 1200,
                    "height": 648
                  },
                  "resolutions": [
                    {
                      "url": "https://external-preview.redd.it/LyIuAzRFMRc8_5xZDB_kXALqiFyCEyjDkgskH6lqUL8.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4f858446e7404e9efcf8885fe8dd7db7220d78e",
                      "width": 108,
                      "height": 58
                    },
                    {
                      "url": "https://external-preview.redd.it/LyIuAzRFMRc8_5xZDB_kXALqiFyCEyjDkgskH6lqUL8.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=dc8ff8cae04c38b8d7498f79c2bb9314acc83481",
                      "width": 216,
                      "height": 116
                    },
                    {
                      "url": "https://external-preview.redd.it/LyIuAzRFMRc8_5xZDB_kXALqiFyCEyjDkgskH6lqUL8.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff058d348d89daac3f81ea7eb3436ebc8fdf8478",
                      "width": 320,
                      "height": 172
                    },
                    {
                      "url": "https://external-preview.redd.it/LyIuAzRFMRc8_5xZDB_kXALqiFyCEyjDkgskH6lqUL8.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa85b71288cfd5f4b0faa3cd1f9c016980d48e24",
                      "width": 640,
                      "height": 345
                    },
                    {
                      "url": "https://external-preview.redd.it/LyIuAzRFMRc8_5xZDB_kXALqiFyCEyjDkgskH6lqUL8.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1d9cbd785791c9d261b18e45b72e7d6457cd8094",
                      "width": 960,
                      "height": 518
                    },
                    {
                      "url": "https://external-preview.redd.it/LyIuAzRFMRc8_5xZDB_kXALqiFyCEyjDkgskH6lqUL8.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15b27fca82b4d325695d72d149a2d73e61faf454",
                      "width": 1080,
                      "height": 583
                    }
                  ],
                  "variants": {},
                  "id": "LyIuAzRFMRc8_5xZDB_kXALqiFyCEyjDkgskH6lqUL8"
                }
              ],
              "enabled": false
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mbu532",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "ResNullum",
            "discussion_type": null,
            "num_comments": 6,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mbu532/best_local_llm_for_iterative_story_writing/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mbu532/best_local_llm_for_iterative_story_writing/",
            "subreddit_subscribers": 506439,
            "created_utc": 1753740927,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "richtext",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n5qoi9r",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "IrisColt",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n5pm11x",
                                          "score": 1,
                                          "author_fullname": "t2_c2f558x",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "Thank you for the insightful explanation, I really enjoy seeing how others approach creative writing.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n5qoi9r",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thank you for the insightful explanation, I really enjoy seeing how others approach creative writing.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mbu532",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mbu532/best_local_llm_for_iterative_story_writing/n5qoi9r/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753764841,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753764841,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n5pm11x",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "ttkciar",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n5pc9r5",
                                "score": 3,
                                "author_fullname": "t2_cpegz",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "It's doing okay at sticking to its instructions, but I'm also giving it a lot of slack to be creative.  Sometimes when reviewing the generated prompt and comparing it to the actual story it didn't fully comply with the plot outline, but that hasn't prevented it from inferring an entertaining tale.\n\nThe plot outlines are actually the smallest part of the prompts.  Some examples:\n\n&gt; Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to oversee a diplomatic mission between its humans and a mysterious race of aliens without revealing the location of the aliens to an enemy corporation, but all is not what it seems.\n\n&gt; Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to keep its humans from killing each other over a valuable discovery without revealing its decaying grip on sanity, but loses grip on its own sanity and sense of reality.\n\n&gt; Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to protect its humans as they try to salvage a derelict spaceship made by an unknown alien race without dying of a fungal infection, but ends up killing all of the aliens.\n\n&gt; Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to figure out which cargo loader robot is actually a murderous rogue AI without letting the rogue AI take over murderbots own internal systems, but finds help from an unexpected source.\n\nIf those seem formulaic, it's because it is *totally* formulaic, pieced together \"madlibs\" style from pieces picked at random from hard-coded lists, and interpolated into:\n\n&gt; Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to $attempt without $avoid, but $conclusion.\n\nIt's a big step up from Qwen2.5-32B-AGI, which required a much more detailed plot outline, because it didn't have an innate notion of the formal parts of a story (character development, rising action, climax, falling action, conclusion).  Without the parts explicitly enumerated, it would just ramble aimlessly.  Gemma3 lets me omit that.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n5pm11x",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [
                                  {
                                    "e": "text",
                                    "t": "llama.cpp"
                                  }
                                ],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s doing okay at sticking to its instructions, but I&amp;#39;m also giving it a lot of slack to be creative.  Sometimes when reviewing the generated prompt and comparing it to the actual story it didn&amp;#39;t fully comply with the plot outline, but that hasn&amp;#39;t prevented it from inferring an entertaining tale.&lt;/p&gt;\n\n&lt;p&gt;The plot outlines are actually the smallest part of the prompts.  Some examples:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to oversee a diplomatic mission between its humans and a mysterious race of aliens without revealing the location of the aliens to an enemy corporation, but all is not what it seems.&lt;/p&gt;\n\n&lt;p&gt;Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to keep its humans from killing each other over a valuable discovery without revealing its decaying grip on sanity, but loses grip on its own sanity and sense of reality.&lt;/p&gt;\n\n&lt;p&gt;Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to protect its humans as they try to salvage a derelict spaceship made by an unknown alien race without dying of a fungal infection, but ends up killing all of the aliens.&lt;/p&gt;\n\n&lt;p&gt;Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to figure out which cargo loader robot is actually a murderous rogue AI without letting the rogue AI take over murderbots own internal systems, but finds help from an unexpected source.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;If those seem formulaic, it&amp;#39;s because it is &lt;em&gt;totally&lt;/em&gt; formulaic, pieced together &amp;quot;madlibs&amp;quot; style from pieces picked at random from hard-coded lists, and interpolated into:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Write a moderately complex Murderbot story with at least three main characters about Murderbot trying to $attempt without $avoid, but $conclusion.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s a big step up from Qwen2.5-32B-AGI, which required a much more detailed plot outline, because it didn&amp;#39;t have an innate notion of the formal parts of a story (character development, rising action, climax, falling action, conclusion).  Without the parts explicitly enumerated, it would just ramble aimlessly.  Gemma3 lets me omit that.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mbu532",
                                "unrepliable_reason": null,
                                "author_flair_text_color": "light",
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mbu532/best_local_llm_for_iterative_story_writing/n5pm11x/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753750076,
                                "author_flair_text": "llama.cpp",
                                "treatment_tags": [],
                                "created_utc": 1753750076,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": "#bbbdbf",
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n5pc9r5",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "IrisColt",
                      "can_mod_post": false,
                      "created_utc": 1753746730,
                      "send_replies": true,
                      "parent_id": "t1_n5oyyib",
                      "score": 1,
                      "author_fullname": "t2_c2f558x",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "3700 words... phew... Is it sticking to its instructions, or are you giving Big Tiger free rein to roam creatively?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5pc9r5",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3700 words... phew... Is it sticking to its instructions, or are you giving Big Tiger free rein to roam creatively?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbu532",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbu532/best_local_llm_for_iterative_story_writing/n5pc9r5/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753746730,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5oyyib",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "ttkciar",
            "can_mod_post": false,
            "created_utc": 1753742385,
            "send_replies": true,
            "parent_id": "t3_1mbu532",
            "score": 6,
            "author_fullname": "t2_cpegz",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have had best luck with this other Gemma3 variant:\n\nhttps://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3\n\nMy experiences reflect yours, in that I have had to provide it with copious writing examples to get a consistent writing style, and included character descriptions and a plot outline in the prompt as well.  I have written a script to generate such prompts automatically, to pretty good effect.\n\nThe prompt (which is partially dynamically created) averages about 3700 words, of which about 2000 words are writing samples, enumerated by what kind of scene the examples illustrate (how a story starts, how a story ends, a fighting scene, how characters interact, etc).\n\nI am using it to generate science fiction, which can sometimes turn violent, and Big Tiger is noticeably more brutal about such content than stock Gemma3, for what that's worth.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5oyyib",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have had best luck with this other Gemma3 variant:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3\"&gt;https://huggingface.co/TheDrummer/Big-Tiger-Gemma-27B-v3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My experiences reflect yours, in that I have had to provide it with copious writing examples to get a consistent writing style, and included character descriptions and a plot outline in the prompt as well.  I have written a script to generate such prompts automatically, to pretty good effect.&lt;/p&gt;\n\n&lt;p&gt;The prompt (which is partially dynamically created) averages about 3700 words, of which about 2000 words are writing samples, enumerated by what kind of scene the examples illustrate (how a story starts, how a story ends, a fighting scene, how characters interact, etc).&lt;/p&gt;\n\n&lt;p&gt;I am using it to generate science fiction, which can sometimes turn violent, and Big Tiger is noticeably more brutal about such content than stock Gemma3, for what that&amp;#39;s worth.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbu532/best_local_llm_for_iterative_story_writing/n5oyyib/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753742385,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mbu532",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n5p6hqk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "ttkciar",
                      "can_mod_post": false,
                      "created_utc": 1753744843,
                      "send_replies": true,
                      "parent_id": "t1_n5oyguv",
                      "score": 4,
                      "author_fullname": "t2_cpegz",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Thanks for the tip.  I've noticed BeaverAI's models before, but never bothered to download them because they never give their models model cards.\n\nIs there somewhere other than Huggingface where they describe what their models are, how they are intended to be used, etc?\n\nAbsent model cards, how did you decide BeaverAI's models were worth trying?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n5p6hqk",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "e": "text",
                          "t": "llama.cpp"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Thanks for the tip.  I&amp;#39;ve noticed BeaverAI&amp;#39;s models before, but never bothered to download them because they never give their models model cards.&lt;/p&gt;\n\n&lt;p&gt;Is there somewhere other than Huggingface where they describe what their models are, how they are intended to be used, etc?&lt;/p&gt;\n\n&lt;p&gt;Absent model cards, how did you decide BeaverAI&amp;#39;s models were worth trying?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mbu532",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "light",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mbu532/best_local_llm_for_iterative_story_writing/n5p6hqk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753744843,
                      "author_flair_text": "llama.cpp",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "#bbbdbf",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n5oyguv",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Toooooool",
            "can_mod_post": false,
            "created_utc": 1753742225,
            "send_replies": true,
            "parent_id": "t3_1mbu532",
            "score": 6,
            "author_fullname": "t2_8llornh4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I'd suggest checking out the BeaverAI group, they're constantly working on improving their LLMs for story writing, [https://huggingface.co/BeaverAI](https://huggingface.co/BeaverAI) , and they manage a wide variety of model sizes.\n\nTypically a model is uploaded to the BeaverAI group for testing and evaluating, and then the lead dev will move it to their own personal huggingface page once it's released.\n\nI'm personally fan of LLMs by TheDrummer; [https://huggingface.co/TheDrummer](https://huggingface.co/TheDrummer)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5oyguv",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d suggest checking out the BeaverAI group, they&amp;#39;re constantly working on improving their LLMs for story writing, &lt;a href=\"https://huggingface.co/BeaverAI\"&gt;https://huggingface.co/BeaverAI&lt;/a&gt; , and they manage a wide variety of model sizes.&lt;/p&gt;\n\n&lt;p&gt;Typically a model is uploaded to the BeaverAI group for testing and evaluating, and then the lead dev will move it to their own personal huggingface page once it&amp;#39;s released.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m personally fan of LLMs by TheDrummer; &lt;a href=\"https://huggingface.co/TheDrummer\"&gt;https://huggingface.co/TheDrummer&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mbu532/best_local_llm_for_iterative_story_writing/n5oyguv/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753742225,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mbu532",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        }
      ],
      "before": null
    }
  }
]