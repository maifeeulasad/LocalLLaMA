[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I'd appreciate any feedback on this basic setup for text interface only. I'd upgrade if there's a major/fatal problem with the specs below, or if there's a dramatic improvement in performance for a small additional amount. For example, I could upgrade to a 3090 Ti for maybe 10% more in cost, not sure if that's worth it. \n\nRyzen 9 5900x\n\nRTX 3090 - EVGA FTW3 Ultra 24gb\n\nMSI mag b550 mobo\n\nCorsair 64gb ram\n\n1tb ssd\n\nCorsair rm850 PSU\n\nNzxr Kraken x73 360 aio cooler\n\nNzxt  h710 mid tower atx case\n\nThanks in advance.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Looking for feedback on this basic setup",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m39xy5",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.67,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_brupa",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": 1752865413,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1752863039,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d appreciate any feedback on this basic setup for text interface only. I&amp;#39;d upgrade if there&amp;#39;s a major/fatal problem with the specs below, or if there&amp;#39;s a dramatic improvement in performance for a small additional amount. For example, I could upgrade to a 3090 Ti for maybe 10% more in cost, not sure if that&amp;#39;s worth it. &lt;/p&gt;\n\n&lt;p&gt;Ryzen 9 5900x&lt;/p&gt;\n\n&lt;p&gt;RTX 3090 - EVGA FTW3 Ultra 24gb&lt;/p&gt;\n\n&lt;p&gt;MSI mag b550 mobo&lt;/p&gt;\n\n&lt;p&gt;Corsair 64gb ram&lt;/p&gt;\n\n&lt;p&gt;1tb ssd&lt;/p&gt;\n\n&lt;p&gt;Corsair rm850 PSU&lt;/p&gt;\n\n&lt;p&gt;Nzxr Kraken x73 360 aio cooler&lt;/p&gt;\n\n&lt;p&gt;Nzxt  h710 mid tower atx case&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1m39xy5",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "HunkaHunka",
            "discussion_type": null,
            "num_comments": 2,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m39xy5/looking_for_feedback_on_this_basic_setup/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1m39xy5/looking_for_feedback_on_this_basic_setup/",
            "subreddit_subscribers": 501076,
            "created_utc": 1752863039,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3v9081",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "QFGTrialByFire",
            "can_mod_post": false,
            "created_utc": 1752865497,
            "send_replies": true,
            "parent_id": "t3_1m39xy5",
            "score": 1,
            "author_fullname": "t2_1h4o7f23eh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hi I guess as with anything it depends on what you want to do. For example I can run the llama 3.1 8B model in 8bit quant on my 3080ti with an old cpu and only 16Gb or RAM. You can also train it using lora further on other data and that works reasonably well on my 3080ti. If you just want to try out running some llms and training llms what you have there should be good enough to get started. From what I can see if you want to train full and larger models you're probably better off running that by renting GPU on vast ai or elsewhere than buying hardware (but I haven't yet tried that so take this part with a grain of salt). From the money you'd save on the 3090ti you could probably rent something quite decent eg a H200 is only around $2.5 dollars an hour to rent. Then you can run a quant version of it locally.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3v9081",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hi I guess as with anything it depends on what you want to do. For example I can run the llama 3.1 8B model in 8bit quant on my 3080ti with an old cpu and only 16Gb or RAM. You can also train it using lora further on other data and that works reasonably well on my 3080ti. If you just want to try out running some llms and training llms what you have there should be good enough to get started. From what I can see if you want to train full and larger models you&amp;#39;re probably better off running that by renting GPU on vast ai or elsewhere than buying hardware (but I haven&amp;#39;t yet tried that so take this part with a grain of salt). From the money you&amp;#39;d save on the 3090ti you could probably rent something quite decent eg a H200 is only around $2.5 dollars an hour to rent. Then you can run a quant version of it locally.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m39xy5/looking_for_feedback_on_this_basic_setup/n3v9081/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752865497,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m39xy5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n3vsl3e",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "PermanentLiminality",
            "can_mod_post": false,
            "created_utc": 1752871296,
            "send_replies": true,
            "parent_id": "t3_1m39xy5",
            "score": 1,
            "author_fullname": "t2_19zqycaf",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "To save power I run my LLM box on a 5700G.  \n\nMake sure that your motherboard has at a minimum a x16 slot and a second x16 slot that is x4 electrically.  About the day you get this setup, you are going to want more VRAM, and a path to it is important to have.  Bonus are boards that are x8, x8 and x4, but these are not common and expensive.  A MSI b550 MAG is about 6 different motherboards and some of the lower end ones, don't have the second slot.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n3vsl3e",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;To save power I run my LLM box on a 5700G.  &lt;/p&gt;\n\n&lt;p&gt;Make sure that your motherboard has at a minimum a x16 slot and a second x16 slot that is x4 electrically.  About the day you get this setup, you are going to want more VRAM, and a path to it is important to have.  Bonus are boards that are x8, x8 and x4, but these are not common and expensive.  A MSI b550 MAG is about 6 different motherboards and some of the lower end ones, don&amp;#39;t have the second slot.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m39xy5/looking_for_feedback_on_this_basic_setup/n3vsl3e/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1752871296,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m39xy5",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]