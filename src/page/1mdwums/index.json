[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "I’m doing preliminary research on open source (and open weight) AI for my uni and I was wondering, how do most people actually engage with released models? Is it mainly to run inference? Do most people run models locally? Are people fine-tuning models themselves, or is that rarely ever the case?\n\nAdditionally, when compared to (non-AI) open source software, to what degree is it possible for individuals to contribute back to the open source community? Or is that only feasible for well-financed research organizations/companies?\n\nSo far, when I’ve searched these things, I find answers relating to businesses, but I’m curious about individuals or smaller teams.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "How do people engage with open source AI?",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mdwums",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.44,
            "author_flair_background_color": null,
            "subreddit_type": "public",
            "ups": 0,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1elzdijdrl",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 0,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1753953629,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m doing preliminary research on open source (and open weight) AI for my uni and I was wondering, how do most people actually engage with released models? Is it mainly to run inference? Do most people run models locally? Are people fine-tuning models themselves, or is that rarely ever the case?&lt;/p&gt;\n\n&lt;p&gt;Additionally, when compared to (non-AI) open source software, to what degree is it possible for individuals to contribute back to the open source community? Or is that only feasible for well-financed research organizations/companies?&lt;/p&gt;\n\n&lt;p&gt;So far, when I’ve searched these things, I find answers relating to businesses, but I’m curious about individuals or smaller teams.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": true,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mdwums",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "EstusFlaskCrochet",
            "discussion_type": null,
            "num_comments": 4,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mdwums/how_do_people_engage_with_open_source_ai/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mdwums/how_do_people_engage_with_open_source_ai/",
            "subreddit_subscribers": 507935,
            "created_utc": 1753953629,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n64ws3x",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "huangrice",
            "can_mod_post": false,
            "created_utc": 1753954848,
            "send_replies": true,
            "parent_id": "t3_1mdwums",
            "score": 2,
            "author_fullname": "t2_nc7a5zj2l",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I don't have much resources and only have the capability to run a 32b model with a slow near unusable speed when not doing anything on that computer, however I do find open source models very useful and beneficial. Firstly, they are cheap and I can access SOTA models like deepseek kimi or qwen for a much lower price, like deepseek r1 is usually 2.5USD/million tokens output compared with other closed source SOTAs like Claude 4 at 15 USD, and qwen performing better at coding have an even lower output price rate. Every day use models are even cheaper such as mistral small 3.2 at 0.05 both in and out and performs decently for every day tasks. Secondly, they have better privacy so we don't have to worry about stuff like openai saying they will offer the logs to the gorvernment, and I almost exclusively choose zero retention providers. Thirdly, they provide more varieties for us to choose from and help control the pricing, because now closed sourced providers can't do whatever they want so we can even get cheaper closed source SOTAs.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n64ws3x",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t have much resources and only have the capability to run a 32b model with a slow near unusable speed when not doing anything on that computer, however I do find open source models very useful and beneficial. Firstly, they are cheap and I can access SOTA models like deepseek kimi or qwen for a much lower price, like deepseek r1 is usually 2.5USD/million tokens output compared with other closed source SOTAs like Claude 4 at 15 USD, and qwen performing better at coding have an even lower output price rate. Every day use models are even cheaper such as mistral small 3.2 at 0.05 both in and out and performs decently for every day tasks. Secondly, they have better privacy so we don&amp;#39;t have to worry about stuff like openai saying they will offer the logs to the gorvernment, and I almost exclusively choose zero retention providers. Thirdly, they provide more varieties for us to choose from and help control the pricing, because now closed sourced providers can&amp;#39;t do whatever they want so we can even get cheaper closed source SOTAs.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdwums/how_do_people_engage_with_open_source_ai/n64ws3x/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753954848,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdwums",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n64w1jl",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Psionikus",
            "can_mod_post": false,
            "created_utc": 1753954436,
            "send_replies": true,
            "parent_id": "t3_1mdwums",
            "score": 2,
            "author_fullname": "t2_8vhsch4i",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It is feasible for programmers who find a great niche and for companies with natural alignment.  Sometimes it happens when companies don't have alignment but pay a company to improve open source that they support.  For programmers, the minimum viable problems have to be solo-scale mostly.  If you can't attract other programmers with something coded alone, there's no way to get off the ground.\n\nI'm working on a more in-between solution, something that works for communities of users.  It's just a raw prototype, but now that I've gotten this much operating, It's about ready to accelerate.  https://prizeforge.com",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n64w1jl",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is feasible for programmers who find a great niche and for companies with natural alignment.  Sometimes it happens when companies don&amp;#39;t have alignment but pay a company to improve open source that they support.  For programmers, the minimum viable problems have to be solo-scale mostly.  If you can&amp;#39;t attract other programmers with something coded alone, there&amp;#39;s no way to get off the ground.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working on a more in-between solution, something that works for communities of users.  It&amp;#39;s just a raw prototype, but now that I&amp;#39;ve gotten this much operating, It&amp;#39;s about ready to accelerate.  &lt;a href=\"https://prizeforge.com\"&gt;https://prizeforge.com&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdwums/how_do_people_engage_with_open_source_ai/n64w1jl/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753954436,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdwums",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n64wsh6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Affectionate-Bus4123",
            "can_mod_post": false,
            "created_utc": 1753954854,
            "send_replies": true,
            "parent_id": "t3_1mdwums",
            "score": 2,
            "author_fullname": "t2_12jk0d9s8f",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "My dumb opinion:\n\n1. Indirect users - People using apps that were built using open weights models. The developer of the app will have selected an open weights model for cost reasons, in order to use advanced techniques, or because they are making an adult app.\n\nWe can assume most adult app users are indirectly using open weights models or finetunes thereof, but it will be difficult to measure how many productivity app users are indirectly using open weights models\n\n2. Privacy oriented including organisations - some companies want to run models within their own infrastructure. Individuals will be running models that fit on a local graphics card. But organisations may be standing up a cluster to run a larger model, or more typically using amazon bedrock and other IaS \"hired cloud infrastructure but under your control\" services from big cloud vendors.  \nFor instance, a medical data processing company may offer a solution that runs entirely in the customers own AWS account, and use an open weights model or finetune running on bedrock as part of that solution.  \nOver time, major closed source vendors have been addressing this e.g. you can run Claude on bedrock now.\n\nEstimate through Amazon Bedrock stats if these exist\n\n3. Bulk processing use cases - sometimes you want to classify a million web pages. Pay per token pricing can make bulk use cases very expensive. Organisations may prefer to run their own model or cluster, perhaps using cloud spot pricing to execute long running processes during off peak hours for lower prices. They would typically be running an open weights model on directly controlled infrastructure.\n\nEstimate through spot GPU instance utilization stats if these exist\n\n4. Privacy oriented home users - super nerds with a use case like \"take a screenshot every 10 seconds and interact with me based on the contents of my screen\" might want to run a model entirely under their control because such unfiltered access to their lives is a scary thing to give to a shady model vendor. Similar for a counselling usecase. I think these are super duper power users and a small population.\n\n5. Coomers - May run locally, use a service like openrouter, or use a model host directly. Typically using something like silly tavern or novelcrafter. Estimate through user stats for these kinds of apps.\n\nThere is an active community fine tuning and merging open source models - some for specialization e.g. roleplay and some for raw reasoning performance. Look at DavidAU or Drummer. These efforts take significant resources and the community is quite small. \n\nOutside the LLM space, there is a much large community fine tuning diffusion models for image and video generation see civitai. There are significant open source models in the audio space, but I don't see much community around these and the bulk of use is where these are incorporated into commercial apps for instance for voice cloning.",
            "edited": 1753955108,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n64wsh6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My dumb opinion:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Indirect users - People using apps that were built using open weights models. The developer of the app will have selected an open weights model for cost reasons, in order to use advanced techniques, or because they are making an adult app.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We can assume most adult app users are indirectly using open weights models or finetunes thereof, but it will be difficult to measure how many productivity app users are indirectly using open weights models&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Privacy oriented including organisations - some companies want to run models within their own infrastructure. Individuals will be running models that fit on a local graphics card. But organisations may be standing up a cluster to run a larger model, or more typically using amazon bedrock and other IaS &amp;quot;hired cloud infrastructure but under your control&amp;quot; services from big cloud vendors.&lt;br/&gt;\nFor instance, a medical data processing company may offer a solution that runs entirely in the customers own AWS account, and use an open weights model or finetune running on bedrock as part of that solution.&lt;br/&gt;\nOver time, major closed source vendors have been addressing this e.g. you can run Claude on bedrock now.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Estimate through Amazon Bedrock stats if these exist&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Bulk processing use cases - sometimes you want to classify a million web pages. Pay per token pricing can make bulk use cases very expensive. Organisations may prefer to run their own model or cluster, perhaps using cloud spot pricing to execute long running processes during off peak hours for lower prices. They would typically be running an open weights model on directly controlled infrastructure.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Estimate through spot GPU instance utilization stats if these exist&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Privacy oriented home users - super nerds with a use case like &amp;quot;take a screenshot every 10 seconds and interact with me based on the contents of my screen&amp;quot; might want to run a model entirely under their control because such unfiltered access to their lives is a scary thing to give to a shady model vendor. Similar for a counselling usecase. I think these are super duper power users and a small population.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Coomers - May run locally, use a service like openrouter, or use a model host directly. Typically using something like silly tavern or novelcrafter. Estimate through user stats for these kinds of apps.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;There is an active community fine tuning and merging open source models - some for specialization e.g. roleplay and some for raw reasoning performance. Look at DavidAU or Drummer. These efforts take significant resources and the community is quite small. &lt;/p&gt;\n\n&lt;p&gt;Outside the LLM space, there is a much large community fine tuning diffusion models for image and video generation see civitai. There are significant open source models in the audio space, but I don&amp;#39;t see much community around these and the bulk of use is where these are incorporated into commercial apps for instance for voice cloning.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdwums/how_do_people_engage_with_open_source_ai/n64wsh6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753954854,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdwums",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n65mvjo",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "ArchdukeofHyperbole",
            "can_mod_post": false,
            "created_utc": 1753966130,
            "send_replies": true,
            "parent_id": "t3_1mdwums",
            "score": 2,
            "author_fullname": "t2_1p41v97q5d",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "In a wide variety of ways. \n\nI've had llms make code, writing stories, do chatting with characters, cleaning ocr. And have used embedding models and faiss for semantic search engines. Pretty much anything you'd do with closed source, except you're not limited with use restrictions and subscriptions. For example, I hear anthropic seems to be limiting users *after* they've went ahead and paid for the service. Just glad I don't have to give a crap about that sort of bait and switch.\n\nOh, and you can make music, audio, and images. \n\nAnd checking out what new models can do is pretty interesting. For example, I recently started using an rwkv model. I have a 6GB gpu and can technically do 1M context with it with no degradation of generation speeds 😂. I'm still messing with it to see how useful the longer context really is at this point but can only get better with newer models.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n65mvjo",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In a wide variety of ways. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve had llms make code, writing stories, do chatting with characters, cleaning ocr. And have used embedding models and faiss for semantic search engines. Pretty much anything you&amp;#39;d do with closed source, except you&amp;#39;re not limited with use restrictions and subscriptions. For example, I hear anthropic seems to be limiting users &lt;em&gt;after&lt;/em&gt; they&amp;#39;ve went ahead and paid for the service. Just glad I don&amp;#39;t have to give a crap about that sort of bait and switch.&lt;/p&gt;\n\n&lt;p&gt;Oh, and you can make music, audio, and images. &lt;/p&gt;\n\n&lt;p&gt;And checking out what new models can do is pretty interesting. For example, I recently started using an rwkv model. I have a 6GB gpu and can technically do 1M context with it with no degradation of generation speeds 😂. I&amp;#39;m still messing with it to see how useful the longer context really is at this point but can only get better with newer models.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mdwums/how_do_people_engage_with_open_source_ai/n65mvjo/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753966130,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mdwums",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        }
      ],
      "before": null
    }
  }
]