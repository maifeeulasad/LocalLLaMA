[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "When I want the absolute best response, I'd use DeepSeek-r1. But sometimes I want a good response fast, or many good responses quickly for agentic use cases. It would help to know the response times to calculate the speed/performance tradeoff.\n\nDesignArena and FamilyBench (for example) are awesome for doing this. ",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "More benchmarks should report response times",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Discussion"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": null,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mjwcac",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.67,
            "author_flair_background_color": "transparent",
            "subreddit_type": "public",
            "ups": 11,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": null,
            "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
            "is_original_content": false,
            "author_fullname": "t2_1a48h7vf",
            "secure_media": null,
            "is_reddit_media_domain": false,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Discussion",
            "can_mod_post": false,
            "score": 11,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "self",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [
              {
                "a": ":X:",
                "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                "e": "emoji"
              }
            ],
            "gildings": {},
            "content_categories": null,
            "is_self": true,
            "mod_note": null,
            "created": 1754562117,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "domain": "self.LocalLLaMA",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When I want the absolute best response, I&amp;#39;d use DeepSeek-r1. But sometimes I want a good response fast, or many good responses quickly for agentic use cases. It would help to know the response times to calculate the speed/performance tradeoff.&lt;/p&gt;\n\n&lt;p&gt;DesignArena and FamilyBench (for example) are awesome for doing this. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "5f921ea4-c7bc-11ed-9c23-3a00622979b4",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": ":X:",
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "num_reports": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "removal_reason": null,
            "link_flair_background_color": "#646d73",
            "id": "1mjwcac",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "entsnack",
            "discussion_type": null,
            "num_comments": 8,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": "dark",
            "permalink": "/r/LocalLLaMA/comments/1mjwcac/more_benchmarks_should_report_response_times/",
            "stickied": false,
            "url": "https://www.reddit.com/r/LocalLLaMA/comments/1mjwcac/more_benchmarks_should_report_response_times/",
            "subreddit_subscribers": 513417,
            "created_utc": 1754562117,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n7e8f3x",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "No_Efficiency_1144",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n7e6ypa",
                                "score": 3,
                                "author_fullname": "t2_1nkj9l14b0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Maybe if they equalised it to vLLM framework and H100 as a standard it would be okay and we can calculate our estimate from there.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n7e8f3x",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe if they equalised it to vLLM framework and H100 as a standard it would be okay and we can calculate our estimate from there.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mjwcac",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mjwcac/more_benchmarks_should_report_response_times/n7e8f3x/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754564076,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754564076,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 3
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n7e6ypa",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754563393,
                      "send_replies": true,
                      "parent_id": "t1_n7e627y",
                      "score": 2,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah token counts is better. But response times are fine if all the benchmarked models are compared with the same hardware and same initial state. Which is difficult to do yeah.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7e6ypa",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah token counts is better. But response times are fine if all the benchmarked models are compared with the same hardware and same initial state. Which is difficult to do yeah.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjwcac",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjwcac/more_benchmarks_should_report_response_times/n7e6ypa/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754563393,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7e627y",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "No_Efficiency_1144",
            "can_mod_post": false,
            "created_utc": 1754562953,
            "send_replies": true,
            "parent_id": "t3_1mjwcac",
            "score": 15,
            "author_fullname": "t2_1nkj9l14b0",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "They started putting out token counts for long agentic tasks.\n\n\nResponse times is tricky as it is mostly hardware \n-based. In particular latency is heavily dependent on the quality of the CUDA kernel due to the high time cost of cache misses at the lower levels of the memory hierarchy.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7e627y",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They started putting out token counts for long agentic tasks.&lt;/p&gt;\n\n&lt;p&gt;Response times is tricky as it is mostly hardware \n-based. In particular latency is heavily dependent on the quality of the CUDA kernel due to the high time cost of cache misses at the lower levels of the memory hierarchy.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjwcac/more_benchmarks_should_report_response_times/n7e627y/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754562953,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjwcac",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7e4tj7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Lessiarty",
            "can_mod_post": false,
            "created_utc": 1754562335,
            "send_replies": true,
            "parent_id": "t3_1mjwcac",
            "score": 2,
            "author_fullname": "t2_70gyn",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Response time is great when you need to compare the three ways to do things; the right way, the wrong way and the Max Power way!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7e4tj7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Response time is great when you need to compare the three ways to do things; the right way, the wrong way and the Max Power way!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjwcac/more_benchmarks_should_report_response_times/n7e4tj7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754562335,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjwcac",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n7e5zav",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Lissanro",
            "can_mod_post": false,
            "created_utc": 1754562913,
            "send_replies": true,
            "parent_id": "t3_1mjwcac",
            "score": 2,
            "author_fullname": "t2_fpfao9g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Usually you can estimate response time after getting some experience in given types task with models in different ranges of parameters. Generally it can vary greatly, given it depends not only on hardware and on a backend of choice, but also task at hand (how long the prompt is, are there multiple prompts before response is given like it is the case in agentic use, and if they change the beginning of the prompt causing cache misses, etc). So the best way, is to just test with your actual task few different model sizes and see if smaller ones still can produce what you consider a good response.",
            "edited": 1754566437,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7e5zav",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Usually you can estimate response time after getting some experience in given types task with models in different ranges of parameters. Generally it can vary greatly, given it depends not only on hardware and on a backend of choice, but also task at hand (how long the prompt is, are there multiple prompts before response is given like it is the case in agentic use, and if they change the beginning of the prompt causing cache misses, etc). So the best way, is to just test with your actual task few different model sizes and see if smaller ones still can produce what you consider a good response.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjwcac/more_benchmarks_should_report_response_times/n7e5zav/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754562913,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjwcac",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "richtext",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": "c07aa42e-51fe-11f0-afcc-462aad931709",
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n7e73sc",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "entsnack",
                      "can_mod_post": false,
                      "created_utc": 1754563461,
                      "send_replies": true,
                      "parent_id": "t1_n7e6cm6",
                      "score": 2,
                      "author_fullname": "t2_1a48h7vf",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I'm sorry I made you uncomfortable. Does it bring back some past trauma?",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n7e73sc",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [
                        {
                          "a": ":X:",
                          "u": "https://emoji.redditmedia.com/tbgegafk739f1_t5_81eyvm/X",
                          "e": "emoji"
                        }
                      ],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m sorry I made you uncomfortable. Does it bring back some past trauma?&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mjwcac",
                      "unrepliable_reason": null,
                      "author_flair_text_color": "dark",
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mjwcac/more_benchmarks_should_report_response_times/n7e73sc/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754563461,
                      "author_flair_text": ":X:",
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 1,
                      "depth": 1,
                      "author_flair_background_color": "transparent",
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n7e6cm6",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "throwaway1512514",
            "can_mod_post": false,
            "created_utc": 1754563096,
            "send_replies": true,
            "parent_id": "t3_1mjwcac",
            "score": -2,
            "author_fullname": "t2_66rmvyi7",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "This guy has been glazing openai non stop for two days straight. I'm not even trying to dig through his profile but every single fucking post these past 2 days have this guy glazing it, I can't unsee this presence.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n7e6cm6",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This guy has been glazing openai non stop for two days straight. I&amp;#39;m not even trying to dig through his profile but every single fucking post these past 2 days have this guy glazing it, I can&amp;#39;t unsee this presence.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mjwcac/more_benchmarks_should_report_response_times/n7e6cm6/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754563096,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mjwcac",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 1,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -2
          }
        }
      ],
      "before": null
    }
  }
]