[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "(Noob here) I am currently using qwen3:14b and qwen2.5-coder:14b which are okay in general task, general coding &amp; normal tool callings.\n\nBut whenever I add it in IDE/extenstions like KiloCode then it just can't handle it. &amp; Stops without completing task.\n\nIn my personal assistant I have added simple tool callings so it works 80\\~90% of the time.\n\nBut when I add Jan AI (sqeuntional calling &amp; browser navigation) then after just 1 \\~ 2 callings it just goes stopped without completing task.\n\nsame with kilo code when I add on kilo code or another extenstions then it just cannot perform task completely. It just stops.\n\n  \nI want smarter then this llm (if smarter then I am okay with slow token response)\n\n\\--\n\nI was researchig about both. When I researched about 20b MoE and asked AI's so they suggested my 14b is more smart then 30b MoE \n\nand\n\n32b I will become slow (since it will run in ram and cpu, so I want to know how much smart it is? I can just use it alternative of chatgpt, if not smart then doesn't make sense to wait for long time)\n\n\\-----\n\nCurrently my 14b llm gives 25\\~35 tokens per second token output in general (avg)\n\nCurrently I am using ollama (I am sure using llama.cpp will boost the performance significantly)\n\nSince I am using ollama then I am currently using gpus power only.\n\nI am planning to switch to llama.cpp so I can do more customization like using all system resources cpu+gpu) and doing quantization.\n\n\\--\n\nI don't know about quants q, k etc too much (but have shallow knowledge)\n\n  \nif you think in my specs I can run bigger llms with quintization (sorry for spelling) &amp; custom configs so please suggest those models as well\n\n\\--\n\nCan I run 70b model? (obiosuly I need to quantize it, but 70b quantized vs 30b which will be smart and which will be faster?)\n\n  \n\\--- \n\nMax llm size which I can run?\n\nBest setting for my requirement?\n\nWhat should I look for to get even better llms?\n\n\n\n    OS: Ubuntu 22.04.5 LTS x86_64 \n    Host: B450 AORUS ELITE V2 -CF \n    Kernel: 5.15.0-130-generic \n    Uptime: 1 day, 5 hours, 42 mins \n    Packages: 1736 (dpkg) \n    Shell: bash 5.1.16 \n    Resolution: 2560x1440 \n    DE: GNOME 42.9 \n    WM: Mutter \n    WM Theme: Yaru-dark \n    Theme: Adwaita-dark [GTK2/3] \n    Icons: Yaru [GTK2/3] \n    Terminal: gnome-terminal \n    CPU: AMD Ryzen 5 5600G with Radeon Graphics (12) @ 3.900GHz \n    GPU: NVIDIA GeForce RTX 3060 Lite Hash Rate (12GB VRAM)\n    Memory: 21186MiB / 48035MiB \n\n  \n",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "(Noob here) Qwen 30b (MoE) vs Qwen 32B which is smartest in coding, reasoning and which faster &amp; smartest? (I have RTX 3060 12GB VRAM + 48 GB RAM)",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "Question | Help"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 57,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1mesvnt",
            "quarantine": false,
            "link_flair_text_color": "dark",
            "upvote_ratio": 0.53,
            "author_flair_background_color": null,
            "ups": 1,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_1b8utegv8t",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "Question | Help",
            "can_mod_post": false,
            "score": 1,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/JMnIT-T7tU4TQdi7zHU4o3GCnNbIEcaUSqSB_BhdJVA.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1754044055,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Noob here) I am currently using qwen3:14b and qwen2.5-coder:14b which are okay in general task, general coding &amp;amp; normal tool callings.&lt;/p&gt;\n\n&lt;p&gt;But whenever I add it in IDE/extenstions like KiloCode then it just can&amp;#39;t handle it. &amp;amp; Stops without completing task.&lt;/p&gt;\n\n&lt;p&gt;In my personal assistant I have added simple tool callings so it works 80~90% of the time.&lt;/p&gt;\n\n&lt;p&gt;But when I add Jan AI (sqeuntional calling &amp;amp; browser navigation) then after just 1 ~ 2 callings it just goes stopped without completing task.&lt;/p&gt;\n\n&lt;p&gt;same with kilo code when I add on kilo code or another extenstions then it just cannot perform task completely. It just stops.&lt;/p&gt;\n\n&lt;p&gt;I want smarter then this llm (if smarter then I am okay with slow token response)&lt;/p&gt;\n\n&lt;p&gt;--&lt;/p&gt;\n\n&lt;p&gt;I was researchig about both. When I researched about 20b MoE and asked AI&amp;#39;s so they suggested my 14b is more smart then 30b MoE &lt;/p&gt;\n\n&lt;p&gt;and&lt;/p&gt;\n\n&lt;p&gt;32b I will become slow (since it will run in ram and cpu, so I want to know how much smart it is? I can just use it alternative of chatgpt, if not smart then doesn&amp;#39;t make sense to wait for long time)&lt;/p&gt;\n\n&lt;p&gt;-----&lt;/p&gt;\n\n&lt;p&gt;Currently my 14b llm gives 25~35 tokens per second token output in general (avg)&lt;/p&gt;\n\n&lt;p&gt;Currently I am using ollama (I am sure using llama.cpp will boost the performance significantly)&lt;/p&gt;\n\n&lt;p&gt;Since I am using ollama then I am currently using gpus power only.&lt;/p&gt;\n\n&lt;p&gt;I am planning to switch to llama.cpp so I can do more customization like using all system resources cpu+gpu) and doing quantization.&lt;/p&gt;\n\n&lt;p&gt;--&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know about quants q, k etc too much (but have shallow knowledge)&lt;/p&gt;\n\n&lt;p&gt;if you think in my specs I can run bigger llms with quintization (sorry for spelling) &amp;amp; custom configs so please suggest those models as well&lt;/p&gt;\n\n&lt;p&gt;--&lt;/p&gt;\n\n&lt;p&gt;Can I run 70b model? (obiosuly I need to quantize it, but 70b quantized vs 30b which will be smart and which will be faster?)&lt;/p&gt;\n\n&lt;p&gt;--- &lt;/p&gt;\n\n&lt;p&gt;Max llm size which I can run?&lt;/p&gt;\n\n&lt;p&gt;Best setting for my requirement?&lt;/p&gt;\n\n&lt;p&gt;What should I look for to get even better llms?&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;OS: Ubuntu 22.04.5 LTS x86_64 \nHost: B450 AORUS ELITE V2 -CF \nKernel: 5.15.0-130-generic \nUptime: 1 day, 5 hours, 42 mins \nPackages: 1736 (dpkg) \nShell: bash 5.1.16 \nResolution: 2560x1440 \nDE: GNOME 42.9 \nWM: Mutter \nWM Theme: Yaru-dark \nTheme: Adwaita-dark [GTK2/3] \nIcons: Yaru [GTK2/3] \nTerminal: gnome-terminal \nCPU: AMD Ryzen 5 5600G with Radeon Graphics (12) @ 3.900GHz \nGPU: NVIDIA GeForce RTX 3060 Lite Hash Rate (12GB VRAM)\nMemory: 21186MiB / 48035MiB \n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/kwcziz5qudgf1.png",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/kwcziz5qudgf1.png?auto=webp&amp;s=3157ea78a79d5ac07e0cb0136d52f49b04ac7557",
                    "width": 929,
                    "height": 380
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/kwcziz5qudgf1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee82b2afc88bd97945a1d776b4636dca0f5e736b",
                      "width": 108,
                      "height": 44
                    },
                    {
                      "url": "https://preview.redd.it/kwcziz5qudgf1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3c0a3c4e2f87bbbfbfd54f8d868d876e621b80ae",
                      "width": 216,
                      "height": 88
                    },
                    {
                      "url": "https://preview.redd.it/kwcziz5qudgf1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d49b24e0a44fed79d0d8f99b520c90146be01046",
                      "width": 320,
                      "height": 130
                    },
                    {
                      "url": "https://preview.redd.it/kwcziz5qudgf1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b9254c90ef792da4f0fe71262c6e728ae0654cfd",
                      "width": 640,
                      "height": 261
                    }
                  ],
                  "variants": {},
                  "id": "DRyixyGCOuvYJ9GLpCPMtiU2SSEAKjFXPknmcG18D9Q"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "2c9831e6-bf92-11ed-98e6-d2b8bcc02ae1",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#5a74cc",
            "id": "1mesvnt",
            "is_robot_indexable": true,
            "num_duplicates": 0,
            "report_reasons": null,
            "author": "InsideResolve4517",
            "discussion_type": null,
            "num_comments": 16,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/",
            "stickied": false,
            "url": "https://i.redd.it/kwcziz5qudgf1.png",
            "subreddit_subscribers": 508541,
            "created_utc": 1754044055,
            "num_crossposts": 0,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6e26lo",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "getmevodka",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6e0ncu",
                                          "score": 1,
                                          "author_fullname": "t2_7uoa6r1b",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "interesting",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6e26lo",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;interesting&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mesvnt",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6e26lo/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754071148,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754071148,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6e0ncu",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Forgot_Password_Dude",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6c728t",
                                "score": 1,
                                "author_fullname": "t2_g8xg6sut",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Someone just ran a test st the 4ks was better than xl",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6e0ncu",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Someone just ran a test st the 4ks was better than xl&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mesvnt",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6e0ncu/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754070713,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754070713,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6c728t",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "getmevodka",
                      "can_mod_post": false,
                      "created_utc": 1754051176,
                      "send_replies": true,
                      "parent_id": "t1_n6bqrk0",
                      "score": 2,
                      "author_fullname": "t2_7uoa6r1b",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "this. if possible get q4 k xl. should run best regarding performance/quality match",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6c728t",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;this. if possible get q4 k xl. should run best regarding performance/quality match&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mesvnt",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6c728t/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754051176,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6bqrk0",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Weird_Researcher_472",
            "can_mod_post": false,
            "created_utc": 1754044277,
            "send_replies": true,
            "parent_id": "t3_1mesvnt",
            "score": 15,
            "author_fullname": "t2_1tytceq8sj",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Pick Qwen3 Coder 30B-A3B (unsloth quants)",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6bqrk0",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Pick Qwen3 Coder 30B-A3B (unsloth quants)&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6bqrk0/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754044277,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mesvnt",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 15
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6bs94a",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "-dysangel-",
            "can_mod_post": false,
            "created_utc": 1754045014,
            "send_replies": true,
            "parent_id": "t3_1mesvnt",
            "score": 7,
            "author_fullname": "t2_12ggykute6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "32B has always felt smarter and more reliable than the MoE for me. Since the new 32B Coder isn't out yet though, the MoE coder might be better for some use cases currently.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6bs94a",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;32B has always felt smarter and more reliable than the MoE for me. Since the new 32B Coder isn&amp;#39;t out yet though, the MoE coder might be better for some use cases currently.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6bs94a/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754045014,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1mesvnt",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 7
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n6ewn5n",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Pristine-Woodpecker",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6cnqqp",
                                "score": 1,
                                "author_fullname": "t2_5b972ieo",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "The new generation of Qwen models seem pretty tuned to agentic coding.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6ewn5n",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The new generation of Qwen models seem pretty tuned to agentic coding.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mesvnt",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6ewn5n/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754080154,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754080154,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6cnqqp",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "InsideResolve4517",
                      "can_mod_post": false,
                      "created_utc": 1754056688,
                      "send_replies": true,
                      "parent_id": "t1_n6btge1",
                      "score": 1,
                      "author_fullname": "t2_1b8utegv8t",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Qwen3-Coder 30B-A3B\n\nIs it good at tool calling? (my 14b be just stucks in 1\\~2 tool calls and stops)",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6cnqqp",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen3-Coder 30B-A3B&lt;/p&gt;\n\n&lt;p&gt;Is it good at tool calling? (my 14b be just stucks in 1~2 tool calls and stops)&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mesvnt",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6cnqqp/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754056688,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6btge1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Pristine-Woodpecker",
            "can_mod_post": false,
            "created_utc": 1754045588,
            "send_replies": true,
            "parent_id": "t3_1mesvnt",
            "score": 2,
            "author_fullname": "t2_5b972ieo",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "For non-agentic coding the 32B looks like the winner. Given that you're talking about tool calling, most likely the Qwen3-Coder 30B-A3B.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6btge1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For non-agentic coding the 32B looks like the winner. Given that you&amp;#39;re talking about tool calling, most likely the Qwen3-Coder 30B-A3B.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6btge1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754045588,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mesvnt",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": {
                                            "kind": "Listing",
                                            "data": {
                                              "after": null,
                                              "dist": null,
                                              "modhash": "",
                                              "geo_filter": "",
                                              "children": [
                                                {
                                                  "kind": "t1",
                                                  "data": {
                                                    "subreddit_id": "t5_81eyvm",
                                                    "approved_at_utc": null,
                                                    "author_is_blocked": false,
                                                    "comment_type": null,
                                                    "awarders": [],
                                                    "mod_reason_by": null,
                                                    "banned_by": null,
                                                    "author_flair_type": "text",
                                                    "total_awards_received": 0,
                                                    "subreddit": "LocalLLaMA",
                                                    "author_flair_template_id": null,
                                                    "distinguished": null,
                                                    "likes": null,
                                                    "replies": "",
                                                    "user_reports": [],
                                                    "saved": false,
                                                    "id": "n6dd8u5",
                                                    "banned_at_utc": null,
                                                    "mod_reason_title": null,
                                                    "gilded": 0,
                                                    "archived": false,
                                                    "collapsed_reason_code": null,
                                                    "no_follow": true,
                                                    "author": "RemindMeBot",
                                                    "can_mod_post": false,
                                                    "send_replies": true,
                                                    "parent_id": "t1_n6dd3of",
                                                    "score": 1,
                                                    "author_fullname": "t2_gbm4p",
                                                    "removal_reason": null,
                                                    "approved_by": null,
                                                    "mod_note": null,
                                                    "all_awardings": [],
                                                    "body": "I will be messaging you in 25 days on [**2025-08-26 15:59:56 UTC**](http://www.wolframalpha.com/input/?i=2025-08-26%2015:59:56%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6dd3of/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1mesvnt%2Fnoob_here_qwen_30b_moe_vs_qwen_32b_which_is%2Fn6dd3of%2F%5D%0A%0ARemindMe%21%202025-08-26%2015%3A59%3A56%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete%20Comment&amp;message=Delete%21%201mesvnt)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List%20Of%20Reminders&amp;message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&amp;subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
                                                    "edited": false,
                                                    "author_flair_css_class": null,
                                                    "name": "t1_n6dd8u5",
                                                    "is_submitter": false,
                                                    "downs": 0,
                                                    "author_flair_richtext": [],
                                                    "author_patreon_flair": false,
                                                    "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I will be messaging you in 25 days on &lt;a href=\"http://www.wolframalpha.com/input/?i=2025-08-26%2015:59:56%20UTC%20To%20Local%20Time\"&gt;&lt;strong&gt;2025-08-26 15:59:56 UTC&lt;/strong&gt;&lt;/a&gt; to remind you of &lt;a href=\"https://www.reddit.com/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6dd3of/?context=3\"&gt;&lt;strong&gt;this link&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FLocalLLaMA%2Fcomments%2F1mesvnt%2Fnoob_here_qwen_30b_moe_vs_qwen_32b_which_is%2Fn6dd3of%2F%5D%0A%0ARemindMe%21%202025-08-26%2015%3A59%3A56%20UTC\"&gt;&lt;strong&gt;CLICK THIS LINK&lt;/strong&gt;&lt;/a&gt; to send a PM to also be reminded and to reduce spam.&lt;/p&gt;\n\n&lt;p&gt;&lt;sup&gt;Parent commenter can &lt;/sup&gt; &lt;a href=\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Delete%20Comment&amp;amp;message=Delete%21%201mesvnt\"&gt;&lt;sup&gt;delete this message to hide from others.&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;&lt;a href=\"https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/\"&gt;&lt;sup&gt;Info&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\n&lt;th&gt;&lt;a href=\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=Reminder&amp;amp;message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here\"&gt;&lt;sup&gt;Custom&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\n&lt;th&gt;&lt;a href=\"https://www.reddit.com/message/compose/?to=RemindMeBot&amp;amp;subject=List%20Of%20Reminders&amp;amp;message=MyReminders%21\"&gt;&lt;sup&gt;Your Reminders&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\n&lt;th&gt;&lt;a href=\"https://www.reddit.com/message/compose/?to=Watchful1&amp;amp;subject=RemindMeBot%20Feedback\"&gt;&lt;sup&gt;Feedback&lt;/sup&gt;&lt;/a&gt;&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;",
                                                    "gildings": {},
                                                    "collapsed_reason": null,
                                                    "link_id": "t3_1mesvnt",
                                                    "associated_award": null,
                                                    "stickied": false,
                                                    "author_premium": false,
                                                    "can_gild": false,
                                                    "top_awarded_type": null,
                                                    "unrepliable_reason": null,
                                                    "author_flair_text_color": null,
                                                    "treatment_tags": [],
                                                    "score_hidden": false,
                                                    "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6dd8u5/",
                                                    "subreddit_type": "public",
                                                    "locked": false,
                                                    "report_reasons": null,
                                                    "created": 1754064037,
                                                    "author_flair_text": null,
                                                    "collapsed": false,
                                                    "created_utc": 1754064037,
                                                    "subreddit_name_prefixed": "r/LocalLLaMA",
                                                    "controversiality": 0,
                                                    "depth": 4,
                                                    "author_flair_background_color": null,
                                                    "collapsed_because_crowd_control": null,
                                                    "mod_reports": [],
                                                    "num_reports": null,
                                                    "ups": 1
                                                  }
                                                }
                                              ],
                                              "before": null
                                            }
                                          },
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n6dd3of",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "InsideResolve4517",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n6dbkx8",
                                          "score": 1,
                                          "author_fullname": "t2_1b8utegv8t",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "ok will try it.\n\nWill also consider\n\nvllm\n\n!RemindMe 25 days",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n6dd3of",
                                          "is_submitter": true,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ok will try it.&lt;/p&gt;\n\n&lt;p&gt;Will also consider&lt;/p&gt;\n\n&lt;p&gt;vllm&lt;/p&gt;\n\n&lt;p&gt;!RemindMe 25 days&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1mesvnt",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6dd3of/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1754063996,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1754063996,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n6dbkx8",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "QFGTrialByFire",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n6cnhot",
                                "score": 2,
                                "author_fullname": "t2_1h4o7f23eh",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Hey, hope those larger models work for you. Prob that MOE version will even fit in 12GB if used in 4bit quant. Let us know if they run at a an ok token generation speed and if you find it performs better. I’m curious, since I have an RTX 3080 Ti — if you see a big improvement, I'll give it a try myself. \n\nAlso i noticed you mentioned ollama and llama.cpp .. your already on linux so give vllm a go. Its much faster than either of those model loaders for a NVDIA GPU.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n6dbkx8",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hey, hope those larger models work for you. Prob that MOE version will even fit in 12GB if used in 4bit quant. Let us know if they run at a an ok token generation speed and if you find it performs better. I’m curious, since I have an RTX 3080 Ti — if you see a big improvement, I&amp;#39;ll give it a try myself. &lt;/p&gt;\n\n&lt;p&gt;Also i noticed you mentioned ollama and llama.cpp .. your already on linux so give vllm a go. Its much faster than either of those model loaders for a NVDIA GPU.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1mesvnt",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6dbkx8/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1754063566,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1754063566,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 2
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n6cnhot",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "InsideResolve4517",
                      "can_mod_post": false,
                      "created_utc": 1754056611,
                      "send_replies": true,
                      "parent_id": "t1_n6c2hry",
                      "score": 1,
                      "author_fullname": "t2_1b8utegv8t",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "&gt;running those as they will just be so slow for that GPU vram when you spill over to system ram\n\nYeah! it will be slow, I am not sure how much slow it will be (but If model have good reasoning+coding or smartest in tool calling then it will be okay, I will use it in another way)\n\n&gt;from my understanding instead of going for bigger models you might be better of going for specificly fine tuned reasoning+coding models instead\n\nI have tried fine tuned smaller models, not specifically Seed-Coder-8B-Reasoning, but models like Qwen2.5-Coder-7B-Instruct-GGUF, deepseek-coder:6.7b, qwen2.5-coder:3b, deepseek-llm:7b etc. I also have orca, llama2, llama3, mistral, phi, starcoder, deepseek-r1 with many variations, parameter size but I have not used more then 1\\~3 times (I am not saying it's bad, but just never tried yet)\n\nI want either small model with best reasoning+tool call and if no coding knowledge then it's okay. Because I thinking if model have best reasoning (aka common sense) and have robust tool calling then I will provide then docs, sources, mcp, tools etc and they will do valualbe things. (100+, 200+ tool calls no worries). I think best reasing with best tool calling combination can connect the dots and can perform task better.\n\nAnd I have seen smaller models doesn't understand what we are saying. If you need to get better result then you need to write large n larger prompt.\n\ntill 14b parameters model with fine tuned &amp; without fine tuned I get below task done:\n\n* grammer fixes (good)\n* mail, reply generation (good)\n* social media post (basic)\n* specific coding task 1\\~2 files (max 1 file good)\n* my personal assistant tool calling (good)\n* mcp, IDE, vscode tool calling, sequenceal thinking, browser automation (bad)\n* autonoums bugfixes (bad)\n\n\\-----\n\n&gt;To me it feels like local models are better suited to being finetuned so bigger models isn't always better getting ones fine tuned for a task might be better and faster than just going for a bigger model.\n\nI agree. For specific task, specific fine tuned models are best combination of performance &amp; output.\n\nBut in case of coding I or someone will need either smartest llm or smartest at tool calling.\\*\n\n\\*\n\nSMARTEST: Must have best reasoning + Must be great in particular domain (for me coding)\n\nSMARTEST at Tool Calling: Good at a domain (for me coding) + Best at tool calling + Good at reasoning\n\n  \nps: here smartest I used for as per my configs/system I will get the smartest.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n6cnhot",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;running those as they will just be so slow for that GPU vram when you spill over to system ram&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yeah! it will be slow, I am not sure how much slow it will be (but If model have good reasoning+coding or smartest in tool calling then it will be okay, I will use it in another way)&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;from my understanding instead of going for bigger models you might be better of going for specificly fine tuned reasoning+coding models instead&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I have tried fine tuned smaller models, not specifically Seed-Coder-8B-Reasoning, but models like Qwen2.5-Coder-7B-Instruct-GGUF, deepseek-coder:6.7b, qwen2.5-coder:3b, deepseek-llm:7b etc. I also have orca, llama2, llama3, mistral, phi, starcoder, deepseek-r1 with many variations, parameter size but I have not used more then 1~3 times (I am not saying it&amp;#39;s bad, but just never tried yet)&lt;/p&gt;\n\n&lt;p&gt;I want either small model with best reasoning+tool call and if no coding knowledge then it&amp;#39;s okay. Because I thinking if model have best reasoning (aka common sense) and have robust tool calling then I will provide then docs, sources, mcp, tools etc and they will do valualbe things. (100+, 200+ tool calls no worries). I think best reasing with best tool calling combination can connect the dots and can perform task better.&lt;/p&gt;\n\n&lt;p&gt;And I have seen smaller models doesn&amp;#39;t understand what we are saying. If you need to get better result then you need to write large n larger prompt.&lt;/p&gt;\n\n&lt;p&gt;till 14b parameters model with fine tuned &amp;amp; without fine tuned I get below task done:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;grammer fixes (good)&lt;/li&gt;\n&lt;li&gt;mail, reply generation (good)&lt;/li&gt;\n&lt;li&gt;social media post (basic)&lt;/li&gt;\n&lt;li&gt;specific coding task 1~2 files (max 1 file good)&lt;/li&gt;\n&lt;li&gt;my personal assistant tool calling (good)&lt;/li&gt;\n&lt;li&gt;mcp, IDE, vscode tool calling, sequenceal thinking, browser automation (bad)&lt;/li&gt;\n&lt;li&gt;autonoums bugfixes (bad)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;-----&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;To me it feels like local models are better suited to being finetuned so bigger models isn&amp;#39;t always better getting ones fine tuned for a task might be better and faster than just going for a bigger model.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I agree. For specific task, specific fine tuned models are best combination of performance &amp;amp; output.&lt;/p&gt;\n\n&lt;p&gt;But in case of coding I or someone will need either smartest llm or smartest at tool calling.*&lt;/p&gt;\n\n&lt;p&gt;*&lt;/p&gt;\n\n&lt;p&gt;SMARTEST: Must have best reasoning + Must be great in particular domain (for me coding)&lt;/p&gt;\n\n&lt;p&gt;SMARTEST at Tool Calling: Good at a domain (for me coding) + Best at tool calling + Good at reasoning&lt;/p&gt;\n\n&lt;p&gt;ps: here smartest I used for as per my configs/system I will get the smartest.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1mesvnt",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6cnhot/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1754056611,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n6c2hry",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "QFGTrialByFire",
            "can_mod_post": false,
            "created_utc": 1754049475,
            "send_replies": true,
            "parent_id": "t3_1mesvnt",
            "score": 2,
            "author_fullname": "t2_1h4o7f23eh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Hi I'm surprised you are considering running those as they will just be so slow for that GPU vram when you spill over to system ram but you mention you don't mind if gives good results so maybe it will be ok. I'm relatively new to this as well but from my understanding instead of going for bigger models you might be better of going for specificly fine tuned reasoning+coding models instead. e.g. give Seed-Coder-8B-Reasoning a go. It runs at 9GB vram on my 3080Ti so will fit on your GPU as well. To me it feels like local models are better suited to being finetuned so bigger models isn't always better getting ones fine tuned for a task might be better and faster than just going for a bigger model.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6c2hry",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m surprised you are considering running those as they will just be so slow for that GPU vram when you spill over to system ram but you mention you don&amp;#39;t mind if gives good results so maybe it will be ok. I&amp;#39;m relatively new to this as well but from my understanding instead of going for bigger models you might be better of going for specificly fine tuned reasoning+coding models instead. e.g. give Seed-Coder-8B-Reasoning a go. It runs at 9GB vram on my 3080Ti so will fit on your GPU as well. To me it feels like local models are better suited to being finetuned so bigger models isn&amp;#39;t always better getting ones fine tuned for a task might be better and faster than just going for a bigger model.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6c2hry/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754049475,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mesvnt",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6df6s1",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "fp4guru",
            "can_mod_post": false,
            "created_utc": 1754064603,
            "send_replies": true,
            "parent_id": "t3_1mesvnt",
            "score": 1,
            "author_fullname": "t2_1tp8zldw5g",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Give the Qwen3 30b thinking 2507 version a shot. I was using it for gpt4o pygame challenge, the completion is very solid.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6df6s1",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Give the Qwen3 30b thinking 2507 version a shot. I was using it for gpt4o pygame challenge, the completion is very solid.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6df6s1/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754064603,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mesvnt",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6caip2",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Current-Rabbit-620",
            "can_mod_post": false,
            "created_utc": 1754052420,
            "send_replies": true,
            "parent_id": "t3_1mesvnt",
            "score": 1,
            "author_fullname": "t2_9mvs9oc9",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "So anyone  recommend \n glm 4.5 air int4 bit?\n\nIts smarter in benchmarks",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6caip2",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So anyone  recommend \n glm 4.5 air int4 bit?&lt;/p&gt;\n\n&lt;p&gt;Its smarter in benchmarks&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6caip2/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754052420,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mesvnt",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n6c179m",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": "LOW_SCORE",
            "no_follow": true,
            "author": "AleksHop",
            "can_mod_post": false,
            "created_utc": 1754048953,
            "send_replies": true,
            "parent_id": "t3_1mesvnt",
            "score": -6,
            "author_fullname": "t2_8dnu3hmd",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": true,
            "body": "Moe will be like 3-4 faster and as dumb as 32b, use normal models",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n6c179m",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Moe will be like 3-4 faster and as dumb as 32b, use normal models&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": "comment score below threshold",
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1mesvnt/noob_here_qwen_30b_moe_vs_qwen_32b_which_is/n6c179m/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1754048953,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1mesvnt",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": -6
          }
        }
      ],
      "before": null
    }
  }
]