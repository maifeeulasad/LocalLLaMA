[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "Check out this chart comparing the latest Qwen3-235B-A22B-2507 models (Instruct and Thinking) to the older versions. The improvements are huge across different tests:\n\n\t•\tGPQA (Graduate-level reasoning): 81 → 71\n\t•\tAIME2025 (Math competition problems): 92 → 81\n\t•\tLiveCodeBench v6 (Code generation and debugging): 74 → 56\n\t•\tArena-Hard v2 (General problem-solving): 80 → 62\n\nEven the new instruct version is way better than the old non-thinking one. Looks like they’ve really boosted reasoning and coding skills here.\n\nWhat do you think is driving this jump, better training, bigger data, or new techniques?",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "New Qwen3-235B update is crushing old models in benchmarks",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "News"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 81,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m8w9ah",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.93,
            "author_flair_background_color": null,
            "ups": 127,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_c705ri9b",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "News",
            "can_mod_post": false,
            "score": 127,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/wQ7SbNTBzIdOQb6lfJFHU10NFUkitTQk5yMGuXDJ-EY.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753441629,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Check out this chart comparing the latest Qwen3-235B-A22B-2507 models (Instruct and Thinking) to the older versions. The improvements are huge across different tests:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;• GPQA (Graduate-level reasoning): 81 → 71\n• AIME2025 (Math competition problems): 92 → 81\n• LiveCodeBench v6 (Code generation and debugging): 74 → 56\n• Arena-Hard v2 (General problem-solving): 80 → 62\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Even the new instruct version is way better than the old non-thinking one. Looks like they’ve really boosted reasoning and coding skills here.&lt;/p&gt;\n\n&lt;p&gt;What do you think is driving this jump, better training, bigger data, or new techniques?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/q009687760ff1.jpeg",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/q009687760ff1.jpeg?auto=webp&amp;s=b2eff0f0d944d9f3cc3dd7822d8f074bf89032b7",
                    "width": 2379,
                    "height": 1392
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/q009687760ff1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f76378abbbe79bad791d59ab511364ecf839f4ba",
                      "width": 108,
                      "height": 63
                    },
                    {
                      "url": "https://preview.redd.it/q009687760ff1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a7d7562fa1030bd11fb35ae20f3f153be32261ae",
                      "width": 216,
                      "height": 126
                    },
                    {
                      "url": "https://preview.redd.it/q009687760ff1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=dff32d54f41f3760a510fcbf21e705869a748449",
                      "width": 320,
                      "height": 187
                    },
                    {
                      "url": "https://preview.redd.it/q009687760ff1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ee6d42068b310b231eceef2e74d8ae35c50e819e",
                      "width": 640,
                      "height": 374
                    },
                    {
                      "url": "https://preview.redd.it/q009687760ff1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d7c3a37e2d1bba48fd4f97b28bd78fe7580bb2ca",
                      "width": 960,
                      "height": 561
                    },
                    {
                      "url": "https://preview.redd.it/q009687760ff1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8cfaba909996daa45a067d35347b915f94c15843",
                      "width": 1080,
                      "height": 631
                    }
                  ],
                  "variants": {},
                  "id": "5z0PiohPQ5P8oWxfKaPaT1JALPktWest18Z3iN05GrQ"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#cc3600",
            "id": "1m8w9ah",
            "is_robot_indexable": true,
            "num_duplicates": 1,
            "report_reasons": null,
            "author": "ResearchCrafty1804",
            "discussion_type": null,
            "num_comments": 15,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/",
            "stickied": false,
            "url": "https://i.redd.it/q009687760ff1.jpeg",
            "subreddit_subscribers": 504974,
            "created_utc": 1753441629,
            "num_crossposts": 1,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n54gdno",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "joninco",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n53yyjz",
                                "score": 6,
                                "author_fullname": "t2_8e8y0",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "Using [chat.qwen.ai](http://chat.qwen.ai) with the thinking model (not coding). If they release a thinking coding model, it's going to be SOTA.\n\n# Evaluation of New Model's Coding Response\n\n**Overall Grade: A+ (96/100)**",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n54gdno",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Using &lt;a href=\"http://chat.qwen.ai\"&gt;chat.qwen.ai&lt;/a&gt; with the thinking model (not coding). If they release a thinking coding model, it&amp;#39;s going to be SOTA.&lt;/p&gt;\n\n&lt;h1&gt;Evaluation of New Model&amp;#39;s Coding Response&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Overall Grade: A+ (96/100)&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m8w9ah",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n54gdno/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753464968,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753464968,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 6
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n53yyjz",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": false,
                      "author": "joninco",
                      "can_mod_post": false,
                      "created_utc": 1753460116,
                      "send_replies": true,
                      "parent_id": "t1_n52grjx",
                      "score": 4,
                      "author_fullname": "t2_8e8y0",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I asked Sonnet thinking to generate 2 non-coding prompts to test \"thinking\" models. It judged the 2 responses from the unsloth Q2 quant higher than Gemini 2.5 PRO responses. For fun I did ask a coding prompt (even though this isn't Qwen coder) and Gemini scored higher, but only slightly. That's wild.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n53yyjz",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I asked Sonnet thinking to generate 2 non-coding prompts to test &amp;quot;thinking&amp;quot; models. It judged the 2 responses from the unsloth Q2 quant higher than Gemini 2.5 PRO responses. For fun I did ask a coding prompt (even though this isn&amp;#39;t Qwen coder) and Gemini scored higher, but only slightly. That&amp;#39;s wild.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8w9ah",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n53yyjz/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753460116,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 4
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n52grjx",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Dr_Me_123",
            "can_mod_post": false,
            "created_utc": 1753443064,
            "send_replies": true,
            "parent_id": "t3_1m8w9ah",
            "score": 29,
            "author_fullname": "t2_59yau29b",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Qwen3-235B-2507 has definitely made significant progress. It feels quite similar to Gemini Pro.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52grjx",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Qwen3-235B-2507 has definitely made significant progress. It feels quite similar to Gemini Pro.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n52grjx/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753443064,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8w9ah",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 29
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": {
                                  "kind": "Listing",
                                  "data": {
                                    "after": null,
                                    "dist": null,
                                    "modhash": "",
                                    "geo_filter": "",
                                    "children": [
                                      {
                                        "kind": "t1",
                                        "data": {
                                          "subreddit_id": "t5_81eyvm",
                                          "approved_at_utc": null,
                                          "author_is_blocked": false,
                                          "comment_type": null,
                                          "awarders": [],
                                          "mod_reason_by": null,
                                          "banned_by": null,
                                          "author_flair_type": "text",
                                          "total_awards_received": 0,
                                          "subreddit": "LocalLLaMA",
                                          "author_flair_template_id": null,
                                          "likes": null,
                                          "replies": "",
                                          "user_reports": [],
                                          "saved": false,
                                          "id": "n56jfws",
                                          "banned_at_utc": null,
                                          "mod_reason_title": null,
                                          "gilded": 0,
                                          "archived": false,
                                          "collapsed_reason_code": null,
                                          "no_follow": true,
                                          "author": "noeda",
                                          "can_mod_post": false,
                                          "send_replies": true,
                                          "parent_id": "t1_n541k2g",
                                          "score": 1,
                                          "author_fullname": "t2_9oskj",
                                          "removal_reason": null,
                                          "approved_by": null,
                                          "mod_note": null,
                                          "all_awardings": [],
                                          "collapsed": false,
                                          "body": "I got one question since you are a Mac user with &gt;100GB VRAM, some context:\n\nI once made this hack for myself to make large models behave more nicely on Macs: (I got 192GB Mac Studio and DeepSeek was problematic): https://github.com/Noeda/llama.cpp/commit/4abcd560da555d03c562c3a446c0df84b3a694d6 (it says commit made week ago but I made the code I think somewhere early this year; had force-pushed it recently to rebase on latest code)\n\nThe hack is about letting llama.cpp evict memory allocated for Metal. Normally it allocates \"wired\" memory which won't evict itself under memory pressure. I had to change how buffers are allocated to make it work better (instead of a few big big buffers, I made it allocate lots of small buffers). IIRC the memory does not count as wired memory when you do this.\n\nI rarely use the hack anymore, it was originally made to stop my Mac Studio from completely locking up if I tried to load a model too large, and I was trying to get DeepSeek model running on my Mac. The hack does work, but, you know, it's a hack and I'm not convinced the explanation in the commit is actually accurate. I did not go back to try verify the claims there to say confidently.\n\nBut my question here is: does this sound like something useful to you? I have not bothered to go back to this code to clean it up for general inclusion in llama.cpp because I thought it was too niche to my own use case.\n\nI'm thinking the hack lets you load up models that are bigger than your RAM, allocate 100% to GPU, and it would know to swap in and out (meaning slow, but it would work, that part I've tested). But your use case maybe is a little different than mine: the model does actually fit in RAM, but maybe if you leave it on background for a long time, the memory can be reclaimed for other stuff, and only when you actually invoke the LLM, it would come back. Maybe. Wondering if this would result in more convenient computer use, and if it gives some motivation to clean up that thing.",
                                          "edited": false,
                                          "top_awarded_type": null,
                                          "author_flair_css_class": null,
                                          "name": "t1_n56jfws",
                                          "is_submitter": false,
                                          "downs": 0,
                                          "author_flair_richtext": [],
                                          "author_patreon_flair": false,
                                          "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I got one question since you are a Mac user with &amp;gt;100GB VRAM, some context:&lt;/p&gt;\n\n&lt;p&gt;I once made this hack for myself to make large models behave more nicely on Macs: (I got 192GB Mac Studio and DeepSeek was problematic): &lt;a href=\"https://github.com/Noeda/llama.cpp/commit/4abcd560da555d03c562c3a446c0df84b3a694d6\"&gt;https://github.com/Noeda/llama.cpp/commit/4abcd560da555d03c562c3a446c0df84b3a694d6&lt;/a&gt; (it says commit made week ago but I made the code I think somewhere early this year; had force-pushed it recently to rebase on latest code)&lt;/p&gt;\n\n&lt;p&gt;The hack is about letting llama.cpp evict memory allocated for Metal. Normally it allocates &amp;quot;wired&amp;quot; memory which won&amp;#39;t evict itself under memory pressure. I had to change how buffers are allocated to make it work better (instead of a few big big buffers, I made it allocate lots of small buffers). IIRC the memory does not count as wired memory when you do this.&lt;/p&gt;\n\n&lt;p&gt;I rarely use the hack anymore, it was originally made to stop my Mac Studio from completely locking up if I tried to load a model too large, and I was trying to get DeepSeek model running on my Mac. The hack does work, but, you know, it&amp;#39;s a hack and I&amp;#39;m not convinced the explanation in the commit is actually accurate. I did not go back to try verify the claims there to say confidently.&lt;/p&gt;\n\n&lt;p&gt;But my question here is: does this sound like something useful to you? I have not bothered to go back to this code to clean it up for general inclusion in llama.cpp because I thought it was too niche to my own use case.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking the hack lets you load up models that are bigger than your RAM, allocate 100% to GPU, and it would know to swap in and out (meaning slow, but it would work, that part I&amp;#39;ve tested). But your use case maybe is a little different than mine: the model does actually fit in RAM, but maybe if you leave it on background for a long time, the memory can be reclaimed for other stuff, and only when you actually invoke the LLM, it would come back. Maybe. Wondering if this would result in more convenient computer use, and if it gives some motivation to clean up that thing.&lt;/p&gt;\n&lt;/div&gt;",
                                          "gildings": {},
                                          "collapsed_reason": null,
                                          "distinguished": null,
                                          "associated_award": null,
                                          "stickied": false,
                                          "author_premium": false,
                                          "can_gild": false,
                                          "link_id": "t3_1m8w9ah",
                                          "unrepliable_reason": null,
                                          "author_flair_text_color": null,
                                          "score_hidden": false,
                                          "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n56jfws/",
                                          "subreddit_type": "public",
                                          "locked": false,
                                          "report_reasons": null,
                                          "created": 1753487944,
                                          "author_flair_text": null,
                                          "treatment_tags": [],
                                          "created_utc": 1753487944,
                                          "subreddit_name_prefixed": "r/LocalLLaMA",
                                          "controversiality": 0,
                                          "depth": 3,
                                          "author_flair_background_color": null,
                                          "collapsed_because_crowd_control": null,
                                          "mod_reports": [],
                                          "num_reports": null,
                                          "ups": 1
                                        }
                                      }
                                    ],
                                    "before": null
                                  }
                                },
                                "user_reports": [],
                                "saved": false,
                                "id": "n541k2g",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": false,
                                "author": "lakySK",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n53nz24",
                                "score": 4,
                                "author_fullname": "t2_y9y2q",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "For now, I’ve set the max GPU allocation to 120gb and fully offloaded the model and filled up to 16k context and it worked (though slowed down the generation to &lt;5 t/s). \n\nFrom what I can see, the model itself uses about 100gb, so that leaves me with around 20gb for context and 8gb for the OS to work with the rest of the stuff going on. In theory sounds doable. In practice, I’m yet to push it to the limits and properly test. \n\nIs there something in particular you’re thinking could cause issues with this setup?",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n541k2g",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For now, I’ve set the max GPU allocation to 120gb and fully offloaded the model and filled up to 16k context and it worked (though slowed down the generation to &amp;lt;5 t/s). &lt;/p&gt;\n\n&lt;p&gt;From what I can see, the model itself uses about 100gb, so that leaves me with around 20gb for context and 8gb for the OS to work with the rest of the stuff going on. In theory sounds doable. In practice, I’m yet to push it to the limits and properly test. &lt;/p&gt;\n\n&lt;p&gt;Is there something in particular you’re thinking could cause issues with this setup?&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m8w9ah",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n541k2g/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753460852,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753460852,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 4
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n53nz24",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "ResearchCrafty1804",
                      "can_mod_post": false,
                      "created_utc": 1753457068,
                      "send_replies": true,
                      "parent_id": "t1_n53hp6v",
                      "score": 1,
                      "author_fullname": "t2_c705ri9b",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Running q3 leaves enough room of other apps on your 128gb ram Mac? There is also q2 unsloth dynamic quant, if you want to try",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n53nz24",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Running q3 leaves enough room of other apps on your 128gb ram Mac? There is also q2 unsloth dynamic quant, if you want to try&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8w9ah",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n53nz24/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753457068,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n53hp6v",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "lakySK",
            "can_mod_post": false,
            "created_utc": 1753455316,
            "send_replies": true,
            "parent_id": "t3_1m8w9ah",
            "score": 11,
            "author_fullname": "t2_y9y2q",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I’ve just tried the instruct (non-thinking) version in the unsloth dynamic q3_k_xl version and it surprised me very nicely so far when answering my questions. Feels like a good amount of detail, well-structured, tolerable amount of hallucination. \n\nIf it keeps going like this, it might be the first local model I’ll use regularly on the 128gb Mac. Especially once I hook it up with some tool calling and web search. \n\nIt gets quite slow once you have 10k+ tokens in your context (5 t/s while 20t/s when no context). ",
            "edited": 1753483588,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n53hp6v",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I’ve just tried the instruct (non-thinking) version in the unsloth dynamic q3_k_xl version and it surprised me very nicely so far when answering my questions. Feels like a good amount of detail, well-structured, tolerable amount of hallucination. &lt;/p&gt;\n\n&lt;p&gt;If it keeps going like this, it might be the first local model I’ll use regularly on the 128gb Mac. Especially once I hook it up with some tool calling and web search. &lt;/p&gt;\n\n&lt;p&gt;It gets quite slow once you have 10k+ tokens in your context (5 t/s while 20t/s when no context). &lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n53hp6v/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753455316,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8w9ah",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 11
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n5327yb",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Salty-Garage7777",
            "can_mod_post": false,
            "created_utc": 1753450755,
            "send_replies": true,
            "parent_id": "t3_1m8w9ah",
            "score": 6,
            "author_fullname": "t2_14m2ycs468",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Are they planning to add thinking to the 480B coder? That would be really something!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n5327yb",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Are they planning to add thinking to the 480B coder? That would be really something!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n5327yb/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753450755,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8w9ah",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n59e31l",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "Pvt_Twinkietoes",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n59cnqb",
                                "score": 1,
                                "author_fullname": "t2_3k9qfjsr",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "My test case was more for generation from scratch, maybe that's why.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n59e31l",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My test case was more for generation from scratch, maybe that&amp;#39;s why.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m8w9ah",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n59e31l/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753535785,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753535785,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n59cnqb",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Aldarund",
                      "can_mod_post": false,
                      "created_utc": 1753535250,
                      "send_replies": true,
                      "parent_id": "t1_n52ia8p",
                      "score": 2,
                      "author_fullname": "t2_bu5xy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Idk, I tried it on re word scenario and its stupid. Feeded it list of changes from one library version to another and asked to check code against it. It found zero actual issues and instead changed correct usage to.incorrect",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n59cnqb",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Idk, I tried it on re word scenario and its stupid. Feeded it list of changes from one library version to another and asked to check code against it. It found zero actual issues and instead changed correct usage to.incorrect&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8w9ah",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n59cnqb/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753535250,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n52ia8p",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "Pvt_Twinkietoes",
            "can_mod_post": false,
            "created_utc": 1753443706,
            "send_replies": true,
            "parent_id": "t3_1m8w9ah",
            "score": 6,
            "author_fullname": "t2_3k9qfjsr",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I have just tried coder 480B. It's fast, and performs really well.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n52ia8p",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have just tried coder 480B. It&amp;#39;s fast, and performs really well.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n52ia8p/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753443706,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8w9ah",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 6
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n53qy6q",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "nore_se_kra",
            "can_mod_post": false,
            "created_utc": 1753457885,
            "send_replies": true,
            "parent_id": "t3_1m8w9ah",
            "score": 1,
            "author_fullname": "t2_1bpvzzmckh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "The arena bench for non thinking is impressive!",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n53qy6q",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The arena bench for non thinking is impressive!&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n53qy6q/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753457885,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8w9ah",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": {
                        "kind": "Listing",
                        "data": {
                          "after": null,
                          "dist": null,
                          "modhash": "",
                          "geo_filter": "",
                          "children": [
                            {
                              "kind": "t1",
                              "data": {
                                "subreddit_id": "t5_81eyvm",
                                "approved_at_utc": null,
                                "author_is_blocked": false,
                                "comment_type": null,
                                "awarders": [],
                                "mod_reason_by": null,
                                "banned_by": null,
                                "author_flair_type": "text",
                                "total_awards_received": 0,
                                "subreddit": "LocalLLaMA",
                                "author_flair_template_id": null,
                                "likes": null,
                                "replies": "",
                                "user_reports": [],
                                "saved": false,
                                "id": "n599j32",
                                "banned_at_utc": null,
                                "mod_reason_title": null,
                                "gilded": 0,
                                "archived": false,
                                "collapsed_reason_code": null,
                                "no_follow": true,
                                "author": "charlesrwest0",
                                "can_mod_post": false,
                                "send_replies": true,
                                "parent_id": "t1_n55bnsk",
                                "score": 1,
                                "author_fullname": "t2_usue4kmrv",
                                "removal_reason": null,
                                "approved_by": null,
                                "mod_note": null,
                                "all_awardings": [],
                                "body": "My initial trial point to... Yeah. It's much better than the last version of the model.",
                                "edited": false,
                                "top_awarded_type": null,
                                "downs": 0,
                                "author_flair_css_class": null,
                                "name": "t1_n599j32",
                                "is_submitter": false,
                                "collapsed": false,
                                "author_flair_richtext": [],
                                "author_patreon_flair": false,
                                "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My initial trial point to... Yeah. It&amp;#39;s much better than the last version of the model.&lt;/p&gt;\n&lt;/div&gt;",
                                "gildings": {},
                                "collapsed_reason": null,
                                "distinguished": null,
                                "associated_award": null,
                                "stickied": false,
                                "author_premium": false,
                                "can_gild": false,
                                "link_id": "t3_1m8w9ah",
                                "unrepliable_reason": null,
                                "author_flair_text_color": null,
                                "score_hidden": false,
                                "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n599j32/",
                                "subreddit_type": "public",
                                "locked": false,
                                "report_reasons": null,
                                "created": 1753534056,
                                "author_flair_text": null,
                                "treatment_tags": [],
                                "created_utc": 1753534056,
                                "subreddit_name_prefixed": "r/LocalLLaMA",
                                "controversiality": 0,
                                "depth": 2,
                                "author_flair_background_color": null,
                                "collapsed_because_crowd_control": null,
                                "mod_reports": [],
                                "num_reports": null,
                                "ups": 1
                              }
                            }
                          ],
                          "before": null
                        }
                      },
                      "user_reports": [],
                      "saved": false,
                      "id": "n55bnsk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Equivalent-Word-7691",
                      "can_mod_post": false,
                      "created_utc": 1753474035,
                      "send_replies": true,
                      "parent_id": "t1_n55aj2o",
                      "score": 2,
                      "author_fullname": "t2_30nt1tdo",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "Yeah it's always about code but what about creative writing? Another BEEF I have with Qwen it generate too few tokens per queries when It try to write,like maybe 800 \n\nDuh soo frustrating, Gemini can generate even 5k with flash",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n55bnsk",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah it&amp;#39;s always about code but what about creative writing? Another BEEF I have with Qwen it generate too few tokens per queries when It try to write,like maybe 800 &lt;/p&gt;\n\n&lt;p&gt;Duh soo frustrating, Gemini can generate even 5k with flash&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8w9ah",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n55bnsk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753474035,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n55aj2o",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "charlesrwest0",
            "can_mod_post": false,
            "created_utc": 1753473700,
            "send_replies": true,
            "parent_id": "t3_1m8w9ah",
            "score": 1,
            "author_fullname": "t2_usue4kmrv",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Any good for creative writing?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n55aj2o",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Any good for creative writing?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8w9ah/new_qwen3235b_update_is_crushing_old_models_in/n55aj2o/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753473700,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8w9ah",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 1
          }
        }
      ],
      "before": null
    }
  }
]