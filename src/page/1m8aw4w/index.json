[
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": 1,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t3",
          "data": {
            "approved_at_utc": null,
            "subreddit": "LocalLLaMA",
            "selftext": "https://www.velocitymicro.com/blog/amd-radeon-ai-pro-r9700/\n\nHey y'all. The R9700 was supposedly launched yesterday, but I couldn't find any reviews or listings online for it, outside of one company that had a \"request a quote\" button instead of an actual price. So I kept digging and found Velocity Micro's blog post, which is from yesterday. I've never heard of them before, but they appear to be a well-established System Integrator/boutique PC builder.\n\nIn their blog post, they compared the RTX 5080 and the R9700's AI Inference performance using Phi 3.5 MoE Q4, Mistral Small 3.1 24B Instruct 2503 Q8, Qwen 3 32B Q6, and DeepSeek R1 Distill Qwen 32B Q6. The results are shown in the screenshot above.\n\nNow, I'll freely admit I've been an AMD fan for a long time (RX590 with ROCm 6.3 says hi), but those performance figures are **heavily** biased towards the R9700. There are two big, glaring issues here:\n\n1. No concrete tokens per second performance figures were presented, only relative performance uplift in percentage.\n\n2. ALL of the models used in the benchmark don't fit within the RTX 5080's 16GB VRAM buffer.\n\nThat completely defeats the point of the benchmark lol. None of those models fully fit within the 5080's VRAM, so God knows how many layers were offloaded to the CPU.\n\nThey don't mention the price in their blog post, but I checked the custom build configuration page of their ProMagix HD150 workstation, and the R9700 adds $1500 to the build cost, whereas the 5080 adds $1710. So I suppose there's an argument to be made about comparing the two, considering how close in price they are, but... the models chosen reek of dishonesty.\n\nOh, and as an aside, that's not the only thing the post reeks of. It reeks of LLM-isms, like this one passage right beneath the benchmarks table: \"The takeaway? For professionals running large prompts or full-sized models locally, the Radeon™ AI PRO R9700 isn’t just competitive—it’s transformative,\" you know, with the classic \"It isn't just X, it's Y!\" But maaaybe I'm being just overly critical in this era of AI slop. idk lol.",
            "user_reports": [],
            "saved": false,
            "mod_reason_title": null,
            "gilded": 0,
            "clicked": false,
            "title": "Velocity Micro Published (Faulty?) LLM Benchmarks for the Radeon AI PRO R9700 and Lists it for $1500 in Their Build Configuration Page",
            "link_flair_richtext": [
              {
                "e": "text",
                "t": "News"
              }
            ],
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "hidden": false,
            "pwls": 6,
            "link_flair_css_class": "",
            "downs": 0,
            "thumbnail_height": 140,
            "top_awarded_type": null,
            "hide_score": false,
            "name": "t3_1m8aw4w",
            "quarantine": false,
            "link_flair_text_color": "light",
            "upvote_ratio": 0.8,
            "author_flair_background_color": null,
            "ups": 12,
            "total_awards_received": 0,
            "media_embed": {},
            "thumbnail_width": 140,
            "author_flair_template_id": null,
            "is_original_content": false,
            "author_fullname": "t2_gp8z8",
            "secure_media": null,
            "is_reddit_media_domain": true,
            "is_meta": false,
            "category": null,
            "secure_media_embed": {},
            "link_flair_text": "News",
            "can_mod_post": false,
            "score": 12,
            "approved_by": null,
            "is_created_from_ads_ui": false,
            "author_premium": false,
            "thumbnail": "https://b.thumbs.redditmedia.com/99Iko3whTqVLFl_kwwdJwnnzIy17oQSxbbdpbYBHMLs.jpg",
            "edited": false,
            "author_flair_css_class": null,
            "author_flair_richtext": [],
            "gildings": {},
            "post_hint": "image",
            "content_categories": null,
            "is_self": false,
            "subreddit_type": "public",
            "created": 1753378626,
            "link_flair_type": "richtext",
            "wls": 6,
            "removed_by_category": null,
            "banned_by": null,
            "author_flair_type": "text",
            "domain": "i.redd.it",
            "allow_live_comments": false,
            "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.velocitymicro.com/blog/amd-radeon-ai-pro-r9700/\"&gt;https://www.velocitymicro.com/blog/amd-radeon-ai-pro-r9700/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hey y&amp;#39;all. The R9700 was supposedly launched yesterday, but I couldn&amp;#39;t find any reviews or listings online for it, outside of one company that had a &amp;quot;request a quote&amp;quot; button instead of an actual price. So I kept digging and found Velocity Micro&amp;#39;s blog post, which is from yesterday. I&amp;#39;ve never heard of them before, but they appear to be a well-established System Integrator/boutique PC builder.&lt;/p&gt;\n\n&lt;p&gt;In their blog post, they compared the RTX 5080 and the R9700&amp;#39;s AI Inference performance using Phi 3.5 MoE Q4, Mistral Small 3.1 24B Instruct 2503 Q8, Qwen 3 32B Q6, and DeepSeek R1 Distill Qwen 32B Q6. The results are shown in the screenshot above.&lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;ll freely admit I&amp;#39;ve been an AMD fan for a long time (RX590 with ROCm 6.3 says hi), but those performance figures are &lt;strong&gt;heavily&lt;/strong&gt; biased towards the R9700. There are two big, glaring issues here:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;No concrete tokens per second performance figures were presented, only relative performance uplift in percentage.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;ALL of the models used in the benchmark don&amp;#39;t fit within the RTX 5080&amp;#39;s 16GB VRAM buffer.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;That completely defeats the point of the benchmark lol. None of those models fully fit within the 5080&amp;#39;s VRAM, so God knows how many layers were offloaded to the CPU.&lt;/p&gt;\n\n&lt;p&gt;They don&amp;#39;t mention the price in their blog post, but I checked the custom build configuration page of their ProMagix HD150 workstation, and the R9700 adds $1500 to the build cost, whereas the 5080 adds $1710. So I suppose there&amp;#39;s an argument to be made about comparing the two, considering how close in price they are, but... the models chosen reek of dishonesty.&lt;/p&gt;\n\n&lt;p&gt;Oh, and as an aside, that&amp;#39;s not the only thing the post reeks of. It reeks of LLM-isms, like this one passage right beneath the benchmarks table: &amp;quot;The takeaway? For professionals running large prompts or full-sized models locally, the Radeon™ AI PRO R9700 isn’t just competitive—it’s transformative,&amp;quot; you know, with the classic &amp;quot;It isn&amp;#39;t just X, it&amp;#39;s Y!&amp;quot; But maaaybe I&amp;#39;m being just overly critical in this era of AI slop. idk lol.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;",
            "likes": null,
            "suggested_sort": null,
            "banned_at_utc": null,
            "url_overridden_by_dest": "https://i.redd.it/hb4sc99vyuef1.jpeg",
            "view_count": null,
            "archived": false,
            "no_follow": false,
            "is_crosspostable": false,
            "pinned": false,
            "over_18": false,
            "preview": {
              "images": [
                {
                  "source": {
                    "url": "https://preview.redd.it/hb4sc99vyuef1.jpeg?auto=webp&amp;s=96302dd6cdcb2b411601841c937d0121fe96dee2",
                    "width": 1080,
                    "height": 2340
                  },
                  "resolutions": [
                    {
                      "url": "https://preview.redd.it/hb4sc99vyuef1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=25e7447d2948ff3ba829b2fe4b668ffa16126aca",
                      "width": 108,
                      "height": 216
                    },
                    {
                      "url": "https://preview.redd.it/hb4sc99vyuef1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2225e2c5840b0bf1a9f78c11b1ad8a32c61bd1ed",
                      "width": 216,
                      "height": 432
                    },
                    {
                      "url": "https://preview.redd.it/hb4sc99vyuef1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9b15cc449c73707c71ff19936883e8c41b86d020",
                      "width": 320,
                      "height": 640
                    },
                    {
                      "url": "https://preview.redd.it/hb4sc99vyuef1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f63a18c6ad86b8d63e1b163fd5dd0ba53844277f",
                      "width": 640,
                      "height": 1280
                    },
                    {
                      "url": "https://preview.redd.it/hb4sc99vyuef1.jpeg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9fc78e96a489a0d8cdec3ba2b56d666ce5f0593e",
                      "width": 960,
                      "height": 1920
                    },
                    {
                      "url": "https://preview.redd.it/hb4sc99vyuef1.jpeg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b575f5d80433824a8e1481ce8eb3f26715a44855",
                      "width": 1080,
                      "height": 2160
                    }
                  ],
                  "variants": {},
                  "id": "ua2gbHgHzn0rn80rVFCnRr-uUof35t7ZglKUGHqi2QE"
                }
              ],
              "enabled": true
            },
            "all_awardings": [],
            "awarders": [],
            "media_only": false,
            "link_flair_template_id": "f8cc0dfe-c1eb-11ed-8d79-72bc34fff7d9",
            "can_gild": false,
            "spoiler": false,
            "locked": false,
            "author_flair_text": null,
            "treatment_tags": [],
            "visited": false,
            "removed_by": null,
            "mod_note": null,
            "distinguished": null,
            "subreddit_id": "t5_81eyvm",
            "author_is_blocked": false,
            "mod_reason_by": null,
            "num_reports": null,
            "removal_reason": null,
            "link_flair_background_color": "#cc3600",
            "id": "1m8aw4w",
            "is_robot_indexable": true,
            "num_duplicates": 2,
            "report_reasons": null,
            "author": "Kamal965",
            "discussion_type": null,
            "num_comments": 8,
            "send_replies": true,
            "media": null,
            "contest_mode": false,
            "author_patreon_flair": false,
            "author_flair_text_color": null,
            "permalink": "/r/LocalLLaMA/comments/1m8aw4w/velocity_micro_published_faulty_llm_benchmarks/",
            "stickied": false,
            "url": "https://i.redd.it/hb4sc99vyuef1.jpeg",
            "subreddit_subscribers": 504023,
            "created_utc": 1753378626,
            "num_crossposts": 2,
            "mod_reports": [],
            "is_video": false
          }
        }
      ],
      "before": null
    }
  },
  {
    "kind": "Listing",
    "data": {
      "after": null,
      "dist": null,
      "modhash": "",
      "geo_filter": "",
      "children": [
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": {
              "kind": "Listing",
              "data": {
                "after": null,
                "dist": null,
                "modhash": "",
                "geo_filter": "",
                "children": [
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4y8tug",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "eloquentemu",
                      "can_mod_post": false,
                      "created_utc": 1753383349,
                      "send_replies": true,
                      "parent_id": "t1_n4xx3ca",
                      "score": 2,
                      "author_fullname": "t2_lpdsy",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I also will mention that the compute spec is quite good on paper at least.  So while bandwidth is so-so this could potentially outperform a 4090 for something like stable diffusion or other compute heavy workloads.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4y8tug",
                      "is_submitter": false,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I also will mention that the compute spec is quite good on paper at least.  So while bandwidth is so-so this could potentially outperform a 4090 for something like stable diffusion or other compute heavy workloads.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8aw4w",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8aw4w/velocity_micro_published_faulty_llm_benchmarks/n4y8tug/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753383349,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 2
                    }
                  },
                  {
                    "kind": "t1",
                    "data": {
                      "subreddit_id": "t5_81eyvm",
                      "approved_at_utc": null,
                      "author_is_blocked": false,
                      "comment_type": null,
                      "awarders": [],
                      "mod_reason_by": null,
                      "banned_by": null,
                      "author_flair_type": "text",
                      "total_awards_received": 0,
                      "subreddit": "LocalLLaMA",
                      "author_flair_template_id": null,
                      "likes": null,
                      "replies": "",
                      "user_reports": [],
                      "saved": false,
                      "id": "n4yz1yk",
                      "banned_at_utc": null,
                      "mod_reason_title": null,
                      "gilded": 0,
                      "archived": false,
                      "collapsed_reason_code": null,
                      "no_follow": true,
                      "author": "Kamal965",
                      "can_mod_post": false,
                      "created_utc": 1753390713,
                      "send_replies": true,
                      "parent_id": "t1_n4xx3ca",
                      "score": 1,
                      "author_fullname": "t2_gp8z8",
                      "removal_reason": null,
                      "approved_by": null,
                      "mod_note": null,
                      "all_awardings": [],
                      "body": "I mean, yeah, of course companies do shady benchmarks all the time. We see that often enough with the AI models being benchmaxxed after all. It's just that these guys are system integrators, right, and they sell both AMD and Nvidia cards. Their previous blog post is about the launch of the RTX PRO 6000. So why BS these benchmarks then? They more than likely sell 10x more Nvidia cards than AMD, at a minimum.",
                      "edited": false,
                      "top_awarded_type": null,
                      "author_flair_css_class": null,
                      "name": "t1_n4yz1yk",
                      "is_submitter": true,
                      "downs": 0,
                      "author_flair_richtext": [],
                      "author_patreon_flair": false,
                      "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I mean, yeah, of course companies do shady benchmarks all the time. We see that often enough with the AI models being benchmaxxed after all. It&amp;#39;s just that these guys are system integrators, right, and they sell both AMD and Nvidia cards. Their previous blog post is about the launch of the RTX PRO 6000. So why BS these benchmarks then? They more than likely sell 10x more Nvidia cards than AMD, at a minimum.&lt;/p&gt;\n&lt;/div&gt;",
                      "gildings": {},
                      "collapsed_reason": null,
                      "distinguished": null,
                      "associated_award": null,
                      "stickied": false,
                      "author_premium": false,
                      "can_gild": false,
                      "link_id": "t3_1m8aw4w",
                      "unrepliable_reason": null,
                      "author_flair_text_color": null,
                      "score_hidden": false,
                      "permalink": "/r/LocalLLaMA/comments/1m8aw4w/velocity_micro_published_faulty_llm_benchmarks/n4yz1yk/",
                      "subreddit_type": "public",
                      "locked": false,
                      "report_reasons": null,
                      "created": 1753390713,
                      "author_flair_text": null,
                      "treatment_tags": [],
                      "collapsed": false,
                      "subreddit_name_prefixed": "r/LocalLLaMA",
                      "controversiality": 0,
                      "depth": 1,
                      "author_flair_background_color": null,
                      "collapsed_because_crowd_control": null,
                      "mod_reports": [],
                      "num_reports": null,
                      "ups": 1
                    }
                  }
                ],
                "before": null
              }
            },
            "user_reports": [],
            "saved": false,
            "id": "n4xx3ca",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": false,
            "author": "qualverse",
            "can_mod_post": false,
            "created_utc": 1753380008,
            "send_replies": true,
            "parent_id": "t3_1m8aw4w",
            "score": 12,
            "author_fullname": "t2_kqw73",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Companies have been doing this for a while. It's maybe misleading, but I wouldn't call it faulty. The main selling point of the R9700 is its 32GB of VRAM capacity and that's pretty much the entire reason to buy one, so I'm not shocked they're trying to show that off.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4xx3ca",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Companies have been doing this for a while. It&amp;#39;s maybe misleading, but I wouldn&amp;#39;t call it faulty. The main selling point of the R9700 is its 32GB of VRAM capacity and that&amp;#39;s pretty much the entire reason to buy one, so I&amp;#39;m not shocked they&amp;#39;re trying to show that off.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8aw4w/velocity_micro_published_faulty_llm_benchmarks/n4xx3ca/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753380008,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8aw4w",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 12
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4y0s2y",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "LagOps91",
            "can_mod_post": false,
            "created_utc": 1753381042,
            "send_replies": true,
            "parent_id": "t3_1m8aw4w",
            "score": 3,
            "author_fullname": "t2_3wi6j7vwh",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Yeah it is highly misleading to use quants that don't fit into 16gb vram. just ignore such marketing BS and wait for actual benchmarks.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4y0s2y",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah it is highly misleading to use quants that don&amp;#39;t fit into 16gb vram. just ignore such marketing BS and wait for actual benchmarks.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8aw4w/velocity_micro_published_faulty_llm_benchmarks/n4y0s2y/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753381042,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8aw4w",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4y876m",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Dundell",
            "can_mod_post": false,
            "created_utc": 1753383166,
            "send_replies": true,
            "parent_id": "t3_1m8aw4w",
            "score": 3,
            "author_fullname": "t2_3gl53gi6",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "I haven't heard of Velocity Micro since 2008. Interesting blog ty",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4y876m",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t heard of Velocity Micro since 2008. Interesting blog ty&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8aw4w/velocity_micro_published_faulty_llm_benchmarks/n4y876m/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753383166,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8aw4w",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "richtext",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": "ed89e5c6-72f1-11ee-9954-1697022cd89d",
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4ykhv7",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "No_Afternoon_4260",
            "can_mod_post": false,
            "created_utc": 1753386653,
            "send_replies": true,
            "parent_id": "t3_1m8aw4w",
            "score": 2,
            "author_fullname": "t2_cj9kap4bx",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "Look that amd card runs deepseek 4.5x faster than on a Nvidia card! /s",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4ykhv7",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [
              {
                "e": "text",
                "t": "llama.cpp"
              }
            ],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Look that amd card runs deepseek 4.5x faster than on a Nvidia card! /s&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": "light",
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8aw4w/velocity_micro_published_faulty_llm_benchmarks/n4ykhv7/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753386653,
            "author_flair_text": "llama.cpp",
            "treatment_tags": [],
            "link_id": "t3_1m8aw4w",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": "#bbbdbf",
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4yqe3k",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "Toooooool",
            "can_mod_post": false,
            "created_utc": 1753388288,
            "send_replies": true,
            "parent_id": "t3_1m8aw4w",
            "score": 2,
            "author_fullname": "t2_8llornh4",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "https://preview.redd.it/myw3h2pbrvef1.png?width=1456&amp;format=png&amp;auto=webp&amp;s=86e376d9b02aa9169adaafd7f9d6aa8633d0cee4\n\nso far i've been going by these benchmarks but.. even then.. what's with the jump between 1 and 2 parallel instances? shouldn't it be much more linear?",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4yqe3k",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/myw3h2pbrvef1.png?width=1456&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=86e376d9b02aa9169adaafd7f9d6aa8633d0cee4\"&gt;https://preview.redd.it/myw3h2pbrvef1.png?width=1456&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=86e376d9b02aa9169adaafd7f9d6aa8633d0cee4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;so far i&amp;#39;ve been going by these benchmarks but.. even then.. what&amp;#39;s with the jump between 1 and 2 parallel instances? shouldn&amp;#39;t it be much more linear?&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8aw4w/velocity_micro_published_faulty_llm_benchmarks/n4yqe3k/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753388288,
            "media_metadata": {
              "myw3h2pbrvef1": {
                "status": "valid",
                "e": "Image",
                "m": "image/png",
                "p": [
                  {
                    "y": 60,
                    "x": 108,
                    "u": "https://preview.redd.it/myw3h2pbrvef1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1ad989b241600aab576c23ef46bfc9fcd536de6d"
                  },
                  {
                    "y": 121,
                    "x": 216,
                    "u": "https://preview.redd.it/myw3h2pbrvef1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=148e4750f569519d28e6a7bb45bd75ca5c760246"
                  },
                  {
                    "y": 180,
                    "x": 320,
                    "u": "https://preview.redd.it/myw3h2pbrvef1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=35a622bcf31b00b22f592aa03bc2ab00377042a9"
                  },
                  {
                    "y": 360,
                    "x": 640,
                    "u": "https://preview.redd.it/myw3h2pbrvef1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2d7c58b465f85b3a170ffb85fd8e9ffaa19e910a"
                  },
                  {
                    "y": 540,
                    "x": 960,
                    "u": "https://preview.redd.it/myw3h2pbrvef1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=b606757003d95e3f455528ad9d4d275fc9da1b52"
                  },
                  {
                    "y": 607,
                    "x": 1080,
                    "u": "https://preview.redd.it/myw3h2pbrvef1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dca5512a572170731b7c0c302baf6214d59ba528"
                  }
                ],
                "s": {
                  "y": 819,
                  "x": 1456,
                  "u": "https://preview.redd.it/myw3h2pbrvef1.png?width=1456&amp;format=png&amp;auto=webp&amp;s=86e376d9b02aa9169adaafd7f9d6aa8633d0cee4"
                },
                "id": "myw3h2pbrvef1"
              }
            },
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8aw4w",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 2
          }
        },
        {
          "kind": "t1",
          "data": {
            "subreddit_id": "t5_81eyvm",
            "approved_at_utc": null,
            "author_is_blocked": false,
            "comment_type": null,
            "awarders": [],
            "mod_reason_by": null,
            "banned_by": null,
            "author_flair_type": "text",
            "total_awards_received": 0,
            "subreddit": "LocalLLaMA",
            "author_flair_template_id": null,
            "likes": null,
            "replies": "",
            "user_reports": [],
            "saved": false,
            "id": "n4z8nki",
            "banned_at_utc": null,
            "mod_reason_title": null,
            "gilded": 0,
            "archived": false,
            "collapsed_reason_code": null,
            "no_follow": true,
            "author": "triynizzles1",
            "can_mod_post": false,
            "created_utc": 1753393534,
            "send_replies": true,
            "parent_id": "t3_1m8aw4w",
            "score": 3,
            "author_fullname": "t2_zr0g49ixt",
            "approved_by": null,
            "mod_note": null,
            "all_awardings": [],
            "collapsed": false,
            "body": "It is the same silicon as 9070 xt but with clamshell memory configuration.\n\nShould benchmark the same.\n\nThe results they are showing is probably true but none of the models fit on a 16 GB card so it’s not a good comparison. It does emphasize the capabilities of having more vram though. More VR is a legitimate selling point, but I don’t think it is fairly displayed in these benchmarks.",
            "edited": false,
            "top_awarded_type": null,
            "author_flair_css_class": null,
            "name": "t1_n4z8nki",
            "is_submitter": false,
            "downs": 0,
            "author_flair_richtext": [],
            "author_patreon_flair": false,
            "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is the same silicon as 9070 xt but with clamshell memory configuration.&lt;/p&gt;\n\n&lt;p&gt;Should benchmark the same.&lt;/p&gt;\n\n&lt;p&gt;The results they are showing is probably true but none of the models fit on a 16 GB card so it’s not a good comparison. It does emphasize the capabilities of having more vram though. More VR is a legitimate selling point, but I don’t think it is fairly displayed in these benchmarks.&lt;/p&gt;\n&lt;/div&gt;",
            "removal_reason": null,
            "collapsed_reason": null,
            "distinguished": null,
            "associated_award": null,
            "stickied": false,
            "author_premium": false,
            "can_gild": false,
            "gildings": {},
            "unrepliable_reason": null,
            "author_flair_text_color": null,
            "score_hidden": false,
            "permalink": "/r/LocalLLaMA/comments/1m8aw4w/velocity_micro_published_faulty_llm_benchmarks/n4z8nki/",
            "subreddit_type": "public",
            "locked": false,
            "report_reasons": null,
            "created": 1753393534,
            "author_flair_text": null,
            "treatment_tags": [],
            "link_id": "t3_1m8aw4w",
            "subreddit_name_prefixed": "r/LocalLLaMA",
            "controversiality": 0,
            "depth": 0,
            "author_flair_background_color": null,
            "collapsed_because_crowd_control": null,
            "mod_reports": [],
            "num_reports": null,
            "ups": 3
          }
        }
      ],
      "before": null
    }
  }
]